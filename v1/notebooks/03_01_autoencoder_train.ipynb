{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Autoencoder"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-12-28 12:54:01.605086: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
                        "To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
                        "/home/cataluna84/Workspace-Antigravity/Generative_Deep_Learning/.venv/lib/python3.13/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
                        "  if not hasattr(np, \"object\"):\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "import os\n",
                "sys.path.insert(0, '../../..')\n",
                "sys.path.insert(0, '../..')\n",
                "sys.path.insert(0, '..')\n",
                "\n",
                "import numpy as np\n",
                "import tensorflow as tf\n",
                "import keras\n",
                "import keras.ops as K\n",
                "from keras.optimizers import Adam\n",
                "\n",
                "import wandb\n",
                "from wandb.integration.keras import WandbMetricsLogger\n",
                "\n",
                "from src.utils.loaders import load_mnist\n",
                "from src.models.AE import Autoencoder\n",
                "from utils.wandb_utils import init_wandb\n",
                "from utils.callbacks import LRFinder, get_lr_scheduler, get_early_stopping\n",
                "\n",
                "gpus = tf.config.list_physical_devices('GPU')\n",
                "if gpus:\n",
                "    tf.config.experimental.set_memory_growth(gpus[0], True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Global Configuration\n",
                "BATCH_SIZE = 1024 # Optimized for 8GB VRAM\n",
                "EPOCHS = 200\n",
                "PRINT_EVERY_N_BATCHES = 100\n",
                "INITIAL_EPOCH = 0\n",
                "INPUT_DIM = (28,28,1)\n",
                "Z_DIM = 2\n",
                "OPTIMIZER_NAME = 'adam'\n",
                "DATASET_NAME = 'digits'\n",
                "MODEL_TYPE = 'autoencoder'\n",
                "\n",
                "# Run Params\n",
                "SECTION = 'vae'\n",
                "RUN_ID = '0001'\n",
                "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
                "RUN_FOLDER += '_'.join([RUN_ID, DATASET_NAME])\n",
                "\n",
                "if not os.path.exists(RUN_FOLDER):\n",
                "    os.makedirs(RUN_FOLDER, exist_ok=True)\n",
                "    os.makedirs(os.path.join(RUN_FOLDER, 'viz'))\n",
                "    os.makedirs(os.path.join(RUN_FOLDER, 'images'))\n",
                "    os.makedirs(os.path.join(RUN_FOLDER, 'weights'))\n",
                "\n",
                "MODE =  'build'\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Set parameters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcataluna84\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Tracking run with wandb version 0.23.1"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Run data is saved locally in <code>/home/cataluna84/Workspace-Antigravity/Generative_Deep_Learning/v1/notebooks/wandb/run-20251228_125411-psdz2vb6</code>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Syncing run <strong><a href='https://wandb.ai/cataluna84/generative-deep-learning/runs/psdz2vb6' target=\"_blank\">03_01_autoencoder</a></strong> to <a href='https://wandb.ai/cataluna84/generative-deep-learning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View project at <a href='https://wandb.ai/cataluna84/generative-deep-learning' target=\"_blank\">https://wandb.ai/cataluna84/generative-deep-learning</a>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View run at <a href='https://wandb.ai/cataluna84/generative-deep-learning/runs/psdz2vb6' target=\"_blank\">https://wandb.ai/cataluna84/generative-deep-learning/runs/psdz2vb6</a>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Initialize W&B\n",
                "run = init_wandb(\n",
                "    name=\"03_01_autoencoder\",\n",
                "    project=\"generative-deep-learning\",\n",
                "    config={\n",
                "        \"model\": MODEL_TYPE,\n",
                "        \"dataset\": DATASET_NAME,\n",
                "        \"learning_rate\": \"auto\",\n",
                "        \"batch_size\": BATCH_SIZE,\n",
                "        \"epochs\": EPOCHS,\n",
                "        \"optimizer\": OPTIMIZER_NAME,\n",
                "    }\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load the data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "(x_train, y_train), (x_test, y_test) = load_mnist()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Define the structure of the neural network"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
                        "I0000 00:00:1766926458.086715   32782 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6094 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
                    ]
                }
            ],
            "source": [
                "AE = Autoencoder(\n",
                "    input_dim = (28,28,1)\n",
                "    , encoder_conv_filters = [32,64,64, 64]\n",
                "    , encoder_conv_kernel_size = [3,3,3,3]\n",
                "    , encoder_conv_strides = [1,2,2,1]\n",
                "    , decoder_conv_t_filters = [64,64,32,1]\n",
                "    , decoder_conv_t_kernel_size = [3,3,3,3]\n",
                "    , decoder_conv_t_strides = [1,2,2,1]\n",
                "    , z_dim = 2\n",
                ")\n",
                "\n",
                "if MODE == 'build':\n",
                "    AE.save(RUN_FOLDER)\n",
                "else:\n",
                "    AE.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.weights.h5'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1mModel: \"functional\"\u001b[0m\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
                            "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
                            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
                            "│ encoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ encoder_conv_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ encoder_conv_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ encoder_conv_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ encoder_conv_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ encoder_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,274</span> │\n",
                            "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
                            "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
                            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
                            "│ encoder_input (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ encoder_conv_0 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ encoder_conv_1 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ encoder_conv_2 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m36,928\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ encoder_conv_3 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m36,928\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ encoder_output (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │         \u001b[38;5;34m6,274\u001b[0m │\n",
                            "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">98,946</span> (386.51 KB)\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m98,946\u001b[0m (386.51 KB)\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">98,946</span> (386.51 KB)\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m98,946\u001b[0m (386.51 KB)\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "AE.encoder.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
                            "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
                            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
                            "│ decoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,408</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ decoder_conv_t_0                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
                            "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ decoder_conv_t_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
                            "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ leaky_re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ decoder_conv_t_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │\n",
                            "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ leaky_re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ decoder_conv_t_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">289</span> │\n",
                            "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
                            "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
                            "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
                            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
                            "│ decoder_input (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m)           │         \u001b[38;5;34m9,408\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ decoder_conv_t_0                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m36,928\u001b[0m │\n",
                            "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ decoder_conv_t_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
                            "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ leaky_re_lu_5 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ decoder_conv_t_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m18,464\u001b[0m │\n",
                            "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ leaky_re_lu_6 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ decoder_conv_t_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │           \u001b[38;5;34m289\u001b[0m │\n",
                            "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
                            "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">102,017</span> (398.50 KB)\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m102,017\u001b[0m (398.50 KB)\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">102,017</span> (398.50 KB)\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m102,017\u001b[0m (398.50 KB)\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "AE.decoder.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Train the autoencoder"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-12-28 12:54:29.476994: I external/local_xla/xla/service/service.cc:163] XLA service 0x7f0939028230 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
                        "2025-12-28 12:54:29.477063: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 2070, Compute Capability 7.5\n",
                        "2025-12-28 12:54:29.646764: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
                        "2025-12-28 12:54:30.337738: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91701\n",
                        "2025-12-28 12:54:31.082583: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[1024,32,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[1024,1,28,28]{3,2,1,0}, f32[32,1,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
                        "2025-12-28 12:54:32.097262: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[1024,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[1024,64,7,7]{3,2,1,0}, f32[64,64,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
                        "I0000 00:00:1766926480.366813   32911 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
                        "2025-12-28 12:54:45.454983: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[608,32,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[608,1,28,28]{3,2,1,0}, f32[32,1,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
                        "2025-12-28 12:54:46.085026: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[608,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[608,64,7,7]{3,2,1,0}, f32[64,64,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
                        "/home/cataluna84/Workspace-Antigravity/Generative_Deep_Learning/.venv/lib/python3.13/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
                        "  self._interrupted_warning()\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Optimal Learning Rate (Recommended): 0.000133\n"
                    ]
                },
                {
                    "data": {
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAA5UZJREFUeJzs3XmcTuX/x/HXfc/KmA0zZsa+U9mFsYTIEIpQ5BcyiEilJNlLihJJGxUqEpLKFom+iiglKRRZsoyxD8Ys99zn98dp7pnbLIZZ7pnxfj4e1+M+9znXOedzzn1m+8y1WAzDMBAREREREREREclDVlcHICIiIiIiIiIiNx8lpUREREREREREJM8pKSUiIiIiIiIiInlOSSkREREREREREclzSkqJiIiIiIiIiEieU1JKRERERERERETynJJSIiIiIiIiIiKS55SUEhERERERERGRPKeklIiIiIiIiIiI5DklpURERMSlKlSoQL9+/VwdRoE3f/58LBYLhw4dytfHFBEREUmmpJSIiEghkJw8+Pnnn10dSoFisVicip+fHy1btmTVqlU3fMxFixYxc+bMnAvyP/369UsTb3JZu3Ztjp8vv6hQoQKdOnVydRgudejQISwWC6+++mqm9SpUqOD0XPj4+NCoUSM+/PDDPIpURETk+ri7OgARERG5ue3btw+r1XX/J7vrrrvo06cPhmFw+PBh3n77bTp37syaNWuIiIi47uMtWrSI3bt388QTT+R4rF5eXrz33ntp1tepU4e77rqLnj174uXllePnlYKjbt26PPXUUwCcOHGC9957j759+xIfH8/AgQNdHJ2IiIgzJaVEREQkx9hsNux2O56enlnex9VJlGrVqvF///d/jvfdunXjlltu4fXXX7+hpFRucnd3d4r1am5ubnkYzfW7fPkyPj4+rg6jUCtdurTTM9KvXz8qVarEjBkzlJQSEZF8R933REREbiLHjh2jf//+lCpVCi8vL2699VY++OADpzoJCQmMHz+eBg0a4O/vj4+PDy1atGDjxo1O9VJ3KZo5cyaVK1fGy8uLP//8k4kTJ2KxWNi/fz/9+vUjICAAf39/Hn74YWJjY52Oc/WYUsldEX/44QdGjBhBUFAQPj4+dO3alVOnTjnta7fbmThxImFhYRQtWpTWrVvz559/Zmucqpo1a1KyZEkOHDjgtP6LL76gY8eOhIWF4eXlReXKlXnhhRdISkpy1GnVqhWrVq3i8OHDji5UFSpUcGyPj49nwoQJVKlSBS8vL8qWLcszzzxDfHz8DcWaWnrjPyV3ffv+++9p1KgR3t7eVKpUKd3uXH/88Qd33nknRYoUoUyZMkyePBm73Z7uudasWUOLFi3w8fHB19eXjh078scffzjV6devH8WKFePAgQPcfffd+Pr60rt3bwBOnz7N3r170zwLN8pms/HCCy84nsEKFSrw3HPPpbmvP//8MxEREZQsWZIiRYpQsWJF+vfv71Rn8eLFNGjQAF9fX/z8/KhVqxavv/56hudOTEykePHiPPzww2m2xcTE4O3tzdNPP+1Y98Ybb3DrrbdStGhRAgMDadiwIYsWLcrmHchYUFAQNWrUSPM8i4iI5AdqKSUiInKTOHnyJE2aNMFisTBs2DCCgoJYs2YNkZGRxMTEOLqbxcTE8N5779GrVy8GDhzIxYsXef/994mIiGD79u3UrVvX6bjz5s0jLi6OQYMG4eXlRfHixR3b7r//fipWrMhLL73EL7/8wnvvvUdwcDBTp069ZryPPfYYgYGBTJgwgUOHDjFz5kyGDRvGp59+6qgzevRopk2bRufOnYmIiOC3334jIiKCuLi4G75PFy5c4Ny5c1SuXNlp/fz58ylWrBgjRoygWLFifPvtt4wfP56YmBheeeUVAMaMGcOFCxc4evQoM2bMAKBYsWKAmUC75557+P777xk0aBA1a9bk999/Z8aMGfz111+sWLEiS/GdPn3a6b2Hhwf+/v4Z1t+/fz/du3cnMjKSvn378sEHH9CvXz8aNGjArbfeCkBUVBStW7fGZrPx7LPP4uPjw5w5cyhSpEia43300Uf07duXiIgIpk6dSmxsLG+//TbNmzfn119/dUrC2Ww2IiIiaN68Oa+++ipFixYFYPbs2UyaNImNGzfSqlWrLF13ZgYMGMCCBQvo3r07Tz31FNu2beOll15iz549fP755wBER0fTrl07goKCePbZZwkICODQoUMsX77ccZz169fTq1cv2rRp43hG9+zZww8//MDjjz+e7rk9PDzo2rUry5cv591333VqJbhixQri4+Pp2bMnAHPnzmX48OF0796dxx9/nLi4OHbt2sW2bdt48MEHs30f0mOz2Th69CiBgYG5cnwREZFsMURERKTAmzdvngEYP/30U4Z1IiMjjdDQUOP06dNO63v27Gn4+/sbsbGxhmEYhs1mM+Lj453qnDt3zihVqpTRv39/x7qDBw8agOHn52dER0c71Z8wYYIBONU3DMPo2rWrUaJECad15cuXN/r27ZvmWtq2bWvY7XbH+ieffNJwc3Mzzp8/bxiGYURFRRnu7u5Gly5dnI43ceJEA3A6ZkYAIzIy0jh16pQRHR1t/Pzzz0b79u0NwHjllVec6ibfn9QeeeQRo2jRokZcXJxjXceOHY3y5cunqfvRRx8ZVqvV2Lx5s9P6d955xwCMH374IdNY+/btawBpSsuWLQ3DSLlvBw8edOxTvnx5AzD+97//OdZFR0cbXl5exlNPPeVY98QTTxiAsW3bNqd6/v7+Tse8ePGiERAQYAwcONAptqioKMPf399pfXK8zz77bJprSX4+Nm7cmOk1J19Dx44dM9y+c+dOAzAGDBjgtP7pp582AOPbb781DMMwPv/882t+jTz++OOGn5+fYbPZrhlXal9//bUBGF999ZXT+rvvvtuoVKmS4/29995r3Hrrrdd1bMNI+Vq7+pm8Wvny5Y127doZp06dMk6dOmX8/vvvxkMPPWQAxtChQ6/7vCIiIrlN3fdERERuAoZh8Nlnn9G5c2cMw+D06dOOEhERwYULF/jll18Ac1yi5NYedruds2fPYrPZaNiwoaNOat26dSMoKCjd8w4ePNjpfYsWLThz5gwxMTHXjHnQoEFYLBanfZOSkjh8+DAAGzZswGaz8eijjzrt99hjj13z2Km9//77BAUFERwcTMOGDdmwYQPPPPMMI0aMcKqXutXQxYsXOX36NC1atCA2Npa9e/de8zxLly6lZs2a1KhRw+n+33nnnQBpukemx9vbm/Xr1zuV6dOnZ7rPLbfcQosWLRzvg4KCqF69Ov/8849j3erVq2nSpAmNGjVyqpfc3S7Z+vXrOX/+PL169XK6Bjc3Nxo3bpzuNQwZMiTNuokTJ2IYRo60klq9ejVAms8rebDv5JkUAwICAFi5ciWJiYnpHisgIIDLly+zfv3664rhzjvvpGTJkk6t+M6dO8f69et54IEHnI5/9OhRfvrpp+s6/vVYt24dQUFBBAUFUatWLT766CMefvhhR2s+ERGR/ETd90RERG4Cp06d4vz588yZM4c5c+akWyc6OtqxvGDBAqZPn87evXud/oCvWLFimv3SW5esXLlyTu+TuxCdO3cOPz+/TGPObF/AkZyqUqWKU73ixYtfV1ele++9l2HDhpGQkMBPP/3ElClTiI2NTTMj4B9//MHYsWP59ttv0yTVLly4cM3z/P333+zZsyfDBF7q+58RNzc32rZte816qV19H8G8l8n3Ecx72bhx4zT1qlev7vT+77//BnAk0q529Wfq7u5OmTJlrive63X48GGsVmua5yAkJISAgADHc9KyZUu6devGpEmTmDFjBq1ataJLly48+OCDjsH2H330UZYsWUKHDh0oXbo07dq14/7776d9+/aZxuDu7k63bt1YtGgR8fHxeHl5sXz5chITE52SUqNGjeKbb76hUaNGVKlShXbt2vHggw/SrFmzHLsfjRs3ZvLkySQlJbF7924mT57MuXPnrmvyARERkbyipJSIiMhNIHnA6v/7v/+jb9++6dapXbs2AB9//DH9+vWjS5cujBw5kuDgYNzc3HjppZfSHSw5vXGHkmU0G5xhGNeMOTv7Xo8yZco4Ej133303JUuWZNiwYbRu3Zr77rsPgPPnz9OyZUv8/Px4/vnnqVy5Mt7e3vzyyy+MGjUqwwHBU7Pb7dSqVYvXXnst3e1ly5bNuYtKJSfvY/J1fvTRR4SEhKTZ7u7u/Kull5dXmuRebkndqi6j7cuWLePHH3/kq6++4uuvv6Z///5Mnz6dH3/8kWLFihEcHMzOnTv5+uuvWbNmDWvWrGHevHn06dOHBQsWZHr8nj178u6777JmzRq6dOnCkiVLqFGjBnXq1HHUqVmzJvv27WPlypWsXbuWzz77jLfeeovx48czadKkHLkPJUuWdDzPERER1KhRg06dOvH666+naU0mIiLiakpKiYiI3ASCgoLw9fUlKSnpmi1tli1bRqVKlVi+fLnTH/oTJkzI7TCvS/ny5QFzIO/UrbXOnDnj1Aroej3yyCPMmDGDsWPH0rVrVywWC5s2beLMmTMsX76cO+64w1H34MGDafbPKDlSuXJlfvvtN9q0aXPNBEpeK1++vKMVVGr79u1zep88+HtwcPB1t9jKLeXLl8dut/P3339Ts2ZNx/qTJ09y/vx5x3OSrEmTJjRp0oQXX3yRRYsW0bt3bxYvXsyAAQMA8PT0pHPnznTu3Bm73c6jjz7Ku+++y7hx49K0xkrtjjvuIDQ0lE8//ZTmzZvz7bffMmbMmDT1fHx8eOCBB3jggQdISEjgvvvu48UXX2T06NF4e3vn0F1J0bFjR1q2bMmUKVN45JFH8PHxyfFziIiI3CiNKSUiInITcHNzo1u3bnz22Wfs3r07zfZTp0451QXnljTbtm1j69atuR/odWjTpg3u7u68/fbbTutnz56dreO6u7vz1FNPsWfPHr744gsg/XuSkJDAW2+9lWZ/Hx+fdLvz3X///Rw7doy5c+em2XblyhUuX76crbiz4+677+bHH39k+/btjnWnTp1i4cKFTvUiIiLw8/NjypQp6Y7LlPo5yszp06fZu3cvsbGx2QscM3aAmTNnOq1PbpHWsWNHwOz2eXXrsOSZJOPj4wEzoZma1Wp1tCBMrpMRq9VK9+7d+eqrr/joo4+w2WxOXffSO76npye33HILhmFkOM5VThg1ahRnzpxJ99kTERFxJbWUEhERKUQ++OAD1q5dm2b9448/zssvv8zGjRtp3LgxAwcO5JZbbuHs2bP88ssvfPPNN5w9exaATp06sXz5crp27UrHjh05ePAg77zzDrfccguXLl3K60vKUKlSpXj88ceZPn0699xzD+3bt+e3335jzZo1lCxZMlutkfr168f48eOZOnUqXbp0oWnTpgQGBtK3b1+GDx+OxWLho48+SrcLXIMGDfj0008ZMWIEt99+O8WKFaNz58489NBDLFmyhMGDB7Nx40aaNWtGUlISe/fuZcmSJXz99dc0bNgwO7fkhj3zzDN89NFHtG/fnscffxwfHx/mzJlD+fLl2bVrl6Oen58fb7/9Ng899BD169enZ8+eBAUFceTIEVatWkWzZs2ylBScPXs2kyZNYuPGjVka7Hz//v1Mnjw5zfp69erRsWNH+vbty5w5cxzdLLdv386CBQvo0qULrVu3Bsxx0t566y26du1K5cqVuXjxInPnzsXPz8+R2BowYABnz57lzjvvpEyZMhw+fJg33niDunXrOrXCysgDDzzAG2+8wYQJE6hVq1aafdq1a0dISAjNmjWjVKlS7Nmzh9mzZ9OxY0d8fX2vefwNGzYQFxeXZn2XLl247bbbMtyvQ4cO3Hbbbbz22msMHToUDw+Pa55LREQkLygpJSIiUohc3WooWb9+/ShTpgzbt2/n+eefZ/ny5bz11luUKFGCW2+9lalTpzrVjYqK4t133+Xrr7/mlltu4eOPP2bp0qVs2rQpj64ka6ZOnUrRokWZO3cu33zzDeHh4axbt47mzZtnqytUkSJFGDZsGBMnTmTTpk20atWKlStX8tRTTzF27FgCAwP5v//7P9q0aUNERITTvo8++ig7d+5k3rx5zJgxg/Lly9O5c2esVisrVqxgxowZfPjhh3z++ecULVqUSpUq8fjjj1OtWrXs3o4bFhoaysaNG3nsscd4+eWXKVGiBIMHDyYsLIzIyEinug8++CBhYWG8/PLLvPLKK8THx1O6dGlatGjBww8/nCvx7du3j3HjxqVZHxkZSceOHXnvvfeoVKkS8+fP5/PPPyckJITRo0c7dTlNTlYtXryYkydP4u/vT6NGjVi4cKGj++f//d//MWfOHN566y3Onz9PSEgIDzzwABMnTszS2FhNmzalbNmy/Pvvv2laSYHZNXThwoW89tprXLp0iTJlyjB8+HDGjh2bpfuwdu3adJPOFSpUyDQpBfD000/Tr18/Fi5cSL9+/bJ0PhERkdxmMXJ6tFARERERFzp//jyBgYFMnjw53TF9RERERCR/0JhSIiIiUmBduXIlzbrksYWy0i1MRERERFxH3fdERESkwPr000+ZP38+d999N8WKFeP777/nk08+oV27djRr1szV4YmIiIhIJpSUEhERkQKrdu3auLu7M23aNGJiYhyDn6c3KLaIiIiI5C8aU0pERERERERERPKcxpQSEREREREREZE8p6SUiIiIiIiIiIjkOY0plYvsdjvHjx/H19cXi8Xi6nBERERERERERHKdYRhcvHiRsLAwrNaM20MpKZWLjh8/TtmyZV0dhoiIiIiIiIhInvv3338pU6ZMhtuVlMpFvr6+gPkh+Pn5uTgaZ3a7nVOnThEUFJRp1rIgK4jXmB9jdmVMeXXu3D5Pbhw/Pz4rkj/pWckZN8N9zI1rjLfF88z6ZwCYdtc0vNy9cuS4yfLj56Kfm/nz+PnxWclRp7bCxvYp71uvhaBw18VTgBX6ZyUPFPp7GB8PY8diGAbRw4cTVKZMjl2nLc7G530+B6Drh11x987ZlE1efjYxMTGULVvWkRfJiJJSuSi5y56fn1++TErFxcXh5+dXOL9RUDCvMT/G7MqY8urcuX2e3Dh+fnxWJH/Ss5Izbob7mBvXGG+Lx7OoJ2D+PpQbSan89rno52b+PH5+fFZyVJwPFE313tcH8tnfHwVFoX9W8kChv4fx8QAYwBVf3xy9TpunjaIe5hezn59friSl8vqzudZQRkpKiYiIiIiIFGTewVCxr/N7Eckdnp4wZQqG3Q42m6ujKfCUlBIRERERESnI/KpB+HxXRyFyc7BYoEQJsNshOtrV0RR4hbAtnYiIiIiIiIiI5HdqKeVidrudhIQEl5w3MTGRuLi4wtnPl4J5jfkxZlfGdCPn9vDwwM3NLZcjExERERGRm1JSEmzaZLaUuuUWV0dT4Ckp5UIJCQkcPHgQu92e5+c2DAO73c7FixevOfBYQVUQrzE/xuzKmG703AEBAYSEhOSbeygiIiIiIoWEzQZLlmAxDBgzxtXRFHhKSrmIYRicOHECNzc3ypYtm+ctUAzDwGaz4e7uXmj/cC+I15gfY3ZlTNd7bsMwiI2NJfq/vt2hoaG5HaKIiIiIiNxMrFZo1Mgc6Dyf9G4pyJSUchGbzUZsbCxhYWEULVr02jvksPyY/MhpBfEa82PMBSkpBVCkSBEAoqOjCQ4OVlc+ERERKfzO/gI/9kt532Q+FK/vqmhECjcPD4iM1EDnOURJKRdJSkoCwNPT08WRiBQ+yYnexMREJaVERESk8LPFwvnfnd+LiBQAamvmYvmlNYxIYaKvKxERERERkfxPLaVERERERERERLIiPh6ee84c6Pzxx10dTYGnpJSIiIiIiIiISFZdugSG4eooCgUlpeS69OvXj/Pnz7NixQpXhyIiIiL5nKebJxNaTXAsi4iIFHienjBhgjn7nsavzTYlpUREREQkV1gsFsJ8w1wdhoiISM6xWCAsTLPv5RANdC455rvvvqNRo0Z4eXkRGhrKs88+i81mc2xftmwZtWrVokiRIpQoUYK2bdty+fJlADZt2kSjRo3w8fEhICCAZs2acfjwYVddioiIiIiIiIjkMrWUkhxx7Ngx7r77bvr168eHH37I3r17GThwIN7e3kycOJETJ07Qq1cvpk2bRteuXbl48SKbN2/GMAxsNhtdunRh4MCBfPLJJyQkJLB9+3bNoCYiIlLA2ew21vy9BoAOVTvgbtWvniIiUsAlJcGWLWZLqSpVXB1NgaffDPKRhg0hKiovz2h+/CEh8PPP2TvSW2+9RdmyZZk9ezYWi4UaNWpw/PhxRo0axfjx4zlx4gQ2m4377ruP8uXLA1CrVi0Azp49y4ULF+jUqROVK1cGoGbNmtkLSERERFwuyZ7Eyr9WAtCucjslpUREpOCz2eDjj83Z98aMcXU0BZ5+M8hHoqLg2LG8OlvOtkLas2cP4eHhTq2bmjVrxqVLlzh69Ch16tShTZs21KpVi4iICNq1a0f37t0JDAykePHi9OvXj4iICO666y7atm3L/fffT2hoaI7GKCIiInnLzepGqwqtHMsiIiIFntUKdepgGIa5LNmipFQ+EhKSl2dLmb4yJCT3u8m5ubmxfv16tmzZwrp163jjjTcYM2YM27Zto2LFisybN4/hw4ezdu1aPv30U8aOHcv69etp0qRJrscmIiIiucPd6k6vWr1cHYaIiEjO8fCARx/VQOc5REmpfCS7Xeiuh2GAzWbD3d2dzIZuOnnS/JorUgS8vDKuV7NmTT777DMMw3C0lvrhhx/w9fWlTJkygDkDT7NmzWjWrBnjx4+nfPnyfP7554wYMQKAevXqUa9ePUaPHk14eDiLFi1SUkpERERERESkkFJSSjJkt8O//zqvO3cOTp68wLp1O/H0NBNVnp4waNAgZs6cyWOPPcawYcPYt28fEyZMYMSIEVitVrZt28aGDRto164dwcHBbNu2jVOnTlGzZk0OHjzInDlzuOeeewgLC2Pfvn38/fff9OnTxzUXLiIiIjnCMAwuJVwCoJhnMU1iIpJbgprCA3Ep760erotFROQ6KCklGYqLS7suKQm2bdtEREQ9p/Vdu0YyZ85qXnllJHPn1iEwsDgPPxzJ2LFjAfDz8+N///sfM2fOJCYmhvLlyzN9+nQ6dOjAyZMn2bt3LwsWLODMmTOEhoYydOhQHnnkkby4TBEREcklCUkJPL3uaQBmdZiFl3smza5F5MZZrOCmry+RPJGQABMnmgOdDxni6mgKPCWlJEOenlC5Mly5YiaorlyBSZPmM3Hi/Az3ee+97U7v//gDvL3Bx6cmH364Fm9vsyuguzuOboOlSpXi888/z8UrEREREREREckBhgFnzpivhnHt+pIpJaUkQ+7uEBholmSGAfHxZpIqOVGV/Gq3pz1GYqJZLl50Xu/mZianvL3N5JeHh/OrmxuZjnUlIiIiIiIikuc8PGD0aAy73VyWbFFSSq6LxWImkry9ndcbhpl8ujpRFRcHNlva4yQlwaVLZkmP1Zo2UZX8mrzs4aHElYiIiIiIiOQhqxUqVNDsezlESSnJERZLSsLIz895W3KyKnWiKi7O7IqbEbvdbJEVH5/5ea+VuFLSSkREREQKvdjjcDTVcBhlukLRMNfFIyKSRUpKSa5LbtXk6+u8PinJTE4lJpoJqvRek5IyP3Zy98D0WQAP3NyMdBNXqV9Tj3ElIiIiIlKgXPoHfh6W8j6gjpJSIrnFboeffjJfy5d3dTQFnpJS4jJubuDjk3mdpKSME1bJrxknpZKPYeHKFbOVVkaSW3olJ9Ay6i5otV7/dYqIiIiIiEghkZgIH3xgzr43ZoyroynwlJSSfC15QPQiRTKuY7enJKdSJ6wSEgwSEgxsNgsJCZZMJ0ZIHsD9Wt0F3d2dW1dZrWaMV5er11utZlFrLBERERERkQLMaoWaNTEMQ60WcoCSUlLgWa3g5WWW1AwDbLYk3N3Nx9xmc05epdfiKr1B2VOz2a5dJzNZSWCB1ZHwslicE1rXek0uIiIiIiIikgs8POCJJzTQeQ5RUkpuChZLShe8zCQlpd/q6urkVWatrq51/MzHybIAbjd28P+kl7DKLImV3var69rtFtzdzaRZetvT2xeUIBMREREREZGMKSklkkpyayVv74zrmC2wUhJMSUlmkjz1+8y2Jb+323PnGpKPe61B4rPOwo1+q7g6gZW6ZHUdWB3JsOQE2rVKQkLKDI5eXkqOiYiIiIiI5EdKSolcp6y2uroWu905YWW3g81mkJiYhMXihmFYsNvNJFhy3eTljF6vVSevGUbK+W/MjbccO30aOnaEI0egaFFzXLKiRdNfLlLEgpubH8WLW/DxSdmWumS0Pnmbu76bioiIiIgUfgkJMGWKOdB5ZKSroynw9GeUXJdTp04xfvx4Vq1axcmTJwkMDKROnTqMHz+eZs2aAWCxWPj888/p0qWLa4O9AdmJfdOmTYwYMYI//viDsmXLMnbsWPr165dhfasVdu/exdChQ/npp58ICgpi2LBhjBgxAnf3lNY9S5cuZdy4cRw6dIiqVasydepU7r77bsdxDMNgwoQJzJ07l/Pnz9OsWTPefvttqlat6qhzzz33sHPnTqKjowkMDOTOO9syefJUQkPDHAmrZcuWMH36FPbv/4sSJYKIjBzGsGEjsdsNbDY7FouVzz5bxFtvTePgwb/x9fWnVasOjBr1CgEBJRzHubqktz71utxmGHD5slkyZgGKZus8Hh4ZJ62KFrXg7u5PiRIWihUzk1hZKcl1ixbVGIoiIiIiIvmCYcCJE3n3B00hp6SUXJdu3bqRkJDAggULqFSpEidPnmTDhg2cOXPG1aG51MGDB+nYsSODBw9m4cKFbNiwgQEDBhAaGkpERES6+8TExNCuXTvatm3LO++8w++//07//v3x8/Nj8ODBAGzZsoVevXrx0ksv0alTJxYtWkSXLl345ZdfuO222wCYNm0as2bNYsGCBVSsWJFx48YRERHBn3/+ifd//RBbt27Nc889R2hoKMeOHePpp5+md+/ubNmyBYA1a9YwYEBv3njjDdq1a8eePXsYOHAgJUsWYejQodhsdrZt28rjj/dhxowZdO7cmWPHjjF48GBefHEgy5cvv6H7ll4SyzlxZZCYaMNqdXe0HMusGEbKuGCXL0OjRhAcDFeuQGxsymtsrFknJyUmwoULZknLAmQyhWQWFClyddLKgodHIP7+GbfuSt0iLCvb3bI3nJmISBoebh481fQpx7KIiEiB5+EBTz2FYbdnv/uMYDEMpfZyS0xMDP7+/ly4cAE/Pz+nbXFxcRw8eJCKFSs6Egd5yTAMbDYb7u7uWLI44M758+cJDAxk06ZNtGzZMt06FSpU4PDhw4735cuX59ChQwB88cUXTJo0iT///JOwsDD69u3LmDFjHLPjnT9/nqeffpovvviC+Ph4GjZsyIwZM6hTpw4AEydOZMWKFQwZMoTJkydz5swZOnXqxNy5c/H393ec87333mP69OkcPHiQ8uXLM3z4cIYOHQpAQkICI0aM4LPPPuPcuXOUKlWKwYMHM3r06Exjv5ZRo0axatUqdu/e7VjXs2dPzp8/z9q1a9Pd5+2332bMmDFERUXh6enpOM6KFSvYu3cvFouFBx54gMuXL7Ny5UrHfk2aNKFu3bq88847GIZBWFgYTz31FE8//TQAFy5coFSpUsyfP5+ePXume+4vv/ySLl26EB8fj4eHBw8++CCJiYksXbrUUeeNN95g2rRpHD58mKSkJGbOnMk777zDgQMHnOpMnTqVo0ePZuk+Xa8beU4ha19fNltKkurSJTtHj57F27s4cXFWR+IqNtZMbqV+f3W51vaCxNPz6m6NKYmr1O8zWnc9db281Porr9jtdqKjowkODsaqm37Dbob7WBCvMT/G7MqY8urcuX2e3Dh+fnxWclT09/BNi5T3bTdDcHPXxVOAFfpnJQ/cLPcwN67TFmdjaQ/zb7IeS3vg7p2z7Yjy8rPJLB+SmlpK5Tfx8earp2dK/63kUbXd3JwHrkmvblKSWd9qdc7aZlT3OgbCKVasGMWKFWPFihU0adIELy+vNHV++ukngoODmTdvHu3bt8ftv6YXmzdvpk+fPsyaNYsWLVpw4MABBg0aBMCECRMA6NGjB0WKFGHNmjX4+/vz7rvv0qZNG/766y+KFy8OwP79+1myZAlfffUVMTExREZG8uijj7Jw4UIAFi5cyPjx45k9ezZ169bl559/ZsiQIRQrVoy+ffsya9YsvvzyS5YsWUK5cuX4999/+ffffzON/dChQ1SsWJGNGzfSqlWrdO/N1q1badu2rdO6iIgInnjiiQzv59atW7njjjscCankfaZNm8a5c+coXrw4W7duZcSIEWmOu2LFCsBsoRUVFeV0bn9/fxo3bszWrVvTTUqdPXuWhQsX0rRpUzz+e0bi4+MpWtS5+1qRIkU4evQohw8fpkyZMoSHhzNmzBhWr15Nhw4diI6OZtmyZU5dCQsSd3fw9TVLUBD4+NgIDs7ZRIndbia+Ll60c+TIGby9S3DlitXRnfDyZbh0Caf3V5fMtue0hASznD+f88dOj7u7mZzy9DRfU5ecWOfpmVIye3/1Nk9PJcxERERERPKCklL5zfDh5uurr5p/LQOsWwdffAHNm8NDD6XUffppxyBrlChhrtu0CZYsMfstpR507bnnzL9uJ0yAsDAALFu3QgZJlvS4u7szf/58Bg4cyDvvvEP9+vVp2bIlPXv2pHbt2gAEBQUBEBAQQEhIiGPfSZMm8eyzz9K3b18AKlWqxAsvvMAzzzzDhAkT+P7779m+fTvR0dGOZNerr77KihUrWLZsmSOBFRcXx4cffkjp0qUBs6VOx44dmT59OiEhIUyYMIHp06dz3333YRgGZcuWZd++fbz77rv07duXI0eOULVqVZo3b47FYqF8+fKOGDOK3cPDg+rVq6dJ2qQWFRVFqVKlnNaVKlWKmJgYrly5QpEiabtuRUVFUbFixTT7JG8rXrx4hseNiopy1Eu9X3p1ko0aNYrZs2cTGxtLkyZNnFpfRURE8OSTT9KvXz9at27N/v37mT59OgAnTpygTJkyNGvWjIULF/LAAw8QFxeHzWajc+fOvPnmmxnel5ud1Wp2tTM//qQcTXolJdk5fDgaX9/gNK27ru6qeKPrr1wxS261p7XZzJIbCbbscnfPOJnl7Z35643WuXpQfc0cKYVBkj2JzUc2A9CiXAvcrOonLCIiBZzdDrt2ma+p/m6UG6OklFyXbt260bFjRzZv3syPP/7ImjVrmDZtGu+9916mg3r/9ttv/PDDD7z44ouOdUlJScTFxREbG8tvv/3GpUuXKJGcXPvPlStXnLqLlStXzpGQAggPD8dut7Nv3z58fX05cOAAkZGRDBw40FHHZrM5uvf169ePu+66i+rVq9O+fXs6depEu3btMr3m0qVLs3fv3izdn/xs5MiRREZGcvjwYSZNmkSfPn1YuXIlFouFgQMHcuDAATp16kRiYiJ+fn48/vjjTJw40dGs888//+Txxx9n/PjxREREcOLECUaOHMngwYN5//33XXx1Nx+LxUxclCiRu616DMNsaJmcoEouqZNWGa3LrE5Cgnnc1OXqdTc+a2P2JSfMXNkF02rNeAbIay2nXlekCMTHe1CmjPm/juTtPj4aR0xyn81u45PfPwEgvEy4klIiuaVYJWjwuvN7EckdiYnw9tvm7Htjxrg6mgJPSan8ZtYs8zVVly7atYM2bdL+9fDqq2nrtmpltqi6+q/UKVPS1DXCw28oRG9vb+666y7uuusuxo0bx4ABA5gwYUKmSalLly4xadIk7rvvvnSPd+nSJUJDQ9m0aVOa7QEBAVmK69KlSwDMnTuXxo0bO41HlDxuVf369Tl48CBr1qzhm2++4f7776dt27YsW7YsS+fISEhICCdPnnRad/LkSfz8/NJtJZXZPsnbMquTenvyutDQUKc6devWddqvZMmSlCxZkmrVqlGzZk3Kli3Ljz/+SHh4OBaLhalTpzJlyhSioqIICgpiw4YNgNmqDeDll1+mWbNmjBw5EoDatWvj4+NDixYtmDx5stP5pfCwWMyWPN7eEBiYt+e22bKWvLp6XXI3xNTL13qflW2pz2ez5f712+1mA9f/vrVlgxUoke4WL6+UBFXqZFVm665eX6wY+PmldIf18zOfF7XyEgCrxUr90PqOZRHJJUXDoPpwV0chcnOwWqFyZQzD0JgPOUBJqfwmnXGacHdPf+yn9Oq6uaX/r++M6uaAW265xTHGEZjd3ZKSkpzq1K9fn3379lGlSpV0j1G/fn2ioqJwd3enQoUKGZ7ryJEjHD9+nLD/uiD++OOPWK1WqlevTqlSpQgLC+Off/6hd+/eGQ6S7efnxwMPPMADDzxA9+7dad++PWfPnqV48eLpxp4V4eHhrF692mnd+vXrCc8k8Zc8RlNiYqJjbKf169dTrVo1Av/76z88PJwNGzY4jU2V+rgVK1YkJCSEDRs2OJJQMTExbNu2jSFDhmR4bvt/TVDik8ca+4+bm5ujJdonn3xCeHg4QUFB2Gw2YmNjHcm91PXBHJBcJKclf+vLpOesyyQlpSSo4uIyf81Knbg4swXZ1QPnp36fvJyTX27J8Z09m3PHBPPHy9WJqsyWM9ru72+29FKCq+DycPPgkYaPuDoMERGRnOPhAc88Y/4HMTra1dEUeEpKSZadOXOGHj160L9/f2rXro2vry8///wz06ZN495773XUq1ChAhs2bKBZs2Z4eXkRGBjI+PHj6dSpE+XKlaN79+5YrVZ+++03du/ezeTJk2nbti3h4eF06dKFadOmUa1aNY4fP86qVavo2rUrDRs2BMxWVX379uXVV18lJiaG4cOHc//99ztaDE2aNInhw4fj7+9PREQEly9fZufOnZw/f54RI0bw2muvERoaSr169bBarSxdupSQkBBHa6z0Yj927Bht2rThww8/pFGjRunem8GDBzN79myeeeYZ+vfvz7fffsuSJUtYtWqVo87s2bP5/PPPHS2QHnzwQSZNmkRkZCSjRo1i9+7dzJo1i1eTW8ABjz/+OC1btmT69Ol07NiRxYsX8/PPPzNnzhwALBYLTzzxBJMnT6Zq1apUrFiRcePGERYWRpcuXQDYtm0bP/30E82bNycwMJADBw4wbtw4Kleu7EhunT59mmXLltGqVSvi4uKYN28eS5cu5bvvvnPE0qlTJwYNGsTbb7/t6L73xBNP0KhRI0eSUORm4eaW0j0uLyV3p0wvWZXebJDmYPkGp0/HYhhFiY21OAbKT95+dbmBvHwaSUlw7pxZssvDAwICnIu/f9p1GdXx8VFSS0RERCS/UlJKsqxYsWI0btyYGTNmcODAARITEylbtiwDBw7kueeec9SbPn06I0aMYO7cuZQuXZpDhw4RERHBypUref7555k6dSoeHh7UqFGDAQMGAGZyZfXq1YwZM4aHH36YU6dOERISwh133OE0iHeVKlW47777uPvuuzl79iydOnXirbfecmwfMGAARYsW5ZVXXmHkyJH4+PhQq1YtR0sjX19fpk2bxt9//42bmxu33347q1evdoyblF7siYmJ7Nu3j9hMBpepWLEiq1at4sknn+T111+nTJkyvPfee0RERDjqnD592ml8LH9/f9atW8fQoUNp0KABJUuWdHSHTNa0aVMWLVrE2LFjee6556hatSorVqzgtttuc9R55plnuHz5MoMGDeL8+fM0b96ctWvX4u3tDUDRokVZvnw5EyZM4PLly4SGhtK+fXvGjh3rNIPiggULePrppzEMg/DwcDZt2kSjRo0craD69evHpUuXmD17Nk899RQBAQHceeedTJ06NQtPj4jkhNTdKUuk3yMvDbvdIDr6IsHBRbBaM8/OGIbZVTGzpNXVSa2LF1NKTEz6y9kZmysxEU6dMsuNcHPLOHFVsqR5H0uUSLscGKgxt0RERERym8VQv5tcExMTg7+/PxcuXMDPz89pW1xcHAcPHqRixYqO5EFeyqhrW342ceJEVqxYwc6dO7NUvyBeY36M2ZUx3ei5r/fry263Ex0dTXBwsCNBmZNy4/i5HbMUHvnhWbHZzLGxUierMkpgpd4eEwPnz5vlwgXzNa9+a7FYnBNXxYsbFCsWR+nS3pQsackwoZV6mMeCJjeelXhbPMPXmOPczOowCy/3dIYTyIb88HxfzZUx5dW59XMzHzIMMFI1dbW4qZnoDSr0z0oeKPT3MDERXnkFu2EQ3acPwaVL59h12uJsLO2xFIAeS3vg7p2z7Yjy8rPJLB+SmlpKiYiISK5yd09pnZQdyYO/Jyeqrk5YpVeu3pbV7omGkdIF8e+/ASxA+hNXpObrayapgoMzLkFB5mvJkmb3RBGRbDv1A3zTIuV9280Q3Nx18YgUZnY7HD5szr7nyumiCwklpURERKRAsFrNgdD9/KBcuevf3zDMLofJyaYzZ8xy+nTa5dTrzp/P+jmSW3wdPJi1+sWLZ57ASl0CAtTwQURExOU8PGDYMAy7Xf9dygFKSkmBMXHiRCZOnOjqMEREpICyWKBYMbOULZv1/Ww2OH3azl9/ncEwSnDunDXdRFby8qlTWZ/R8OxZs+zde+267u5mcio0NPMSEqLfkUVERHKN1Qq1amn2vRyipJSIiIhIJpKTQZBEcLD5u+i1mIks83fV5HLqlPP71OXSpawd8/hxs1xLUNC1k1ehoVDk2j0SRURERHKNklIiIiIiOczd3WyxFBKStfqxseknra5eFxUFJ09eewiL5BkLd+3KvF5AQOoWVhb8/X2pVAnCwpyTV35+6jooIiICmD+E9+0zXwMDXR1NgaeklIiIiIiLFS0K5cub5VqSksyE04kTzuX48bTrEhMzP1byAPB79oA5mLtPuvWKFDETbKm7CKbXbTAoCNzcru/aRURECpTERJg50xzofMwYV0dT4CkpJSIiIlKAuLmltMKqVy/jeoZhjleVWdIqucTGZn7OK1fMwduvNYC7m1vKuFchIRAcCr+VNpNuK+KhXOmUbd7e13/tIiIiLme1QpkyGIaRtT79kiklpUREREQKIYsFSpQwy223ZVzPMMwZA48etbN373muXAng5EkrUVFpk1fnzmV+zqSklLoAuAEdzMUfxgBJKXWTuw4mt7rKqCWWZh0UEZF8xcMDxo3TQOc5REkpERERkZuYxWKOGVWjBhQvnpDpYO7x8Tglq65OXCW/P3nSTFBlxrnrYMa8vNImrpJfS5UCT093brvNXOeu32xFREQKFP3oFpF8zzAMLPo3uYiIy3l5ZW3sq6Qkc/bBI8dgwjaze2CbcDgVlTaZda2ug/HxcPiwWdKyAiUBM7kWHJx2kPbU78PCzOSVh8eNXL2IiIjkNHWAlOty6tQphgwZQrly5fDy8iIkJISIiAh++OEHRx2LxcKKFStcF2Q2ZBb7ggULaN68OQATJ06kRo0a+Pj4EBgYSNu2bdm2bdt1n+/s2bP07t0bPz8/AgICiIyM5NI15gWPi4tj6NChlChRgmLFitGtWzdOnjzpVOfIkSN07NiRokWLEhwczMiRI7HZbE51Nm3aRP369fHy8qJKlSrMnz/fafv//vc/OnfuTOnSpfH09Ez3vmTlPtxzzz2UK1cOb29vQkNDeeihhzielfnMU/nhhx/4448/rmsfERFxHTc3sxVT7dpQtgxUrwbPPAOzZsHSpbB5M+zfD5cvQ0yMOYnRd9/B4sUwcyaMGgV9+kC7dlCrljmA+rUYhtlC69dfYfVqeP99mDwZHn0UunaFJk2gXDnw9DSPV6cOtG8PDz9sjlM7ezZ89hls3QqHDpnJMBERkTQSE2H6dHjttWvPKCLXpJZScl26detGQkICCxYsoFKlSpw8eZINGzZw5swZV4eW67744gvuueceAKpVq8bs2bOpVKkSV65cYcaMGbRr1479+/cTlJXfnP/Tu3dvTpw4wfr160lMTOThhx9myJAhfPLJJxnu8+STT7Jq1SqWLl2Kv78/w4YN47777nMkBpOSkujYsSMhISFs2bKFEydO0KdPHzw8PJgyZQoABw8epGPHjgwePJiFCxeyYcMGBgwYQGhoKBEREQBcvnyZOnXq8PDDD9OtW7d0Y8nKfWjdujXPPfccoaGhHDt2jKeffpru3buzZcuWLN+nzz77jOLFi3PrrbdmeR8RESkYfH3NUq1a5vUSE82kU1Sq1lbHj9v55584zp8vQlSUhePHzfVX/R8mjdOnzbJrV+b1ihc3W1eVLp32NXk5OFgzDoqI3FTsdvjrL3P2Pbvd1dEUfIbkmgsXLhiAceHChTTbrly5Yvz555/GlStXXBCZYdjtdiMhIcGw2+1Z3ufcuXMGYGzatCnDOuXLlzcARylfvrxj24oVK4x69eoZXl5eRsWKFY2JEycaiYmJTsePjIw0SpYsafj6+hqtW7c2du7c6dg+YcIEo06dOsY777xjlClTxihSpIjRo0cP4/z5804xzJ0716hRo4bh5eVlVKtWzZg9e7ZjW3x8vDF06FAjJCTE8PLyMsqVK2dMmTLlmrFfuXLF8PHxMfbs2ZPudSd/1t98802W7qVhGMaff/5pAMZPP/3kWLd69WrDYrEYR48eTXef8+fPGx4eHsbSpUsd6/bs2WMAxtatWx3HsFqtRlRUlKPO22+/bfj5+Rnx8fGGYRjGM888Y9x6661Ox37ggQeMiIiINOe02+0GYCxfvvya15SV+/DFF18YFovFSEhIuObxkp/TcuXKGbVq1bpm/WTX+/WVlJRknDhxwkhKSsryOa5Hbhw/t2OWwkPPSs64Ge5jrnyvsicZPx/72fj52M9Gkj3n7116MSclGcbJk4axc6dhrFljGO+/bxiTJxvGo48aRteuhtGkiWGUK2cYHh6GYbavyl5xczOMMmUMo1Ej8/iPPmo3Ro+OMebNSzLWrzeMP/80jAsXDOM6fuXK0ftREM+jn5s34MwOw1h5S0o5s8PVERVYhf5ZyQOF/h4mJRnGzz8bSdu3GyeOHcvR60y8kmgs6rTIWNRpkZF4JfHaO1ynvPxsMsuHpKaWUvnN5SNmuR5+1cH7qtY5SQlwZnsmOxlYkpLAtyIUu8bAEP8pVqwYxYoVY8WKFTRp0gQvL680dX766SeCg4OZN28e7du3x+2/fx1u3ryZPn36MGvWLFq0aMGBAwcYNGgQABMmTACgR48eFClShDVr1uDv78+7775LmzZt+OuvvyhevDgA+/fvZ8mSJXz11VfExMQQGRnJo48+ysKFCwFYuHAh48ePZ/bs2dStW5eff/6ZIUOGUKxYMfr27cusWbP48ssvWbJkCeXKlePff//l33//zTR2gA0bNlC6dGlq1KiR5poTEhKYM2cO/v7+1KlTx7G+VatWVKhQIU23uGRbt24lICCAhg0bOta1bdsWq9XKtm3buO+++9Lss2PHDhITE2nbtq1jXY0aNShXrhxbt26lSZMmbN26lVq1alGqVClHnYiICIYMGcIff/xBvXr12Lp1q9Mxkus88cQT6caaFRndh9TOnj3LwoULadq0KR4ZDOhx+fJlfv31V8AcS+rvv//myBHza+Lzzz93tMCyWCw0bNgw3edQRETyB6vFSoOwBnl7TqvZeik42OyilxHDgLNn4fhxs+VV8mvq5ePHzZKQkPFxkpLg6FGzmCyAb5p6Pj5pW1qVLg1ly0KZMuZrZoPMi2SqeH3oqKEORPKE1QoNGmj2vRyipFR+c+AD2D3p+vZpuggq9HJel3AGvmmR4S4WzA/fuG081M7a+dzd3Zk/fz4DBw7knXfeoX79+rRs2ZKePXtSu3ZtAEfCICAggJCQEMe+kyZN4tlnn6Vv374AVKpUiRdeeIFnnnmGCRMm8P3337N9+3aio6MdSYZXX32VFStWsGzZMkcCKy4ujg8//JDSpUsD8MYbb9CxY0emT59OSEgIEyZMYPr06dx3330YhkHZsmXZt28f7777Ln379uXIkSNUrVqV5s2bY7FYKJ9qpNaMYgfnrnvJVq5cSc+ePYmNjSU0NJT169dTsmRJx/Zy5coRGhqa4f2MiooiODg4zT0uXrw4UVFRGe7j6elJQECA0/pSpUo59omKinJKSCVvT96WWZ2YmBiuXLlCkSJFMoz7ate6DwCjRo1i9uzZxMbG0qRJE1auXJnh8Xx8fNi3bx/Dhw8n9qrRb5MTdX5+fsyZM4dmzZplOU4REZHULBYoUcIstWplXM8w4MwZMzl17FjKa+rl48fNv0sMI+PjXL4Mf/1lloy4u6dNVJUp47xcqpQSVyIiUngoKSXXpVu3bnTs2JHNmzfz448/smbNGqZNm8Z7771Hv379Mtzvt99+44cffuDFF190rEtKSiIuLo7Y2Fh+++03Ll26RIkSJZz2u3LlCgcOHHC8L1eunCMhBRAeHo7dbmffvn34+vpy4MABIiMjGThwoKOOzWbD398fgH79+nHXXXdRvXp12rdvT6dOnWjXrl2m12wYBl999RVLlixxWt+6dWt27tzJ6dOnmTt3Lvfffz/btm1zJJo+/PDDTI9bWFzrPgCMHDmSyMhIDh8+zKRJk+jTpw8rV67McEa9yMhImjZtSs+ePdl11YAft99+O4sXL6ZSpUq5el0iIpJ9dsPOryfM1q/1QuthtRS8bIrFAiVLmuW//8GlKzHRbF119KidP/+8QGysP8ePW9Mkry5ezPgYNltmMw2akhNX6SWtwsKgSBErJUoocSUikmvsdjh40Hz18XF1NAWeklJy3by9vbnrrru46667GDduHAMGDGDChAmZJqUuXbrEpEmT0u2S5u3tzaVLlwgNDWXTpk1ptl/dKiizcwDMnTuXxo0bYxgGNpsNd3d33N3NR71+/focPHiQNWvW8M0333D//ffTtm1bli1bluFxt2/fjs1mo2nTpk7rfXx8qFKlClWqVKFJkyZUrVqV999/n9GjR2cp3pCQEKKvau5ps9k4e/ZsmpZaqfdJSEjg/PnzTvfl5MmTjn1CQkLYvt2562by7Hyp61w9Y9/Jkyfx8/O7rlZSkLX7ULJkSUqWLEm1atWoWbMmZcuW5ccffyQ8PDzD49asWZN58+bRoIFzt4+FCxcqISUiUkAkJiUyZ8ccAGZ1mIWXe+Htcu3hYc7uV6YMVKoUn2FXvIsXU1paHTsG//5rdv1Lfj161GyZlZHME1dWIBh3d4PSpaF8+fRL2bJwnT/uRUQkWWIiTJtmDnQ+Zoyroynw8kVS6s033+SVV14hKiqKOnXq8MYbb9CoUaN0686dO5cPP/yQ3bt3A9CgQQOmTJniVH/ixIksXryYf//9F09PTxo0aMCLL75I48aNHXVefPFFVq1axc6dO/H09OT8+fNO5zlz5gy9e/dm165dnDlzhuDgYO69916mTJmCn59fzt+EZJX7Q0jba9dLza962nWeJaDt5gx3MTBISkrCzbfidQaY1i233MKKFSsc7z08PEhKSnKqU79+ffbt20eVKlXSPUb9+vWJiorC3d2dChUqZHiuI0eOcPz4ccLCwgD48ccfsVqtVK9enVKlShEWFsY///xD7969nZJSqVvk+Pn58cADD/DAAw/QvXt32rdvz9mzZylevHi6sX/xxRd07NjRaYyp9NjtduKvY/7o8PBwzp8/z44dOxyJl2+//Ra73e70rKbWoEEDPDw82LBhg2NGvH379nHkyBFHgic8PJwXX3yR6OhoR2ul9evX4+fnxy233OKos3r1aqdjr1+/PtMkUVZd6z7Y/5uhIiv36ssvvwTMroUJCQmcO3eOlStX8uSTT2Y7ThERyX1Wi5VqJao5lsWcabBGDbNkJDbWOWGVOmmV/Jp54spyzRZXwcHpJ6zKlTNfAwLMVmIiInIVi8X8JmoY+kaZA1yelPr0008ZMWIE77zzDo0bN2bmzJlERESwb9++NOPtAGzatIlevXrRtGlTvL29mTp1Ku3ateOPP/5wdOvKyjT1CQkJ9OjRg/DwcN5///0057Fardx7771MnjyZoKAg9u/fz9ChQzl79iyLFi3KvRviU84s2eXmCcHNM95uGBg2m9kGPIvOnDlDjx496N+/P7Vr18bX15eff/6ZadOmce+99zrqVahQgQ0bNtCsWTO8vLwIDAxk/PjxdOrUiXLlytG9e3esViu//fYbu3fvZvLkybRt25bw8HC6dOnCtGnTqFatGsePH2fVqlV07drVMRi4t7c3ffv25dVXXyUmJobhw4dz//33O1oATZo0ieHDh+Pv709ERASXL19m586dnD9/nhEjRvDaa68RGhpKvXr1sFqtLF26lJCQEEero/Ri//LLL3n++ecd13f58mVefPFF7rnnHkJDQzl9+jRvvvkmx44do0ePHo56ffr0oXTp0rz00kvp3s+aNWvSvn17xxhdiYmJPPbYY9x///2OpNuxY8do06YNH374IY0aNcLf35/IyEhGjBhB8eLF8fPz47HHHiM8PJwmTZoA0K5dO2655RYeeughpk2bRlRUFGPHjmXo0KGO8boGDx7M7NmzeeaZZ+jfvz/ffvstS5YsYdWqVY74Ll26xP79+zH+GyDj4MGD7Ny5k+LFi1OuXLks3Ydt27bx008/0bx5cwIDAzlw4ADjxo2jcuXKWUqALV++nHbt2rFgwQISExN58MEHWb58uZJSIiIFhIebB081fcrVYRQ4RYtC1apmyUhy4ip1ourIEYN//oknOtqLI0csnDuX8f7R0Wb56af0t/v6ZpywKldO3QPznZi/Yc/UlPc1R4FfJg+QiNw4T0944QUMDXSeM3J9HsBraNSokTF06FDH+6SkJCMsLMx46aWXsrS/zWYzfH19jQULFmRYJ7Np6ufNm2f4+/tn6Vyvv/66UaZMmSzVTX3e9KZAvN4p63Oa3W43EhISDPt1zE8cFxdnPPvss0b9+vUNf39/o2jRokb16tWNsWPHGrGxsY56X375pVGlShXD3d3dKF++vGP92rVrjaZNmxpFihQx/Pz8jEaNGhlz5sxxbI+JiTEee+wxIywszPDw8DDKli1r9O7d2zhy5IhhGIYxYcIEo06dOsZbb71lhIWFGd7e3kb37t2Ns2fPOsW5cOFCo27duoanp6cRGBho3HHHHcby5csNwzCMOXPmGHXr1jV8fHwMPz8/o02bNsYvv/ySYez79+83vLy8jEuXLjnqXLlyxejatasRFhZmeHp6GqGhocY999xjbN++3SmOli1bGn379s30np45c8bo1auXUaxYMcPPz8/o16+fcfbsWcfncvDgQQMwNm7c6HT+Rx991AgMDDSKFi1qdO3a1Thx4oTTcQ8dOmR06NDBKFKkiFGyZEnjqaeeMhITnacU3bhxo+M+VapUyZg3b16a7UCaknxNWbkPu3btMlq3bm0UL17c8PLyMipUqGAMHjzYOHr0aKb3Jfkapk6dasTHxzvuh81mMyZOnGicOnUq032v9+tLU1tLYaZnJWfcDPexIF5jfozZlTFdfe6YGMP4/XfDWLnSMN56yzBGjTKMnj0NIzzcMMLCDMNiMQzzX/3XX7y97UaNGnajQwfDGDLEMKZNM4ylSw3j558N48wZw7iOXzGveR05IT8+Kznq5GbDWEhKObnZ1REVWIX+WckDN8s9zI3rTLySaCzqtMhY1GmRkXgl8do7XKe8/Gwyy4ekZjGMzOYJyV0JCQkULVqUZcuW0aVLF8f6vn37cv78eb744otrHuPixYsEBwezdOlSOnXqlO45Zs2axeTJk9m/f3+aWcHmz5/PE088kab73tWOHz/Ogw8+SJkyZfj444/TrRMfH+/UJSkmJoayZcty7ty5NF3+4uLiOHToEBUrVsTb2/ua15kbEhMT8fDwcMm5b8TEiRP54osv+PXXX7O8T3av8bXXXmPDhg1OLYhyW378XFwZ042cOy4ujoMHD1KhQoUsfX3Z7XZOnTpFUFAQ1lz4129uHD+3Y5bCQ89KzrgZ7mNBvMb8GLMrY7recyckmC2skrv6HTkCR45YOHIk5X1Cwo11TfHzM6hQASpUgIoVoWJFw7FcoQIUK5Zz15EV+fFZyVGnvse6oaXjrb3NdxCUSa8JyVChf1bywM1yD3PjOm1xNpbdb4533H1Jd9y9c7ZzW15+NjExMQQGBnLhwoVMh0Byafe906dPk5SUlO7U9Hv37s3SMUaNGkVYWBht2zqPw5SVaeqzolevXnzxxRdcuXKFzp07895772VY96WXXmLSpElp1p86dYq4uDindYmJidjtdmw2Gzab7brjyi7DMBxjJ2U0A1p+Y7fbHeNEZUVOXGNoaCgjR47Ms88oP34urozpRs9ts9mw2+2cOXMmSwktu93OhQsXMAwj15JSOX383I5ZCg89KznjZriPuXGN8UnxvLTd7MY+utFovNxydqDz/Pi5uDKmGzl3sWJw661mSXs8OHXKyrFjbhw96sbRo1aOHnXjyBE3Dh2ycOyYB3Fx6Z8nJsbCrl2QMomu88/x4sXtlCtno1y5JMqVS6JsWbNUqJBEWFgisbH6uXk9PM6fI/Uc1ufOnSPRULeiG1HYn5W8UOjvYWIiRT/8EMMwOH/PPTl6nbY4G/EJZkOX6OjoXElK5dVnczGz6WZTcfmYUtnx8ssvs3jxYjZt2pSmNURWpqnPihkzZjBhwgT++usvRo8ezYgRI3jrrbfSrZu8PVlyS6mgoKB0W0pdvHjRaWY4V8hvLXIyY7VasVgs132/snONvXr1uuF9syM/fi6ujOl6z+3u7o7VaqVEiRJZbillsVhytaVUTh8/t2OWwkPPSs64Ge5jblxjvC0eu7s5wUVwUHCOz76XHz8XV8aUG+cOCYFatdKe59SpU5QsGcTp0+bM6AcPmq2rDh60cPAgHDpkvrfZ0v+n0tmzVs6e9WTnzrTb3NwMypYNplo1K1WqWKha1aByZahSxWxp5el5/deRH5+VHGUJdHobGBgIQdf3d4+YCv2zkgcK/T2Mj8dy+DCGYRDg50dQcHCOJqW8PM2flcHBwbmSlMqrzyarPcJcmpQqWbIkbm5u6U5NnzxwdUZeffVVXn75Zb755htq166dZntWpqnPipCQEEJCQqhRowbFixenRYsWjBs3jtDQ0DR1vby8HANJp2a1WtN84MkJluSS1wzDcJw3v7TIuZZJkyal2xItIwXxGvNjzK6M6UbPnfx1ld7XXmb7XE/965Ubx8/tmKXw0LOSM26G+5jT12i1WrH810Imt+5dfvxcXBlTXp3bYrHg5mYlNNRKaCg0bZq2TlKSORh7ctIqOVmVvHzsmDlCVdr9LBw65M6hQ7BuHaRuZWW1mgOtV6liDgRfpUpKqVQJMvsbKD8+KznmqtktrRarRqPPhkL9rOSRQn0PPT2hXz8Mux2Lh0fO/9y0FI6fm1k9vkuTUp6enjRo0IANGzY4xpSy2+1s2LCBYcOGZbjftGnTePHFF/n6668ds7Jdy7Wmqc/qMSBrU9mLiIiIiNzM3NzMBFK5ctCyZdrt8fHmuFWpk1b//AP79xv89ZfB5ctp/6Cx283E1qFD8M03ztssFihTJm2yKrmFlYhIjnBzMzPxmn0vR7i8+96IESPo27cvDRs2pFGjRsycOZPLly/z8MMPA9CnTx9Kly7NSy+Z4xFMnTqV8ePHs2jRIipUqEBUVBQAxYoVo1ixYlmaph7gyJEjnD17liNHjpCUlMTO/9oOV6lShWLFirF69WpOnjzJ7bffTrFixfjjjz8YOXIkzZo1o0KFCnl6j0REREREChsvLzOBVLWq83q73eDkyWggmH/+sbJ/P+zfD3//nfIaE5P2eIYB//5rlm+/vXqrldDQIGrWtFC9Ok6lXDnzb0wREcl7Lk9KPfDAA5w6dYrx48cTFRVF3bp1Wbt2rWPw8yNHjjg1+3r77bdJSEige/fuTseZMGECEydOxM3Njb1797JgwQJOnz5NiRIluP3229m8eTO3phrBcfz48SxYsMDxvl69egBs3LiRVq1aUaRIEebOncuTTz5JfHw8ZcuW5b777uPZZ5/NzdshIiIiInLTs1ggOBhCQ6FZM+dthgFnzpAmWZVczp5N/5gnTrhx4kTahJW3t5kYuzpZVb06+PvnzvWJSAFmt5v9j+12yIdjARc0Lk9KAQwbNizD7nqbNm1yen/o0KFMj+Xt7c3y5cuvec758+czf/78DLe3bt2aLVu2XPM4IiIiIiKSdywWKFnSLE2apN1+9qxzkspMXBns22dw7lzaLoFxcfD772a5WqlSZnKqRg3nZFWFCuDCuYpExJUSE2HyZCyGAWPGuDqaAk/fSkVEREREpNAoXhwaNTJLMrvdIDo6Gqs1mL//trJvH05l/36w2dIe6+RJs/zvf87rPTzMsaqSk1Q1asCtt0LNmlCsWO5en4i4mMUCAQFms818MjlVQaaklIiIiIiI3BRKljS7BV7dJdBmMwda37cP9u51TlilN45xYiLs2WOWq1WoYCaoUpeaNaFo0Vy5JBHJa56eMHUqhgY6zxFKSkmea9WqFXXr1mXmzJkAVKhQgSeeeIInnngiV8+7b98+WrZsyd9//42vr2+unutann32WS5fvswbb7zh0jhERERExOyKlzzoeqdOztvOnydNy6p9+8yxrNKblDt5dsBVq1LWWSzmDIC33eacrKpRwxzTSkTkZpW2U7VIBjp37kz79u3T3bZ582YsFgu7du3K46iybvTo0Tz22GNOCamvv/6aJk2a4OvrS1BQEN26dUszbtmmTZuoX78+Xl5eVKlSJc1YZAsXLqRs2bIEBgYyYsQIp22HDh2iWrVqxFw1RczTTz/NggUL+Oeff677Oo4cOULHjh0pWrQowcHBjBw5Elt67c1TOXv2LL1798bPz4+AgAAiIyO5dOmSU51du3bRokULvL29KVu2LNOmTUtznKVLl1KjRg28vb2pVasWq1evzvCcgwcPxmKxOJKPV4uPj6du3bpYLBbH7JcAEydOxGKxYLFYsFqteHp6YrVa8fHxyfQaRURERHJDQAA0bgx9+sCLL8KyZeb4U5cvwz//wJo1MH069O9v1kvvf5+GYdb98kt46SX4v/+DevXAxweqVYOuXWHsWPjkE9i1K/1kV+ZB1oK2m1NKQK2cuHQRkVynllKSZZGRkXTr1o2jR49SpkwZp23z5s2jYcOG1K5d20XRZe7IkSOsXLnSqWXSwYMHuffeexkxYgQLFy7kwoULPPnkk9x333388ssvjjodO3Zk8ODBLFy4kA0bNjBgwABCQ0OJiIjg9OnTDBgwgPnz51OpUiU6duzInXfeSaf//sX26KOP8vLLL+Pn5+cUT8mSJYmIiODtt9/mlVdeyfJ1JCUl0bFjR0JCQtiyZQsnTpygT58+eHh4MGXKlAz36927NydOnGD9+vUkJiby8MMPM2jQIBYtWgRATEwM7dq1o23btrzzzjv8/vvv9O/fn4CAAAYOHAjAli1b6NWrFy+99BKdOnVi0aJFdOnShV9++YXbbrvN6Xyff/45P/74I2FhYRnG9MwzzxAWFsZvv/3mtP7pp59m8ODBABiGgc1mo3379tx+++1Zvk8iIiIiuc3NzWz9VLEipP6/rWHAv//CH384lz//NBNZqdntZourv/+GFSucj121qtma6rbboHZtqFvXPFe6Q9h4+kNw81y4ShFJIzERPvjA/AK+ummlXDe1lJIs69SpE0FBQWlaCl26dImlS5cSGRnJmTNn6NWrF6VLl6Zo0aLUqlWLTz755LrOc/78eQYMGEBQUBB+fn7ceeedjsTFoUOHsFqt/Pzzz077zJw5k/Lly2O329M95pIlS6hTpw6lS5d2rNuxYwdJSUlMnjyZypUrU79+fZ5++ml27txJYmIiAO+88w4VK1Zk+vTp1KxZk2HDhtG9e3dmzJgBwD///IO/vz8PPPAAt99+O61bt2bPf4MLfPLJJ3h4eHDfffelG1Pnzp1ZvHjxdd2bdevW8eeff/Lxxx9Tt25dOnTowAsvvMCbb75JQkJCuvvs2bOHtWvX8t5779G4cWOaN2/OG2+8weLFizl+/DhgtvZKSEjggw8+4NZbb6Vnz54MHz6c1157zXGcWbNm0b59e0aOHEnNmjV54YUXqF+/PrNnz3Y637Fjx3jsscdYuHAhHhlMkbpmzRrWrVvHq6++mmZbsWLFCAkJcZSTJ0/y559/EhkZeV33SkRERMQVLBYoVw46dICnn4Z582D7doiJMcet+uorePlleOghqF8fihRJe4ykJHNsq88+g0mToFs3qFzZbLV1xx3w2GPw/vuwY4c5e6CI5CG7HX75Bcuvv5rLki1KSuUThmFgi7O5pBiGkaUY3d3d6dOnD/Pnz3faZ+nSpSQlJdGrVy/i4uJo0KABq1atYvfu3QwaNIiHHnqI7du3Z/le9OjRg+joaNasWcOOHTuoX78+bdq04ezZs1SoUIG2bdsyb948p33mzZtHv379sFrTf6Q3b95Mw4YNndY1aNAAq9XKvHnzSEpK4sKFC3z00Ue0bdvWkUzZunUrbdu2ddovIiKCrVu3AlC1alViY2P59ddfOXv2LD/99BO1a9fm3LlzjBs3Lk3CJrVGjRpx9OhRp+6CFStW5Pnnn89wn61bt1KrVi1KlSrlFE9MTAx//PFHhvsEBAQ4XX/btm2xWq1s27bNUeeOO+7A09PT6bj79u3j3LlzWboXAHa7nYceeoiRI0dy6623phvPyZMnGThwIB999BFFszDi57x586hWrRotWrS4Zl0REclf3K3u9KrVi161euFuVQN9ublZreYg6J06wahR8OGHZlLp4kVz9r8vvoApU6B3b7NVlJdX2mPExMDmzTB7NgwYAA0bmrP93Xab2SXw1Vdh/Xo4dSqvr07kJuLuDr16YfTsaS5LtugO5hNJ8Uks7bE0z85nYGDYDSxWC/cvvR9376w9Cv379+eVV17hu+++o1WrVoCZNOjWrRv+/v74+/vz9NNPO+o/9thjfP311yxZsoRGqeflzcD333/P9u3biY6Oxuu/n8SvvvoqK1asYNmyZQwaNIgBAwYwePBgXnvtNby8vPjll1/4/fff+eKLLzI87uHDh9MkpSpWrMi6deu4//77eeSRR0hKSiI8PNxpnKSoqCinBBBAqVKliImJ4cqVKwQGBrJgwQL69OnDlStX6NOnDxEREURGRjJs2DAOHjzIPffcQ2JiIhMnTqR79+6O4yR3bTt8+DAVKlQAoHLlypQsWTLD68gonuRtGe0THBzstM7d3Z3ixYs79omKiqJixYoZHtfX1zfDc6c+79SpU3F3d2f48OHpxmIYBv369WPw4ME0bNgwzfhdV4uLi+OTTz5h1KhRmdYTEZH8yc3qRqsKrVwdhki+5uZmtoKqXBnuuSdlfVKSOQ7Vrl3w22+wc6f5euSI8/5JSSldBBcuTFkfFmYmt+rUMV/r1jXP4eaW+9ckUqi5uUGrVmYrKc2+l21KSsl1qVGjBk2bNuWDDz6gVatW7N+/n82bNzta9yQlJTFlyhSWLFnCsWPHSEhIID4+PkstYgB+++03Ll26RIkSJZzWX7lyhQMHDgDQpUsXhg4dyueff07Pnj2ZP38+rVu3diR20nPlyhW8r5raJCoqioEDB9K3b1969erFxYsXGT9+PN27d2f9+vVY0u2wn1bXrl3p2rWr4/13333Hrl27eOONN6hSpQqffPIJISEhNGrUiDvuuMORICryX1vt2NhYx77ffPPNNQctz6927NjB66+/zi+//JLhvXvjjTe4ePEio0ePztIxP//8cy5evEjfvn1zMlQRERGRfC95XKmqVc3ue8nOnnVOUu3cCUf+uUjloL2OOnuP1+D4cV+OH4fU89IULZoyPlVysqp2bXO9iIgrKCmVT7h5udFjaY88O1/yANLu7u64eV3fv0siIyN57LHHePPNN5k3bx6VK1emZcuWALzyyiu8/vrrzJw5k1q1auHj48MTTzyR4XhHV7t06RKhoaFs2rQpzbaAgAAAPD096dOnD/PmzeO+++5j0aJFvP7665ket2TJko5uaMnefPNN/P39nWaZ+/jjjylbtizbtm2jSZMmjjGNUjt58iR+fn6OpFJq8fHxPProo3z00Ufs378fm83muDfVqlVj27ZtdO7cGTBnxAMICgrK/KakEhISkqYrZHJ8ISEhGe4TfVUG32azcfbsWcc+GV1n6uNmVCd5++bNm4mOjqZcuXKO7UlJSTz11FPMnDmTQ4cO8e2337J161ZHK7hkDRs2pHfv3ixYsMBp/fvvv8/dd9+dpoWWiIgUDHbDzv6z+wGoUrwKVotGjhDJruLFoXVrsyRLPP4bHptShjp47MvNLFzXnKt+/SU2Fn780SzJ3NygZk1o0CCl1K2rRJVIhgzD7CNrt5vLki1KSuUTFosly13ocoJhGGAzu3FltUVQsvvvv5/HH3+cRYsW8eGHHzJkyBDHMX744Qfuvfde/u///g8wxxj666+/uOWWW7J07Pr16xMVFYW7u3umLZ8GDBjAbbfdxltvvYXNZstwMPFk9erV488//3RaFxsbm2YMKrf/2jMnD5h+dXc+gPXr1xMeHp7ueSZPnkz79u2pX78+v/76q1Orp8TERJKSkhzvd+/ejYeHR4ZjL6UnPDycF198kejoaEeLq/Xr1+Pn55fhPQ4PD+f8+fPs2LGDBg0aAPDtt99it9tp3Lixo86YMWNITEx0jKe1fv16qlevTmBgIDabjfDwcDZs2MATTzyR7r146KGH0h1z6qGHHuLhhx8GzMHSJ0+e7Nh+/PhxIiIi+PTTTx2xJDt48CAbN25k+fLlWb4/IiKSvyQmJTJ9y3QAZnWYhZd7OoPkiEi2eVz1Z8Qbs2BWkDkLYOoWVTt3ml0CU0tKgt27zZL8/0GrNW2iqk4dc/wqkZteQgKMG4fFMGDMGFdHU+ApKSXXrVixYjzwwAOMHj2amJgY+vXr59hWtWpVli1bxpYtWwgMDOS1117j5MmTWU5KtW3blvDwcLp06cK0adOoVq0ax48fZ9WqVXTt2tUxLlTNmjVp0qQJo0aNon///um2WkotIiKCAQMGkJSU5Eg8dezYkRkzZvD88887uu8999xzlC9fnnr16gEwePBgZs+ezTPPPEP//v359ttvWbJkCatWrUpzjj///JNPP/2UX3/9FTC7OlqtVt5//31CQkLYu3cvt99+u6P+5s2badGihVPsbdu25Z577slwTKZ27dpxyy238NBDDzFt2jSioqIYO3YsQ4cOdbQ+2r59O3369GHDhg2ULl2amjVr0r59ewYOHMg777xDYmIiw4YNo2fPno5xrR588EEmTZpEZGQko0aNYvfu3bz++uuOWQYBhg8fTqtWrZg+fTodO3Zk8eLF/Pzzz8yZMweAEiVKpOl26eHhQUhICNWrVwdwakUF5rME5lhaZcqUcdr2wQcfEBoaSvvUcyyLiEiBYrFYCPUNdSyLSN5JngWwXDnnsapiYsxxqnbuhF9/NQdb/+MPSD2ChN2eMk7Vhx+mHK9GDedEVb16SlTJTapIEbWSyiFKSskNiYyMdHStSk5sAIwdO5Z//vmHiIgIihYtyqBBg+jSpQsXLlzI0nEtFgurV69mzJgxPPzww5w6dYqQkBDuuOOONF24IiMj2bJlC/3797/mcTt06IC7uzvffPMNERERANx5550sWrSIadOmMW3aNIoWLUp4eDhr1651JIoqVqzIqlWrePLJJ3n99dcpU6YM7733nuMYyQzDYNCgQbz22mv4+PgA5phR8+fPZ+jQocTHxzN79mxKly7t2Gfx4sVMnDjR6TgHDhzg9OnTGV6Hm5sbK1euZMiQIYSHh+Pj40Pfvn2dZuyLjY1l3759JCYmOtYtXLiQYcOG0aZNG6xWK926dWPWrFmO7f7+/qxbt46hQ4fSoEEDSpYsyfjx4xk0aJBjpsWmTZuyaNEixo4dy3PPPUfVqlVZsWIFt9122zXv//Wy2+3Mnz+fvn37OpKIIiJS8Hi6eTKx1URXhyEiqfj5QfPmZkkWF2cmqnbsSCm7dzsnqgwD9uwxy8cfm+ssFqhePW2iytc3b69JJE95ecHMmRga6DxHWAxD6b3cEhMTg7+/PxcuXMDPz89pW1xcHAcPHqRixYppBuDOC6nHlCqo/7l84YUXWLp0Kbt27Up3+9XX+Oabb/Lll1/y9ddf53Gkaa1Zs4annnqKXbt24Z5qGtH8+Lm4MqYbPff1fn3Z7XZHl8iru3TmhNw4fm7HLIWHnpWccTPcx4J4jfkxZlfGlFfn1s/NfCj6e/gmZUwp2m6G4OYZ18+CuDgzMZU6UfX775Dq/57psligWjUzQdWoETRubCaqvApI791C/6zkgZvlHubGddribCztsRSAHkt75PgQP3n52WSWD0lNLaWkwLl06RKHDh1i9uzZTuMTXcsjjzzC+fPnuXjxIr4u/vfN5cuXmTdvnlNCSkREREQkv/D2hoYNzZIsPj79RFXqOY0MA/btM8uiReY6Dw8zMdW4sVmaNIFKlcwElojc3PQXsRQ4w4YN45NPPqFLly5Z6rqXzN3dnTH5ZCC67t27uzoEERGRXJeQlMCUzVMAeK7Fc3i6ebo4IhHJDi+vlG56yRISnBNVv/xiDqyeOlGVmAjbt5vljTfMdSVLmi2pmjQxE1WNGsF/k22L5G82m9mH1W6Hdu1cHU2Bp6SUFDjz589n/vz5rg5DRERErsEwDE5cPOFYFpHCx9MT6tc3y8CB5rrERLMF1bZtKWXvXuf9Tp+G1avNkqxGDefWVLVqgToWSL6TlARbt5qz77Vp4+poCjx9iYuIiIiIiEiO8fBISVQNGWKuO3cOfvrJTFD9+KP5euaM835795plwQLzfZEiZqus5CRV48ZQpoy6/YmLublBt27mQOealCnblJQSERERERGRXBUYaPZ0Su7tZBjwzz8pCapt2+DXX50HUr9yBb7/3izJQkPNBFWzZtCyJdStq9ZUksfc3c0HWbPv5Qh9+YqIiIiIiEiesligcmWz9O5trouLg507nVtTHTzovN+JE/D552YB8PU1E1R33GGW2283uxSKSMGgpJSIiIiIiIi4nLe32QqqSRN4/HFzXXS089hU27dDTEzKPhcvwtq1Zkk+Rni42YrqjjvMLn9Fi+b9tUghZhhw4YLZUkrjJWabklIiIiIiIiIFmXcQVOjt/L6QCA6Gzp3NAmYe4M8/4X//M8t330FUVEr9uDjYuNEsYI5v1ahRSkuqZs3M1lUiNywhAUaNMgc6zyezuxdkSkqJiIiIiIgUZH7VoenHro4iT1itcNttZnn0UbOhyv79zkmqw4dT6icmwg8/mOWll8z969dPaUnVvDkUL+6665ECympVK6kcoqSU5KpWrVpRt25dZs6c6epQRERERESkkLFYoGpVs0RGmusOH05JUv3vf/DXXyn17Xb4+WezTJ9u7l+rVkpLqubNNbufXIOXF7z9tjn7ngY6zzarqwOQgqVfv35YLBYGDx6cZtvQoUOxWCz069fPsW758uW88MIL2T5nly5dsnWM7FiwYAHNmzcHzOtp164dJUqUwGKxsHPnzjT14+LiGDp0KCVKlKBYsWJ069aNkydPXvd5jxw5QseOHSlatCjBwcGMHDkSm82W6T5nz56ld+/e+Pn5ERAQQGRkJJcuXXKqs2vXLlq0aIG3tzdly5Zl2rRpaY6zdOlSatSogbe3N7Vr12bNmjVO2w3DYPz48YSGhlKkSBHatm3L33//nW5M8fHx1K1bN839OnToEBaLJU358ccfs3iHRERERETSKl8eHnoI5s6Fffvg+HH49FOzZdVttznXNQzYtQtmz4b774ewMCutWpXgqacsrF0LsbGuuQaRm4WSUnLdypYty+LFi7ly5YpjXVxcHIsWLaJcuXJOdYsXL45vAe+0/cUXX3DPPfcAcPnyZZo3b87UqVMzrP/kk0/y1VdfsXTpUr777juOHz/Offfdd13nTEpKomPHjiQkJLBlyxYWLFjA/PnzGT9+fKb79e7dmz/++IP169ezcuVK/ve//zFo0CDH9piYGNq1a0f58uXZsWMHr7zyChMnTmTOnDmOOlu2bKFXr15ERkby66+/cu+999K9e3d2797tqDNt2jRmzZrFO++8w7Zt2/Dx8SEiIoK4uLg0MT3zzDOEhYVlGPM333zDiRMnHKVBgwbXc6tERERERDIVGmomnN58E37/HU6fNmfve/JJaNDA7ImV2r59HsycaaFDBwgMhLZt4ZVX4LffzJZWIpJzlJSS61a/fn3Kli3L8uXLHeuWL19OuXLlqFevnlPdVq1a8cQTTzjeV6hQgSlTptC/f398fX0pV66cU0LkRnz33Xc0atQILy8vQkNDefbZZ51aFC1btoxatWpRpEgRSpQoQdu2bbl8+TIAmzZtolGjRvj4+BAQEECzZs04nKoTelxcHOvWrXMkpR566CHGjx9P27Zt043lwoULvP/++7z22mvceeedNGjQgHnz5rFly5bragG0bt06/vzzTz7++GPq1q1Lhw4deOGFF3jzzTdJSEhId589e/awdu1a3nvvPRo3bkzz5s154403WLx4McePHwdg4cKFJCQk8MEHH3DrrbfSs2dPhg8fzmuvveY4zuuvv0779u0ZOXIkNWvW5IUXXqBevXrMnj0bMFtJzZw5k7Fjx3LvvfdSu3ZtPvzwQ44fP86KFSucYlqzZg3r1q3j1VdfzfBaS5QoQUhIiKN4eHhk+T6JiIiIiFyvEiWgSxd47TWzG9/Zs7B6NTz7LDRubGC1powVlJAAGzbAM89A3boQFma2wvroI+cB1uUmYrPBJ5+Y5Ro9WeTalJTKZ+Jt8ddd7EZKut5u2Im3xZOYlJil496o/v37M2/ePMf7Dz74gIcffjhL+06fPp2GDRvy66+/8uijjzJkyBD27dt3Q3EcO3aMu+++m9tvv53ffvuNt99+m/fff5/JkycDcOLECR588EH69+/Pnj172LRpE/fddx+GYWCz2ejSpQstW7Zk165dbN26lUGDBmFJ1Yl8w4YNlC5dmho1amQpnh07dpCYmOiUtKpRowblypVj69atjnUVKlRg4sSJGR5n69at1KpVi1KlSjnWRUREEBMTwx9//JHhPgEBATRs2NCxrm3btlitVrZt2+aoc8cdd+Dp6el03H379nHu3DlHnauTbnfddZcjqXbw4EGioqKc6vj7+9O4cWOnazx58iQDBw7ko48+omgm8/Dec889BAcH07x5c7788ssM64mIiIhIBs7+Cmvqp5Szv7o6ogLF3x86dDAHQt+yxeCPP6JZssTOoEFmV8DUTp6Ejz+GPn3MFlh16sDIkbB+vTnzn9wEkpJg0yYs331nLku2aKDzfGb4muHXvc+gBoNoEGZ2efr1xK/M2TGHaiWq8VTTpxx1ntvwHJcSUsYWMjAw7AZz7rmxVkr/93//x+jRox2tin744QcWL17Mpk2brrnv3XffzaOPPgrAqFGjmDFjBhs3bqR69erXHcdbb71F2bJlmT17NhaLhRo1anD8+HFGjRrFuHHjiIqKwmazcd9991H+v58otWrVAszxly5cuECnTp2oXLkyADVr1nQ6fuque1kRFRWFp6cnAQEBTutLlSpFVKp/pVSuXJmSJUtmepzUCankYyRvy2if4OBgp3Xu7u4UL17csU9UVBQVK1bM8LiBgYEZnjv1MVLvl14dwzDo168fgwcPpmHDhhw6dChNvMWKFWP69Ok0a9YMq9XKZ599RpcuXVixYsV13XMREcm/3KxudKrWybEsIrnEdhnO/er8Xm5YQIBBt27Qo4c55tTff8O6dWbZuBFSD9m6a5dZXn0VvL3NWf3atTPLrbdq0PRCyc0NOnUyBzp308+27FJSSm5IUFAQHTt2ZP78+RiGQceOHTNNsqRWu3Ztx7LFYiEkJIToG5y1YM+ePYSHhzu1bmrWrBmXLl3i6NGj1K5dmzZt2lCrVi0iIiJo164d3bt3JzAwkOLFi9OvXz8iIiK46667aNu2Lffffz+hoaGAmVj56quvWLJkyQ3FlpkNGzbk+DHzkzfeeIOLFy8yevToDOuULFmSESNGON7ffvvtHD9+nFdeeUVJKRGRQsLd6k7n6p1dHYaIyA2zWKBaNbMMG2Z25/vxR/j6azNJtWOHmbgCs6XU11+bBcyWVMkJqrZt4ar/H0tB5e4OnTubA4xp9r1sU1Iqn5nVYdZ17+PhljIGT73QeszqMAurxbln5pQ2U5zeJ3dfy47+/fszbNgwAN58880s73f1mEEWiwV7Lo0Y6Obmxrp169i6dSvr1q3jjTfeYMyYMWzbto2KFSsyb948hg8fztq1a/n0008ZO3Ys69evp0mTJmzfvh2bzUbTpk2zfL6QkBASEhI4f/68U2upkydPEhIScl3H+emnn5zWJc/gl9Fx0kvu2Ww2zp4969gnJCQkzUyAVx83ozqptyevS07gJb+vW7cuAN9++y1bt27Fy8vL6TgNGzakd+/eLFiwIN1raNy4MevXr093m4iIiIiIq3l6wh13mOXFF81B0zdsMBNUX38Nx46l1D1xAhYsMAtAvXpmN8F77oHbb087wLrIzUhfBvmMl7vXdZfUCSirxYqXu5dToiqz42ZH+/btSUhIIDExkYiIiGwd60bVrFmTrVu3YhgpgxH+8MMP+Pr6UqZMGcBMejVr1oxJkybx66+/4unpyeeff+6oX69ePUaPHs2WLVu47bbbWLRoEWB23evYsSNu19Eks0GDBnh4eDi1hNq3bx9HjhwhPDw8y8cJDw/n999/d0oyrV+/Hj8/P2655ZYM9zl//jw7duxwrPv222+x2+00btzYUed///sfiYkpY46tX7+e6tWrExgY6KhzdUuuDRs20KRJEwAqVqxISEiIU52YmBi2bdvmuMZZs2bx22+/sXPnTnbu3Mnq1asB+PTTT3nxxRczvO6dO3c6JbpERKRgMwyD4xePc/zicaef1SIihUXJkvDAA/D++/Dvv/DHHzBjhpl8KlLEue6vv8KUKdCkCZQuDYMGwcqVkGpScykIDANiY82in23ZppZScsPc3NzYs2ePYzk3XbhwgZ07dzqtK1GiBI8++igzZ87kscceY9iwYezbt48JEyYwYsQIrFYrP/74I5s2bSIiIoLg4GC2bdvGqVOnqFmzJgcPHmTOnDncc889hIWFsW/fPv7++2/69OkDwJdffsnzzz/vdM6zZ89y5MgRx2x2yQO0J88c5+/vT2RkJCNGjKB48eL4+fnx2GOPER4e7kjqALRp04auXbs6WppdrV27dtxyyy089NBDTJs2jaioKMaOHcvQoUMdrY+2b99Onz59HIOx16xZk/bt2zNw4EDeeecdEhMTGTZsGD179iQsLAyABx98kEmTJhEZGcmoUaPYvXs3r7/+OjNmzHCc+/HHH6dly5ZMnz6djh078sknn7Bjxw7HLIkWi4UnnniCyZMnU7VqVSpWrMi4ceMICwujS5cuAJQrV87peooVKwaYY2klJwsXLFiAp6enY8bG5cuX88EHH/Dee+9d63EQEZECIiEpgUmbJgFma/Ds/kNMRCQ/s1jgllvM8sQTZne+LVtSuvql/nMmKgrmzjVL0aJmF7977oGOHdXNL99LSIAnn8RiGDBmjKujKfCUlJJs8fPzy5PzbNq0yZG8SBYZGcl7773H6tWrGTlyJHXq1KF48eJERkYyduxYAHx9fdm8eTOvv/46MTExlC9fnunTp9OhQwdOnjzJ3r17WbBgAWfOnCE0NJShQ4fyyCOPcODAAfbv35+mBdiXX37pNMtgz549AZgwYYJjNr0ZM2ZgtVrp1q0b8fHxRERE8NZbbzkd58CBA5w+fTrD63Vzc2PlypUMGTKE8PBwfHx86Nu3r1OSLDY2ln379jm1elq4cCHDhg2jTZs2jhhmzUrpEurv78+6desYOnQoDRo0oGTJkowfP55BgwY56jRt2pRFixYxduxYnnvuOapWrcqyZcu47bbbHHWeeeYZLl++zKBBgzh//jzNmzdn7dq1eHt7Z3hN6XnhhRc4fPgw7u7u1KhRg08//ZTu3btf1zFERCR/K+ZZzNUhiIi4hLc33HmnWaZONRNRK1fCl186z9YXGwsrVpjFYoHwcDNBde+9UL26BkuXws1iqC11romJicHf358LFy6kSd7ExcVx8OBBKlaseN1/yOeE5DGl3N3dnQYJL0yyc42vvfYa33zzjaPbWV7Jj5+LK2O60XNf79eX3W4nOjqa4OBgrLnQuT83jp/bMUvhoWclZ9wM97EgXmN+jNmVMeXVufVzMx+K/h6+aZHyvu1mCG7uungKsLx6VmJj4Ztv4Isv4Kuv4NSp9OtVrWomqO65B5o2NcfYzu8K/debYYDdbl7n6dMElyqVY9dpi7OxtMdSAHos7YG7d85+4Hn52WSWD0mtED4hItlXpkyZTGeOExERERERuVFFi5qJpvffNwdE37IFnn3W7PqX2t9/w/Tp0LIlhIRA377w2Wdw8aJr4hbMpmtubmbJJw0JCjIlpUTScf/999OiRYtrVxQREREREckGNzezy95LL5kDpadORKVuzHLmDHz4IXTvbg6wfvfd8M47zjP+iRQ0SkqJiIiISK5ITEpk+pbpTN8yncSkxGvvICIiVKkCI0bApk0QHQ0ffQQ9ekCxVEP0JSTAmjUwZAiUKQMNG8KLL8L+/S4L++Zhs5nN1T77zFyWbFFSSkRERERyhd2w89eZv/jrzF/YDburwxERKXBKlID/+z9YsgROn4a1a+HRR81EVGo7dsDYseYYVLffbra0OnrUNTEXeklJsG4dlvXrzWXJFiWlXEzjzIvkPH1diYiIiEhh4+UFERHw5ptw5Aj88gtMnAhXTVLOzz/D009D2bJwxx3w1ltmiyvJIW5u0K4dxl13mcuSLQVg7P7Cye2/hzchIYEiRYq4OBqRwiU2NhYADw8PF0ciIiIikgdKhsP9l1LeW/N+dm/JWxaLmYyqVw8mTIDDh83WVIsXm8mqZJs3m2X4cGjTBnr2hK5dISDAZaEXfO7u0K0b2O3K9uUAJaVcxN3dnaJFi3Lq1Ck8PDzyfKpMwzCw2Wy4u7tjKaQzBhTEa8yPMbsypus9t2EYxMbGEh0dTUBAgCP5KyIiIlKoWd3A6uPqKMSFypeHkSPN8tdfZnLqk09g715z+389zli3DgYPhg4dzARV587go0dHXEhJKRexWCyEhoZy8OBBDh8+nOfnNwwDu92O1WrNN8mPnFYQrzE/xuzKmG703AEBAYSEhORiZCIiIiIi+VO1ajB+PIwbB7//bianFi+GQ4fM7QkJ8MUXZila1ExM9eoF7dubXQTlGgzDbCVlt5vLki1KSrmQp6cnVatWJSEhIc/PbbfbOXPmDCVKlMjzVlp5pSBeY36M2ZUx3ci5PTw81EJKRERERG56FgvUrm2WKVNg+3YzQbVkCZw4YdaJjYVPPzWLv7/Zta9XL7jzTrOXmqQjIQGGD8diGDBmjKujKfD0mLmY1WrF2zvv+3zb7XY8PDzw9vbON8mPnFYQrzE/xuzKmPLj/RARERERKWgsFmjc2CzTp5vjTH3yCSxbBmfPmnUuXID5880SFATdu5sJqmbNQL+KS27RoyUiIiIiIlKQXTkBf7+bUq6ccHVEko+5uUGrVvDuuxAVBatXQ58+4OubUufUKXj7bXP2vnLlzFn+kpJcFXE+4+kJM2ZgvPaauSzZoqSUiIiIiIhIQXbxAPw0OKVcPODqiKSA8PAwBz1fsMCcSO6zz6BHD0jdmefYMZg0CT7/3HVx5isWizkYV9Gi5rJki5JSIiIiIiIiIjc5b2+47z5zzKnoaPj4Y2jXLmX7l1+6LjYpvDSmlIiIiIiIiIg4+PpC795mq6kSJeDSJVi71pxw7qYfX8pmgzVrzJvRoIGroynwbvbHSURERERERETS4ekJbduay6dOwY4dro0nX0hKgpUrsaxapYG2coBaSomIiIhIrnCzutGqQivHsoiIFDx33w0rVpjLq1fD7be7NBzX+2+keMNuN5clW5SUEhEREZFc4W51p1etXq4OQ0REsqFDh5TlNWtgwgTXxZIvuLtDr15m973oaFdHU+Cp+56IiIiIiIiIpKtMGahVy1zevt3sxieSU5SUEhEREZFcYRgGF+MvcjH+IoZhuDocERG5QXffbb4aBnz9tWtjkcJFSSkRERERyRUJSQk8ve5pnl73NAlJCa4OR0REbtDVXfhuavHxMGQIlkcfNZclW5SUEhEREREREZEMNW0Kfn7m8tq1mnQOu90skm0a6FxEREREcoWXuxfvdn7X1WGIiEg2eXjAXXfBZ5/B2bPw00/QpImro3IRT0+YOtWcfU8tpbJNLaVEREREREREJFPJ40oBrF7tujhczmKBgACzWCyujqbAU0spERERERGRgqxYRag33fm9SA5r3z5lefVqeP5518UihYeSUiIiIiKSKxKTEvng1w8A6F+vPx5uHi6OSKSQKloaao5wdRRSyIWFQd26sHMn7NgBJ09CqVKujsoFbDb49ltzTKnbbnN1NAVevui+9+abb1KhQgW8vb1p3Lgx27dvz7Du3LlzadGiBYGBgQQGBtK2bds09SdOnEiNGjXw8fFx1Nm2bZtTnRdffJGmTZtStGhRAgIC0pznt99+o1evXpQtW5YiRYpQs2ZNXn/99Ry5XhEREZGbgd2w88uJX/jlxC/YDQ0IKyJS0KXuwrd2revicKmkJPjsMyzLl2vE9xzg8qTUp59+yogRI5gwYQK//PILderUISIigujo6HTrb9q0iV69erFx40a2bt1K2bJladeuHceOHXPUqVatGrNnz+b333/n+++/p0KFCrRr145Tp0456iQkJNCjRw+GDBmS7nl27NhBcHAwH3/8MX/88Qdjxoxh9OjRzJ49O2dvgIiIiIiIiEgB0KFDyvKaNa6Lw6Xc3CA8HKNJE3NZssXl3fdee+01Bg4cyMMPPwzAO++8w6pVq/jggw949tln09RfuHCh0/v33nuPzz77jA0bNtCnTx8AHnzwwTTneP/999m1axdt2rQBYNKkSQDMnz8/3bj69+/v9L5SpUps3bqV5cuXM2zYsOu/UBEREREREZECrEkTc3zv8+fh66/NnmzuLs8q5DF3d+jXz+y+l0FjGsk6lz4+CQkJ7Nixg9GjRzvWWa1W2rZty9atW7N0jNjYWBITEylevHiG55gzZw7+/v7UqVMnW/FeuHAhw/MAxMfHE59qSsiYmBgA7HY7dnv+arJut9sxDCPfxZWTCuI15seYXRlTXp07t8+TG8fPj8+K5E96VnLGzXAfc+17FYZjOafvX378XPRzM38ePz8+K5I/6VnJnNUK7dpZWLLEwvnzsGWLnebNnevcLPcwN79XJS8X5J+bWT2HS5NSp0+fJikpiVJXjY5WqlQp9u7dm6VjjBo1irCwMNq2beu0fuXKlfTs2ZPY2FhCQ0NZv349JUuWvOFYt2zZwqeffsqqVasyrPPSSy85WmCldurUKeLi4m743LnBbrdz4cIFDMPAanV5L85cURCvMT/G7MqY8urcuX2e3Dh+fnxWJH/Ss5Izbob7mBvXGJ8Uz5UrVwCIPhWNl5tXjhw3WX78XPRzM38ePz8+KznJ4/w2SvzSxfH+TP0VJAY0dl1ABVhhf1ZyQrNm3ixZEgDAZ5/FUq3aJaftN8s9zI3rtMXZiE8wG7pER0fj7p2zKZu8/GwuXryYpXoFuqHdyy+/zOLFi9m0aRPe3t5O21q3bs3OnTs5ffo0c+fO5f7772fbtm0EBwdf93l2797Nvffey4QJE2jXrl2G9UaPHs2IESmzXsTExFC2bFmCgoLw8/O77vPmJrvdjsViISgoqNB+oyiI15gfY3ZlTHl17tw+T24cPz8+K5I/6VnJGTfDfcyNa4y3xVOkSBEAgoOC8XLP+aRUfvtc9HMzfx4/Pz4rOcoS6PQ2MDAQgq7/7x65CZ6VHNCjBzz+uLn8v//5MGNGUafthf4exsdjefZZDMPAMmIEQcHBOZqU8vI0f1YGBwfnSlIqrz6bq3M0GXFpUqpkyZK4ublx8uRJp/UnT54kJCQk031fffVVXn75Zb755htq166dZruPjw9VqlShSpUqNGnShKpVq/L+++87dRXMij///JM2bdowaNAgxo4dm2ldLy8vvLzS/rJltVrz5RejxWLJt7HllIJ4jfkxZlfGlFfnzu3z5Mbx8+OzIvmTnpWccTPcx5y+RqvVigWLYzk37l1+/Fz0czN/Hj8/Pis5xuJ8TVaL1exnJTekUD8rOSA0FBo2hJ9/hp07LURFWQgLc65TqO+h1QpxcWAYufNz01I4fm5m9fgufUI8PT1p0KABGzZscKyz2+1s2LCB8PDwDPebNm0aL7zwAmvXrqVhw4ZZOpfdbnca7ykr/vjjD1q3bk3fvn158cUXr2tfERERERERkcIo9Sx8a9e6Lg6X8PSEF17AeP55c1myxeVpyxEjRjB37lwWLFjAnj17GDJkCJcvX3bMxtenTx+n1k1Tp05l3LhxfPDBB1SoUIGoqCiioqK4dMnsx3r58mWee+45fvzxRw4fPsyOHTvo378/x44do0ePHo7jHDlyhJ07d3LkyBGSkpLYuXMnO3fudBxn9+7dtG7dmnbt2jFixAjHeU6dOpWHd0dEREREREQkf7n77pTl1atdF4dLWCwQHGyW/1o1yY1z+ZhSDzzwAKdOnWL8+PFERUVRt25d1q5d6xj8/MiRI07Nvt5++20SEhLo3r2703EmTJjAxIkTcXNzY+/evSxYsIDTp09TokQJbr/9djZv3sytt97qqD9+/HgWLFjgeF+vXj0ANm7cSKtWrVi2bBmnTp3i448/5uOPP3bUK1++PIcOHcqNWyEiIiIiIiKS791+O5QoAWfOwPr1kJgIHh6ujkoKIpcnpQCGDRvGsGHD0t22adMmp/fXSgh5e3uzfPnya55z/vz5zJ8/P8PtEydOZOLEidc8joiIiIiIiMjNxM0NIiJg0SKIiYEtW6BlS1dHlUeSkmDzZrDboXp1V0dT4Lm8+56IiIiIiIiIFCw3bRc+mw0++QTL4sXmsmSLklIiIiIikiusFiv1Q+tTP7S+ORuYiIgUGhERKUMqrVnj2ljylNUK9etj1KunWS5zQL7oviciIiIihY+HmwePNHzE1WGIiEguKFkSGjWCbdvg99/h33+hbFlXR5UHPDzgkUfM7nvR0a6OpsBTWk9ERERERERErluHDinLa9e6Lg4puJSUEhEREREREZHrdtOOKyU5Rt33RERERCRXxNviGb5mOACzOszCy93LxRGJFFLuRcC3mvN7kTzQoAEEBcGpU/DNN5CQAO6FPcuQkADjxmExDBg2zNXRFHiF/XEREREREREp3Io3gM77XB2F3ISsVmjfHj76CC5dgu+/h1atXB1VLjMMOH/efDUMV0dT4CkpJSIiIiK5wtPNk1fbvepYFhGRwufuu82kFJhd+Ap9UsrDA8aOxbDbzWXJFo0pJSIiIiK5wmKx4Ovli6+XL5bkecNFRKRQadfObDEFsGaNa2PJE1arOc1g2bIpFy43THdQRERERERERG5I8eLQpIm5/OefcOiQS8ORAkZJKRERERHJFTa7jU9+/4RPfv8Em93m6nBERCSXpJ6Fr9C3lkpKgi1bzJKU5OpoCjwlpUREREQkVyTZk9h0aBObDm0iya5f3EVyzcX9sP2RlHJxv6sjkptMhw4py2vXFvLu2jYbLFiA5cMPzWXJFg10LiIiIiIiUpBdiYL9c1LeV3gIfKu4Lh656dStCyEhEBUF334LcXGujigXWa1w220YhqExpXKA7qCIiIiIiIiI3DCrFdq3N5djYy38+GMhnnHVwwMeewyGDdPsezlASSkRERERERERyZbU40p9+62X6wKRAkVJKRERERERERHJlrvuAjc3c1lJKckqJaVEREREREREJFsCAqBpU3P5wAF3DhxwaTi5JyEBxo3DMn68uSzZoqSUiIiIiIiIiGRb6i58a9e6Lo5cZRgQHW0Ww3B1NAWeklIiIiIiIiIikm0dOqQsr15tcV0gucnDA555BmPkSA10ngOUlBIRERERERGRbKtdG8LCzNZDmzbBlSuujSdXWK1QubJZrEqpZJfuoIiIiIiIiIhkm8WS0loqLs7Cpk0uDUcKACWlRERERERERCRHtG+fMs7SmjUuDCS32O2wY4dZ7HZXR1PgKSklIiIiIiIiIjmibVtwdzcTU6tWFcKxwBMTYc4cLHPnmsuSLUpKiYiIiEiusFqsVCtRjWolqmG16NdOEZGbgZ8fNGqUAMA//8Dff7s4oJxmtUK1ahjVqmlMqRzg7uoARERERKRw8nDz4KmmT7k6DJHCL6AWtNno/F7Ehdq0iWfLFi/A7MJXrZqLA8pJHh7w1FNm173oaFdHU+AprSciIiIiIlKQefpDqVYpxdPfxQHJza5NmwTH8urVLgxE8j0lpUREREREREQkx1SrZqNsWXMwqe++g8uXXRyQ5FtKSomIiIhIroi3xfPU10/x1NdPEW+Ld3U4IiKSRywW6NDBXI6Ph40bM69foCQmwgsvwOTJGug8BygpJSIiIiK55lLCJS4lXHJ1GCIiksc6dEiZdq9QdeGz2+HoUSxHj5rLki0a6FxEREREcoWnmycTWk1wLItILkm8BBf/SnnvWw08irkuHhHgzjvB0xMSEszBzg3DbEFV4Hl4wBNPYNjt5rJki1pKiYiIiEiusFgshPmGEeYbhqVQ/CUikk+d2wlrG6SUcztdHZEIxYrBHXeYy4cOwd69Lg0n51itULOmWaxKqWSX7qCIiIiIiIiI5LjkcaWgkHXhkxyjpJSIiIiI5Aqb3cZX+77iq31fYbPbXB2OiIjksbvvTlles8Z1ceQoux1+/90sGlMq25SUEhEREZFckWRPYuVfK1n510qS7EmuDkdERPJY9epQsaK5/L//wcWLro0nRyQmwuzZWN58U7Pv5QAlpUREREREREQkx1ksKV34EhPh229dG0+OsFqhfHmM8uU1plQO0B0UERERERERkVyRugtfoRhXysMDnnsORo/W7Hs5QEkpEREREREREckVrVuDl5e5vHo1GIZr45H8RUkpEREREREREckVRYtCq1bm8tGj8McfLg1H8hklpUREREREREQk1xSqLnyJiTBtGrzyigY6zwFKSomIiIiIiIhIrkke7BxgzRrXxZEj7HY4cADLgQPmsmSLu6sDEBEREREREZHCq2pVqFIF9u+H77+HCxfA39/VUd0gDw8YMgTDbtdA5zlALaVEREREREREJFclt5ay2eCbb1wbS7ZYrVC3rlmsSqlkl+6giIiIiIhIQeZVEsr3TCleJV0dkUgaqceVKvBd+CTHqPueiIiIiIhIQeZfA5p94uooRDLVsiUUKQJXrphJKcMAi8XVUd0Au93sh2i3g5+fq6Mp8NRSSkRERERERERyVZEi0Lq1uXz8OOza5dp4blhiIkyfjuW11zT7Xg5QUkpEREREcoXFYiHUN5RQ31AsBfLf4SIikpNSd+Fbvdp1cWSLxQKhoWbRz7ZsU/c9EREREckVnm6eTGw10dVhiIhIPpE82DmYSanRo10Xyw3z9ISJE83Z96KjXR1NgaeWUiIiIiIiIiKS6ypVgurVzeWtW+HcOdfGI66npJSIiIiIiEhBdm4nrL09pZzb6eqIRDKU3IUvKQnWr3dtLOJ6SkqJiIiISK5ISEpg4qaJTNw0kYSkBFeHI1J4JV6Csz+nlMRLro5IJENXd+ErcBITYeZMeP11DXSeAzSmlIiIiIjkCsMwOHHxhGNZRETkjjugaFGIjYW1a8FuB2tBai5jt8OePVgMw1yWbFFSSkRERERyhYebB081fcqxLCIi4uUFbdrAV1/ByZPw66/QoIGro7oOHh7Qv7850LmHfrZlV0HKR4qIiIhIAWK1WKlWohrVSlTDatGvnSIiYkoeVwpgzRrXxXFDrFZo3NgsBaqJV/6kOygiIiIiIiIieabAjyslOUZJKRERERHJFUn2JDYd2sSmQ5tIsie5OhwREcknypeHW24xl3/8Ec6ccW0818Vuh0OHzKIxpbJNSSkRERERyRU2u41Pfv+ET37/BJvd5upwREQkH0nuwmcYsG6da2O5LomJ8NJLWF5+WbPv5QAlpUREREREREQkT6XuwlegklIWC5QoYRaLxdXRFHiafU9ERERERERE8lSzZlCkCFy5YialDKOA5Hg8PWHKFHP2vehoV0dT4KmllIiIiIiIiIjkKS8vuOMOc/n4cdizx7XxiGsoKSUiIiIiIiIiea5du5Tl9etdF4e4zv+3d+fxUVX3/8ffdyYbOwESFqWkCBRBIOwgUEFicENxAUG/FdEvWpWv1ohFpGXRIotALYIgoAUVhS62VX7KKrEsERQMIgVUKoJASCJLCEsmmXt/f1yZECAQyMzcmcnr+XjcR8+duTnnc+9cM+mHcz7X8aTUzJkzlZSUpLi4OHXu3FkbN24s9di5c+eqR48eio+PV3x8vFJSUs45fuzYsWrevLmqVKniO2bDhg0ljhk/fryuvfZaVa5cWTVr1jzvWE888YTat2+v2NhYJScnl/c0AQAAAADAGW64obgdNkmpwkLp1VelWbModO4HjialFi9erLS0NI0ZM0abN29WmzZt1KdPH2WXsi4zPT1dgwYN0urVq5WRkaGGDRsqNTVV+/bt8x3TrFkzzZgxQ1u3btXatWuVlJSk1NRU5eTk+I7xeDzq37+/Hn300QvG9+CDD+qee+7xz8kCAAAAQCDU6SL1P1q81enidERAmVxzjVSvnt1OT5c8HkfDKRvTlLZskbFli91GuTialJo2bZqGDh2qIUOGqEWLFpo9e7YqV66sN95447zHL1y4UI899piSk5PVvHlzzZs3T6ZpatWqVb5j7r33XqWkpKhx48Zq2bKlpk2bpry8PH355Ze+Y8aNG6ennnpKrVq1KjW26dOn6/HHH1fjxo39d8IAAAAA4G+uKCm6evHm4nlWCA+GIaWk2O3jx6WMDGfjKZOoKOl//kfWfffZbZSLY1fQ4/Fo06ZNGjlypO81l8ullJQUZZTxTjxx4oQKCwtVq1atUseYM2eOatSooTZt2vgl7gspKChQQUGBbz8vL0+SZJqmzBDLoJqmKcuyQi4ufwrHcwzFmJ2MKVhjB3qcQPQfivcKQhP3in9UhOsYsN9Vsnxtf1+/UPxc+N4Mzf5D8V5BaOJeKb9LvYYpKdLbb9vzZZYvt9SjhxXI8MrPMKRu3ezzzMkJyO+q0+1w/t4s6xiOJaVyc3Pl9XpVt27dEq/XrVtXO3bsKFMfI0aMUIMGDZRyOrX6kyVLlmjgwIE6ceKE6tevrxUrVqhOnTp+i700EyZM0Lhx4855PScnR6dOnQr4+JfCNE0dPXpUlmXJ5XK8tFhAhOM5hmLMTsYUrLEDPU4g+g/FewWhiXvFPyrCdQzEORZ4C3Ty5ElJUnZOtmLdsX7p97RQ/Fz43gzN/kPxXkFo4l4pv0u9hsnJLkmJkqSPPirU//3foQBH6B+BuFeKThWpwGNPdMnOzlZUnH9TNsG8v48dO1am48J2rtnEiRO1aNEipaenKy4ursR7vXr1UmZmpnJzczV37lwNGDBAGzZsUGJiYkBjGjlypNLS0nz7eXl5atiwoRISElS9evWAjn2pTNOUYRhKSEiI2F+24XiOoRizkzEFa+xAjxOI/kPxXkFo4l7xj4pwHQNxjgVFBapUqZIkKTEhUbFR/k9KhdrnwvdmaPYfivcKQhP3Svld6jVMTJSuucbSV18ZysyMVlRUokpZDBUaLEs6cMA+zxo1lJCY6NekVGyM/V2ZmJgYkKRUsO7vs/M0pXEsKVWnTh253W4dPHiwxOsHDx5UvdOVzkoxZcoUTZw4UStXrlTr1q3Peb9KlSpq0qSJmjRpoi5duqhp06Z6/fXXSywVDITY2FjFxp77x5bL5QrJX2iGYYRsbP4SjucYijE7GVOwxg70OIHoPxTvFYQm7hX/qAjX0d/n6HK5ZMjwtQNx7ULxc+F7MzT7D8V7xW9OZkn7lhTvX3GrVOnC/58KpYvoeyVILvUa3nCD9NVXkmUZSk83dPfdAQ6wPAoKpBdekGFZMkaN8v/3phEZ35tl7d+x/8piYmLUvn37EkXKTxct79q1a6k/N3nyZL3wwgtaunSpOnToUKaxTNMsUesJAAAAwVE1pqqqxlR1Ogwgsh37Vto4tHg79q3TEQGXJDW1uL1ihXNxlFnVqvaGcnN0+V5aWpoGDx6sDh06qFOnTnr55Zd1/PhxDRkyRJJ0//3364orrtCECRMkSZMmTdLo0aP1zjvvKCkpSVlZWZKkqlWrqmrVqjp+/LjGjx+v2267TfXr11dubq5mzpypffv2qX///r5x9+zZo0OHDmnPnj3yer3KzMyUJDVp0kRVf7qxvv32W+Xn5ysrK0snT570HdOiRQvFxMQE6QoBAACEr9ioWE3tM9XpMAAAIe6Xv5RiYiSPR1q+3F4h99OEodATGytNnSrLNKXsbKejCXuOJqXuuece5eTkaPTo0crKylJycrKWLl3qK36+Z8+eElO+Zs2aJY/Ho7vPmss3ZswYjR07Vm63Wzt27NCCBQuUm5ur2rVrq2PHjlqzZo1atmzpO3706NFasGCBb79t27aSpNWrV6tnz56SpP/93//VJ598cs4x3333nZKSkvx6HQAAAAAAqKgqV5a6dZNWr5Z275Z27ZKaNHE6KgSD44XOhw0bpmHDhp33vfT09BL7u3fvvmBfcXFxeu+99y465vz58zV//vwLHnP22AAAAAAAIDBuuMFOSkn2Ej6SUhUDldsAAAAQEIXeQk1dP1VT109VobfQ6XAAACEsbOpKFRZKr79ub4V8t5WX4zOlAAAAEJlMy9TXP37tawMAUJq2baXataUff5Q+/lgqKpKiQjFjYZrSxo0yLKtkJg2XJRQ/YgAAAESAaHe0Hm7/sK8NAEBpXC6pd2/pL3+Rjh6VPvtM6trV6ajOIypKGjDALnQeklmz8MLyPQAAAASEy3CpfYP2at+gvVwGf3YCAC7shhuK2yG7hM/ttrNnvXvbbZQLfx0AAAAAAADHhUVSCn5FUgoAAAABYVqmNu3fpE37N1FTCgBwUY0aSc2a2e1PP5Xy8pyN57wsyy589eOPdhvlQlIKAAAAAVHoLdScTXM0Z9Mcnr4HACiT07Olioqk9HRHQzk/j0d67jkZo0bZbZQLSSkAAAAAABASwmIJX0yMvaHcKBUPAAAAAOGsapKUPLnkPhCmevWy64d7vSGalIqNlV55xX76Xna209GEPZJSAAAAABDOKl8ptXjG6SgAv6heXerSRVq3Ttq5U9qzR/rZz5yOCoHC8j0AAAAAABAywmIJH/yCpBQAAAAAAAgZIZ2UKiqS3nrL3oqKnI4m7JGUAgAAAAAAIaNTJ3sZnyStWiWZprPxlOD1SmvXyli3zm6jXEhKAQAAAACAkBEVJV1/vd3OzZUyMx0NpyS3W7r9dlm33Wa3US4kpQAAAAAgnGWvld6NKt6y1zodEVBuZy7hW77cuTjOERUl3XyzvUXx7LjyIikFAAAAAOHO8hZvQAQI6bpS8BuSUgAAAAAAIKQ0aSIlJdnttWulEyccDaeYZUnHjtmbZTkdTdgjKQUAAAAAAEKKYRTPlvJ4pDVrnI3Hx+ORhg+X8cwzdhvlQlIKAAAAAACEnJCtKwW/oSoXAAAAAiI2Klav9X3N6TAAAGHq+uvtGVOWFUJ1pWJjpddek2WaUna209GEPWZKAQAAAACAkFO7ttShg93eulXKynI2HvgfSSkAAAAAABCSzlzCt3Klc3EgMC4rKbV371798MMPvv2NGzfqN7/5jebMmeO3wAAAABDeCr2Feu3z1/Ta56+p0FvodDgAgDAUcnWlioqkv/zF3oqKnI4m7F1WUuree+/V6tWrJUlZWVm64YYbtHHjRo0aNUrPP/+8XwMEAABAeDItU5sPbNbmA5tlWqbT4QAAwlDXrlLlynZ75Uq7vpSjvF5p1SoZH39st1Eul5WU+uqrr9SpUydJ0l/+8hddc801Wr9+vRYuXKj58+f7Mz4AAACEqShXlAa1GqRBrQYpysXzdQAAly42VurZ024fOCBt2+ZoOJLbLd10k6wbb7TbKJfL+uugsLBQsbGxkqSVK1fqtttukyQ1b95cBw4c8F90AAAACFtul1s9k3o6HQYAIMzdcIP04Yd2e8UK6ZprHAwmKkrq10/i6Xt+cVkzpVq2bKnZs2drzZo1WrFihW688UZJ0v79+1W7dm2/BggAAAAAuAB3nFT1quLNHed0RIBfhVxdKfjNZc2UmjRpku644w699NJLGjx4sNq0aSNJev/9933L+gAAAFCxmZapbw99K0lqUquJXAYPfgYConYH6bZvnY4CCJgWLaQGDaT9+6VPPpEKCuxlfY6wLMnjsWdKOV7gKvxdVlKqZ8+eys3NVV5enuLj432vP/zww6p8ugIZAAAAKrRCb6Gmrp8qSZp+03TFRjn1/yAAAOHMMOzZUgsWSCdPSuvXS716ORSMxyM98YQMy5JGjXIoiMhxWf9cdfLkSRUUFPgSUt9//71efvll7dy5U4mJiX4NEAAAAAAAVGxnLuFbscK5OOBfl5WUuv322/Xmm29Kko4cOaLOnTtr6tSp6tevn2bNmuXXAAEAAAAAQMWWklLcdrSuVEyMNH26rD/9yW6jXC4rKbV582b16NFDkvS3v/1NdevW1ffff68333xT06dP92uAAAAAAACgYqtbV2rd2m5v3iz9+KNDgRiGXdAqNtZuo1wuKyl14sQJVatWTZK0fPly3XnnnXK5XOrSpYu+//57vwYIAAAAALiAY7ukzx4v3o7tcjoiICBSU+3/tSxp1SpnY4F/XFZSqkmTJvrnP/+pvXv3atmyZUr96c7Izs5W9erV/RogAAAAAOACTh6Qvnm1eDt5wOmIgIAIibpSRUXSP/9pb0VFDgUROS4rKTV69GgNHz5cSUlJ6tSpk7p27SrJnjXVtm1bvwYIAAAAAADQo4e9ak6y60pZlgNBeL3SRx/JWLrUbqNcoi7nh+6++251795dBw4cUJs2bXyv9+7dW3fccYffggMAAAAAAJCkSpWk7t3tpXt79kjffCM1axbkINxuqXdvWaZpt1Eul5WUkqR69eqpXr16+uGHHyRJV155pTp16uS3wAAAAAAAAM6UmlpcT2rFCgeSUlFR0oABkmlK2dlBHjzyXNbyPdM09fzzz6tGjRpq1KiRGjVqpJo1a+qFF16QaZr+jhEAAAAAACA06krBby5rptSoUaP0+uuva+LEierWrZskae3atRo7dqxOnTql8ePH+zVIAAAAAACANm2khAQpJ0f6+GOpsFCKjnY6Klyuy0pKLViwQPPmzdNtt93me61169a64oor9Nhjj5GUAgAAAAAAfudySb17S4sWSceOSRs3Sj/NlQmOggLpiSdkWJY0alQQB45Ml7V879ChQ2revPk5rzdv3lyHDh0qd1AAAAAAAADnk5pa3GYJX3i7rKRUmzZtNGPGjHNenzFjhlq3bl3uoAAAABD+YtwxmpI6RVNSpyjGHeN0OACACOFoXamYGGnKFFkvvWS3US6XtXxv8uTJuuWWW7Ry5Up17dpVkpSRkaG9e/fqww8/9GuAAAAACE+GYahabDWnwwAARJgrr5SaN5d27JA2bJCOHpVq1AjS4IYhVatmP33v5MkgDRq5Lmum1HXXXaevv/5ad9xxh44cOaIjR47ozjvv1LZt2/TWW2/5O0YAAAAAAACf07OlvF5p9WpnY8Hlu6yZUpLUoEGDcwqab9myRa+//rrmzJlT7sAAAAAQ3orMIv11218lSf1b9leU67L/9AQAoITUVOmVV+z2ihVSv35BGrioSFq+3J4plZwcpEEjF38ZAAAAICC8plfpu9MlSXdefSdJKSBQal4jXb+i5D4Q4a67ToqKsnNEQa0r5fVK//qX/fS9Vq2COHBk4i8DAAAABITb5datzW71tQEESExNqV6K01EAQVWtmtS1q7RmjfTNN9Lu3VJSUhAGdrul7t1lmabdRrmQlAIAAEBARLmi1PcXfZ0OAwAQoW64wU5KSfZsqaFDgzBoVJT0q1/Zy/eys4MwYGS7pKTUnXfeecH3jxw5Up5YAAAAAAAAyiQ1VRo92m4HLSkFv7qkpFSNizxjsUaNGrr//vvLFRAAAAAig2VZOpB/QJJUv2p9GYbhcEQAgEjSoYNUs6Z05Ii0apVd7okVdeHlkpJSf/7znwMVBwAAACKMx+vRuPRxkqTpN01XbFSswxEBEarouHRsV/F+taukqCrOxQMEidstXX+99N570qFD0ubNUseOAR60oEAaPtwudP7MMwEeLPK5nA4AAAAAAFAOh76QPmpTvB36wumIgKC54YbidtCewufx2BvKjULnAAAAAAAgLKWmFrdXrJCeey7AA8bESC++aD99r6gowINFPmZKAQAAAACAsNS4sb1J0rp10vHjAR7QMKTate2NWonlRlIKAAAAAACErdNL+AoLpU8+cTYWXBqSUgAAAAAAIGwFta6U12s/6u/04/5QLiSlAAAAAABA2Lr+esn1U3Yj4EmpoiLpL3+R8de/UlPKD0hKAQAAAACAsBUfL3XsaLe3bZP27w/gYC6X1KmTrI4dizNhuGxcQQAAAAAAENaCtoQvOlp66CF7i44O4EAVQ0gkpWbOnKmkpCTFxcWpc+fO2rhxY6nHzp07Vz169FB8fLzi4+OVkpJyzvFjx45V8+bNVaVKFd8xGzZsKHHM+PHjde2116py5cqqWbPmecfas2ePbrnlFlWuXFmJiYl65plnVMT0PAAAAAAAQkpQ60rBbxxPSi1evFhpaWkaM2aMNm/erDZt2qhPnz7Kzs4+7/Hp6ekaNGiQVq9erYyMDDVs2FCpqanat2+f75hmzZppxowZ2rp1q9auXaukpCSlpqYqJyfHd4zH41H//v316KOPnnccr9erW265RR6PR+vXr9eCBQs0f/58jR492r8XAAAAAAAAlEuXLlLVqnZ75UrJspyNB2XjeFJq2rRpGjp0qIYMGaIWLVpo9uzZqly5st54443zHr9w4UI99thjSk5OVvPmzTVv3jyZpqlVq1b5jrn33nuVkpKixo0bq2XLlpo2bZry8vL05Zdf+o4ZN26cnnrqKbVq1eq84yxfvlz/+c9/9Pbbbys5OVk33XSTXnjhBc2cOVMej8e/FwEAAAAAAFy2mBipZ0+7ffCgtHVrgAYqKJCeflrG8OF2G+XiaFLK4/Fo06ZNSklJ8b3mcrmUkpKijIyMMvVx4sQJFRYWqlatWqWOMWfOHNWoUUNt2rQpc2wZGRlq1aqV6tat63utT58+ysvL07Zt28rcDwAAAAAACLwzl/AtXx7AgfLz7Q3lFuXk4Lm5ufJ6vSUSP5JUt25d7dixo0x9jBgxQg0aNCiR2JKkJUuWaODAgTpx4oTq16+vFStWqE6dOmWOLSsr67xxnX7vfAoKClRwRqY0Ly9PkmSapkzTLPPYwWCapizLCrm4/CkczzEUY3YypmCNHehxAtF/KN4rCE3cK/5REa5jIM4xyojS73/5e1/b39cvFD8XvjdDs/9QvFf8KjpeRsO7fLtWdLwUqecaYBF/rwSBk9ewd2/p9Nyb5cstpaUFYA1fVJT0+9/b5xnl3++209fudDucvzfLOoajSanymjhxohYtWqT09HTFxcWVeK9Xr17KzMxUbm6u5s6dqwEDBmjDhg1KTEwMWDwTJkzQuHHjznk9JydHp06dCti4l8M0TR09elSWZckVoY+xDMdzDMWYnYwpWGMHepxA9B+K9wpCE/eKf1SE6xioc4z66c/NnJM5Fzny0oXi58L3Zmj2H4r3in/VlprOKN4tkFRKjV5cWOTfK4Hn5DWsVUtq0CBB+/e7tWaNtGdPts5KFfjHT8moo0ePypL8dp5Fp4pU4LEnumRnZysqzr8pm2B+NseOHSvTcY4mperUqSO3262DBw+WeP3gwYOqV6/eBX92ypQpmjhxolauXKnWrVuf836VKlXUpEkTNWnSRF26dFHTpk31+uuva+TIkWWKrV69euc81e90nKXFNnLkSKWlpfn28/Ly1LBhQyUkJKh69eplGjdYTNOUYRhKSEiI2F+24XiOoRizkzEFa+xAjxOI/kPxXkFo4l7xj4pwHcPxHEMxZr43Q7P/ULxXEJq4V8rP6WuYmmpo/nzp1ClD33yT+NPsKf8LxHkWnSpSbEysJCkxMTEgSalgfTZnTxwqjaNJqZiYGLVv316rVq1Sv379JMlXtHzYsGGl/tzkyZM1fvx4LVu2TB06dCjTWKZpllhadzFdu3bV+PHjlZ2d7ZtdtWLFClWvXl0tWrQ478/ExsYqNjb2nNddLldI/kIzDCNkY/OXcDzHUIzZyZiCNXagxwlE/6F4ryA0ca/4R0W4jv4+xyKzSB9985Ek6aamNynK5f8/PUPxc+F7MzT7D8V7BaGJe6X8nLyGqanS/Pl2e+VKV4k6U37h9Urr10umKaNJE7+ep8vlkmEYvnYgrl+wPpuy9u/4f2VpaWmaO3euFixYoO3bt+vRRx/V8ePHNWTIEEnS/fffX2J206RJk/T73/9eb7zxhpKSkpSVlaWsrCzl/1Rk7Pjx43ruuef06aef6vvvv9emTZv04IMPat++ferfv7+vnz179igzM1N79uyR1+tVZmamMjMzff2kpqaqRYsW+tWvfqUtW7Zo2bJl+t3vfqfHH3/8vIknAAAAlOQ1vVry9RIt+XqJvKbX6XAAABXAmTOjVqwIwABFRdLbb8tYuNBuo1wcryl1zz33KCcnR6NHj1ZWVpaSk5O1dOlSX1HxPXv2lMiwzZo1Sx6PR3fffXeJfsaMGaOxY8fK7XZrx44dWrBggXJzc1W7dm117NhRa9asUcuWLX3Hjx49WgsWLPDtt23bVpK0evVq9ezZU263W0uWLNGjjz6qrl27qkqVKho8eLCef/75QF4OAACAiOF2udUzqaevDQBAoCUmSm3bSl98YW85OVJCgh8HcLmkNm3sguTMpis3x5NSkjRs2LBSl+ulp6eX2N+9e/cF+4qLi9N777130THnz5+v+afn9JWiUaNG+vDDDy/aFwAAAM4V5YrSoFaDnA4DiHyHt0gbf12832m2FN/GuXgAh91wg52QkqRVq6SBA/3YeXS09Nhj9hMueaBAuZHWAwAAAIBwVnhM+vHT4q2wbE+9AiLVmXWkVq50Lg5cHEkpAAAABIRlWTpWcEzHCo7ZyxwAAAiCbt2kmBi7fdbiK4QYklIAAAAICI/Xo+HLh2v48uHyeD1OhwMAqCAqVZK6dLHbu3ZJe/f6sXOPR3ruORmjRtltlAtJKQAAAAAAEFF69ixu+3W2lGVJP/5ob8wCLjeSUgAAAAAAIKL06lXc9mtSKjpaGjlS1rPP2m2US0g8fQ8AAAAAAMBfunSRYmOlggJp9Wo/duxySUlJPH3PT5gpBQAAAAAAIkpcnNS1q93+7jvp+++djQfnR1IKAAAAAABEnIDUlTJNacMGezNNP3VacZGUAgAAAAAAEScgdaUKC6U33pDx5z/bbZQLNaUAAAAAAEDE6dTJXsZ36pQf60q5XNLVV8uyLLuNcuEKAgAAAACAiHNmXanvv5d27/ZDp9HR0m9+Iz35JE/f8wOSUgAAAAAAICKduYTPr0/hg1+wfA8AAAAAwlmdztJdPxbvR1dzLhYgxJxd7HzIEKciwfmQlAIAAACAcOaKlmJrOR0FEJI6dZIqVZJOnrRnSlmWZBjl6NDjkV58UYZlSQ895Lc4KyqW7wEAAAAAgIgUGytde63d3rtX+u67cnZoWdKBA/ZmWeWOr6JjphQAAAACItodraevfdrXBgDACb16SatW2e3Vq6XGjcvRWXS09PTTskyTQud+wEwpAAAABITLcKlZ7WZqVruZXAZ/dgIAnHF2XalycbmkZs3szcV3W3kxUwoAAAAAwtnJg9KBj4r3698kVarrXDxAiOnYUapcWTpxwk91peA3JKUAAAAQEF7TqzV71kiSevysh9wut8MRARHq2DfSp2c8UixlDUkp4AwxMVK3btKKFdK+fdKuXVKTJpfZmWlKX35p/2+9en6NsyJirhkAAAACosgs0rtb39W7W99VkVnkdDgAgAqsV6/i9urV5eiosFCaNUvG7Nl2G+VCUgoAAAAB4TJcale/ndrVb0dNKQCAo/xWV8rlkq66StZVV1FTyg9YvgcAAICAiHZH65EOjzgdBgAA6tBBqlJFOn68nHWloqOl3/7WXr6Xne33OCsa0noAAAAAACCiRUdL3bvb7QMHpG++cTYe2EhKAQAAAACAiOe3ulLwG5JSAAAACIiCogI98sEjeuSDR1RQVOB0OACACs4vdaUKC6UXX5QmTKDQuR9QUwoAAAAAAES89u2lqlWl/Pxy1JUyTen772VYlt1GuTBTCgAAAAAARLyoKKlHD7t98KC0c+dldBIdLQ0bJuvxx+02yoWkFAAAAAAAqBDKXVfK5ZJatbI3FymV8uIKAgAAAACACsEvdaXgN9SUAgAAAAAAFULbtlL16lJenp2UuuS6UqZpr/szTSk+PlBhVhgkpQAAAAAgnFVpJLV5seQ+gPM6XVfq//0/KTtb2r5datHiEjooLJReftkudD5qVMDirChISgEAAABAOKvSUGo50ukogLDRq5edlJLsulKXlJRyuaQrr5RlWdSU8gOuIAAAAAAAqDDKVVcqOlr6/e+l3/2Op+/5AUkpAAAAAABQYSQnSzVq2O30dLs8FJxBUgoAAAAAAFQYbrf0y1/a7dxc6T//cTaeioykFAAAAAAAqFB69Spur159CT9YWChNnSpNm2a3US4kpQAAAAAgnOWskxbFFm8565yOCAh5l11XyjSlr7+W8fXXrPvzA56+BwAAgICIdkfr4fYP+9oAAsSyJNNTch/ABbVpI8XHS4cPF9eVKtPD9KKjpYcflmWaFDr3A2ZKAQAAICBchkvtG7RX+wbt5TL4sxMAEDpcruK6UocOSV99dQk/2L69vZUpi4UL4QoCAAAAAIAK57LrSsFvSEoBAAAgIEzL1Kb9m7Rp/yaZFnU3AACh5bLqSpmmtGuXvVFTqtxISgEAACAgCr2FmrNpjuZsmqNCL08oAgCEllatpFq17PYnn5Qxx1RYKE2eLOOll3j6nh+QlAIAAEBAuAyXmtVupma1m1FTCgAQclwu6brr7Pbhw9KXX5bhhwxDSky0N8MIaHwVAU/fAwAAQEBEu6P19LVPOx0GAACl6tVL+sc/7Pbq1VJy8kV+ICZGeuEF++l72dmBDi/i8U9WAAAAAACgQrqsulLwG5JSAAAAAACgQmrZUqpTx25/8onk9TobT0VDUgoAAAABUVBUoKeXPa2nlz2tgqICp8MBAOAcZ9aVOnpU2rLlIj9QWCi98oo0YwaFzv2ApBQAAAACJt+Tr3xPvtNhAABQql69iturV1/kYNOUvvpKxldflfFxfbgQCp0DAAAAQDhzx0pVGpXcB1BmZ9eVevpCz+iIipIGD7YLnUeRUikvriAAAAAAhLPaHaXbdzsdBRC2WrSQEhKknBzp3/+WiooukG9yu6Vrr7VnSfH0vXJj+R4AAAAAAKiwDKN4tlRenpSZ6WQ0FQtJKQAAAAAAUKGVua6UaUp799obNaXKjaQUAAAAAACo0M6uK1WqwkLpD3+QMX48T9/zA5JSAAAAAACgQmveXKpb126vWWPXlTovw5Bq1rQ3wwhSdJGLQucAAAAAEM6O7ZJ2/ql4/xdPStWuci4eIAydriu1eLF07Ji0ebPUqdN5DoyJkSZNsp++R6HzcmOmFAAAAACEs5MHpK9fKd5OHnA6IiAsnbmE74J1peA3JKUAAAAAAECFd2ax8wvWlYLfsHwPAAAAAABUeM2aSfXqSVlZdl2pwkIpOvqsgwoLpTfesJ+8d+utjsQZSZgpBQAAAAAAKjzDKJ4tdfy4tGnTeQ4yTWnzZhlffGG3US7MlAIAAEBARLmiNKjVIF8bAIBQ17On9O67dnv1aqlLl7MOiIqSBg2yC51H8d1WXiExU2rmzJlKSkpSXFycOnfurI0bN5Z67Ny5c9WjRw/Fx8crPj5eKSkp5xw/duxYNW/eXFWqVPEds2HDhhLHHDp0SPfdd5+qV6+umjVr6qGHHlJ+fn6JY/7yl78oOTlZlStXVqNGjfTSSy/576QBAAAinNvlVs+knuqZ1FNul9vpcAAAuKiL1pVyu+3MVc+edhvl4nhSavHixUpLS9OYMWO0efNmtWnTRn369FF2KY9WTE9P16BBg7R69WplZGSoYcOGSk1N1b59+3zHNGvWTDNmzNDWrVu1du1aJSUlKTU1VTk5Ob5j7rvvPm3btk0rVqzQkiVL9O9//1sPP/yw7/2PPvpI9913n37961/rq6++0quvvqo//vGPmjFjRuAuBgAAAAAAcEyTJlKDBnZ77VrJ43E2nkjneFJq2rRpGjp0qIYMGaIWLVpo9uzZqly5st54443zHr9w4UI99thjSk5OVvPmzTVv3jyZpqlVq1b5jrn33nuVkpKixo0bq2XLlpo2bZry8vL05ZdfSpK2b9+upUuXat68eercubO6d++uV155RYsWLdL+/fslSW+99Zb69eunX//612rcuLFuueUWjRw5UpMmTZJlWYG/MAAAAGHOtEx9/ePX+vrHr2Va1N0AAIS+M+tKnTghff75WQdYlpSdbW/kBsrN0aSUx+PRpk2blJKS4nvN5XIpJSVFGRkZZerjxIkTKiwsVK1atUodY86cOapRo4batGkjScrIyFDNmjXVoUMH33EpKSlyuVy+ZX4FBQWKi4sr0VelSpX0ww8/6Pvvv7+k8wQAAKiICr2Fmrp+qqaun6pCb6HT4QAAUCY9exa3V68+602PR/r972WMHs00Kj9wtCpXbm6uvF6v6tatW+L1unXraseOHWXqY8SIEWrQoEGJxJYkLVmyRAMHDtSJEydUv359rVixQnXq1JEkZWVlKTExscTxUVFRqlWrlrKysiRJffr00VNPPaUHHnhAvXr10rfffqupU6dKkg4cOKCkpKRzYikoKFBBQYFvPy8vT5JkmqbMEKvKb5qmLMsKubj8KRzPMRRjdjKmYI0d6HEC0X8o3isITdwr/lERrmMgztGyLNWrWs/X9vf1C8XPhe/N0Ow/FO8Vv7LMErMNTMvkqWCXKeLvlSCIhGt43XXS6Tk8q1dbGjnyjBlRpikjLk6WZQXsd9Xpdjh/b5Z1jLAuFT9x4kQtWrRI6enp58xq6tWrlzIzM5Wbm6u5c+dqwIAB2rBhwznJqNIMHTpUu3bt0q233qrCwkJVr15dTz75pMaOHSuX6/wTzCZMmKBx48ad83pOTo5OnTp16ScYQKZp6ujRo7Isq9TzCXfheI6hGLOTMQVr7ECPE4j+Q/FeQWjiXvGPinAdA3WOj179qCTpyI9H/NbnaaH4ufC9GZr9h+K94k/RRw6r9hn7hw8fVqF1/hq9uLBIv1eCIRKuYdWqUoMGCdq/361166S9e7MVG3vGASNHFp9ndrbfzrPoVJEKPPZEl+zsbEXF+TdlE8zP5tixY2U6ztGkVJ06deR2u3Xw4MESrx88eFD16tW74M9OmTJFEydO1MqVK9W6detz3q9SpYqaNGmiJk2aqEuXLmratKlef/11jRw5UvXq1TunkHpRUZEOHTrkG9cwDE2aNEkvvviisrKylJCQ4Ktb1bhx4/PGNHLkSKWlpfn28/Ly1LBhQyUkJKh69eoXvyBBZJqmDMNQQkJC2P6iuJhwPMdQjNnJmII1dqDHCUT/oXivIDRxr/hHRbiO4XiOoRgz35uh2X8o3it+ZcSX2I2Pj5cSyvaP8Sgp4u+VIIiUa3j99Ybefls6dcrQ998nqnv3ku8H4jyLThUpNsbOfiUmJgYkKRWsz+bsiUOlcTQpFRMTo/bt22vVqlXq16+fJPmKlg8bNqzUn5s8ebLGjx+vZcuWlagLdSGmafqW1nXt2lVHjhzRpk2b1L59e0nSxx9/LNM01blz5xI/53a7dcUVV0iS3n33XXXt2lUJCQnnHSM2NlaxJdKnNpfLFZL/MRqGEbKx+Us4nmMoxuxkTMEaO9DjBKL/ULxXEJq4V/yjIlzHcDzHUIyZ783Q7D8U7xW/iW8l9Vzq23XFt5Ii8TyDJKLvlSCJhGvYq5f09tt2+5NPXPrlL889xt/n6XK5ZBiGrx2I6xesz6as/Tu+fC8tLU2DBw9Whw4d1KlTJ7388ss6fvy4hgwZIkm6//77dcUVV2jChAmSpEmTJmn06NF65513lJSU5KsBVbVqVVWtWlXHjx/X+PHjddttt6l+/frKzc3VzJkztW/fPvXv31+SdPXVV+vGG2/U0KFDNXv2bBUWFmrYsGEaOHCgGvz07Mfc3Fz97W9/U8+ePXXq1Cn9+c9/1l//+ld98sknDlwlAACA8OPxevTimhclSc/1eE4x7hiHIwIiVEy81KCP01EAEeX0E/gkKT1d+v3vf9opKrKzVaYppaY6EVpEcTwpdc899ygnJ0ejR49WVlaWkpOTtXTpUl/x8z179pTIsM2aNUsej0d33313iX7GjBmjsWPHyu12a8eOHVqwYIFyc3NVu3ZtdezYUWvWrFHLli19xy9cuFDDhg1T79695XK5dNddd2n69Okl+lywYIGGDx8uy7LUtWtXpaenq1OnTgG8GgAAAJHDsiwdOHbA1wYAIFwkJUk/+5m0Z4+0fr1UUCC7rpTXK2VkyLAsqXdvp8MMe44npSRp2LBhpS7XS09PL7G/e/fuC/YVFxen995776Jj1qpVS++8806p79epU0cZGRkX7QcAAAAAAEQWw7BnSy1YIJ06JW3YIHsJn9st3XWXLNO02yiX8F3gCQAAAAAAECA9exa3V6/+qREVZS/bS0212ygXklIAAAAAEM6KjktHthVvRcedjgiICGcmpc5axAU/Ia0HAAAAAOHs0BfSyh7F+ylrpMTupR8PoEySkuxt924pI8NexhcXa0lHj9qFzqmXWG7MlAIAAAAAADiP00/hKyiQPv1UkscjjRgh49ln7TbKhaQUAAAAAADAeZy3rpTLZW8oN5bvAQAAAAAAnMc5daXGxUqzZtlP38vOdiiqyEFqDwAAAAAA4Dx+9jOpcWO7/emn0smTzsYTaUhKAQAAAAAAlOJ0XSmPxy54Dv8hKQUAAAAAAFCKM5fwfbKqSHr3XXsrKnIspkhBTSkAAAAAAIBSnJmUWpPulXLTZViW1L27YzFFCpJSAAAACAi3y61bm93qawMAEI6uvFJq0kT69lspY6NbBU/dquhoU3Lz3VZeJKUAAAAQEFGuKPX9RV+nwwAAoNx69bKTUqeKorSmZl9dfz1P3/MHakoBAAAAAABcwJlL+FavdiyMiENSCgAAAAFhWZb2H9uv/cf2y7Isp8MBAOCyFSelLGWsOiGdOCHx3VZuLN8DAABAQHi8Ho1LHydJmn7TdMVGxTocERChYmtLV95Rch+AXzVoIDVrJu3+2qNBG59S0f9Z0thRTocV9khKAQAAIGCqxlR1OgQg8tW4Wvrle05HAUS8Xr2kP38tmZZ08KAU7XRAEYCkFAAAAAIiNipWU/tMdToMAAD8omdP6bXXYvSYXtVvr7H0ZEyO0yGFPWpKAQAAAAAAXIRdV8qQKbfS17glw3A4ovBHUgoAAAAAAOAi6tWTmje32599JuXnk5QqL5bvAQAAICAKvYWavmG6JOmJzk8o2k31DQBAeOt9XZFa7PiX5JU+y+ihxo2djii8kZQCAABAQJiWqa9//NrXBhAgh7+UPn+seL/Dq1J8a+fiASJYzx5e/fjacknShvU9dc99DgcU5khKAQAAAEA4K8yTctaV3AcQED16uvWYUiVJ+z6r5HA04Y+kFAAAAAAAQBnUvSJKW5vepW++kaK/tHTypKUqVZyOKnxR6BwAAAAAAKCMunWz/7ew0NDnnzsbS7gjKQUAAAAAAFAWlqUe13rlkleSpfXrnQ4ovJGUAgAAAAAAKAuPR3esfEyv6jHFyKO1aw2nIwprJKUAAAAAAADKqGYNKS7WkiRlZEgmD5i9bBQ6BwAAAAAAKIuYGBkv/1Ef/GDJ81GMPIcNbd8utWzpdGDhiZlSAAAAAAAAZWEYUuXK6tSzkiR76d66dc6GFM5ISgEAAAAAAFyC00/gk6S1a52LI9yxfA8AAAAAAKAsioqkjz5ShwJTlWNu1glPNDOlyoGZUgAAAAAAAGXh9UpLlihm+f9TuzanJEn//a904IDDcYUpZkoBAAAgINwut3om9fS1AQAIe2631LOnLNNUu2iv1n5mv7xunXT33c6GFo5ISgEAACAgolxRGtRqkNNhAJGvTmfpzuzi/ZiajoUCRLyoKGnQIMk01dE6Kr1qv7x2LUmpy0FSCgAAAADCmStaiktwOgqgwmnf3uNrU+z88lBTCgAAAAFhWZaOFRzTsYJjsizL6XAAAPCr+HhLLVva32+ZmVJ+vrPxhCOSUgAAAAgIj9ej4cuHa/jy4fJ4PRf/AQAAQl1BgfToozIee0wqKNC119ove73Shg3OhhaOSEoBAAAAAACUlWnam6Ru3YpnAq9b51RA4YuaUgAAAAiI2KhYvdb3NafDACLfqWzpwPLi/fqpUlyic/EAkSwmRpo0SZZpSgUF6tat+C3qSl06klIAAAAAEM7yvpYyflW8n7KGpBQQKIYh1axpz5TKztbPfy7Vry8dOCBlZEhFRfYD+lA2LN8DAAAAAAC4DIYhde9ut/Pzpa1bnY0n3JCUAgAAQEAUegv12uev6bXPX1Oht9DpcAAAKL+iImn5cnsrKpKkEkv4qCt1aUhKAQAAICBMy9TmA5u1+cBmmZbpdDgAAJSf1yv9/e8y3nvPbqt4ppREXalLxUpHAAAAAACAsnC7pa5d7ULnbrckqU0bqUoV6fhxOyllWfayPlwcM6UAAAAAAADKIipKeuABe/uponlUlNSli/32vn3Snj2ORRd2SEoBAAAAAACUA3WlLg9JKQAAAAAAgHKgrtTlISkFAAAAAABQFgUF0m9+I+Opp+z2T7p0kVw/ZViYKVV2JKUAAAAAAADK6uRJeztDtWp2wXNJ2rpVOnIk+GGFI56+BwAAAAAAUBYxMdILL9hP37OsEm916yZ98YX9ckaGdNNNDsUYRpgpBQAAAAAAUBaGISUm2pthlHjrzLpSLOErG2ZKAQAAAEA4q/IzqfULJfcBBN2ZT+Cj2HnZkJQCAAAAgHBW5WfSNb9zOgqgYvB6pTVrJNOUfvGLEm9deaXUqJH0/ffSxo2Sx2Ov9kPpWL4HAAAAAABQFkVF0rvvyli0yG6f5fQSvpMn7fpSuDCSUgAAAAgIl+FSu/rt1K5+O7kM/uwEAEQAl0tq105W27Z2+yxnLuGjrtTFsXwPAAAAARHtjtYjHR5xOgwAAPwnOlp65BF7+V529jlvn1nsfO1aKS0tiLGFIf7JCgAAAAAAwA9atpRq1LDb69ZJluVsPKGOpBQAAAAAhLOc9dLiKsVbznqnIwIqLJdLuvZau52dLX37rbPxhDqSUgAAAAiIgqICPfLBI3rkg0dUUFTgdDhA5LJMyXuieLNMpyMCIpfHI40YIePZZ+32eVBXquxISgEAAAAAAJSFZUlHjthbKWvzzq4rhdKFRFJq5syZSkpKUlxcnDp37qyNGzeWeuzcuXPVo0cPxcfHKz4+XikpKeccP3bsWDVv3lxVqlTxHbNhw4YSxxw6dEj33Xefqlevrpo1a+qhhx5Sfn5+iWOWLVumLl26qFq1akpISNBdd92l3bt3++28AQAAIlmMO0ZTUqdoSuoUxbhjnA4HAIDyi46Wfvc7WaNG2e3z6NhRivrpsXLMlLowx5NSixcvVlpamsaMGaPNmzerTZs26tOnj7LPU8VektLT0zVo0CCtXr1aGRkZatiwoVJTU7Vv3z7fMc2aNdOMGTO0detWrV27VklJSUpNTVVOTo7vmPvuu0/btm3TihUrtGTJEv373//Www8/7Hv/u+++0+23367rr79emZmZWrZsmXJzc3XnnXcG7mIAAABEEMMwVC22mqrFVpNhGE6HAwBA+blcUsOG9uY6f0qlcmWpfXu7vWOHdEYqAmdxPCk1bdo0DR06VEOGDFGLFi00e/ZsVa5cWW+88cZ5j1+4cKEee+wxJScnq3nz5po3b55M09SqVat8x9x7771KSUlR48aN1bJlS02bNk15eXn68ssvJUnbt2/X0qVLNW/ePHXu3Fndu3fXK6+8okWLFmn//v2SpE2bNsnr9eoPf/iDrrrqKrVr107Dhw9XZmamCgsLA39hAAAAAABAWDqzrtR6nj1QKkeTUh6PR5s2bVJKSorvNZfLpZSUFGVkZJSpjxMnTqiwsFC1atUqdYw5c+aoRo0aatOmjSQpIyNDNWvWVIcOHXzHpaSkyOVy+Zb5tW/fXi6XS3/+85/l9Xp19OhRvfXWW0pJSVF0KVP0AAAAUKzILNK7W9/Vu1vfVZFZ5HQ4AACUn9drZ5nWr7fbpTizrhRL+EoX5eTgubm58nq9qlu3bonX69atqx07dpSpjxEjRqhBgwYlEluStGTJEg0cOFAnTpxQ/fr1tWLFCtWpU0eSlJWVpcTExBLHR0VFqVatWsrKypIk/fznP9fy5cs1YMAAPfLII/J6veratas+/PDDUmMpKChQQUHxk2Xy8vIkSaZpyjRD6wkYpmnKsqyQi8ufwvEcQzFmJ2MK1tiBHicQ/YfivYLQxL3iHxXhOgbiHAuLCrV692pJUr9f9JMryr//HhqKnwvfm6HZfyjeK35lmSVmG5iWKUXquQZYxN8rQRDx19DjkTF/vmRZskaNKvU8u3SRTs8DWrvWkmmevyj6mU5fu9Ntf1/DYH42ZR3D0aRUeU2cOFGLFi1Senq64uLiSrzXq1cvZWZmKjc3V3PnztWAAQO0YcOGc5JRpcnKytLQoUM1ePBgDRo0SMeOHdPo0aN19913a8WKFeetizBhwgSNGzfunNdzcnJ06tSpyzvJADFNU0ePHpVlWXKVsg423IXjOYZizE7GFKyxAz1OIPoPxXsFoYl7xT8qwnUMxDkWeAt08uRJSVJ2TrZi3bF+6fe0UPxc+N4Mzf5D8V7xp+gjh1X7jP3Dhw+r0Dp/jV5cWKTfK8EQ8dewsFCVGzWSZVk6kpcnKzv7vOdpGFLjxnX03/9G6fPPpe+/z1alShfuuuhUkQo89kSX7OxsRcX5N2UTzM/m2LFjZTrO0aRUnTp15Ha7dfDgwRKvHzx4UPXq1bvgz06ZMkUTJ07UypUr1bp163Per1Klipo0aaImTZqoS5cuatq0qV5//XWNHDlS9erVO6eQelFRkQ4dOuQbd+bMmapRo4YmT57sO+btt99Ww4YNtWHDBnWx054ljBw5Umlpab79vLw8NWzYUAkJCapevfrFL0gQmaYpwzCUkJAQmb8oFJ7nGIoxOxlTsMYO9DiB6D8U7xWEJu4V/6gI1zEQ51hQVKBKP/0FnpiQqNgo/yelQu1z4XszNPsPxXvFr4z4Ervx8fFSQtn+MR4lRfy9EgQV4hqOHCnTNFUzJ+eC5/nLXxr673+lwkJDe/YkqkePC3dbdKpIsTH2d2ViYmJAklLB+mzOnjhUGkeTUjExMWrfvr1WrVqlfv36SZKvaPmwYcNK/bnJkydr/PjxWrZsWYm6UBdimqZvaV3Xrl115MgRbdq0Se1/Kon/8ccfyzRNde7cWZJdq+rsD8ntdvv6Op/Y2FjFxp77x5bL5QrJ/xgNwwjZ2PwlHM8xFGN2MqZgjR3ocQLRfyjeKwhN3Cv+URGuo7/P0eVyyZDhawfi2oXi58L3Zmj2H4r3it8YJc/JZbhKfSoYLi6i75UgqSjX8GLn2b27NH++3c7IcOm66y7cn8vl8q3KCvfvzbL27/gdkpaWprlz52rBggXavn27Hn30UR0/flxDhgyRJN1///0aOXKk7/hJkybp97//vd544w0lJSUpKytLWVlZys/PlyQdP35czz33nD799FN9//332rRpkx588EHt27dP/fv3lyRdffXVuvHGGzV06FBt3LhR69at07BhwzRw4EA1aNBAknTLLbfos88+0/PPP69vvvlGmzdv1pAhQ9SoUSO1bds2yFcJAAAAAACEkzOLna9d61wcoczxmlL33HOPcnJyNHr0aGVlZSk5OVlLly71FT/fs2dPiQzbrFmz5PF4dPfdd5foZ8yYMRo7dqzcbrd27NihBQsWKDc3V7Vr11bHjh21Zs0atWzZ0nf8woULNWzYMPXu3Vsul0t33XWXpk+f7nv/+uuv1zvvvKPJkydr8uTJqly5srp27aqlS5f6pqEDAAAAgONcMVKlK0ruAwgMj0d64QUZliU9/PAFD23WTKpTR8rNtR/WZ5pMYjyb40kpSRo2bFipy/XS09NL7O/evfuCfcXFxem999676Ji1atXSO++8c8FjBg4cqIEDB160LwAAAABwTJ1O0h0/OB0FUDFYlpSdbf+vdeEn6hmG1K2b9K9/SYcPS9u3S2fMlYFCYPkeAAAAAABAWIiOln77W1nPPGO3L6Jbt+L2unUBjCtMkZQCAAAAAAAoC5dLuuoqeyvDWjzqSl0YSSkAAAAAAIAAaNdOio2128yUOhdJKQAAAAAAgLIwTWnTJnszzYseHhsrdepkt//7X2n//gDHF2ZISgEAAABAOMv/r7QprXjL/6/TEQGRq7BQmjNHxty5drsMqCtVupB4+h4AAAAij8twqVntZr42gAA5sV/a+cfi/YZ3SlUbOxcPEMlcLqlZM1mWVaaaUlLJulLr1kn9+wcotjBEUgoAAAABEe2O1tPXPu10GAAA+E90tPT00/bSvezsMv3ItdcWtyl2XhL/ZAUAAAAAABAg8fFSy5Z2OzNTys93NJyQQlIKAAAAAAAggE4v4fN6pQ0bnI0llJCUAgAAQEAUFBXo6WVP6+llT6ugqMDpcAAAKL/CQumFF6Q//KHMhc4lip2XhppSAAAACJh8D2sUAAARxDSlH36QYVl2u4zOLHZOXaliJKUAAAAQEDHuGI3pOcbXBgAg7EVHS7/5jSzTtNtllJQk1a8vHTggZWRIRUVSFBkZlu8BAAAgMAzDUINqDdSgWgMZhuF0OAAAlJ/LJV19tb25yp5SMYzi2VL5+dLWrQGKL8yQlAIAAAAAAAgw6kqdi6QUAAAAAqLILNIHOz/QBzs/UJFZ5HQ4AACUn2na05y2br2kmlISdaXOh6QUAAAAAsJrerXk6yVa8vUSeU2v0+EAAFB+hYXSjBkyZs68pKfvSVKbNlKVKnZ77VrJsgIQX5ghKQUAAAAAAFAWLpfUqJGsRo0uqaaUZBc279LFbu/bJ+3ZE4D4wgy13gEAAAAgnNVoIV23pOQ+gMCIjpaee85eupedfck/3q2btGqV3V67VmrUyM/xhRmSUgAAAAAQzmJrSVfc4nQUAMrgzLpS69ZJ993nXCyhgOV7AAAAAAAAQdClS/GqP4qdk5QCAAAAAAAom8JCafJk6aWXLrnQuSRVq2YXPJekr76Sjhzxb3jhhqQUAAAAAABAWZimtGuXjF277PZlOL2Ez7KkjAw/xhaGSEoBAAAAQDgrOiHl7Szeik44HREQuaKjpUcflfXrX9vty9CtW3F73To/xRWmKHQOAAAAAOHs0GZpZY/i/ZQ1UmL30o8HcPlcLik5+bKfvieVTEpV9LpSzJQCAAAAAAAIkiuvlBo1stsbN0oej7PxOImkFAAAAAAAQFmYpvT11/Z2mTWlpOK6UidPSl984afYwhBJKQAAAAAAgLIoLJSmTpUxbdplPX3vNOpK2UhKAQAAICAMw1D9avVVv1p9GYbhdDgAAJSfYUj169tbOb7bup9R9q0i15Wi0DkAAAACIsYdo7E9xzodBgAA/hMTI40dK6schc4lqWVLqUYN6ehRe6aUZfkxxjDCTCkAAAAAAIAgcrmka6+129nZ0rffOhuPU0hKAQAAAAAABBl1pUhKAQAAIEA8Xo/Gpo/V2PSx8ngr8POuAQCRo7BQevll6U9/Klehc4m6UhI1pQAAABAglmXpwLEDvjYAAGHPNKXt22VYlt0uh44dpehoO7dFUgoAAADwo2h3tJ6+9mlfGwCAsBcdLT34oF3oPLp8322VK0vt2kkbNkg7d0o5OX6KMYyQlAIAAEBAuAyXmtVu5nQYAAD4j8slde5sz5Iqx9P3Tuve3U5KSdKnn5a7u7BDTSkAAAAACGextaQr+hZvsbWcjghAGZ1Z7Dwjw7k4nMJMKQAAAASE1/RqzZ41kqQeP+sht8vtcERAhKrRQrrufaejACoG05T27LH/Ny6u3N2dmZRav15qm1DuLsMKM6UAAAAQEEVmkd7d+q7e3fquiswip8MBAKD8CgulCRNkTJxY7qfvSVJiotS0qd3etEnyesvdZVghKQUAAAAAAFAWhiHVrm1vhuGXLrt3t/+3qEg6ctQvXYYNklIAAAAAAABlERMjvfiirPHj7bYfnLmE7/Ahv3QZNkhKAQAAAAAAOOT0TClJOlTBklIUOgcAAACAcHZkq/T5/xXvd3hFqtnKuXgAXJJmzaQ6daQjudKhw5JlOR1R8JCUAgAAAIBw5jkqZX9Sch9AYBQWSnPn2pmj227zS5eGYS/h+3//srvPz/dLt2GB5XsAAAAAAABlYZrSli0ytmyx235SUZfwMVMKAAAAAACgLKKipP/5H1mmabf95Mxi5ySlAAAAAAAAUJLbLfXoYc+Sys72W7ft2kmxsZIKKlZSiuV7AAAAAAAADoqNlTp0sNsnTkr79zsbT7CQlAIAAAAAACgLy7IzRvv3+/0xeddeW9zOyPBr1yGLpBQAAAAAAEBZeDzSuHEynn/ebvtR167FbZJSAAAAQDlVjamqqjFVnQ4DAAD/qVrV3vysS5fi9vr1fu8+JFHoHAAAAAERGxWrqX2mOh0GAAD+ExsrTZ1qP33Pj4XOJSk+XqpRXTIM6brr7NWBhuHXIUIOSSkAAAAAAIAQ0KOHnYjqPyHyE1ISy/cAAAAAAABCQkVIRJ2JmVIAAAAIiEJvoaZvmC5JeqLzE4p2RzscEQAA5VRYKL35pmSa0o03Oh1N2CMpBQAAgIAwLVNf//i1rw0gQGp3ku7YX7wfU9u5WIBIZ5rSxo0yLEtKTXU6mrBHUgoAAAABEe2O1sPtH/a1AQSIO0aqVN/pKICKISpKGjDALnQeRUqlvLiCAAAACAiX4VL7Bu2dDgMAAP9xu6Xeve0ZU35++l5FRKFzAAAAAAAABB0zpQAAABAQpmXqiwNfSJLa1m8rl8G/hwIAwpxlSYcO2TOlLMvpaMIeSSkAAAAERKG3UHM2zZEkTb9pumKjYh2OCIhQp3KkrJXF+/VSpLgE5+IBIpnHIz33nF3ofNQop6MJeyHxz1UzZ85UUlKS4uLi1LlzZ23cuLHUY+fOnasePXooPj5e8fHxSklJOef4sWPHqnnz5qpSpYrvmA0bNpQ45tChQ7rvvvtUvXp11axZUw899JDy8/NL9GEYxjlblSpV/HvyAAAAAFAeeTul9fcWb3k7nY4IiGwxMfaGcnM8KbV48WKlpaVpzJgx2rx5s9q0aaM+ffoou5SCYenp6Ro0aJBWr16tjIwMNWzYUKmpqdq3b5/vmGbNmmnGjBnaunWr1q5dq6SkJKWmpionJ8d3zH333adt27ZpxYoVWrJkif7973/r4Ycf9r0/fPhwHThwoMTWokUL9e/fP3AXAwAAAAAAhK7YWOmVV2RNn263US6OJ6WmTZumoUOHasiQIWrRooVmz56typUr64033jjv8QsXLtRjjz2m5ORkNW/eXPPmzZNpmlq1apXvmHvvvVcpKSlq3LixWrZsqWnTpikvL09ffvmlJGn79u1aunSp5s2bp86dO6t79+565ZVXtGjRIu3fv1+SVLVqVdWrV8+3HTx4UP/5z3/00EMPBf6iAAAAAAAARDhHk1Iej0ebNm1SSkqK7zWXy6WUlBRlZGSUqY8TJ06osLBQtWrVKnWMOXPmqEaNGmrTpo0kKSMjQzVr1lSHDh18x6WkpMjlcp2zzO+0efPmqVmzZurRo0dZTw8AAAAAAAClcLTQeW5urrxer+rWrVvi9bp162rHjh1l6mPEiBFq0KBBicSWJC1ZskQDBw7UiRMnVL9+fa1YsUJ16tSRJGVlZSkxMbHE8VFRUapVq5aysrLOGePUqVNauHChnn322QvGUlBQoIKCAt9+Xl6eJMk0TZmmWabzCRbTNGVZVsjF5U/heI6hGLOTMQVr7ECPE4j+Q/FeQWjiXvGPinAdA/a7Spav7e/rF4qfC9+bodl/KN4rfmWZJWYbmJZpPxkMlyzi75UgiPhrWFQkvfuuLMuS1bt3QH5XnW6H8/dmWccI66fvTZw4UYsWLVJ6erri4uJKvNerVy9lZmYqNzdXc+fO1YABA7Rhw4ZzklFl8Y9//EPHjh3T4MGDL3jchAkTNG7cuHNez8nJ0alTpy553EAyTVNHjx6VZVlyuRxfxRkQ4XiOoRizkzEFa+xAjxOI/kPxXkFo4l7xj4pwHQNxjgXeAp08eVKSlJ2TrVi3f2tvhOLnwvdmaPYfiveKP0UfOazaZ+wfPnxYhdb5a/TiwiL9XgmGiL+GBQWqvnKlLMvS0bZtZbndfjvPolNFKvDYE12ys7MVFefflE0wP5tjx46V6ThHk1J16tSR2+3WwYMHS7x+8OBB1atX74I/O2XKFE2cOFErV65U69atz3m/SpUqatKkiZo0aaIuXbqoadOmev311zVy5EjVq1fvnELqRUVFOnTo0HnHnTdvnm699dZzZnSdbeTIkUpLS/Pt5+XlqWHDhkpISFD16tUv+LPBZpqmDMNQQkJCZP6iUHieYyjG7GRMwRo70OMEov9QvFcQmrhX/KMiXMdAnGNBUYEqVaokSUpMSFRslP+TUqH2ufC9GZr9h+K94ldGfInd+Ph4KeHS/zEeFeBeCYKIv4ZFRdI998iyLNWoVUsJiYl+TUrFxtjflYmJiQFJSgXrszl74lBpHE1KxcTEqH379lq1apX69esnSb6i5cOGDSv15yZPnqzx48dr2bJlJepCXYhpmr6ldV27dtWRI0e0adMmtW/fXpL08ccfyzRNde7cucTPfffdd1q9erXef//9i44RGxur2PNU33e5XCH5H6NhGCEbm7+E4zmGYsxOxhSssQM9TiD6D8V7BaGJe8U/KsJ19Pc5ulwuGTJ87UBcu1D8XPjeDM3+Q/Fe8Ruj5Dm5DJcUiecZJBF9rwRJRF/DmBjp1lvtBE92tv+/N43I+N4sa/+OL99LS0vT4MGD1aFDB3Xq1Ekvv/yyjh8/riFDhkiS7r//fl1xxRWaMGGCJGnSpEkaPXq03nnnHSUlJflqQFWtWlVVq1bV8ePHNX78eN12222qX7++cnNzNXPmTO3bt0/9+/eXJF199dW68cYbNXToUM2ePVuFhYUaNmyYBg4cqAYNGpSI74033lD9+vV10003BfGqAAAAAAAARDbHk1L33HOPcnJyNHr0aGVlZSk5OVlLly71LZXbs2dPiQzbrFmz5PF4dPfdd5foZ8yYMRo7dqzcbrd27NihBQsWKDc3V7Vr11bHjh21Zs0atWzZ0nf8woULNWzYMPXu3Vsul0t33XWXpk+fXqJP0zQ1f/58PfDAA3K73QG8CgAAAAAAIORZlpSfbz9M4Kei5Lh8jielJGnYsGGlLtdLT08vsb979+4L9hUXF6f33nvvomPWqlVL77zzzgWPcblc2rt370X7AgAAAAAAFYDHIw0fLsOypFGjnI4m7IVEUipSnX6UY15ensORnMs0TR07dkxxcXGRuc5X4XmOoRizkzEFa+xAjxOI/kPxXkFo4l7xj4pwHQNxjgVFBfKc8Eiy/x4KRKHzUPtc+N4Mzf5D8V7xq2PHpRNn7ceF3v8HCQcRf68EQcRfw4ICyeORZVn2eebl+bXQ+YlC+z/mvLw8RXn8X+g8WJ/N6TyIdZHZZIZ1sSNw2X744Qc1bNjQ6TAAAAAAAACCbu/evbryyitLfZ+kVACZpqn9+/erWrVqvgr6oaRjx4767LPPnA4joMLxHEMxZidjCtbYgR7H3/3n5eWpYcOG2rt3r6pXr+63fhGZQvH3SjiqCNcxHM8xFGPmezP0+ud7E5ciFH+vhJuKcg3D8TyDFfPpmWQNGjS44Kwslu8FkMvlumBG0Glutzviv5TD8RxDMWYnYwrW2IEeJ1D9V69ePeTuF4SeUPy9Eo4qwnUMx3MMxZj53gzd/vneRFmE4u+VcFNRrmE4nmcwY65Ro8ZFj4nABZ4oq8cff9zpEAIuHM8xFGN2MqZgjR3ocULxc0XFwf3nHxXhOobjOYZizHxvhn7/wIVw/5VfRbmG4XieoRYzy/cAIAzl5eWpRo0aOnr0aNj96wwAAMHG9yYAhCZmSgFAGIqNjdWYMWMUG+vfJ1kBABCJ+N4EgNDETCkAAAAAAAAEHTOlAAAAAAAAEHQkpQAAAAAAABB0JKUAAAAAAAAQdCSlAAAAAAAAEHQkpQCgAkhKSlLr1q2VnJysXr16OR0OAAAh7cSJE2rUqJGGDx/udCgAENGinA4AABAc69evV9WqVZ0OAwCAkDd+/Hh16dLF6TAAIOIxUwoAAAAAfvLNN99ox44duummm5wOBQAiHkkpAHDYv//9b/Xt21cNGjSQYRj65z//ec4xM2fOVFJSkuLi4tS5c2dt3LjxksYwDEPXXXedOnbsqIULF/opcgAAgisY35nDhw/XhAkT/BQxAOBCWL4HAA47fvy42rRpowcffFB33nnnOe8vXrxYaWlpmj17tjp37qyXX35Zffr00c6dO5WYmChJSk5OVlFR0Tk/u3z5cjVo0EBr167VFVdcoQMHDiglJUWtWrVS69atA35uAAD4U6C/Mz/77DM1a9ZMzZo10/r16wN+PgBQ0RmWZVlOBwEAsBmGoX/84x/q16+f77XOnTurY8eOmjFjhiTJNE01bNhQ//d//6dnn332ksd45pln1LJlSz3wwAN+ihoAgOALxHfmyJEj9fbbb8vtdis/P1+FhYV6+umnNXr06ECdBgBUaCzfA4AQ5vF4tGnTJqWkpPhec7lcSklJUUZGRpn6OH78uI4dOyZJys/P18cff6yWLVsGJF4AAJzij+/MCRMmaO/evdq9e7emTJmioUOHkpACgABi+R4AhLDc3Fx5vV7VrVu3xOt169bVjh07ytTHwYMHdccdd0iSvF6vhg4dqo4dO/o9VgAAnOSP70wAQHCRlAKACNe4cWNt2bLF6TAAAAgrLHMHgMBj+R4AhLA6derI7Xbr4MGDJV4/ePCg6tWr51BUAACEHr4zASD8kJQCgBAWExOj9u3ba9WqVb7XTNPUqlWr1LVrVwcjAwAgtPCdCQDhh+V7AOCw/Px8ffvtt7797777TpmZmapVq5Z+9rOfKS0tTYMHD1aHDh3UqVMnvfzyyzp+/LiGDBniYNQAAAQf35kAEFkMy7Isp4MAgIosPT1dvXr1Ouf1wYMHa/78+ZKkGTNm6KWXXlJWVpaSk5M1ffp0de7cOciRAgDgLL4zASCykJQCAAAAAABA0FFTCgAAAAAAAEFHUgoAAAAAAABBR1IKAAAAAAAAQUdSCgAAAAAAAEFHUgoAAAAAAABBR1IKAAAAAAAAQUdSCgAAAAAAAEFHUgoAAAAAAABBR1IKAAAAAAAAQUdSCgAA4DySkpL08ssvOx2GIzwej5o0aaL169c7HUrAXernPHv2bPXt2zdwAQEAUIGQlAIAAI554IEH1K9fP6fDOK/PPvtMDz/8cMDHSUpKkmEYMgxDlStXVqtWrTRv3rxL7scwDP3zn//0S0yzZ8/Wz3/+c1177bUB6b+svvvuO917771q0KCB4uLidOWVV+r222/Xjh07ghrHmR588EFt3rxZa9ascSwGAAAiBUkpAABQoRQWFpbpuISEBFWuXDnA0dief/55HThwQF999ZX+53/+R0OHDtVHH30UlLHPZlmWZsyYoYceesiR8U8rLCzUDTfcoKNHj+q9997Tzp07tXjxYrVq1UpHjhxxLK6YmBjde++9mj59umMxAAAQKUhKAQCAkPXVV1/ppptuUtWqVVW3bl396le/Um5uru/9pUuXqnv37qpZs6Zq166tW2+9Vbt27fK9v3v3bhmGocWLF+u6665TXFycFi5c6JuhNWXKFNWvX1+1a9fW448/XiJhdfayLsMwNG/ePN1xxx2qXLmymjZtqvfff79EvO+//76aNm2quLg49erVSwsWLJBhGBdNolSrVk316tVT48aNNWLECNWqVUsrVqzwvf/ZZ5/phhtuUJ06dVSjRg1dd9112rx5c4lYJemOO+6QYRi+fUn617/+pXbt2ikuLk6NGzfWuHHjVFRUVGosmzZt0q5du3TLLbdcMOYzmaap559/XldeeaViY2OVnJyspUuXljhm/fr1Sk5OVlxcnDp06KB//vOfMgxDmZmZ5+1z27Zt2rVrl1599VV16dJFjRo1Urdu3fSHP/xBXbp08R33ww8/aNCgQapVq5aqVKmiDh06aMOGDZKkXbt26fbbb1fdunVVtWpVdezYUStXrrzguRw5ckT/+7//q4SEBFWvXl3XX3+9tmzZUuKYvn376v3339fJkyfLfI0AAMC5SEoBAICQdOTIEV1//fVq27atPv/8cy1dulQHDx7UgAEDfMccP35caWlp+vzzz7Vq1Sq5XC7dcccdMk2zRF/PPvusnnzySW3fvl19+vSRJK1evVq7du3S6tWrtWDBAs2fP1/z58+/YEzjxo3TgAED9OWXX+rmm2/Wfffdp0OHDkmyl5rdfffd6tevn7Zs2aJHHnlEo0aNuqRzNk1Tf//733X48GHFxMT4Xj927JgGDx6stWvX6tNPP1XTpk11880369ixY5LspJUk/fnPf9aBAwd8+2vWrNH999+vJ598Uv/5z3/02muvaf78+Ro/fnypMaxZs0bNmjVTtWrVyhz3n/70J02dOlVTpkzRl19+qT59+ui2227TN998I0nKy8tT37591apVK23evFkvvPCCRowYccE+ExIS5HK59Le//U1er/e8x+Tn5+u6667Tvn379P7772vLli367W9/6/v88/PzdfPNN2vVqlX64osvdOONN6pv377as2dPqeP2799f2dnZ+uijj7Rp0ya1a9dOvXv39n3OktShQwcVFRX5kl8AAOAyWQAAAA4ZPHiwdfvtt5/3vRdeeMFKTU0t8drevXstSdbOnTvP+zM5OTmWJGvr1q2WZVnWd999Z0myXn755XPGbdSokVVUVOR7rX///tY999zj22/UqJH1xz/+0bcvyfrd737n28/Pz7ckWR999JFlWZY1YsQI65prrikxzqhRoyxJ1uHDh89/AX4aJyYmxqpSpYoVFRVlSbJq1aplffPNN6X+jNfrtapVq2Z98MEHJeL7xz/+UeK43r17Wy+++GKJ19566y2rfv36pfb95JNPWtdff/05r5+v/9MaNGhgjR8/vsRrHTt2tB577DHLsixr1qxZVu3ata2TJ0/63p87d64lyfriiy9KjWXGjBlW5cqVrWrVqlm9evWynn/+eWvXrl2+91977TWrWrVq1o8//lhqH2dr2bKl9corr/j2z/yc16xZY1WvXt06depUiZ+56qqrrNdee63Ea/Hx8db8+fPLPC4AADgXM6UAAEBI2rJli1avXq2qVav6tubNm0uSb4neN998o0GDBqlx48aqXr26b9na2TNhOnTocE7/LVu2lNvt9u3Xr19f2dnZF4ypdevWvnaVKlVUvXp138/s3LlTHTt2LHF8p06dynSuzzzzjDIzM/Xxxx+rc+fO+uMf/6gmTZr43j948KCGDh2qpk2bqkaNGqpevbry8/MvOONHsq/h888/X+IaDh06VAcOHNCJEyfO+zMnT55UXFxcmeKW7FlQ+/fvV7du3Uq83q1bN23fvl2SfW1at25dot+yXJvHH39cWVlZWrhwobp27aq//vWvatmypW9pY2Zmptq2batatWqd9+fz8/M1fPhwXX311apZs6aqVq2q7du3l3rdtmzZovz8fNWuXbvENfvuu+9KLAuVpEqVKpV6DQEAQNlEOR0AAADA+eTn56tv376aNGnSOe/Vr19fkl3bp1GjRpo7d64aNGgg0zR1zTXXyOPxlDi+SpUq5/QRHR1dYt8wjHOW/fnjZ8qiTp06atKkiZo0aaK//vWvatWqlTp06KAWLVpIkgYPHqwff/xRf/rTn9SoUSPFxsaqa9eu55zn2fLz8zVu3Djdeeed57xXWuKpTp062rp1a7nPyV+qVaumvn37qm/fvvrDH/6gPn366A9/+INuuOEGVapU6YI/O3z4cK1YsUJTpkxRkyZNVKlSJd19992lXrf8/HzVr19f6enp57xXs2bNEvuHDh1SQkLC5Z4WAAAQSSkAABCi2rVrp7///e9KSkpSVNS5f7L8+OOP2rlzp+bOnasePXpIktauXRvsMH1+8Ytf6MMPPyzx2unaTpeiYcOGuueeezRy5Ej961//kiStW7dOr776qm6++WZJ0t69e0sUfJfshNnZtZfatWunnTt3lph1dTFt27bVrFmzZFmWDMO46PHVq1dXgwYNtG7dOl133XW+19etW+ebDfWLX/xCb7/9tgoKChQbGyvp8q6NYRhq3ry51q9fL8meuTZv3jwdOnTovLOl1q1bpwceeEB33HGHJDvptHv37lL7b9eunbKyshQVFVWiWPzZdu3apVOnTqlt27aXfA4AAKAYy/cAAICjjh49qszMzBLb3r179fjjj+vQoUMaNGiQPvvsM+3atUvLli3TkCFD5PV6FR8fr9q1a2vOnDn69ttv9fHHHystLc2x83jkkUe0Y8cOjRgxQl9//bX+8pe/+AqnlyW5c6Ynn3xSH3zwgT7//HNJUtOmTfXWW29p+/bt2rBhg+67775zZgklJSVp1apVysrK0uHDhyVJo0eP1ptvvqlx48Zp27Zt2r59uxYtWqTf/e53pY7dq1cv5efna9u2bee89913353zWR0/flzPPPOMJk2apMWLF2vnzp169tlnlZmZqSeffFKSdO+998o0TT388MPavn27li1bpilTplzw2mRmZur222/X3/72N/3nP//Rt99+q9dff11vvPGGbr/9dknSoEGDVK9ePfXr10/r1q3Tf//7X/39739XRkaG77q99957yszM1JYtW3xxlCYlJUVdu3ZVv379tHz5cu3evVvr16/XqFGjfJ+FZBeDb9y4sa666qpS+wIAABdHUgoAADgqPT1dbdu2LbGNGzfON/vG6/UqNTVVrVq10m9+8xvVrFlTLpdLLpdLixYt0qZNm3TNNdfoqaee0ksvveTYefz85z/X3/72N7333ntq3bq1Zs2a5Xv63unZQWXVokULpaamavTo0ZKk119/XYcPH1a7du30q1/9Sk888YQSExNL/MzUqVO1YsUKNWzY0DeDp0+fPlqyZImWL1+ujh07qkuXLvrjH/+oRo0alTp27dq1dccdd2jhwoXnvJeWlnbOZ/XFF1/oiSeeUFpamp5++mm1atVKS5cu1fvvv6+mTZtKsmdTffDBB8rMzFRycrJGjRrlO7fSlhFeeeWVSkpK0rhx49S5c2e1a9dOf/rTnzRu3DjfdY2JidHy5cuVmJiom2++Wa1atdLEiRN9tcKmTZum+Ph4XXvtterbt6/69Omjdu3alXruhmHoww8/1C9/+UsNGTJEzZo108CBA/X999+rbt26vuPeffddDR06tNR+AABA2RiWZVlOBwEAABCJxo8fr9mzZ2vv3r1Oh3JJvvzyS91www3atWuXqlatGpAxFi5cqCFDhujo0aMXrQ0VSrZt26brr79eX3/9tWrUqOF0OAAAhDVqSgEAAPjJq6++qo4dO6p27dpat26dXnrpJQ0bNszpsC5Z69atNWnSJH333Xdq1aqVX/p888031bhxY11xxRXasmWLRowYoQEDBoRVQkqSDhw4oDfffJOEFAAAfsBMKQAAAD956qmntHjxYh06dEg/+9nP9Ktf/UojR448b6H2imby5Ml69dVXlZWVpfr166tfv34aP368Kleu7HRoAADAISSlAAAAAAAAEHQUOgcAAAAAAEDQkZQCAAAAAABA0JGUAgAAAAAAQNCRlAIAAAAAAEDQkZQCAAAAAABA0JGUAgAAAAAAQNCRlAIAAAAAAEDQkZQCAAAAAABA0JGUAgAAAAAAQND9fywYCt10STiQAAAAAElFTkSuQmCC",
                        "text/plain": [
                            "<Figure size 1200x600 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=======================================================\n",
                        "             LR FINDER RESULTS\n",
                        "=======================================================\n",
                        "  🔴 Steepest Gradient : 0.000398  (aggressive)\n",
                        "  🟠 Steepest / 3      : 0.000133  (balanced) ★ DEFAULT\n",
                        "  🟣 Valley (80%)      : 0.000447  (robust)\n",
                        "  🟢 Min Loss / 10     : 0.000045  (conservative)\n",
                        "=======================================================\n",
                        "  Selected Method: 'recommended' → LR = 0.000133\n",
                        "=======================================================\n",
                        "Optimal LR: 0.00013270238802457848\n"
                    ]
                }
            ],
            "source": [
                "# Learning Rate Finder\n",
                "\n",
                "# Clone the model to avoid pre-training the actual model\n",
                "lr_model = tf.keras.models.clone_model(AE.model)\n",
                "\n",
                "# Define reconstruction loss locally as expected by LRFinder/Keras\n",
                "def r_loss_lr(y_true, y_pred):\n",
                "    return K.mean(K.square(y_true - y_pred), axis=[1, 2, 3])\n",
                "\n",
                "lr_opt = Adam(learning_rate=1e-6)\n",
                "lr_model.compile(loss=r_loss_lr, optimizer=lr_opt)\n",
                "\n",
                "lr_finder = LRFinder(min_lr=1e-6, max_lr=1e-1, steps=100)\n",
                "lr_model.fit(x_train, x_train,\n",
                "             batch_size=BATCH_SIZE,\n",
                "             steps_per_epoch=50,\n",
                "             epochs=2,\n",
                "             callbacks=[lr_finder],\n",
                "             verbose=0)\n",
                "\n",
                "lr_finder.plot_loss()\n",
                "optimal_lr = lr_finder.get_optimal_lr()\n",
                "print(f\"Optimal LR: {optimal_lr}\")\n",
                "\n",
                "# Update W&B\n",
                "wandb.config.update({\"learning_rate\": optimal_lr})\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "AE.compile(optimal_lr)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/200\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.2271\n",
                        "Epoch 1: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 1: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 152ms/step - loss: 0.2137 - learning_rate: 1.3270e-04\n",
                        "Epoch 2/200\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1066\n",
                        "Epoch 2: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 2: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - loss: 0.0937 - learning_rate: 1.3270e-04\n",
                        "Epoch 3/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0718\n",
                        "Epoch 3: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 3: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - loss: 0.0706 - learning_rate: 1.3270e-04\n",
                        "Epoch 4/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0679\n",
                        "Epoch 4: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 4: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0667 - learning_rate: 1.3270e-04\n",
                        "Epoch 5/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0624\n",
                        "Epoch 5: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 5: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.0613 - learning_rate: 1.3270e-04\n",
                        "Epoch 6/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0596\n",
                        "Epoch 6: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 6: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - loss: 0.0590 - learning_rate: 1.3270e-04\n",
                        "Epoch 7/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0579\n",
                        "Epoch 7: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 7: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 0.0577 - learning_rate: 1.3270e-04\n",
                        "Epoch 8/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0571\n",
                        "Epoch 8: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 8: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 0.0570 - learning_rate: 1.3270e-04\n",
                        "Epoch 9/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0567\n",
                        "Epoch 9: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 9: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - loss: 0.0566 - learning_rate: 1.3270e-04\n",
                        "Epoch 10/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0563\n",
                        "Epoch 10: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 10: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - loss: 0.0562 - learning_rate: 1.3270e-04\n",
                        "Epoch 11/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0559\n",
                        "Epoch 11: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 11: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 0.0559 - learning_rate: 1.3270e-04\n",
                        "Epoch 12/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0556\n",
                        "Epoch 12: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 12: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 0.0556 - learning_rate: 1.3270e-04\n",
                        "Epoch 13/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0554\n",
                        "Epoch 13: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 13: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 0.0553 - learning_rate: 1.3270e-04\n",
                        "Epoch 14/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0551\n",
                        "Epoch 14: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 14: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 0.0550 - learning_rate: 1.3270e-04\n",
                        "Epoch 15/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0549\n",
                        "Epoch 15: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 15: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0548 - learning_rate: 1.3270e-04\n",
                        "Epoch 16/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0544\n",
                        "Epoch 16: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 16: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - loss: 0.0545 - learning_rate: 1.3270e-04\n",
                        "Epoch 17/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0542\n",
                        "Epoch 17: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 17: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - loss: 0.0542 - learning_rate: 1.3270e-04\n",
                        "Epoch 18/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0540\n",
                        "Epoch 18: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 18: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - loss: 0.0539 - learning_rate: 1.3270e-04\n",
                        "Epoch 19/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0538\n",
                        "Epoch 19: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 19: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 70ms/step - loss: 0.0537 - learning_rate: 1.3270e-04\n",
                        "Epoch 20/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0535\n",
                        "Epoch 20: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 20: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 0.0535 - learning_rate: 1.3270e-04\n",
                        "Epoch 21/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0532\n",
                        "Epoch 21: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 21: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - loss: 0.0532 - learning_rate: 1.3270e-04\n",
                        "Epoch 22/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0529\n",
                        "Epoch 22: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 22: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.0530 - learning_rate: 1.3270e-04\n",
                        "Epoch 23/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0528\n",
                        "Epoch 23: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 23: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.0528 - learning_rate: 1.3270e-04\n",
                        "Epoch 24/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0527\n",
                        "Epoch 24: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 24: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0526 - learning_rate: 1.3270e-04\n",
                        "Epoch 25/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0525\n",
                        "Epoch 25: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 25: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - loss: 0.0524 - learning_rate: 1.3270e-04\n",
                        "Epoch 26/200\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0522\n",
                        "Epoch 26: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 26: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - loss: 0.0522 - learning_rate: 1.3270e-04\n",
                        "Epoch 27/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0520\n",
                        "Epoch 27: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 27: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0521 - learning_rate: 1.3270e-04\n",
                        "Epoch 28/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0519\n",
                        "Epoch 28: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 28: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.0519 - learning_rate: 1.3270e-04\n",
                        "Epoch 29/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0518\n",
                        "Epoch 29: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 29: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - loss: 0.0518 - learning_rate: 1.3270e-04\n",
                        "Epoch 30/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0517\n",
                        "Epoch 30: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 30: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0516 - learning_rate: 1.3270e-04\n",
                        "Epoch 31/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0516\n",
                        "Epoch 31: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 31: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0515 - learning_rate: 1.3270e-04\n",
                        "Epoch 32/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0513\n",
                        "Epoch 32: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 32: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0514 - learning_rate: 1.3270e-04\n",
                        "Epoch 33/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0513\n",
                        "Epoch 33: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 33: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 0.0512 - learning_rate: 1.3270e-04\n",
                        "Epoch 34/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0512\n",
                        "Epoch 34: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 34: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0511 - learning_rate: 1.3270e-04\n",
                        "Epoch 35/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0510\n",
                        "Epoch 35: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 35: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0510 - learning_rate: 1.3270e-04\n",
                        "Epoch 36/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0509\n",
                        "Epoch 36: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 36: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0509 - learning_rate: 1.3270e-04\n",
                        "Epoch 37/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0509\n",
                        "Epoch 37: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 37: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0508 - learning_rate: 1.3270e-04\n",
                        "Epoch 38/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0508\n",
                        "Epoch 38: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 38: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0507 - learning_rate: 1.3270e-04\n",
                        "Epoch 39/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0505\n",
                        "Epoch 39: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 39: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0507 - learning_rate: 1.3270e-04\n",
                        "Epoch 40/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0505\n",
                        "Epoch 40: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 40: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0505 - learning_rate: 1.3270e-04\n",
                        "Epoch 41/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0504\n",
                        "Epoch 41: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 41: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.0504 - learning_rate: 1.3270e-04\n",
                        "Epoch 42/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0504\n",
                        "Epoch 42: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 42: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0503 - learning_rate: 1.3270e-04\n",
                        "Epoch 43/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0503\n",
                        "Epoch 43: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 43: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0503 - learning_rate: 1.3270e-04\n",
                        "Epoch 44/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0503\n",
                        "Epoch 44: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 44: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 0.0502 - learning_rate: 1.3270e-04\n",
                        "Epoch 45/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0502\n",
                        "Epoch 45: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 45: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0501 - learning_rate: 1.3270e-04\n",
                        "Epoch 46/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0500\n",
                        "Epoch 46: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 46: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - loss: 0.0500 - learning_rate: 1.3270e-04\n",
                        "Epoch 47/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0500\n",
                        "Epoch 47: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 47: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 0.0499 - learning_rate: 1.3270e-04\n",
                        "Epoch 48/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0500\n",
                        "Epoch 48: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 48: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0499 - learning_rate: 1.3270e-04\n",
                        "Epoch 49/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0499\n",
                        "Epoch 49: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 49: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0498 - learning_rate: 1.3270e-04\n",
                        "Epoch 50/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0498\n",
                        "Epoch 50: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 50: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0497 - learning_rate: 1.3270e-04\n",
                        "Epoch 51/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0497\n",
                        "Epoch 51: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 51: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0496 - learning_rate: 1.3270e-04\n",
                        "Epoch 52/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0497\n",
                        "Epoch 52: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 52: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0496 - learning_rate: 1.3270e-04\n",
                        "Epoch 53/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0496\n",
                        "Epoch 53: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 53: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 53: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0495 - learning_rate: 1.3270e-04\n",
                        "Epoch 54/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0494\n",
                        "Epoch 54: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 54: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0494 - learning_rate: 1.3270e-04\n",
                        "Epoch 55/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0493\n",
                        "Epoch 55: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 55: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0494 - learning_rate: 1.3270e-04\n",
                        "Epoch 56/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0495\n",
                        "Epoch 56: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 56: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 56: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0494 - learning_rate: 1.3270e-04\n",
                        "Epoch 57/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0491\n",
                        "Epoch 57: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 57: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0492 - learning_rate: 1.3270e-04\n",
                        "Epoch 58/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0492\n",
                        "Epoch 58: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 58: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 0.0492 - learning_rate: 1.3270e-04\n",
                        "Epoch 59/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0492\n",
                        "Epoch 59: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 59: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 59: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - loss: 0.0492 - learning_rate: 1.3270e-04\n",
                        "Epoch 60/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0492\n",
                        "Epoch 60: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 60: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0491 - learning_rate: 1.3270e-04\n",
                        "Epoch 61/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0489\n",
                        "Epoch 61: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 61: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0491 - learning_rate: 1.3270e-04\n",
                        "Epoch 62/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0490\n",
                        "Epoch 62: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 62: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - loss: 0.0490 - learning_rate: 1.3270e-04\n",
                        "Epoch 63/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0491\n",
                        "Epoch 63: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 63: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0490 - learning_rate: 1.3270e-04\n",
                        "Epoch 64/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0490\n",
                        "Epoch 64: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 64: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 64: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0489 - learning_rate: 1.3270e-04\n",
                        "Epoch 65/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0489\n",
                        "Epoch 65: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 65: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 0.0489 - learning_rate: 1.3270e-04\n",
                        "Epoch 66/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0488\n",
                        "Epoch 66: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 66: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - loss: 0.0488 - learning_rate: 1.3270e-04\n",
                        "Epoch 67/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0488\n",
                        "Epoch 67: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 67: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 67: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0488 - learning_rate: 1.3270e-04\n",
                        "Epoch 68/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0486\n",
                        "Epoch 68: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 68: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0487 - learning_rate: 1.3270e-04\n",
                        "Epoch 69/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0487\n",
                        "Epoch 69: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 69: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0487 - learning_rate: 1.3270e-04\n",
                        "Epoch 70/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0486\n",
                        "Epoch 70: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 70: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 70: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0487 - learning_rate: 1.3270e-04\n",
                        "Epoch 71/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0486\n",
                        "Epoch 71: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 71: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0486 - learning_rate: 1.3270e-04\n",
                        "Epoch 72/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0486\n",
                        "Epoch 72: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 72: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0486 - learning_rate: 1.3270e-04\n",
                        "Epoch 73/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0487\n",
                        "Epoch 73: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 73: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 73: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0486 - learning_rate: 1.3270e-04\n",
                        "Epoch 74/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0487\n",
                        "Epoch 74: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 74: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0485 - learning_rate: 1.3270e-04\n",
                        "Epoch 75/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0486\n",
                        "Epoch 75: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 75: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0485 - learning_rate: 1.3270e-04\n",
                        "Epoch 76/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0486\n",
                        "Epoch 76: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 76: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 0.0484 - learning_rate: 1.3270e-04\n",
                        "Epoch 77/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0485\n",
                        "Epoch 77: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 77: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 77: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0485 - learning_rate: 1.3270e-04\n",
                        "Epoch 78/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0483\n",
                        "Epoch 78: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 78: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - loss: 0.0483 - learning_rate: 1.3270e-04\n",
                        "Epoch 79/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0484\n",
                        "Epoch 79: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 79: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0484 - learning_rate: 1.3270e-04\n",
                        "Epoch 80/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0483\n",
                        "Epoch 80: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 80: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 80: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.0483 - learning_rate: 1.3270e-04\n",
                        "Epoch 81/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0483\n",
                        "Epoch 81: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 81: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0483 - learning_rate: 1.3270e-04\n",
                        "Epoch 82/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0483\n",
                        "Epoch 82: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 82: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 82: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0483 - learning_rate: 1.3270e-04\n",
                        "Epoch 83/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0483\n",
                        "Epoch 83: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 83: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0482 - learning_rate: 1.3270e-04\n",
                        "Epoch 84/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0481\n",
                        "Epoch 84: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 84: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0482 - learning_rate: 1.3270e-04\n",
                        "Epoch 85/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0482\n",
                        "Epoch 85: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 85: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 85: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.0482 - learning_rate: 1.3270e-04\n",
                        "Epoch 86/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0482\n",
                        "Epoch 86: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 86: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0482 - learning_rate: 1.3270e-04\n",
                        "Epoch 87/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0481\n",
                        "Epoch 87: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 87: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 87: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0481 - learning_rate: 1.3270e-04\n",
                        "Epoch 88/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0480\n",
                        "Epoch 88: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 88: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0481 - learning_rate: 1.3270e-04\n",
                        "Epoch 89/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0479\n",
                        "Epoch 89: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 89: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0481 - learning_rate: 1.3270e-04\n",
                        "Epoch 90/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0480\n",
                        "Epoch 90: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 90: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 90: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0480 - learning_rate: 1.3270e-04\n",
                        "Epoch 91/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0480\n",
                        "Epoch 91: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 91: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0480 - learning_rate: 1.3270e-04\n",
                        "Epoch 92/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0481\n",
                        "Epoch 92: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 92: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0480 - learning_rate: 1.3270e-04\n",
                        "Epoch 93/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0480\n",
                        "Epoch 93: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 93: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 93: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0480 - learning_rate: 1.3270e-04\n",
                        "Epoch 94/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0479\n",
                        "Epoch 94: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 94: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0480 - learning_rate: 1.3270e-04\n",
                        "Epoch 95/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0480\n",
                        "Epoch 95: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 95: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 95: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0479 - learning_rate: 1.3270e-04\n",
                        "Epoch 96/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0479\n",
                        "Epoch 96: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 96: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - loss: 0.0479 - learning_rate: 1.3270e-04\n",
                        "Epoch 97/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0478\n",
                        "Epoch 97: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 97: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0478 - learning_rate: 1.3270e-04\n",
                        "Epoch 98/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0478\n",
                        "Epoch 98: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 98: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 98: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0478 - learning_rate: 1.3270e-04\n",
                        "Epoch 99/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0477\n",
                        "Epoch 99: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 99: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - loss: 0.0478 - learning_rate: 1.3270e-04\n",
                        "Epoch 100/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0477\n",
                        "Epoch 100: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 100: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - loss: 0.0478 - learning_rate: 1.3270e-04\n",
                        "Epoch 101/200\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0478\n",
                        "Epoch 101: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 101: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 101: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - loss: 0.0478 - learning_rate: 1.3270e-04\n",
                        "Epoch 102/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0477\n",
                        "Epoch 102: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 102: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 0.0477 - learning_rate: 1.3270e-04\n",
                        "Epoch 103/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0477\n",
                        "Epoch 103: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 103: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 103: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 0.0477 - learning_rate: 1.3270e-04\n",
                        "Epoch 104/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0477\n",
                        "Epoch 104: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 104: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - loss: 0.0477 - learning_rate: 1.3270e-04\n",
                        "Epoch 105/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0475\n",
                        "Epoch 105: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 105: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.0476 - learning_rate: 1.3270e-04\n",
                        "Epoch 106/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0476\n",
                        "Epoch 106: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 106: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 106: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0476 - learning_rate: 1.3270e-04\n",
                        "Epoch 107/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0476\n",
                        "Epoch 107: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 107: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0476 - learning_rate: 1.3270e-04\n",
                        "Epoch 108/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0477\n",
                        "Epoch 108: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 108: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 108: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.0476 - learning_rate: 1.3270e-04\n",
                        "Epoch 109/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0476\n",
                        "Epoch 109: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 109: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 0.0476 - learning_rate: 1.3270e-04\n",
                        "Epoch 110/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0476\n",
                        "Epoch 110: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 110: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 0.0476 - learning_rate: 1.3270e-04\n",
                        "Epoch 111/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0476\n",
                        "Epoch 111: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 111: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 111: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0475 - learning_rate: 1.3270e-04\n",
                        "Epoch 112/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0475\n",
                        "Epoch 112: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 112: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - loss: 0.0475 - learning_rate: 1.3270e-04\n",
                        "Epoch 113/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0475\n",
                        "Epoch 113: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 113: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 113: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 0.0475 - learning_rate: 1.3270e-04\n",
                        "Epoch 114/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0473\n",
                        "Epoch 114: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 114: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 0.0475 - learning_rate: 1.3270e-04\n",
                        "Epoch 115/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0475\n",
                        "Epoch 115: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 115: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 115: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.0475 - learning_rate: 1.3270e-04\n",
                        "Epoch 116/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0475\n",
                        "Epoch 116: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 116: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0474 - learning_rate: 1.3270e-04\n",
                        "Epoch 117/200\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0473\n",
                        "Epoch 117: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 117: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0474 - learning_rate: 1.3270e-04\n",
                        "Epoch 118/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0474\n",
                        "Epoch 118: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 118: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 118: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.0474 - learning_rate: 1.3270e-04\n",
                        "Epoch 119/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0475\n",
                        "Epoch 119: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 119: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - loss: 0.0473 - learning_rate: 1.3270e-04\n",
                        "Epoch 120/200\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0471\n",
                        "Epoch 120: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 120: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 120: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 0.0473 - learning_rate: 1.3270e-04\n",
                        "Epoch 121/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0471\n",
                        "Epoch 121: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 121: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.0473 - learning_rate: 1.3270e-04\n",
                        "Epoch 122/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0475\n",
                        "Epoch 122: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 122: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 122: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0474 - learning_rate: 1.3270e-04\n",
                        "Epoch 123/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0472\n",
                        "Epoch 123: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 123: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0472 - learning_rate: 1.3270e-04\n",
                        "Epoch 124/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0474\n",
                        "Epoch 124: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 124: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0473 - learning_rate: 1.3270e-04\n",
                        "Epoch 125/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0472\n",
                        "Epoch 125: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 125: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 125: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0472 - learning_rate: 1.3270e-04\n",
                        "Epoch 126/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0473\n",
                        "Epoch 126: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 126: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.0472 - learning_rate: 1.3270e-04\n",
                        "Epoch 127/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0470\n",
                        "Epoch 127: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 127: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 127: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0471 - learning_rate: 1.3270e-04\n",
                        "Epoch 128/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0471\n",
                        "Epoch 128: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 128: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0472 - learning_rate: 1.3270e-04\n",
                        "Epoch 129/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0472\n",
                        "Epoch 129: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 129: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 129: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0472 - learning_rate: 1.3270e-04\n",
                        "Epoch 130/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0472\n",
                        "Epoch 130: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 130: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0472 - learning_rate: 1.3270e-04\n",
                        "Epoch 131/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0471\n",
                        "Epoch 131: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 131: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0471 - learning_rate: 1.3270e-04\n",
                        "Epoch 132/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0470\n",
                        "Epoch 132: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 132: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0471 - learning_rate: 1.3270e-04\n",
                        "Epoch 133/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0471\n",
                        "Epoch 133: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 133: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 133: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0471 - learning_rate: 1.3270e-04\n",
                        "Epoch 134/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0471\n",
                        "Epoch 134: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 134: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0470 - learning_rate: 1.3270e-04\n",
                        "Epoch 135/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0471\n",
                        "Epoch 135: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 135: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 135: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0470 - learning_rate: 1.3270e-04\n",
                        "Epoch 136/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0470\n",
                        "Epoch 136: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 136: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0469 - learning_rate: 1.3270e-04\n",
                        "Epoch 137/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0469\n",
                        "Epoch 137: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 137: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 0.0470 - learning_rate: 1.3270e-04\n",
                        "Epoch 138/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0469\n",
                        "Epoch 138: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 138: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 138: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0470 - learning_rate: 1.3270e-04\n",
                        "Epoch 139/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0469\n",
                        "Epoch 139: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 139: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - loss: 0.0469 - learning_rate: 1.3270e-04\n",
                        "Epoch 140/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0470\n",
                        "Epoch 140: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 140: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 140: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0469 - learning_rate: 1.3270e-04\n",
                        "Epoch 141/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0469\n",
                        "Epoch 141: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 141: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0469 - learning_rate: 1.3270e-04\n",
                        "Epoch 142/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0471\n",
                        "Epoch 142: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 142: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 142: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 0.0469 - learning_rate: 1.3270e-04\n",
                        "Epoch 143/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0468\n",
                        "Epoch 143: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 143: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - loss: 0.0468 - learning_rate: 1.3270e-04\n",
                        "Epoch 144/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0468\n",
                        "Epoch 144: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 144: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0469 - learning_rate: 1.3270e-04\n",
                        "Epoch 145/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0469\n",
                        "Epoch 145: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 145: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 145: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - loss: 0.0468 - learning_rate: 1.3270e-04\n",
                        "Epoch 146/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0468\n",
                        "Epoch 146: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 146: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - loss: 0.0468 - learning_rate: 1.3270e-04\n",
                        "Epoch 147/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0468\n",
                        "Epoch 147: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 147: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 147: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 0.0467 - learning_rate: 1.3270e-04\n",
                        "Epoch 148/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0467\n",
                        "Epoch 148: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 148: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0467 - learning_rate: 1.3270e-04\n",
                        "Epoch 149/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0468\n",
                        "Epoch 149: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 149: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 149: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.0468 - learning_rate: 1.3270e-04\n",
                        "Epoch 150/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0468\n",
                        "Epoch 150: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 150: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0467 - learning_rate: 1.3270e-04\n",
                        "Epoch 151/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0469\n",
                        "Epoch 151: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 151: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 0.0467 - learning_rate: 1.3270e-04\n",
                        "Epoch 152/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0466\n",
                        "Epoch 152: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 152: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 152: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - loss: 0.0467 - learning_rate: 1.3270e-04\n",
                        "Epoch 153/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0466\n",
                        "Epoch 153: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 153: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0466 - learning_rate: 1.3270e-04\n",
                        "Epoch 154/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0467\n",
                        "Epoch 154: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 154: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0466 - learning_rate: 1.3270e-04\n",
                        "Epoch 155/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0466\n",
                        "Epoch 155: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 155: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 155: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 0.0466 - learning_rate: 1.3270e-04\n",
                        "Epoch 156/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0465\n",
                        "Epoch 156: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 156: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0466 - learning_rate: 1.3270e-04\n",
                        "Epoch 157/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0466\n",
                        "Epoch 157: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 157: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 157: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0465 - learning_rate: 1.3270e-04\n",
                        "Epoch 158/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0467\n",
                        "Epoch 158: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 158: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0466 - learning_rate: 1.3270e-04\n",
                        "Epoch 159/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0465\n",
                        "Epoch 159: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 159: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0465 - learning_rate: 1.3270e-04\n",
                        "Epoch 160/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0466\n",
                        "Epoch 160: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 160: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0465 - learning_rate: 1.3270e-04\n",
                        "Epoch 161/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0464\n",
                        "Epoch 161: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 161: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 161: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0464 - learning_rate: 1.3270e-04\n",
                        "Epoch 162/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0464\n",
                        "Epoch 162: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 162: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0464 - learning_rate: 1.3270e-04\n",
                        "Epoch 163/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0463\n",
                        "Epoch 163: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 163: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 163: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0464 - learning_rate: 1.3270e-04\n",
                        "Epoch 164/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0463\n",
                        "Epoch 164: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 164: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0464 - learning_rate: 1.3270e-04\n",
                        "Epoch 165/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0463\n",
                        "Epoch 165: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 165: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0463 - learning_rate: 1.3270e-04\n",
                        "Epoch 166/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0464\n",
                        "Epoch 166: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 166: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - loss: 0.0463 - learning_rate: 1.3270e-04\n",
                        "Epoch 167/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0463\n",
                        "Epoch 167: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 167: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 167: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0463 - learning_rate: 1.3270e-04\n",
                        "Epoch 168/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0464\n",
                        "Epoch 168: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 168: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0464 - learning_rate: 1.3270e-04\n",
                        "Epoch 169/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0463\n",
                        "Epoch 169: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 169: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 169: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.0464 - learning_rate: 1.3270e-04\n",
                        "Epoch 170/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0463\n",
                        "Epoch 170: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 170: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0463 - learning_rate: 1.3270e-04\n",
                        "Epoch 171/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0463\n",
                        "Epoch 171: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 171: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 171: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0463 - learning_rate: 1.3270e-04\n",
                        "Epoch 172/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0461\n",
                        "Epoch 172: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 172: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0462 - learning_rate: 1.3270e-04\n",
                        "Epoch 173/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0461\n",
                        "Epoch 173: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 173: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0461 - learning_rate: 1.3270e-04\n",
                        "Epoch 174/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0462\n",
                        "Epoch 174: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 174: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 174: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0461 - learning_rate: 1.3270e-04\n",
                        "Epoch 175/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0462\n",
                        "Epoch 175: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 175: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0461 - learning_rate: 1.3270e-04\n",
                        "Epoch 176/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0462\n",
                        "Epoch 176: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 176: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 176: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0461 - learning_rate: 1.3270e-04\n",
                        "Epoch 177/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0461\n",
                        "Epoch 177: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 177: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0461 - learning_rate: 1.3270e-04\n",
                        "Epoch 178/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0461\n",
                        "Epoch 178: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 178: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 178: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0461 - learning_rate: 1.3270e-04\n",
                        "Epoch 179/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0460\n",
                        "Epoch 179: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 179: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0460 - learning_rate: 1.3270e-04\n",
                        "Epoch 180/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0462\n",
                        "Epoch 180: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 180: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0461 - learning_rate: 1.3270e-04\n",
                        "Epoch 181/200\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0460\n",
                        "Epoch 181: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 181: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 181: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - loss: 0.0459 - learning_rate: 1.3270e-04\n",
                        "Epoch 182/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0458\n",
                        "Epoch 182: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 182: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0460 - learning_rate: 1.3270e-04\n",
                        "Epoch 183/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0460\n",
                        "Epoch 183: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 183: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 183: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 0.0460 - learning_rate: 1.3270e-04\n",
                        "Epoch 184/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0458\n",
                        "Epoch 184: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 184: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0459 - learning_rate: 1.3270e-04\n",
                        "Epoch 185/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0458\n",
                        "Epoch 185: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 185: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0459 - learning_rate: 1.3270e-04\n",
                        "Epoch 186/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0458\n",
                        "Epoch 186: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 186: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 186: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0458 - learning_rate: 1.3270e-04\n",
                        "Epoch 187/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0458\n",
                        "Epoch 187: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 187: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0458 - learning_rate: 1.3270e-04\n",
                        "Epoch 188/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0460\n",
                        "Epoch 188: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 188: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 188: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - loss: 0.0459 - learning_rate: 1.3270e-04\n",
                        "Epoch 189/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0457\n",
                        "Epoch 189: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 189: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0458 - learning_rate: 1.3270e-04\n",
                        "Epoch 190/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0457\n",
                        "Epoch 190: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 190: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0457 - learning_rate: 1.3270e-04\n",
                        "Epoch 191/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0456\n",
                        "Epoch 191: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 191: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 191: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - loss: 0.0458 - learning_rate: 1.3270e-04\n",
                        "Epoch 192/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0457\n",
                        "Epoch 192: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 192: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - loss: 0.0457 - learning_rate: 1.3270e-04\n",
                        "Epoch 193/200\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0457\n",
                        "Epoch 193: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 193: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 193: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 0.0457 - learning_rate: 1.3270e-04\n",
                        "Epoch 194/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0458\n",
                        "Epoch 194: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 194: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0457 - learning_rate: 1.3270e-04\n",
                        "Epoch 195/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0459\n",
                        "Epoch 195: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 195: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0456 - learning_rate: 1.3270e-04\n",
                        "Epoch 196/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0456\n",
                        "Epoch 196: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 196: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - loss: 0.0456 - learning_rate: 1.3270e-04\n",
                        "Epoch 197/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0457\n",
                        "Epoch 197: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 197: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 197: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 0.0456 - learning_rate: 1.3270e-04\n",
                        "Epoch 198/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0455\n",
                        "Epoch 198: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 198: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 0.0456 - learning_rate: 1.3270e-04\n",
                        "Epoch 199/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0456\n",
                        "Epoch 199: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 199: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 199: ReduceLROnPlateau reducing learning rate to 6.635119643760845e-05.\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 0.0456 - learning_rate: 1.3270e-04\n",
                        "Epoch 200/200\n",
                        "\u001b[1m58/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0455\n",
                        "Epoch 200: saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\n",
                        "Epoch 200: finished saving model to run/vae/0001_digits/weights/weights.weights.h5\n",
                        "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - loss: 0.0455 - learning_rate: 1.3270e-04\n",
                        "Restoring model weights from the end of the best epoch: 200.\n"
                    ]
                }
            ],
            "source": [
                "AE.train(\n",
                "    x_train,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    epochs=EPOCHS,\n",
                "    run_folder=RUN_FOLDER,\n",
                "    print_every_n_batches=PRINT_EVERY_N_BATCHES,\n",
                "    initial_epoch=INITIAL_EPOCH,\n",
                "    extra_callbacks=[WandbMetricsLogger(), get_lr_scheduler(monitor=\"loss\"), get_early_stopping(monitor=\"loss\", patience=10)]\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Error in callback <bound method _WandbInit._pre_run_cell_hook of <wandb.sdk.wandb_init._WandbInit object at 0x7f0a326a5d30>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f09b4428f30, raw_cell=\"# Plot training history with improved visualizatio..\" transformed_cell=\"# Plot training history with improved visualizatio..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://wsl%2Bubuntu/home/cataluna84/Workspace-Antigravity/Generative_Deep_Learning/v1/notebooks/03_01_autoencoder_train.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D>,),kwargs {}:\n"
                    ]
                },
                {
                    "ename": "MailboxClosedError",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mMailboxClosedError\u001b[39m                        Traceback (most recent call last)",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace-Antigravity/Generative_Deep_Learning/.venv/lib/python3.13/site-packages/wandb/sdk/wandb_init.py:588\u001b[39m, in \u001b[36m_WandbInit._pre_run_cell_hook\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    586\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.notebook \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.notebook.save_ipynb():\n\u001b[32m    587\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.run \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m588\u001b[39m     res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    589\u001b[39m     \u001b[38;5;28mself\u001b[39m._logger.info(\u001b[33m\"\u001b[39m\u001b[33msaved code: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, res)\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.backend.interface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace-Antigravity/Generative_Deep_Learning/.venv/lib/python3.13/site-packages/wandb/sdk/wandb_run.py:458\u001b[39m, in \u001b[36m_raise_if_finished.<locals>.wrapper_fn\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    455\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    456\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_fn\u001b[39m(\u001b[38;5;28mself\u001b[39m: Run, *args: _P.args, **kwargs: _P.kwargs) -> _T:\n\u001b[32m    457\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_finished\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m458\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    460\u001b[39m     message = (\n\u001b[32m    461\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRun (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) is finished. The call to\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    462\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` will be ignored.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    463\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Please make sure that you are using an active run.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    464\u001b[39m     )\n\u001b[32m    466\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UsageError(message)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace-Antigravity/Generative_Deep_Learning/.venv/lib/python3.13/site-packages/wandb/sdk/wandb_run.py:400\u001b[39m, in \u001b[36m_log_to_run.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    397\u001b[39m     run_id = \u001b[38;5;28mself\u001b[39m._attach_id\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m wb_logging.log_to_run(run_id):\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace-Antigravity/Generative_Deep_Learning/.venv/lib/python3.13/site-packages/wandb/sdk/wandb_run.py:445\u001b[39m, in \u001b[36m_attach.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    442\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    443\u001b[39m         _is_attaching = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace-Antigravity/Generative_Deep_Learning/.venv/lib/python3.13/site-packages/wandb/sdk/wandb_run.py:1184\u001b[39m, in \u001b[36mRun.log_code\u001b[39m\u001b[34m(self, root, name, include_fn, exclude_fn)\u001b[39m\n\u001b[32m   1179\u001b[39m     wandb.termwarn(\n\u001b[32m   1180\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo relevant files were detected in the specified directory. No code will be logged to your run.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1181\u001b[39m     )\n\u001b[32m   1182\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1184\u001b[39m artifact = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[38;5;28mself\u001b[39m._config.update(\n\u001b[32m   1187\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33m_wandb\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mcode_path\u001b[39m\u001b[33m\"\u001b[39m: artifact.name}},\n\u001b[32m   1188\u001b[39m     allow_val_change=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   1189\u001b[39m )\n\u001b[32m   1191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m artifact\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace-Antigravity/Generative_Deep_Learning/.venv/lib/python3.13/site-packages/wandb/sdk/wandb_run.py:3314\u001b[39m, in \u001b[36mRun._log_artifact\u001b[39m\u001b[34m(self, artifact_or_path, name, type, aliases, tags, distributed_id, finalize, is_user_created, use_after_commit)\u001b[39m\n\u001b[32m   3312\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.interface:\n\u001b[32m   3313\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._settings._offline:\n\u001b[32m-> \u001b[39m\u001b[32m3314\u001b[39m         handle = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43minterface\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeliver_artifact\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3315\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3316\u001b[39m \u001b[43m            \u001b[49m\u001b[43martifact\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3317\u001b[39m \u001b[43m            \u001b[49m\u001b[43maliases\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3318\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3319\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3320\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfinalize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfinalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3321\u001b[39m \u001b[43m            \u001b[49m\u001b[43mis_user_created\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_user_created\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3322\u001b[39m \u001b[43m            \u001b[49m\u001b[43muse_after_commit\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_after_commit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3323\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3324\u001b[39m         artifact._set_save_handle(handle, \u001b[38;5;28mself\u001b[39m._public_api().client)\n\u001b[32m   3325\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace-Antigravity/Generative_Deep_Learning/.venv/lib/python3.13/site-packages/wandb/sdk/interface/interface.py:599\u001b[39m, in \u001b[36mInterfaceBase.deliver_artifact\u001b[39m\u001b[34m(self, run, artifact, aliases, tags, history_step, is_user_created, use_after_commit, finalize)\u001b[39m\n\u001b[32m    597\u001b[39m     log_artifact.history_step = history_step\n\u001b[32m    598\u001b[39m log_artifact.staging_dir = get_staging_dir()\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_deliver_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_artifact\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace-Antigravity/Generative_Deep_Learning/.venv/lib/python3.13/site-packages/wandb/sdk/interface/interface_shared.py:382\u001b[39m, in \u001b[36mInterfaceShared._deliver_artifact\u001b[39m\u001b[34m(self, log_artifact)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_deliver_artifact\u001b[39m(\n\u001b[32m    378\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    379\u001b[39m     log_artifact: pb.LogArtifactRequest,\n\u001b[32m    380\u001b[39m ) -> MailboxHandle[pb.Result]:\n\u001b[32m    381\u001b[39m     rec = \u001b[38;5;28mself\u001b[39m._make_request(log_artifact=log_artifact)\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_deliver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace-Antigravity/Generative_Deep_Learning/.venv/lib/python3.13/site-packages/wandb/sdk/interface/interface_sock.py:50\u001b[39m, in \u001b[36mInterfaceSock._deliver\u001b[39m\u001b[34m(self, record)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_deliver\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: pb.Record) -> MailboxHandle[pb.Result]:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_asyncer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdeliver_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace-Antigravity/Generative_Deep_Learning/.venv/lib/python3.13/site-packages/wandb/sdk/lib/asyncio_manager.py:136\u001b[39m, in \u001b[36mAsyncioManager.run\u001b[39m\u001b[34m(self, fn)\u001b[39m\n\u001b[32m    133\u001b[39m future = \u001b[38;5;28mself\u001b[39m._schedule(fn, daemon=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m concurrent.futures.CancelledError:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RunCancelledError \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/concurrent/futures/_base.py:456\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace-Antigravity/Generative_Deep_Learning/.venv/lib/python3.13/site-packages/wandb/sdk/lib/asyncio_manager.py:219\u001b[39m, in \u001b[36mAsyncioManager._wrap\u001b[39m\u001b[34m(self, fn, daemon, name)\u001b[39m\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mand\u001b[39;00m (task := asyncio.current_task()):\n\u001b[32m    217\u001b[39m         task.set_name(name)\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fn()\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    221\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m daemon:\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace-Antigravity/Generative_Deep_Learning/.venv/lib/python3.13/site-packages/wandb/sdk/interface/interface_sock.py:58\u001b[39m, in \u001b[36mInterfaceSock.deliver_async\u001b[39m\u001b[34m(self, record)\u001b[39m\n\u001b[32m     55\u001b[39m request = spb.ServerRequest()\n\u001b[32m     56\u001b[39m request.record_publish.CopyFrom(record)\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m handle = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.deliver(request)\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m handle.map(\u001b[38;5;28;01mlambda\u001b[39;00m response: response.result_communicate)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace-Antigravity/Generative_Deep_Learning/.venv/lib/python3.13/site-packages/wandb/sdk/lib/service/service_client.py:53\u001b[39m, in \u001b[36mServiceClient.deliver\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdeliver\u001b[39m(\n\u001b[32m     41\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     42\u001b[39m     request: spb.ServerRequest,\n\u001b[32m     43\u001b[39m ) -> MailboxHandle[spb.ServerResponse]:\n\u001b[32m     44\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Send a request and return a handle to wait for a response.\u001b[39;00m\n\u001b[32m     45\u001b[39m \n\u001b[32m     46\u001b[39m \u001b[33;03m    NOTE: This may mutate the request. The request should not be used\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     51\u001b[39m \u001b[33;03m            stopped due to an error.\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     handle = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mailbox\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequire_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_server_request(request)\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace-Antigravity/Generative_Deep_Learning/.venv/lib/python3.13/site-packages/wandb/sdk/mailbox/mailbox.py:76\u001b[39m, in \u001b[36mMailbox.require_response\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._handles_lock:\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._closed:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m MailboxClosedError()\n\u001b[32m     78\u001b[39m     handle = MailboxResponseHandle(address, asyncer=\u001b[38;5;28mself\u001b[39m._asyncer)\n\u001b[32m     79\u001b[39m     \u001b[38;5;28mself\u001b[39m._handles[address] = handle\n",
                        "\u001b[31mMailboxClosedError\u001b[39m: "
                    ]
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 1400x500 with 2 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Current Optimizer LR: 1.33e-04\n",
                        "=======================================================\n",
                        "               TRAINING SUMMARY\n",
                        "=======================================================\n",
                        "  Initial Loss  : 0.213727\n",
                        "  Final Loss    : 0.045522\n",
                        "  Min Loss      : 0.045522 (Epoch 200)\n",
                        "  Improvement   : 78.7%\n",
                        "  Total Epochs  : 200\n",
                        "  Logged LR     : 1.33e-04 (from history)\n",
                        "=======================================================\n",
                        "Error in callback <bound method _WandbInit._post_run_cell_hook of <wandb.sdk.wandb_init._WandbInit object at 0x7f0a326a5d30>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f09b4428590, execution_count=11 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f09b4428f30, raw_cell=\"# Plot training history with improved visualizatio..\" transformed_cell=\"# Plot training history with improved visualizatio..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://wsl%2Bubuntu/home/cataluna84/Workspace-Antigravity/Generative_Deep_Learning/v1/notebooks/03_01_autoencoder_train.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D> result=None>,),kwargs {}:\n"
                    ]
                },
                {
                    "ename": "ConnectionResetError",
                    "evalue": "Connection lost",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mConnectionResetError\u001b[39m                      Traceback (most recent call last)",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace-Antigravity/Generative_Deep_Learning/.venv/lib/python3.13/site-packages/wandb/sdk/wandb_init.py:604\u001b[39m, in \u001b[36m_WandbInit._post_run_cell_hook\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    601\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    603\u001b[39m \u001b[38;5;28mself\u001b[39m._logger.info(\u001b[33m\"\u001b[39m\u001b[33mresuming backend\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43minterface\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpublish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace-Antigravity/Generative_Deep_Learning/.venv/lib/python3.13/site-packages/wandb/sdk/interface/interface.py:811\u001b[39m, in \u001b[36mInterfaceBase.publish_resume\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    809\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpublish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    810\u001b[39m     resume = pb.ResumeRequest()\n\u001b[32m--> \u001b[39m\u001b[32m811\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_publish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace-Antigravity/Generative_Deep_Learning/.venv/lib/python3.13/site-packages/wandb/sdk/interface/interface_shared.py:334\u001b[39m, in \u001b[36mInterfaceShared._publish_resume\u001b[39m\u001b[34m(self, resume)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_publish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m, resume: pb.ResumeRequest) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    333\u001b[39m     rec = \u001b[38;5;28mself\u001b[39m._make_request(resume=resume)\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace-Antigravity/Generative_Deep_Learning/.venv/lib/python3.13/site-packages/wandb/sdk/interface/interface_sock.py:46\u001b[39m, in \u001b[36mInterfaceSock._publish\u001b[39m\u001b[34m(self, record, nowait)\u001b[39m\n\u001b[32m     44\u001b[39m     \u001b[38;5;28mself\u001b[39m._asyncer.run_soon(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m._client.publish(request))\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_asyncer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpublish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace-Antigravity/Generative_Deep_Learning/.venv/lib/python3.13/site-packages/wandb/sdk/lib/asyncio_manager.py:136\u001b[39m, in \u001b[36mAsyncioManager.run\u001b[39m\u001b[34m(self, fn)\u001b[39m\n\u001b[32m    133\u001b[39m future = \u001b[38;5;28mself\u001b[39m._schedule(fn, daemon=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m concurrent.futures.CancelledError:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RunCancelledError \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/concurrent/futures/_base.py:456\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace-Antigravity/Generative_Deep_Learning/.venv/lib/python3.13/site-packages/wandb/sdk/lib/asyncio_manager.py:219\u001b[39m, in \u001b[36mAsyncioManager._wrap\u001b[39m\u001b[34m(self, fn, daemon, name)\u001b[39m\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mand\u001b[39;00m (task := asyncio.current_task()):\n\u001b[32m    217\u001b[39m         task.set_name(name)\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fn()\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    221\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m daemon:\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace-Antigravity/Generative_Deep_Learning/.venv/lib/python3.13/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[39m, in \u001b[36mServiceClient.publish\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb.ServerRequest) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     37\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_server_request(request)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace-Antigravity/Generative_Deep_Learning/.venv/lib/python3.13/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[39m, in \u001b[36mServiceClient._send_server_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     61\u001b[39m data = request.SerializeToString()\n\u001b[32m     62\u001b[39m \u001b[38;5;28mself\u001b[39m._writer.write(data)\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._writer.drain()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/asyncio/streams.py:386\u001b[39m, in \u001b[36mStreamWriter.drain\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transport.is_closing():\n\u001b[32m    376\u001b[39m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n\u001b[32m    377\u001b[39m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    383\u001b[39m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n\u001b[32m    384\u001b[39m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n\u001b[32m    385\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol._drain_helper()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/asyncio/streams.py:166\u001b[39m, in \u001b[36mFlowControlMixin._drain_helper\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_drain_helper\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    165\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection_lost:\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionResetError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mConnection lost\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._paused:\n\u001b[32m    168\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
                        "\u001b[31mConnectionResetError\u001b[39m: Connection lost"
                    ]
                }
            ],
            "source": [
                "# Plot training history with improved visualization\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "\n",
                "history = AE.model.history.history\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Plot 1: Training Loss\n",
                "axes[0].plot(history['loss'], 'b-', linewidth=2)\n",
                "axes[0].set_xlabel('Epoch')\n",
                "axes[0].set_ylabel('Loss')\n",
                "axes[0].set_title('Training Loss Over Epochs')\n",
                "axes[0].grid(True, alpha=0.3)\n",
                "\n",
                "# Plot 2: Learning Rate with better handling\n",
                "if 'learning_rate' in history:\n",
                "    lr_data = np.array(history['learning_rate'])\n",
                "    lr_min, lr_max = lr_data.min(), lr_data.max()\n",
                "    lr_range = lr_max - lr_min\n",
                "    \n",
                "    if lr_range > 1e-10:  # LR actually changed\n",
                "        axes[1].semilogy(lr_data, 'r-', linewidth=2)\n",
                "        axes[1].set_title(f'Learning Rate Schedule (Range: {lr_min:.2e} - {lr_max:.2e})')\n",
                "    else:  # LR was constant\n",
                "        axes[1].plot(lr_data, 'r-', linewidth=2)\n",
                "        axes[1].set_ylim([lr_min * 0.5, lr_max * 1.5])  # Add padding\n",
                "        axes[1].set_title(f'Learning Rate (Constant: {lr_data[0]:.2e})')\n",
                "        axes[1].text(0.5, 0.95, 'Note: ReduceLROnPlateau changes may not be logged in history',\n",
                "                     transform=axes[1].transAxes, fontsize=9, ha='center', va='top',\n",
                "                     style='italic', color='gray')\n",
                "    \n",
                "    axes[1].set_xlabel('Epoch')\n",
                "    axes[1].set_ylabel('Learning Rate')\n",
                "    axes[1].grid(True, alpha=0.3)\n",
                "else:\n",
                "    axes[1].text(0.5, 0.5, 'LR not tracked in history', ha='center', va='center')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Get actual current LR from optimizer\n",
                "try:\n",
                "    current_lr = float(AE.model.optimizer.learning_rate)\n",
                "    print(f\"Current Optimizer LR: {current_lr:.2e}\")\n",
                "except:\n",
                "    pass\n",
                "\n",
                "# Print summary\n",
                "print(f\"{'='*55}\")\n",
                "print('               TRAINING SUMMARY')\n",
                "print(f\"{'='*55}\")\n",
                "print(f\"  Initial Loss  : {history['loss'][0]:.6f}\")\n",
                "print(f\"  Final Loss    : {history['loss'][-1]:.6f}\")\n",
                "print(f\"  Min Loss      : {min(history['loss']):.6f} (Epoch {history['loss'].index(min(history['loss'])) + 1})\")\n",
                "print(f\"  Improvement   : {((history['loss'][0] - history['loss'][-1]) / history['loss'][0] * 100):.1f}%\")\n",
                "print(f\"  Total Epochs  : {len(history['loss'])}\")\n",
                "if 'learning_rate' in history:\n",
                "    print(f\"  Logged LR     : {history['learning_rate'][-1]:.2e} (from history)\")\n",
                "print(f\"{'='*55}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▇▇▇▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>199</td></tr><tr><td>epoch/learning_rate</td><td>0.00013</td></tr><tr><td>epoch/loss</td><td>0.04497</td></tr></table><br/></div></div>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View run <strong style=\"color:#cdcd00\">03_01_autoencoder</strong> at: <a href='https://wandb.ai/cataluna84/generative-deep-learning/runs/wy58jsue' target=\"_blank\">https://wandb.ai/cataluna84/generative-deep-learning/runs/wy58jsue</a><br> View project at: <a href='https://wandb.ai/cataluna84/generative-deep-learning' target=\"_blank\">https://wandb.ai/cataluna84/generative-deep-learning</a><br>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Find logs at: <code>./wandb/run-20251228_121850-wy58jsue/logs</code>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "wandb.finish()\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
