{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE Training - Faces Dataset (CelebA)\n",
    "\n",
    "Variational Autoencoder training on the CelebA face dataset with:\n",
    "- W&B experiment tracking\n",
    "- LRFinder for optimal learning rate\n",
    "- Learning rate scheduling and early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-30 20:48:46.226053: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/cataluna84/Workspace-Antigravity/Generative_Deep_Learning/.venv/lib/python3.13/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU enabled: /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Robust GPU memory growth setup\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(f\"GPU enabled: {gpus[0].name}\")\n",
    "else:\n",
    "    print(\"No GPU found, using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TensorFlow/Keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Local imports\n",
    "from src.models.VAE import VariationalAutoencoder\n",
    "\n",
    "# W&B and utilities\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbMetricsLogger\n",
    "from utils.callbacks import LRFinder, get_lr_scheduler, get_early_stopping, LRLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run folder: run/vae/0002_faces\n"
     ]
    }
   ],
   "source": [
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# GLOBAL CONFIGURATION\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "SECTION = 'vae'\n",
    "RUN_ID = '0002'\n",
    "DATA_NAME = 'faces'\n",
    "MODE = 'build'  # 'build' or 'load'\n",
    "\n",
    "# Data\n",
    "DATA_FOLDER = '../data/img_align_celeba/'\n",
    "INPUT_DIM = (128, 128, 3)\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 384\n",
    "EPOCHS = 200\n",
    "INITIAL_EPOCH = 0\n",
    "PRINT_EVERY_N_BATCHES = 100\n",
    "\n",
    "# VAE-specific\n",
    "R_LOSS_FACTOR = 10000\n",
    "Z_DIM = 200\n",
    "\n",
    "# Architecture\n",
    "ENCODER_FILTERS = [32, 64, 64, 64]\n",
    "ENCODER_KERNELS = [3, 3, 3, 3]\n",
    "ENCODER_STRIDES = [2, 2, 2, 2]\n",
    "DECODER_FILTERS = [64, 64, 32, 3]\n",
    "DECODER_KERNELS = [3, 3, 3, 3]\n",
    "DECODER_STRIDES = [2, 2, 2, 2]\n",
    "USE_BATCH_NORM = True\n",
    "USE_DROPOUT = True\n",
    "\n",
    "# Run folder setup\n",
    "RUN_FOLDER = f'run/{SECTION}/{RUN_ID}_{DATA_NAME}'\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.makedirs(RUN_FOLDER)\n",
    "    os.makedirs(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.makedirs(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.makedirs(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "print(f\"Run folder: {RUN_FOLDER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W&B Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcataluna84\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/cataluna84/Workspace-Antigravity/Generative_Deep_Learning/v1/notebooks/wandb/run-20251230_204855-x0hjafbf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cataluna84/generative-deep-learning/runs/x0hjafbf' target=\"_blank\">vae-faces-0002</a></strong> to <a href='https://wandb.ai/cataluna84/generative-deep-learning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cataluna84/generative-deep-learning' target=\"_blank\">https://wandb.ai/cataluna84/generative-deep-learning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cataluna84/generative-deep-learning/runs/x0hjafbf' target=\"_blank\">https://wandb.ai/cataluna84/generative-deep-learning/runs/x0hjafbf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project=\"generative-deep-learning\",\n",
    "    name=f\"vae-faces-{RUN_ID}\",\n",
    "    config={\n",
    "        \"model\": \"VAE\",\n",
    "        \"dataset\": DATA_NAME,\n",
    "        \"learning_rate\": \"auto\",  # Updated after LRFinder\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"z_dim\": Z_DIM,\n",
    "        \"r_loss_factor\": R_LOSS_FACTOR,\n",
    "        \"input_dim\": INPUT_DIM,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path pattern: ../data/img_align_celeba/*/*.jpg\n",
      "Found 202599 images\n"
     ]
    }
   ],
   "source": [
    "# Check data path\n",
    "print(f\"Data path pattern: {os.path.join(DATA_FOLDER, '*/*.jpg')}\")\n",
    "\n",
    "filenames = np.array(glob(os.path.join(DATA_FOLDER, '*/*.jpg')))\n",
    "NUM_IMAGES = len(filenames)\n",
    "print(f\"Found {NUM_IMAGES} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202599 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create data generator\n",
    "data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "data_flow = data_gen.flow_from_directory(\n",
    "    DATA_FOLDER,\n",
    "    target_size=INPUT_DIM[:2],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    class_mode='input',\n",
    "    subset=\"training\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1767127743.484494   11041 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6094 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "vae = VariationalAutoencoder(\n",
    "    input_dim=INPUT_DIM,\n",
    "    encoder_conv_filters=ENCODER_FILTERS,\n",
    "    encoder_conv_kernel_size=ENCODER_KERNELS,\n",
    "    encoder_conv_strides=ENCODER_STRIDES,\n",
    "    decoder_conv_t_filters=DECODER_FILTERS,\n",
    "    decoder_conv_t_kernel_size=DECODER_KERNELS,\n",
    "    decoder_conv_t_strides=DECODER_STRIDES,\n",
    "    z_dim=Z_DIM,\n",
    "    use_batch_norm=USE_BATCH_NORM,\n",
    "    use_dropout=USE_DROPOUT\n",
    ")\n",
    "\n",
    "if MODE == 'build':\n",
    "    vae.save(RUN_FOLDER)\n",
    "else:\n",
    "    vae.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n",
       "\u2503<span style=\"font-weight: bold\"> Layer (type)        </span>\u2503<span style=\"font-weight: bold\"> Output Shape      </span>\u2503<span style=\"font-weight: bold\">    Param # </span>\u2503<span style=\"font-weight: bold\"> Connected to      </span>\u2503\n",
       "\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n",
       "\u2502 encoder_input       \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 -                 \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 encoder_conv_0      \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> \u2502 encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\u2026 \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 batch_normalization \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> \u2502 encoder_conv_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\u2026 \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 leaky_re_lu         \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 batch_normalizat\u2026 \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 leaky_re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \u2502\n",
       "\u2502                     \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 encoder_conv_1      \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> \u2502 dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 batch_normalizatio\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \u2502 encoder_conv_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\u2026 \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 leaky_re_lu_1       \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 batch_normalizat\u2026 \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 leaky_re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\u2026 \u2502\n",
       "\u2502                     \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 encoder_conv_2      \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> \u2502 dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 batch_normalizatio\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \u2502 encoder_conv_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\u2026 \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 leaky_re_lu_2       \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 batch_normalizat\u2026 \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 leaky_re_lu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\u2026 \u2502\n",
       "\u2502                     \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 encoder_conv_3      \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> \u2502 dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 batch_normalizatio\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \u2502 encoder_conv_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\u2026 \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 leaky_re_lu_3       \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 batch_normalizat\u2026 \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 leaky_re_lu_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\u2026 \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)      \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 mu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       \u2502    <span style=\"color: #00af00; text-decoration-color: #00af00\">819,400</span> \u2502 flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 log_var (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       \u2502    <span style=\"color: #00af00; text-decoration-color: #00af00\">819,400</span> \u2502 flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 kl_loss_layer       \u2502 [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>),     \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 mu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">KLLossLayer</span>)       \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)]      \u2502            \u2502 log_var[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 encoder_output      \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 kl_loss_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\u2026 \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            \u2502                   \u2502            \u2502 kl_loss_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\u2026 \u2502\n",
       "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n",
       "\u2503\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u2503\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u2503\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u2503\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\u2503\n",
       "\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n",
       "\u2502 encoder_input       \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  \u2502          \u001b[38;5;34m0\u001b[0m \u2502 -                 \u2502\n",
       "\u2502 (\u001b[38;5;33mInputLayer\u001b[0m)        \u2502 \u001b[38;5;34m3\u001b[0m)                \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 encoder_conv_0      \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    \u2502        \u001b[38;5;34m896\u001b[0m \u2502 encoder_input[\u001b[38;5;34m0\u001b[0m]\u2026 \u2502\n",
       "\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m32\u001b[0m)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 batch_normalization \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    \u2502        \u001b[38;5;34m128\u001b[0m \u2502 encoder_conv_0[\u001b[38;5;34m0\u001b[0m\u2026 \u2502\n",
       "\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m32\u001b[0m)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 leaky_re_lu         \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 batch_normalizat\u2026 \u2502\n",
       "\u2502 (\u001b[38;5;33mLeakyReLU\u001b[0m)         \u2502 \u001b[38;5;34m32\u001b[0m)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dropout (\u001b[38;5;33mDropout\u001b[0m)   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 leaky_re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \u2502\n",
       "\u2502                     \u2502 \u001b[38;5;34m32\u001b[0m)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 encoder_conv_1      \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    \u2502     \u001b[38;5;34m18,496\u001b[0m \u2502 dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \u2502\n",
       "\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m64\u001b[0m)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 batch_normalizatio\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    \u2502        \u001b[38;5;34m256\u001b[0m \u2502 encoder_conv_1[\u001b[38;5;34m0\u001b[0m\u2026 \u2502\n",
       "\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m64\u001b[0m)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 leaky_re_lu_1       \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 batch_normalizat\u2026 \u2502\n",
       "\u2502 (\u001b[38;5;33mLeakyReLU\u001b[0m)         \u2502 \u001b[38;5;34m64\u001b[0m)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dropout_1 (\u001b[38;5;33mDropout\u001b[0m) \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 leaky_re_lu_1[\u001b[38;5;34m0\u001b[0m]\u2026 \u2502\n",
       "\u2502                     \u2502 \u001b[38;5;34m64\u001b[0m)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 encoder_conv_2      \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    \u2502     \u001b[38;5;34m36,928\u001b[0m \u2502 dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \u2502\n",
       "\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m64\u001b[0m)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 batch_normalizatio\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    \u2502        \u001b[38;5;34m256\u001b[0m \u2502 encoder_conv_2[\u001b[38;5;34m0\u001b[0m\u2026 \u2502\n",
       "\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m64\u001b[0m)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 leaky_re_lu_2       \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 batch_normalizat\u2026 \u2502\n",
       "\u2502 (\u001b[38;5;33mLeakyReLU\u001b[0m)         \u2502 \u001b[38;5;34m64\u001b[0m)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dropout_2 (\u001b[38;5;33mDropout\u001b[0m) \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 leaky_re_lu_2[\u001b[38;5;34m0\u001b[0m]\u2026 \u2502\n",
       "\u2502                     \u2502 \u001b[38;5;34m64\u001b[0m)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 encoder_conv_3      \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)  \u2502     \u001b[38;5;34m36,928\u001b[0m \u2502 dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \u2502\n",
       "\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 batch_normalizatio\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)  \u2502        \u001b[38;5;34m256\u001b[0m \u2502 encoder_conv_3[\u001b[38;5;34m0\u001b[0m\u2026 \u2502\n",
       "\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 leaky_re_lu_3       \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)  \u2502          \u001b[38;5;34m0\u001b[0m \u2502 batch_normalizat\u2026 \u2502\n",
       "\u2502 (\u001b[38;5;33mLeakyReLU\u001b[0m)         \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dropout_3 (\u001b[38;5;33mDropout\u001b[0m) \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)  \u2502          \u001b[38;5;34m0\u001b[0m \u2502 leaky_re_lu_3[\u001b[38;5;34m0\u001b[0m]\u2026 \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 flatten (\u001b[38;5;33mFlatten\u001b[0m)   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)      \u2502          \u001b[38;5;34m0\u001b[0m \u2502 dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 mu (\u001b[38;5;33mDense\u001b[0m)          \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)       \u2502    \u001b[38;5;34m819,400\u001b[0m \u2502 flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 log_var (\u001b[38;5;33mDense\u001b[0m)     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)       \u2502    \u001b[38;5;34m819,400\u001b[0m \u2502 flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 kl_loss_layer       \u2502 [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m),     \u2502          \u001b[38;5;34m0\u001b[0m \u2502 mu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         \u2502\n",
       "\u2502 (\u001b[38;5;33mKLLossLayer\u001b[0m)       \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)]      \u2502            \u2502 log_var[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 encoder_output      \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)       \u2502          \u001b[38;5;34m0\u001b[0m \u2502 kl_loss_layer[\u001b[38;5;34m0\u001b[0m]\u2026 \u2502\n",
       "\u2502 (\u001b[38;5;33mLambda\u001b[0m)            \u2502                   \u2502            \u2502 kl_loss_layer[\u001b[38;5;34m0\u001b[0m]\u2026 \u2502\n",
       "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,732,944</span> (6.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,732,944\u001b[0m (6.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,732,496</span> (6.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,732,496\u001b[0m (6.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vae.encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n",
       "\u2503<span style=\"font-weight: bold\"> Layer (type)                    </span>\u2503<span style=\"font-weight: bold\"> Output Shape           </span>\u2503<span style=\"font-weight: bold\">       Param # </span>\u2503\n",
       "\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n",
       "\u2502 decoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            \u2502             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           \u2502       <span style=\"color: #00af00; text-decoration-color: #00af00\">823,296</span> \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       \u2502             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 decoder_conv_t_0                \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               \u2502                        \u2502               \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 batch_normalization_4           \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     \u2502           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            \u2502                        \u2502               \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     \u2502             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     \u2502             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 decoder_conv_t_1                \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               \u2502                        \u2502               \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 batch_normalization_5           \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     \u2502           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            \u2502                        \u2502               \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 leaky_re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     \u2502             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     \u2502             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 decoder_conv_t_2                \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               \u2502                        \u2502               \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 batch_normalization_6           \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     \u2502           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            \u2502                        \u2502               \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 leaky_re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     \u2502             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     \u2502             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 decoder_conv_t_3                \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    \u2502           <span style=\"color: #00af00; text-decoration-color: #00af00\">867</span> \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               \u2502                        \u2502               \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    \u2502             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502\n",
       "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n",
       "\u2503\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u2503\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u2503\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\u2503\n",
       "\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n",
       "\u2502 decoder_input (\u001b[38;5;33mInputLayer\u001b[0m)      \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            \u2502             \u001b[38;5;34m0\u001b[0m \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dense (\u001b[38;5;33mDense\u001b[0m)                   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           \u2502       \u001b[38;5;34m823,296\u001b[0m \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 reshape (\u001b[38;5;33mReshape\u001b[0m)               \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       \u2502             \u001b[38;5;34m0\u001b[0m \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 decoder_conv_t_0                \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     \u2502        \u001b[38;5;34m36,928\u001b[0m \u2502\n",
       "\u2502 (\u001b[38;5;33mConv2DTranspose\u001b[0m)               \u2502                        \u2502               \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 batch_normalization_4           \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     \u2502           \u001b[38;5;34m256\u001b[0m \u2502\n",
       "\u2502 (\u001b[38;5;33mBatchNormalization\u001b[0m)            \u2502                        \u2502               \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)       \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     \u2502             \u001b[38;5;34m0\u001b[0m \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     \u2502             \u001b[38;5;34m0\u001b[0m \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 decoder_conv_t_1                \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     \u2502        \u001b[38;5;34m36,928\u001b[0m \u2502\n",
       "\u2502 (\u001b[38;5;33mConv2DTranspose\u001b[0m)               \u2502                        \u2502               \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 batch_normalization_5           \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     \u2502           \u001b[38;5;34m256\u001b[0m \u2502\n",
       "\u2502 (\u001b[38;5;33mBatchNormalization\u001b[0m)            \u2502                        \u2502               \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 leaky_re_lu_5 (\u001b[38;5;33mLeakyReLU\u001b[0m)       \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     \u2502             \u001b[38;5;34m0\u001b[0m \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     \u2502             \u001b[38;5;34m0\u001b[0m \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 decoder_conv_t_2                \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     \u2502        \u001b[38;5;34m18,464\u001b[0m \u2502\n",
       "\u2502 (\u001b[38;5;33mConv2DTranspose\u001b[0m)               \u2502                        \u2502               \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 batch_normalization_6           \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     \u2502           \u001b[38;5;34m128\u001b[0m \u2502\n",
       "\u2502 (\u001b[38;5;33mBatchNormalization\u001b[0m)            \u2502                        \u2502               \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 leaky_re_lu_6 (\u001b[38;5;33mLeakyReLU\u001b[0m)       \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     \u2502             \u001b[38;5;34m0\u001b[0m \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     \u2502             \u001b[38;5;34m0\u001b[0m \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 decoder_conv_t_3                \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    \u2502           \u001b[38;5;34m867\u001b[0m \u2502\n",
       "\u2502 (\u001b[38;5;33mConv2DTranspose\u001b[0m)               \u2502                        \u2502               \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 activation (\u001b[38;5;33mActivation\u001b[0m)         \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    \u2502             \u001b[38;5;34m0\u001b[0m \u2502\n",
       "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">917,123</span> (3.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m917,123\u001b[0m (3.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">916,803</span> (3.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m916,803\u001b[0m (3.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> (1.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m320\u001b[0m (1.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vae.decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Finder\n",
    "\n",
    "Find the optimal learning rate by training on a sample batch with exponentially increasing LR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample batch shape: (384, 128, 128, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-30 20:49:25.370323: I external/local_xla/xla/service/service.cc:163] XLA service 0x7663580096b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-12-30 20:49:25.370383: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 2070, Compute Capability 7.5\n",
      "2025-12-30 20:49:25.774128: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-12-30 20:49:27.402173: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91701\n",
      "I0000 00:00:1767127790.757725   11187 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Learning Rate (Recommended): 0.000001\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAA46tJREFUeJzs3XmcTfUfx/HXvbMyzFjHjDC2rMkaBoXIKJQSkbKNrShFKWUt1S9FmzYSKgoloSyTpYSskWyVSGHsjG2WO/f7++M0d+YawzBm7izv5+NxHp3zPd/zPZ9znJnb/cz3fL82Y4xBREREREREREQkC9k9HYCIiIiIiIiIiOQ9SkqJiIiIiIiIiEiWU1JKRERERERERESynJJSIiIiIiIiIiKS5ZSUEhERERERERGRLKeklIiIiIiIiIiIZDklpUREREREREREJMspKSUiIiIiIiIiIllOSSkREREREREREclySkqJiIhIlihbtiw9evTwdBg53rRp07DZbOzbty9btykiIiJyJUpKiYiI5CBJyYONGzd6OpQcxWazuS2BgYE0bdqUb7/99prbnDlzJm+++eb1C/I/PXr0SBVv0rJ48eLrfr7somzZsrRt29bTYXjUvn37sNlsvP7665etV7ZsWbfnIiAggPr16/PJJ59kUaQiIiLXh7enAxAREZG8Yffu3djtnvt72B133EG3bt0wxvD333/z/vvv065dOxYtWkRERMRVtzdz5kx+++03nnjiieseq5+fHx999FGq8po1a3LHHXfQuXNn/Pz8rvt5JeeoVasWQ4YMAeDQoUN89NFHdO/enbi4OPr06ePh6ERERNJHSSkRERG5ag6HA6fTia+vb7qP8XQSpVKlSjz00EOu7Q4dOlCtWjXeeuuta0pKZSZvb2+3WC/m5eWVhdFcvXPnzhEQEODpMHK1G264we0Z6dGjB+XLl+eNN95QUkpERHIMvb4nIiKSCx04cIBevXpRokQJ/Pz8qF69Oh9//LFbnfj4eEaOHEndunUJCgoiICCAW2+9lRUrVrjVS/lK0ZtvvkmFChXw8/Njx44djB49GpvNxp9//kmPHj0oVKgQQUFB9OzZk/Pnz7u1c/GYUkmvIq5evZrBgwdTvHhxAgICuPfeezl69KjbsU6nk9GjR1OyZEny589P8+bN2bFjR4bGqapatSrFihVjz549buXffPMNbdq0oWTJkvj5+VGhQgVefPFFEhMTXXWaNWvGt99+y99//+16haps2bKu/XFxcYwaNYqKFSvi5+dH6dKlGTp0KHFxcdcUa0qXGv8p6dW3n376ifr16+Pv70/58uUv+TrX9u3buf3228mXLx+lSpVi7NixOJ3OS55r0aJF3HrrrQQEBFCwYEHatGnD9u3b3er06NGDAgUKsGfPHu666y4KFixI165dATh27Bi7du1K9SxcK4fDwYsvvuh6BsuWLctzzz2X6r5u3LiRiIgIihUrRr58+ShXrhy9evVyq/PFF19Qt25dChYsSGBgIDVq1OCtt95K89wJCQkUKVKEnj17ptoXExODv78/Tz31lKvsnXfeoXr16uTPn5/ChQtTr149Zs6cmcE7kLbixYtTpUqVVM+ziIhIdqaeUiIiIrnM4cOHadiwITabjYEDB1K8eHEWLVpEZGQkMTExrtfNYmJi+Oijj+jSpQt9+vThzJkzTJkyhYiICNavX0+tWrXc2p06dSqxsbH07dsXPz8/ihQp4trXqVMnypUrxyuvvMLmzZv56KOPCA4O5tVXX71ivI899hiFCxdm1KhR7Nu3jzfffJOBAwcya9YsV51hw4Yxbtw42rVrR0REBFu3biUiIoLY2Nhrvk+nT5/m5MmTVKhQwa182rRpFChQgMGDB1OgQAGWL1/OyJEjiYmJ4bXXXgPg+eef5/Tp0/z777+88cYbABQoUACwEmh33303P/30E3379qVq1aps27aNN954g99//5158+alK75jx465bfv4+BAUFJRm/T///JP777+fyMhIunfvzscff0yPHj2oW7cu1atXByA6OprmzZvjcDh49tlnCQgIYNKkSeTLly9Ve59++indu3cnIiKCV199lfPnz/P+++/TpEkTfvnlF7cknMPhICIigiZNmvD666+TP39+ACZOnMiYMWNYsWIFzZo1S9d1X07v3r2ZPn06999/P0OGDGHdunW88sor7Ny5k6+//hqAI0eO0KpVK4oXL86zzz5LoUKF2LdvH3PnznW1ExUVRZcuXWjRooXrGd25cyerV69m0KBBlzy3j48P9957L3PnzuXDDz906yU4b9484uLi6Ny5MwCTJ0/m8ccf5/7772fQoEHExsby66+/sm7dOh588MEM34dLcTgc/PvvvxQuXDhT2hcREckURkRERHKMqVOnGsBs2LAhzTqRkZEmNDTUHDt2zK28c+fOJigoyJw/f94YY4zD4TBxcXFudU6ePGlKlChhevXq5Srbu3evAUxgYKA5cuSIW/1Ro0YZwK2+Mcbce++9pmjRom5lYWFhpnv37qmupWXLlsbpdLrKn3zySePl5WVOnTpljDEmOjraeHt7m/bt27u1N3r0aAO4tZkWwERGRpqjR4+aI0eOmI0bN5rWrVsbwLz22mtudZPuT0r9+vUz+fPnN7Gxsa6yNm3amLCwsFR1P/30U2O3282qVavcyj/44AMDmNWrV1821u7duxsg1dK0aVNjTPJ927t3r+uYsLAwA5gff/zRVXbkyBHj5+dnhgwZ4ip74oknDGDWrVvnVi8oKMitzTNnzphChQqZPn36uMUWHR1tgoKC3MqT4n322WdTXUvS87FixYrLXnPSNbRp0ybN/Vu2bDGA6d27t1v5U089ZQCzfPlyY4wxX3/99RV/RgYNGmQCAwONw+G4YlwpLVmyxABmwYIFbuV33XWXKV++vGv7nnvuMdWrV7+qto1J/lm7+Jm8WFhYmGnVqpU5evSoOXr0qNm2bZt5+OGHDWAGDBhw1ecVERHxFL2+JyIikosYY/jqq69o164dxhiOHTvmWiIiIjh9+jSbN28GrHGJknp7OJ1OTpw4gcPhoF69eq46KXXo0IHixYtf8rz9+/d327711ls5fvw4MTExV4y5b9++2Gw2t2MTExP5+++/AVi2bBkOh4NHH33U7bjHHnvsim2nNGXKFIoXL05wcDD16tVj2bJlDB06lMGDB7vVS9lr6MyZMxw7doxbb72V8+fPs2vXriueZ86cOVStWpUqVaq43f/bb78dINXrkZfi7+9PVFSU2zJ+/PjLHlOtWjVuvfVW13bx4sWpXLkyf/31l6vsu+++o2HDhtSvX9+tXtLrdkmioqI4deoUXbp0cbsGLy8vGjRocMlreOSRR1KVjR49GmPMdekl9d133wGk+vdKGuw7aSbFQoUKAbBw4UISEhIu2VahQoU4d+4cUVFRVxXD7bffTrFixdx68Z08eZKoqCgeeOABt/b//fdfNmzYcFXtX42lS5dSvHhxihcvTo0aNfj000/p2bOnqzefiIhITqDX90RERHKRo0ePcurUKSZNmsSkSZMuWefIkSOu9enTpzN+/Hh27drl9gW+XLlyqY67VFmSMmXKuG0nvUJ08uRJAgMDLxvz5Y4FXMmpihUrutUrUqTIVb2qdM899zBw4EDi4+PZsGEDL7/8MufPn081I+D27dsZPnw4y5cvT5VUO3369BXP88cff7Bz5840E3gp739avLy8aNmy5RXrpXTxfQTrXibdR7DuZYMGDVLVq1y5stv2H3/8AeBKpF3s4n9Tb29vSpUqdVXxXq2///4bu92e6jkICQmhUKFCruekadOmdOjQgTFjxvDGG2/QrFkz2rdvz4MPPugabP/RRx9l9uzZ3Hnnndxwww20atWKTp060bp168vG4O3tTYcOHZg5cyZxcXH4+fkxd+5cEhIS3JJSzzzzDN9//z3169enYsWKtGrVigcffJDGjRtft/vRoEEDxo4dS2JiIr/99htjx47l5MmTVzX5gIiIiKcpKSUiIpKLJA1Y/dBDD9G9e/dL1rn55psB+Oyzz+jRowft27fn6aefJjg4GC8vL1555ZVLDpZ8qXGHkqQ1G5wx5ooxZ+TYq1GqVClXoueuu+6iWLFiDBw4kObNm3PfffcBcOrUKZo2bUpgYCAvvPACFSpUwN/fn82bN/PMM8+kOSB4Sk6nkxo1ajBhwoRL7i9duvT1u6gUrud9TLrOTz/9lJCQkFT7vb3d/xfSz88vVXIvs6TsVZfW/i+//JKff/6ZBQsWsGTJEnr16sX48eP5+eefKVCgAMHBwWzZsoUlS5awaNEiFi1axNSpU+nWrRvTp0+/bPudO3fmww8/ZNGiRbRv357Zs2dTpUoVatas6apTtWpVdu/ezcKFC1m8eDFfffUV7733HiNHjmTMmDHX5T4UK1bM9TxHRERQpUoV2rZty1tvvZWqN5mIiEh2paSUiIhILlK8eHEKFixIYmLiFXvafPnll5QvX565c+e6fdEfNWpUZod5VcLCwgBrIO+UvbWOHz/u1gvoavXr14833niD4cOHc++992Kz2Vi5ciXHjx9n7ty53Hbbba66e/fuTXV8WsmRChUqsHXrVlq0aHHFBEpWCwsLc/WCSmn37t1u20mDvwcHB191j63MEhYWhtPp5I8//qBq1aqu8sOHD3Pq1CnXc5KkYcOGNGzYkJdeeomZM2fStWtXvvjiC3r37g2Ar68v7dq1o127djidTh599FE+/PBDRowYkao3Vkq33XYboaGhzJo1iyZNmrB8+XKef/75VPUCAgJ44IEHeOCBB4iPj+e+++7jpZdeYtiwYfj7+1+nu5KsTZs2NG3alJdffpl+/foREBBw3c8hIiJyvWlMKRERkVzEy8uLDh068NVXX/Hbb7+l2n/06FG3uuDek2bdunWsXbs28wO9Ci1atMDb25v333/frXzixIkZatfb25shQ4awc+dOvvnmG+DS9yQ+Pp733nsv1fEBAQGXfJ2vU6dOHDhwgMmTJ6fad+HCBc6dO5ehuDPirrvu4ueff2b9+vWusqNHjzJjxgy3ehEREQQGBvLyyy9fclymlM/R5Rw7doxdu3Zx/vz5jAWOFTvAm2++6Vae1COtTZs2gPXa58W9w5JmkoyLiwOshGZKdrvd1YMwqU5a7HY7999/PwsWLODTTz/F4XC4vbp3qfZ9fX2pVq0axpg0x7m6Hp555hmOHz9+yWdPREQkO1JPKRERkRzo448/ZvHixanKBw0axP/+9z9WrFhBgwYN6NOnD9WqVePEiRNs3ryZ77//nhMnTgDQtm1b5s6dy7333kubNm3Yu3cvH3zwAdWqVePs2bNZfUlpKlGiBIMGDWL8+PHcfffdtG7dmq1bt7Jo0SKKFSuWod5IPXr0YOTIkbz66qu0b9+eRo0aUbhwYbp3787jjz+OzWbj008/veQrcHXr1mXWrFkMHjyYW265hQIFCtCuXTsefvhhZs+eTf/+/VmxYgWNGzcmMTGRXbt2MXv2bJYsWUK9evUyckuu2dChQ/n0009p3bo1gwYNIiAggEmTJhEWFsavv/7qqhcYGMj777/Pww8/TJ06dejcuTPFixdn//79fPvttzRu3DhdScGJEycyZswYVqxYka7Bzv/880/Gjh2bqrx27dq0adOG7t27M2nSJNdrluvXr2f69Om0b9+e5s2bA9Y4ae+99x733nsvFSpU4MyZM0yePJnAwEBXYqt3796cOHGC22+/nVKlSvH333/zzjvvUKtWLbdeWGl54IEHeOeddxg1ahQ1atRIdUyrVq0ICQmhcePGlChRgp07dzJx4kTatGlDwYIFr9j+smXLiI2NTVXevn17brrppjSPu/POO7npppuYMGECAwYMwMfH54rnEhER8SQlpURERHKgi3sNJenRowelSpVi/fr1vPDCC8ydO5f33nuPokWLUr16dV599VW3utHR0Xz44YcsWbKEatWq8dlnnzFnzhxWrlyZRVeSPq+++ir58+dn8uTJfP/994SHh7N06VKaNGmSoVeh8uXLx8CBAxk9ejQrV66kWbNmLFy4kCFDhjB8+HAKFy7MQw89RIsWLYiIiHA79tFHH2XLli1MnTqVN954g7CwMNq1a4fdbmfevHm88cYbfPLJJ3z99dfkz5+f8uXLM2jQICpVqpTR23HNQkNDWbFiBY899hj/+9//KFq0KP3796dkyZJERka61X3wwQcpWbIk//vf/3jttdeIi4vjhhtu4NZbb6Vnz56ZEt/u3bsZMWJEqvLIyEjatGnDRx99RPny5Zk2bRpff/01ISEhDBs2zO2V06Rk1RdffMHhw4cJCgqifv36zJgxw/X650MPPcSkSZN47733OHXqFCEhITzwwAOMHj06XWNjNWrUiNKlS/PPP/+k6iUF1quhM2bMYMKECZw9e5ZSpUrx+OOPM3z48HTdh8WLF18y6Vy2bNnLJqUAnnrqKXr06MGMGTPo0aNHus4nIiLiKTZzvUcRFREREckCp06donDhwowdO/aSY/qIiIiISPamMaVEREQk27tw4UKqsqSxhdLzWpiIiIiIZD96fU9ERESyvVmzZjFt2jTuuusuChQowE8//cTnn39Oq1ataNy4safDExEREZFroKSUiIiIZHs333wz3t7ejBs3jpiYGNfg55caFFtEREREcgaNKSUiIiIiIiIiIllOY0qJiIiIiIiIiEiWU1JKRERERERERESynMaUSien08nBgwcpWLAgNpvN0+GIiIiIiIiIiGRLxhjOnDlDyZIlsdvT7g+lpFQ6HTx4kNKlS3s6DBERERERERGRHOGff/6hVKlSae5XUiqdChYsCFg3NDAw8KqOdTqdHD16lOLFi182Q5hRVzzP0bWwonXydvPFUDz8+rR9vWOVPC1HPR9xcTB8uLU+diz4+Xk0nBx1765BTrq+7Barp+LJNp+B2azt7PZ8ZCdxjjiGRg0FYNwd4/Dz9uzv1aymZ+Pa5fZ7l9OuLzvFm5c/Ax2xDr7u9jUA935yL97+V5cC0GegXKuYmBhKly7tyqWkRUmpdEp6ZS8wMPCaklKxsbEEBgZm+i+jy54nNgDyp9guGADpvJbrfQ1ZdU8kZ8pRz0dcXPJ6YGC2SErlmHt3DXLS9WW3WD0VT7b5DMxmbWe35yM7iXPE4ZvfF7D+vysvJqX0bFyb3H7vctr1Zad48/JnoMPXQX4f60tgYGDgNSWl9BkoGXGl4Y+UlMpL/IOhXHf3bRHJGF9fePnl5HURERERERFJFyWl8pLAShA+zdNRiOQuNhsULerpKERERERERHIc9ZUTEREREREREZEsp55S11FiYiIJCQmpyp1OJwkJCcTGxmb6u8SZdZ7r3XZW3RPJmZKej8TExOz/fCQmwsqV1nqzZuDl5cloREREREREcgwlpa4DYwzR0dGcOnUqzf1Op5MzZ85ccZCvjMaRWee53m1n1T2RnCnl81G4cGFCQkKy73PicMDs2dZ6kyZKSomIiIiIiKSTklLXQVJCKjg4mPz586f68myMweFw4O3tnelJqcw6z/VuO6vuieRMxhgSEhKIj4/n6NGjAISGhno4qjTY7VC/fvK6iIiIiIiIpIuSUhmUmJjoSkgVTWOw42yTlHKcg3P7krcDyoJ3wPVp+3rHKnmaMQZvb28KFiyIzWbjyJEjBAcH45UdeyH5+EBkpKejEBERERERyXGUlMqgpDGk8ufP7+FI0sE4wXHBfVskm0v62UpISMieSSkRERERERG5JnrX5DpRbx+RzKGfLRERERERkdxJSSkRkYyIi4MhQ6wlLs7T0YiIiIiIiOQYen1PRCSjzp71dAQiIiIiIiI5jpJSeViPyP6cijnHvHnzPB2KSM7l6wujRiWvi4hIhvh6+TKq2SjXuoiIiOReSkqJiGSEzQYlS3o6ChGRXMNms1GyoH6vioiI5AUaU0ou6YcffqB+/fr4+fkRGhrKs88+i8PhcO3/8ssvqVGjBvny5aNo0aK0bNmSc+fOAbBy5Urq169PQEAAhQoVonHjxvz999+euhQRERERERERyYbUU0pSOXDgAHfddRc9evTgk08+YdeuXfTp0wdfX19eeOEFDh06RJcuXRg3bhz33nsvZ86cYdWqVRhjcDgctG/fnj59+vD5558THx/P+vXrNYOa5F6JibBmjbXeqBF4eXk2HhGRHM7hdLDoj0UA3HnjnXjb9b+rIiIiuZU+5TNJvXoQHZ2yJGtudYkSXmzcmLE23nvvPUqXLs3EiROx2WxUqVKFAwcO8OyzzzJ69GgOHTqEw+HgvvvuIywsDIAaNWoAcOLECU6fPk3btm2pUKECAFWrVs1YQCLZmcMBn31mrdevr6SUiEgGJToTWfj7QgBaVWilpJSIiEgupk/5TBIdDQcOJG1lVS+h63OenTt3Eh4e7ta7qXHjxpw9e5Z///2XmjVr0qJFC2rUqEFERAStWrXi/vvvp3DhwhQpUoQePXoQERHBHXfcQcuWLenUqROhoaHXJTaRbMduh5o1k9dFRCRDvOxeNCvbzLUuIiIiuZeSUpkkJCTllkmxnpkJKkOJEiaTzwFeXl5ERUWxZs0ali5dyjvvvMPzzz/PunXrKFeuHFOnTuXxxx9n8eLFzJo1i+HDhxMVFUXDhg0zNS4Rj/DxgUcf9XQUIiK5hrfdmy41ung6DBEREckCSkplkpSv0BkDDocDb29vMnNoJes8iWT0n7Vq1ap89dVXGGNcvaVWr15NwYIFKVWqFGDNjNO4cWMaN27MyJEjCQsL4+uvv2bw4MEA1K5dm9q1azNs2DDCw8OZOXOmklIiclWcTjh1Co4dS15CQqB0aU9HJiIiIiIi14OSUnmJdwEoUid52+7D6dOn2bJli1u1vn378uabb/LYY48xcOBAdu/ezejRoxk0aBB2u51169axbNkyWrVqRXBwMOvWrePo0aNUrVqVvXv3MmnSJO6++25KlizJ7t27+eOPP+jWrVvWXquIZCvGwNmz7gmmo0fdty9ejh+3ElPu7FSsWIy+faF7dwgO9sTViEhmMsZwNv4sAAV8C2iyFBERkVxMSam8xGbj4lf7Vq5cSe3atd3KIiMj+e6773j66aepWbMmRYoUoVevXjz33HMABAYG8uOPP/Lmm28SExNDWFgY48eP58477+Tw4cPs2rWL6dOnc/z4cUJDQxkwYAD9+vXLqqsUyVrx8TB6tLU+ejT4+noymmzj4EH44QdYudL679691q26Hv7805uhQ+G556BdO4iMhIgI8NYnmkiuEJ8Yz1NLnwLg7Tvfxs/bz8MRiYiISGbR/8LnYdOmTWPatGlp7l+/fr1r3RiDw+EArNf7Fi9efMljSpQowddff31d4xTJ1oyxuvQkredRBw9aCaikJNTvv197WwUKQLFiqZdChWDFCsMPP1jJdYcDvv7aWm64AXr0gF69oHz563BBIiIiIiKS6ZSUEhHJCB8fGDYseT2POHAguSfUypXwxx9p1/XxgcqVrVftihe/dMIp5eLvn3ZbI0YYfv75GPPnF2P6dBvR0cnxvPSStdx+u9V76r77Lt+WiIiIiIh4lkfnL//xxx9p164dJUuWxGazMW/ePLf9o0ePpkqVKgQEBFC4cGFatmzJunXrXPtXrlyJzWa75LJhwwZXvV9//ZVbb70Vf39/Spcuzbhx47LqEkUkt7PboWxZa7F79FdqpjpwAGbOhL59oVIlKFUKunaFyZNTJ6R8fKBxY3j+eYiKgpMnYds2WLYMvvgCJk603nQcOBA6d4aWLaFWLavN9CSRypdP5OWXDf/8A998A3ffDV4pZo1fvtyKLTQUHnsMLho2T0REREREsgmP9pQ6d+4cNWvWpFevXtx3332p9leqVImJEydSvnx5Lly4wBtvvEGrVq34888/KV68OI0aNeLQoUNux4wYMYJly5ZRr149AGJiYmjVqhUtW7bkgw8+YNu2bfTq1YtChQrRt2/fLLnObCMxHhJOJW/7FAIvjX8jIqnFxsKCBbB0qdUT6s8/067r4wMNGkCzZtYSHg7582d+jN7eVkLq7rvh0CH45BOYMiU5SXbqlJUAmzgR6tSxek89+KD1GqCIiIiIiHieR5NSd955J3feeWea+x988EG37QkTJjBlyhR+/fVXWrRoga+vLyEhIa79CQkJfPPNNzz22GOumVpmzJhBfHw8H3/8Mb6+vlSvXp0tW7YwYcKEvJeUcsbBuf3J24H5lJQSySinE5J6Zt5yS47uLWUMrFsH06ZZPZpOn750PU8loS4nNBSeeQaGDoVVq6zk1Jw5cOGCtX/zZmsZMgTuvx8GDICGDT0bs4iIiIhIXpdjxpSKj49n0qRJBAUFUbNmzUvWmT9/PsePH6dnz56usrVr13Lbbbfhm2JGrIiICF599VVOnjxJ4cKFL9lWXFwccXFxru2YmBgAnE4nzhRzlDudTowxriUtSfsuV+d6uNJ5Us69Z6yK163tq5VV90RyppTPhzEm1c9ethEXh23KFADMzTeDn2dniUr6nXQ19+rAAfjsM5g+3cbu3amnXvfxMTRsCLfdBk2bmksmobLqnyY919ekibW8+SZ8/jlMnWpj40brumJjrWv97DN47TUnTz7538SkHoo1K3kqnqw6b2aeJzPazm7PR3bidDox1v+lZN/f/ZlIz8a1y+33LqddX3aKNy9/BibtS1q/2lj0GSjXKr3/vtk+KbVw4UI6d+7M+fPnCQ0NJSoqimLFil2y7pQpU4iIiKBUqVKusujoaMqVK+dWr0SJEq59aSWlXnnlFcaMGZOq/OjRo8TGxrq2ExIScDqdOBwO1+x0FzPGkJiYCODqwZUZrnQemyPR7R880ZGI4dIxX23b1ztWydtSPh8OhwOn08nx48fxyY4DiSckkP+/3znnjx3z+GDnTqeT06dPY4zBfpleW7GxsGSJP7Nm5eOHH3xxOt1/DvPlc9KuXRz33nuB+vXj3ZJQZ89aiyek9/qS3HeftWzf7s3nn+fjq6/yceqUddzTT9vZufMcL7xwxm1MKk/Fmtk8FU9WnTczz5MZbWe35yM7iUuM48J/3RyPHD2Cn5dnk/1ZTc/Gtcvt9y6nXV92ijcvfwY6Yh3ExVudLY4cOYK3/9WlAPQZKNfqzJkz6aqX7ZNSzZs3Z8uWLRw7dozJkyfTqVMn1q1bR3BwsFu9f//9lyVLljB79uzrct5hw4YxePBg13ZMTAylS5emePHiBAYGuspjY2M5c+YM3t7eeHtf/nZm1RfqtM/j/q3Ly9vLGpTlurR9bbJlkkGyDR8fHxITE7Hb7RQtWhT/7DqV2vDhABTwcBhgfcjbbDaKFy+e6kPeGFi/3uoRNWsWnDqVOiHctKmhWzdDhw5QsKAfkL2+DF7u+i4nOBiaN4e334b//c/w4ovWtX/8cQDHjuVnxgxz3V9BvNZYM4un4smq82bmeTKj7ez2fGQncY448uXLB0Bw8WD8vLPX76HMpmfj2uX2e5fTri87xZuXPwMdsQ78fK3fo8HBwdeUlNJnoFyL9H53y/ZJqYCAACpWrEjFihVp2LAhN954I1OmTGFY0hTs/5k6dSpFixbl7rvvdisPCQnh8OHDbmVJ2ynHo7qYn58ffpd4Dcdut7v94NjtdrdZ/y7FGOPal9k9pa7mPDarYqa0ndXtSe5y8fNhs9lS/exJ2i6+X0mv502bBrt2pa4fFgY9ekC3blC+vA33F32zn4w8D/nzwwsvQPny0KcPOBwwf76NFi1sLFhgJa+yS6yZwVPxZNV5M/M8mdF2dns+sgu73Y7tv99DefX+6Nm4drn93uW068tO8ebVz8Ck76tJ69cShz4D5Vqk99822yelLuZ0Ot3GegLrC+zUqVPp1q1bqp434eHhPP/88yQkJLj2RUVFUbly5TRf3RMRyemSZs+bNs2aQe/iV7rz54eOHa1k1G235ejx2a9Jjx5www3QoQOcOWP1IAsPh0WLoFIlT0cnIiIiIpI3ePRryNmzZ9myZQtbtmwBYO/evWzZsoX9+/dz7tw5nnvuOX7++Wf+/vtvNm3aRK9evThw4AAdO3Z0a2f58uXs3buX3r17pzrHgw8+iK+vL5GRkWzfvp1Zs2bx1ltvub2aJyJyzeLjYfRoa4mP93Q0OBwwZkxBbrjBRufOsHixe0KqaVOYOhWio62EVbNmeS8hleSOO+Cnn6zkFMBff0GjRrBmjWfjEhERERHJKzz6VWTjxo3Url2b2rVrAzB48GBq167NyJEj8fLyYteuXXTo0IFKlSrRrl07jh8/zqpVq6hevbpbO1OmTKFRo0ZUqVIl1TmCgoJYunQpe/fupW7dugwZMoSRI0fSt2/fLLnG7Ozo0WM88sgjlClTBj8/P0JCQoiIiGD16tWuOjabjXnz5nkuyAzISOwrV66kTp06+Pn5UbFiRaZNm3bFY3799VduvfVW/P39KV26NOPGjUtVZ86cOVSpUgV/f39q1KjBd99957bfGMPIkSMJDQ0lX758tGzZkj/++MOtzokTJ+jatSuBgYEUKlSIyMhIzl406vSVYpk7dy716tWjUKFCBAQEUKtWLT799NN03h1xYwwcOmQt2WAmyZkz4YMPAtzGiwoLg1GjYM8eWLnS6iVUsKDHQsxWbr4Zfv4ZatSwto8fhxYt4KuvPBuXiIiIiEhe4NHX95o1a+aanvJS5s6dm652Zs6cedn9N998M6tWrbqq2PKCDg88RHxCItOnT6d8+fIcPnyYZcuWcfz4cU+H5lF79+6lTZs29O/fnxkzZrBs2TJ69+5NaGgoERERlzwmJiaGVq1a0bJlSz744AO2bdtGr169KFSokCsBumbNGrp06cIrr7xC27ZtmTlzJu3bt2fz5s3cdNNNAIwbN463336b6dOnU65cOUaMGEFERAQ7duxwDRTXtWtXDh06RFRUFAkJCfTs2ZO+ffu6fg7SE0uRIkV4/vnnqVKlCr6+vixcuJCePXsSHByc5jVKGnx8YMiQ5HUPmzIlORn14IPQu7fVOyqv9oZKj1KlYNUq61W+ZcusVx87doQJE+CJJzwdnUje4+Plw5BGQ1zrIiIikosZSZfTp08bwJw+fdqt/MKFC2bHjh3mwoULaR7rdDpNfHy8cTqdmRrjFc8TH2PMsQ3GHNtgTu5ZbgCzcuXKNNsLCwszgGsJCwtztT1v3jxTu3Zt4+fnZ8qVK2dGjx5tEhISXMeePHnSREZGmmLFipmCBQua5s2bmy1btrj2jxw50tx8883m/fffN6VKlTL58uUzHTt2NKdOnXKLYfLkyaZKlSrGz8/PVK5c2bz77ruufXFxcWbAgAEmJCTE+Pn5mTJlypiXX345zdjTa+jQoaZ69epuZQ888ICJiIhI85j33nvPFC5c2MTFxbnKnnnmGVO5cmXXdqdOnUybNm3cjmvQoIHp16+fMcb69wsJCTGvvfaaa/+pU6eMn5+f+fzzz40xxuzYscMAZsOGDa46ixYtMjabzRw4cCDdsVxK7dq1zfDhwy9bJ6ukfJbT8zMmlh07jLG6axlTrZrTZPKvHI9ITEw0hw4dMomJide97bg4Y7p3T76HYMygQcY4HNfWXmbGei08FU9WnTczz5MZbWe350OyDz0b1y6337ucdn3ZKd68/BmYcCHBzGw708xsO9MkXEi4xNHX3va1yk7PhmSetHIoF9PfzjNTXJy1pOwN5nBYZQ7HlesmJlplCQnpq3sVCgTko0CBAsybNy/VwPFJNmzYAFgzGx48eJA1/w20smrVKrp168agQYPYsWMHH374IdOmTeOll15yHduxY0eOHDnCokWL2LRpE3Xq1KFFixacOHHCVWfPnj3MmTOHBQsWsHjxYn755RceffRR1/4ZM2YwcuRIXnrpJXbu3MnLL7/MiBEjmD59OgBvv/028+fPZ/bs2ezevZsZM2ZQtmzZVLEfOnTItb1v3z5sNhsrV65M896sXbuWli1bupVFRESwdu3ayx5z22234evr63bM7t27OXnyZLra3bt3L9HR0W51goKCaNCggavO2rVrKVSoEPXq1XPVadmyJXa7nXXr1qU7lpSMMSxbtozdu3dz2223pXmNkv1NmZK83ru3Se/kmvIfX19rvK2RI5PL3nrL6jV14YLn4hIRERERya2UlMpMjz9uLSnH+1m61Cr7/HP3uk89ZZWnSNqwcqVV9skn7nWfe84qP3QouewqR+b19vZm2kfvM336dAoVKkTjxo157rnn+PXXX111ihcvDkChQoUICQlxbY8ZM4Znn32W7t27U758ee644w5efPFFPvzwQwB++ukn1q9fz5w5c6hXrx433ngjr7/+OoUKFeLLL790tR8bG8v06dOpVasWt912G++88w5ffPEF0dHRAIwaNYrx48dz3333Ua5cOe677z6efPJJ13n279/PjTfeSJMmTQgLC6NJkyZ06dLlsrH7+PhQuXJl8ufPn+a9iY6OpkSJEm5lJUqUICYmhgtpfDNN65ikfZerk3J/yuPSqhN80Zz13t7eFClS5IrnSXkOgNOnT1OgQAF8fX1p06YN77zzDnfcccclr08uw+mELVus5eIp7rJQfDz8l6/F19fQtavHQsnRbDYYM8ZK8Hl5WWVffw233w5Hj3o2NpG8ItGZyMp9K1m5byWJzqv7o5uIiIjkLB4dU0qymN0PAkq7NjvcfzNt7rmfVatW8fPPP7No0SLGjRvHRx99RI8ePdJsZuvWraxevdqtZ1RiYiKxsbGcP3+erVu3cvbsWYoWLep23IULF9izZ49ru0yZMtyQNO0VEB4ejtPpZPfu3RQsWJA9e/YQGRlJnz59XHUcDgdBQUEA9OjRgzvuuIPKlSvTunVr2rZtS6tWrS57C2644QZ27dp1+fuURxQsWJAtW7Zw9uxZli1bxuDBgylfvjzNmjXzdGg5S0ICvP++tf722+Dn55EwvvkGjh2z1u+6K5ZixTwTR27Rq5c1K9/991t/V/j5Z2tmvkWLoGJFT0cnkrs5nA4+32b98S68VDhedi8PRyQiIiKZRUmpzPT229Z/fXySX69r1cqa2snrov/Bev11678pXrmiWTNo0iT1CMUvv5y6bqNGV47Hyxe83HvQ+HvBHXfcwR133MGIESPo3bs3o0aNumxS6uzZs4wZM4b77rsv1T5/f3/Onj1LaGjoJV+RK1So0JXj/O8cAJMnT6ZBgwbul/HfvatTpw579+5l0aJFfP/993Tq1ImWLVu69ca6FiEhIRw+fNit7PDhwwQGBpIvX76rOiZp3+XqpNyfVBYaGupWp1atWq46R44ccWvD4XBw4sSJK54n5TkA7HY7Ff/7dl2rVi127tzJK6+8oqTU1bLboUKF5HUP+eij5PUHH7wAKCmVURER1gDod91ldUz9808ID4cFC6BhQ09HJ5J72W126oTWca2LiIhI7qVP+szk52ctKQd28fa2yry9r1zXy8squ3hGr7TqXgfVqlXj3Llzrm0fHx8SLxqvqk6dOuzevZuKFSumWux2O3Xq1CE6Ohpvb+9U+4sVK+ZqZ//+/Rw8eNC1/fPPP2O326lcuTIlSpSgZMmS/PXXX6naKFeunOuYwMBAHnjgASZPnsysWbP46quvXONWXSr29AgPD2fZsmVuZVFRUYSHh1/2mB9//JGEFON/RUVFUblyZQoXLpyudsuVK0dISIhbnZiYGNatW+eqEx4ezqlTp9i0aZOrzvLly3E6na7kXXpiuRSn05nm+GJyGT4+MHSotXho9r19+yAqylovX97QuHG8R+LIjWrVsnpJVa9ubR87Bs2bW6/0iUjm8PHyoV+9fvSr10+z74mIiORySkrlUcePH+f222/ns88+49dff2Xv3r3MmTOHcePGcc8997jqlS1blmXLlhEdHe0aJHvkyJF88sknjBkzhu3bt7Nz506++OILhg8fDlgDb4eHh9O+fXuWLl3Kvn37WLNmDc8//zwbN250te3v70+PHj3YunUrq1at4vHHH6dTp06u3jxjxozhlVde4e233+b3339n27ZtTJ06lQkTJgAwYcIEPv/8c3bt2sXvv//OnDlzCAkJcfXGulTsBw4coEqVKqxfvz7Ne9O/f3/++usvhg4dyq5du3jvvfeYPXs2Tz75pKvOxIkTadGihWv7wQcfxNfXl8jISLZv386sWbN46623GDx4sKvOoEGDWLx4MePHj2fXrl2MHj2ajRs3MnDgQABsNhtPPPEEY8eOZf78+Wzbto1u3bpRsmRJ2rdvD0DVqlVp3bo1ffr0Yf369axevZqBAwfSuXNnSpYsme5YXnnlFaKiovjrr7/YuXMn48eP59NPP+Whhx5Kz+Mj2czHHyfPe9Crl/Fkh61cqUwZ+OknKxkFEBsLHTokd4YVEREREZFrlDWTAeZ8aU1nmJ7p6lNOb5+ZruY8sbGx5tlnnzV16tQxQUFBJn/+/KZy5cpm+PDh5vz586568+fPNxUrVjTe3t4mLCzM1fbixYtNo0aNTL58+UxgYKCpX7++mTRpkuu4mJgY89hjj5mSJUsaHx8fU7p0adO1a1ezf/9+Y4wxI0eONDfffLN59913TcmSJY2/v7+5//77zYkTJ9zinDFjhqlVq5bx9fU1hQsXNrfddpuZO3euMcaYSZMmmVq1apmAgAATGBhoWrRoYTZv3pxm7MYYs3fvXgOYFStWXPb+rFixwnXe8uXLm6lTp7rtHzVqlKvNJFu3bjVNmjQxfn5+5oYbbjD/+9//UrU7e/ZsU6lSJePr62uqV69uvv32W7f9TqfTjBgxwpQoUcL4+fmZFi1amN27d7vVOX78uOnSpYspUKCACQwMND179jRnzpy5qlief/55U7FiRePv728KFy5swsPDzRdffHHZe5KVUj7L6fkZy8sSEoy54QZjwBgvL2P++Sd3T7HrySmE4+KMefhh614nLU8+aUxaoWS36Y7z8nTY2bHt7PZ8SPahZ+Pa5fZ7l9OuLzvFm5c/AxMuJJiZbWeamW1nmoQLCde17WuVnZ4NyTxp5VAuZjMm6e/rcjkxMTEEBQVx+vRpAgMDXeWxsbHs3buXcuXK4e/vf8ljjTE4HA68vb2xZeIc7Vc8z6X+qdMZz/W+hlGjRjFv3jy2bNmSqfdEcqaUz1tcXNwVf8Y8KiEBXnvNWn/66Sx/he/bb6FtW2v97rvh66+dHDlyhODgYOy5sMuU0+nZ6zMGRo6EsWOTy3r0sMb0uvgtak/HejFPxZNV583M82RG29nt+chO4hxxPL7ocQDevvNt/Lzz1hh5ejauXW6/dznt+rJTvHn5M9AR62BOxzkAdJzTEW//qxtWWp+Bcq3SyqFcTAOd5yWOsxCzO3k7sDL4FPRcPCK5gdMJf/+dvJ7FJk9OXu/dO8tPn+fYbPDii9Yrff37W//k06bB+fPw2WceG1ZMRERERCRHUlJKRCQjfHzgv3HBsjojcegQLFxorZcsCXfemaWnz9P69IEiRaBLF6uz3OzZcOGC9d/s2KFPRERERCQ7Ul858YikQb5Fcjy7HWrUsJYs7n48bRokTTDZs2fqST0lc3XoAPPmJSehFiywXqVMMYGpiIiIiIhchpJSIiI5kNMJU6Ykb0dGei6WvOyuu+C77yAgwNpetgwiIuD0ac/GJSIiIiKSEygpJSKSEU4n7NxpLVk4ptTKlbBnj7XesiWUK5dlp5aLNG8OUVEQFGRtr14Nt98Ox455Ni4RERERkexOSSkRkYxISIA337SWhIQsO+1HHyWv9+mTZaeVNISHw4oVUKyYtb15M9x+u40jR/QxKyIiIiKSFv3fsohIRtjtUKqUtWTRmFLHj8NXX1nrRYvCPfdkyWnlCmrXhh9+gNBQa3v7dhvt2xdh/37PxiUiIiIikl0pKSUikhE+PjBihLVk0ex7n30G8fHWevfu4OeXJaeVdKhWDVatgrAwa3vvXm+aNrXx55+ejUtEREREJDtSUkpEJAcxBiZPTt7u3dtzscilVahgJaZuvNEAsH+/jVtvhe3bPRyYiIiIiEg2o6SUiGQpY4ynQ8jR1q1LTm40bgxVq3o2Hrm00qVh5UpDlSrWOGPR0dC0qTXWlIiIiIiIWJSUysOOHj3GI488QpkyZfDz8yMkJISIiAhWr17tqmOz2Zg3b57ngsyAy8U+ffp0mjRpAsDo0aOpUqUKAQEBFC5cmJYtW7Ju3bqrPt+JEyfo2rUrgYGBFCpUiMjISM6ePXvZY2JjYxkwYABFixalQIECdOjQgcOHD7vV2b9/P23atCF//vwEBwfz9NNP43A43OqsXLmSOnXq4OfnR8WKFZk2bVqqc7377ruULVsWf39/GjRowPr16686lscff5y6devi5+dHrVq10n9zUli9ejXbc1OXkYQEGD/eWrJgoHP1kso5QkLgq69OUK+elYg9ftyaqW/NGg8HJiIiIiKSTSgplYd1eOAhfvnlF6ZPn87vv//O/PnzadasGcePH/d0aJnum2++4e677wagUqVKTJw4kW3btvHTTz9RtmxZWrVqxdGjR6+qza5du7J9+3aioqJYuHAhP/74I3379r3sMU8++SQLFixgzpw5/PDDDxw8eJD77rvPtT8xMZE2bdoQHx/PmjVrmD59OtOmTWPkyJGuOnv37qVNmzY0b96cLVu28MQTT9C7d2+WLFniqjNr1iwGDx7MqFGj2Lx5MzVr1iQiIoIjR46kO5YkvXr14oEHHriqe5PSV199xVdJo3TnBk4n/P67tTidmXqqmBj44gtrPTAQOnbM1NPJdVCkiGHpUsN/OXBiYqBVK1i+3LNxiYiIiIhkC0bS5fTp0wYwp0+fdiu/cOGC2bFjh7lw4UKaxzqdThMfH2+cTmemxnjF8yScNebkNmNObjMn9602gFm5cmWa7YWFhRnAtYSFhbnanjdvnqldu7bx8/Mz5cqVM6NHjzYJCQmuY0+ePGkiIyNNsWLFTMGCBU3z5s3Nli1bXPtHjhxpbr75ZvP++++bUqVKmXz58pmOHTuaU6dOucUwefJkU6VKFePn52cqV65s3n33Xde+uLg4M2DAABMSEmL8/PxMmTJlzMsvv5xm7EkuXLhgAgICzM6dOy953Un/1t9//32a9+ZiO3bsMIDZsGGDq2zRokXGZrOZAwcOXPKYU6dOGR8fHzNnzhxX2c6dOw1g1q5da4wx5rvvvjN2u91ER0e76rz//vsmMDDQxMXFGWOMGTp0qKlevbpb2w888ICJiIhwbdevX98MGDDAtZ2YmGhKlixpXnnllXTHktKoUaNMzZo1r3hfLqVMmTKmRo0al62T8llOz8+YRyUmGrNxo7UkJmbqqT780BhrVClj+vdPK5xEc+jQIZOYybF4Sk66vpSxnj1rzB13JP/7+fkZs3Ch5+LJjefNzPNkRts56VnOaonORLPxwEaz8cBGk+jMe/dHz8a1y+33LqddX3aKNy9/BiZcSDAz2840M9vONAkXEi5x9LW3fa2y07MhmSetHMrFvD2SCcsrzu23Fgy2xETw8gJslz8msDL4F3cvS4yH4+svXT+l/KXBr2Ta+70DoNBNABQo4KBAgQLMmzePhg0b4neJ6bs2bNhAcHAwU6dOJSIiwjUW0KpVq+jWrRtvv/02t956K3v27HH1CBo1ahQAHTt2JF++fCxatIigoCA+/PBDWrRowe+//06RIkUA2LNnD3PmzGHBggXExMQQGRnJo48+yowZMwCYMWMGI0eOZOLEidSuXZtffvmFPn36EBAQQPfu3Xn77beZP38+s2fPpkyZMvzzzz/8888/qWJv3bo1Xl5erutatmwZN9xwA1WqVEl1zfHx8UyaNImgoCBq1qzpKm/WrBlly5a95GtxAGvXrqVQoULUq1fPVdayZUvsdjvr1q3j3nvvTXXMpk2bSEhIoGXLlq6yKlWqUKZMGdauXUvDhg1Zu3YtNWrUoESJEq46ERERPPLII2zfvp3atWuzdu1atzaS6jzxxBOua9q0aRPDhg1z7bfb7bRs2ZK1a9emO5Zrce7cOX755RfX9l9//cX+/fsB+Prrryle3HrWbTYb9erVu+RzmO3Z7VC3bpac6qOPktf16l7OEhAA8+fDAw9Y/42Lg/btYeZM9XgTuZjdZqduyaz5vSoiIiKepaRUZtrzMfw2BhtXcaMbzYSyXdzL4o/D97de+dibRkLV4ek6jbe3N9OmTaNPnz588MEH1KlTh6ZNm9K5c2duvvlmAFfCoFChQoSEhLjGMRozZgzPPvss3bt3B6B8+fK8+OKLDB06lFGjRvHTTz+xfv16jhw54koyvP7668ybN48vv/zSlcCKjY1l+vTplCpVCoB33nmHNm3aMH78eEJCQhg1ahTjx493vUJWrlw5duzYwYcffkj37t3Zv38/N954I02aNMFmsxGWNAf7JWJPKeWre0kWLlxI586dOX/+PKGhoURFRVGsWDHX/jJlyhAaGprm/YyOjiY4ODjVPS5SpAjR0dFpHuPr60uhQoXcykuUKOE6Jjo62i0hlbQ/ad/l6sTExHDhwgVOnjxJYmLiJevs2rUr3bFci4CAAHbv3s3jjz/O+fPn3fYl/bsGBgYyadIkGjdufM3n8bSZM2HFCvjwQytHlRm2boUNG6z12rWzLA8m15G/P3z5JTz8MMyaBQ4HdO4MFy5At26ejk5EREREJOtpTKk8rEOHDhw8eJD58+fTunVr12DZafUGSrJ161ZeeOEFChQo4Fr69OnDoUOHOH/+PFu3buXs2bOuAbOTlr1797Jnzx5XO2XKlOGGG25wbYeHh+N0Otm9ezfnzp1jz549REZGurUxduxYVxs9evRgy5YtVK5cmccff5ylS5de8ZqNMSxYsCBVUippPKY1a9bQunVrOnXq5Dbe0ieffMIrr7ySntsqF4mMjGTjxo2uZGdKt9xyC7/88kuGxqjytPcmOhnRdQ/LP9rD00OcZNbkguollTv4+MCMGdCrl7XtdEL37vD++56NSyQ7cRonmw5uYtPBTThN5o7VJyIiIp6lnlJ5nL+/P3fccQd33HEHI0aMoHfv3owaNYoePXqkeczZs2cZM2bMJQfB9vf35+zZs4SGhrJy5cpU+y/uiXO5cwBMnjyZBg0auO1LehWvTp067N27l0WLFvH999/TqVMnWrZsyZdffplmu+vXr8fhcNCoUSO38oCAACpWrEjFihVp2LAhN954I1OmTHF75e1yQkJC3JJYAA6HgxMnTqTqqZXymPj4eE6dOuV2Xw4fPuw6JiQkJNUseUkz4qWsc/EseYcPHyYwMJB8+fLh5eWFl5fXJeukbONKsWRE1apVmTZtGnXq1HErnzFjBuXLl89w+55UsngCzzAOAzz+5tsUC/YjnY9Nul24AJ99Zq3nywcPPnh925es5eVlzaIYEADvvGOVPfqoNTvf88+D7QpveYvkdgmJCUzaNAmAt+98Gz/vHPhqt4iIiKSLklKZqUIvCGmJwZCYmIiXlxe29IwpdTHfotBy1ZXPl7/0tcWZQrVq1Zg3b55r28fHh8TERLc6derUYffu3VSsWPGSbdSpU4fo6Gi8vb0pW7Zsmufav38/Bw8edPWW+vnnn7Hb7VSuXJkSJUpQsmRJ/vrrL7p27ZpmG4GBgTzwwAM88MAD3H///bRu3ZoTJ05QpEiRS8b+zTff0KZNG7cxpi7F6XQSFxd32TophYeHc+rUKTZt2kTd/96rWr58OU6nM1VSLUndunXx8fFh2bJldOjQAYDdu3ezf/9+wsPDXe2+9NJLHDlyxPV6YFRUFIGBgVSrVs1V57vvvnNrOyoqytWGr68vdevWZdmyZbRv3951fcuWLWPgwIHpjiWj5s+fD1ivBMbHx3Py5EkWLlzIk08+eV3a95T299r4pW0wCxeCwcZzz0HRonCFiRevyldfwalT1nrHjpDO3K5kY3Y7vPWWlZj63/+sshEj4MgRePPNzHsNVCQnsNvsVCpaybUuIiIiuZeSUpkpoIy1GINxOMDb+9r+BO7lC8FNrlzPGGuQkrQkxsIFa3yg48dP0rHHk/SK7M3NN99MwYIF2bhxI+PGjeOee+5xHVK2bFmWLVtGo0aN8PLyonjx4owcOZK2bdtSpkwZ7r//fux2O1u3buW3335j7NixtGzZkvDwcNq3b8+4ceOoVKkSBw8e5Ntvv+Xee+91DQbu7+9Pjx49eP3114mJieHxxx+nU6dOrp45Y8aM4fHHHycoKIjWrVsTFxfHxo0bOXnyJIMHD2bChAmEhoZSu3Zt7HY7c+bMISQkxNXTJyn2xo0b4+fnR+HChZk/fz4vvPCC6/rOnTvHSy+9xN13301oaCjHjh3j3Xff5cCBA3RMMfpwt27duOGGG9J8ha9q1aq0bt3aNUZXQkICAwcOpHPnzpQsaQ0+f+DAAVq0aMEnn3xC/fr1CQoKIjIyksGDB1OkSBECAwN57LHHCA8Pdw0s3qpVK6pVq8bDDz/MuHHjiI6OZvjw4QwYMMA1Xlf//v2ZOHEiQ4cOpVevXixfvpzZs2fz7bffuuIbPHgw3bt3p169etSvX58333yTc+fO0bNnT4B0xQLw559/cvbsWaKjo7lw4QJbtmwBrGSmr69v2s8e8NVXXxEREcH06dOJj4/nwQcfZO7cuTk+KYWvL7UXvEjUOEh4xirq3x+KFIH7778+p5g8OXm9T5/r06Z4ns0Gr7xiPStDh1pl77wDR4/C9OlwhR8pkVzLx8uHIY2GeDoMERERyQpZMhdgLpDWdIbpma4+5fT2memK54mPMebYBmOObTCxB1abZ58ebOrUqWOCgoJM/vz5TeXKlc3w4cPN+fPnXYfMnz/fVKxY0Xh7e5uwsDBX24sXLzaNGjUy+fLlM4GBgaZ+/fpm0qRJruNiYmLMY489ZkqWLGl8fHxM6dKlTdeuXc3+/fuNMcaMHDnS3Hzzzebdd981JUuWNP7+/ub+++83J06ccAt5xowZplatWsbX19cULlzY3HbbbWbu3LnGGGMmTZpkatWqZQICAkxgYKBp0aKF2bx5c5qx//nnn8bPz8+cPXvWVefChQvm3nvvNSVLljS+vr4mNDTU3H333Wb9+vVucTRt2tR07979svf/+PHjpkuXLqZAgQImMDDQ9OzZ05w5c8a1f+/evQYwK1ascDv/o48+agoXLmzy589v7r33XnPo0CG3dvft22fuvPNOky9fPlOsWDEzZMgQk5DgPp3rihUrXPepfPnyZurUqanie+edd0yZMmWMr6+vqV+/vvn555/d9qcnlqZNmxog1bJ3797L3pt9+/aZcePGuT2bDofDjB492hw9ejRV/ZTPcnp+xrKLp582xsoOG+PjY8zSpRlvc/fu5DarVDHmSr9GcvsUuznp+q4m1qlTjfHySv63btXKmBS/PrI8npx43sw8j6bDlqykZ+Pa5fZ7l9OuLzvFm5c/AxMuJJiZbWeamW1nmoQLCZc4+trbvlbZ6dmQzJNWDuViNmMya1je3CUmJoagoCBOnz5NYGCgqzw2Npa9e/dSrlw5/P39L3msMQaHw4G3tze2TBws5IrnSTgDMbuTtwMrg0/B69P2VRo1ahTz5s1jy5YtmXpPUpowYQLff/99qlfdJPtJ+bzFxcVd8WcsuzDGGoT844+t7YAAWL4c6te/9jaHDoXXXrPWX38dhlyh84DT6XS97mnPhe+A5aTru9pYFyyATp0gNtbavuUW+O47SDERaJbGc71k1Xkz8zyZ0XZOepYla+nZuHa5/d7ltOvLTvHm5c9AR6yDOR3nANBxTke8/a/uZSl9Bsq1SiuHcjE9AZJnlCpVKt0Dl4ukW0KC9c7VO+9gcyTw4Yfw39BdnDsHd94JO3deW9Px8dZrXGDN2tat23WJWLKpdu0gKip5zLANG6BJE/j7b4+GJZLl4hxxDFkyhCFLhhDnSP/4jiIiIpLzKCkleUanTp249dZbPR2G5DZOJ/z2m7U4nXh7w+efQ7Nm1u4TJ+COO64tsbBwoTXwNViJruLFr1fQkl01aQI//gj/DUXH7t3QuDFs3+7ZuESy2tn4s5yNP+vpMERERCSTKSklHjF69Gg2btzo6TBEMs7bG7p3txZvqzu0vz988w3UqWNVOXAAWrWyBrC+GikHOO/d+zrFK9lejRqwejVUsiYf48ABuPVWWLPGs3GJiIiIiFxvSkqJiGSElxc0amQtXl6u4sBAWLQoObHw++/Wq3wxMelrdv9+WLLEWg8Lg5Ytr3Pckq2VLQs//QT/TVbKyZPWM6Ah8UREREQkN1FSSkQkkwQHw9KlcMMN1vamTdZreEkDWV/Oxx9bA6cDREaCxoDMe4oXtwbKT0pIXrgAd98Nn37q2bhERERERK4Xfc0REckIpxP++cdanM5Uu8PCrMRUkSLW9ooV0KULOBxpN5mYmDyDn90OPXtmQtySIxQsaI0t1qmTtZ2YaA14P368Z+MSEREREbkelJQSEcmIhAQYO9ZaEhIuWaVaNeu1q4AAa3vePOjXL7kn1MWWLrVyXGC98leq1PUPW3IOPz+YORMGDEgue+opeOaZtJ8hEREREZGcQEkpEZGMsNmgUCFrsdnSrNagAXz9Nfj4WNsffwzPPnvpuh99lLyuAc4FrOHK3nkHxoxJLhs3znq183K97kREREREsjMlpUREMsLXF1591Vp8fS9b9Y47YMaM5NzVuHHWktLhwzB/vrUeEgJt2mRCzJIj2WwwciS8/37yMzR1Ktx3nzXelIiIiIhITqOklGRIs2bNeOKJJ1zbZcuW5c0338z08+7evZuQkBDOnDmT6ee6kmeffZbHHnvM02FIDtGxo5VUSPLMMzBlSvL29OnJPV969EjuWSWSpH9/mD07OQe6YAG0amXN0CciIiIikpMoKZWXeOWDwMoQWJl23UbQuu39l6y2atUqbDYbv/76axYHmH7Dhg3jscceo2DBgq6yJUuW0LBhQwoWLEjx4sXp0KED+/btcztu5cqV1KlTBz8/PypWrMi0adPc9s+YMYPSpUtTuHBhBg8e7LZv3759VKpUiZiYGLfyp556iunTp/PXX39d9XXs37+fNm3akD9/foKDg3n66adxXOFdnBMnTtC1a1cCAwMpVKgQkZGRnD171q3Or7/+yq233oq/vz+lS5dm3MXdcYA5c+ZQpUoV/P39qVGjBt9dNNe8MYaRI0cSGhpKvnz5aNmyJX/88Ydbnd9//5177rmHYsWKERgYSJMmTVixYoVr//Hjx2ndujUlS5bEz8+P0qVLM3DgwFT3MK/p1w9eeil5u29fmDvXGh8o5at7kZFZH5vkDPffD4sWQYEC1vZPP0HTpnDwoGfjEhERERG5GkpK5SV2b/ApCD4FiezTj6jvv+fff/9NVW3q1KnUq1ePm2++2QNBXtn+/ftZuHAhPXr0cJXt3buXe+65h9tvv50tW7awZMkSjh07xn333edWp02bNjRv3pwtW7bwxBNP0Lt3b5YsWQLAsWPH6N27N6+//jpLly7ls88+Y+HCha7jH330Uf73v/8RGBjoFk+xYsWIiIjg/ZTdX9IhMTGRNm3aEB8fz5o1a5g+fTrTpk1j5MiRlz2ua9eubN++naioKBYuXMiPP/5I3759XftjYmJo1aoVYWFhbNq0iddee43Ro0czadIkV501a9bQpUsXIiMj+eWXX2jfvj3t27fnt99+c9UZN24cb7/9Nh988AHr1q0jICCAiIgIYmNjXXXatm2Lw+Fg+fLlbNq0iZo1a9K2bVuio6MBsNvt3HPPPcyfP5/ff/+dadOm8f3339O/f/+rulfZWkICfPihtaQx0PmlDBsGTz5prTud1ox8L7wASXm/5s2hYsVMiFdyjdtvh5UroXhxa3vbNmjcGPbs8WhYIiIiIiLpZyRdTp8+bQBz+vRpt/ILFy6YHTt2mAsXLqR5rNPpNPHx8cbpdGZqjFdznoSEBFOiRAnz4osvupWfOXPGFChQwLz//vvm2LFjpnPnzqZkyZImX758pnr16mbGjBlu9Zs2bWoGDRrk2g4LCzNvvPGGa/vkyZMmMjLSFCtWzBQsWNA0b97cbNmyxTidTvP7778bm81mNmzY4NbmG2+8YcqUKWMSExMvGftrr71m6tWr51Y2Z84c4+3t7XbM/Pnzjc1mM/Hx8cYYY4YOHWqqV6/udtwDDzxgIiIijDHGrFu3zpQoUcK1r1OnTmbcuHHGGGNmzpxp7r777kvGY4wx06dPN6VKlUpz/6V89913xm63m+joaFfZ+++/bwIDA01cXNwlj9mxY4cB3O7ZokWLjM1mMwcOHDDGGPPee++ZwoULu7XxzDPPmMqVK7tdW5s2bdzabtCggenXr58xxnqWQkJCzGuvvebaf+rUKePn52c+//xzY4wxR48eNYD58ccfXXViYmIMYKKiotK87rfeeuuK9yrls5yenzGPio01pm9fa4mNvapDExON6dbNGKuPlPsyc+a1hZOYmGgOHTqU5s9PTpeTri+rYv39d2PKlk1+dkJDjdm+3XPxeOq8mXmezGg7Jz3LWS02Idb0nd/X9J3f18QmXN3v1dxAz8a1y+33LqddX3aKNy9/BiZcSDAz2840M9vONAkXEq5r29cqOz0bknnSyqFcTD2lMoExBkeswyOLSef84N7e3nTr1o1p06a5HTNnzhwSExPp0qULsbGx1K1bl2+//ZZt27bRu3dvunXrxvr169N9Lzp27MiRI0dYtGgRmzZtok6dOrRo0YITJ05QtmxZWrZsydSpU92OmTp1Kj169MBuv/TjuWrVKurVq+dWVrduXex2O1OnTiUxMZHTp0/z6aef0rJlS3z+G5Rn7dq1tGzZ0u24iIgI1q5dC8CNN97I+fPn+eWXXzhx4gQbNmzg5ptv5uTJk4wYMYKJEyemeZ3169fn33//dXtdsGzZsowePTrNY9auXUuNGjUoUaKEWzwxMTFs3749zWMKFSrkdv0tW7bEbrezbt06V53bbrsN3xSDbkdERLB7925O/jfozJXuxd69e4mOjnarExQURIMGDVx1ihYtSuXKlfnkk084d+4cDoeDDz/8kODgYOrWrXvJ+A8ePMjcuXNp2rRpmvclx/H2tro5delirV8Fu916Xa9dO/fyIkXg3nuvY4ySq914I6xeDdWrW9uHDlmv8m3e7Nm4RK6Vt92bLjW60KVGF7ztV/d7VURERHIWfdJngsS4ROZ0nOPaNhiM02Cz27CR9pTxGWUw3DvzXlcS5kp69erFa6+9xg8//ECzZs0AKyHUoUMHgoKCCAoK4qmnnrLaNoYBAwbw/fffM3v2bOrXr3/F9n/66SfWr1/PkSNH8PPzA+D1119n3rx5fPnll/Tq1YvIyEgeeeQRJkyYgJ+fH5s3b2bbtm188803abb7999/p0pKlStXjqVLl9KpUyf69etHYmIi4eHhbuMkRUdHuyWAAEqUKEFMTAwXLlygcOHCTJ8+nW7dunHhwgW6detGREQEkZGRDBw4kL1793L33XeTkJDA6NGjuf/+5DG5SpYs6YqtbNmyAFSoUIFixYqleR1pxZO0L61jgoOD3cq8vb0pUqSI65jo6GjKlSuXZruFCxdO89wp20h53KXq2Gw2vv/+e9q3b0/BggWx2+0EBwezePFiChcu7HZcly5d+Oabb7hw4QLt2rXjo5QDJ+V0Xl7w38/PtfDxgVmzICICVq2yyh56CPz9r094kjeULGm9yhcRYSWjjh2zXu/77jto1MjT0YlcHS+7F83KNvN0GCIiIpIF1FMqL3EmguOca6lS6UYaNWrExx9/DMCff/7JqlWriPxvdOXExERefPFFatSoQdGiRSlcuDBLlixh//796Trd1q1bOXv2LEWLFqVAgQKuZe/evez5b9CT9u3b4+Xlxddffw3AtGnTaN68uSuxcykXLlzA/6Jv7NHR0fTp04fu3buzYcMGfvjhB3x9fbn//vvT3XsM4N5772Xbtm38+eefjB49mh9++IFff/2Vvn370rlzZ958802++uorIiMjOXLkiOu4fPnyAXD+/HlX2bJlyxg4cGC6z53TJCUqg4ODWbVqFevXr6d9+/a0a9eOQ4cOudV944032Lx5M9988w179uxJNYh8XpcvnzWD2oMPwl13wYgRno5IcqJixWD5cmtcKYDTp61Z+ZYt82xcIiIiIiJpUU+pTODl50XHOR1d28YYHA4H3t7e2GyZ2FPKGIzXZRIwiechZnfydmBlIiMjeeyxx3j33XeZOnUqFSpUcL1a9dprr/HWW2/x5ptvctNNN+Hn58fTTz9NfHx8uuI5e/YsoaGhrFy5MtW+oKAgAHx9fenWrRtTp07lvvvuY+bMmbz11luXbbdYsWKu19CSvPvuuwQFBbnNMvfZZ59RunRp1q1bR8OGDQkJCeHw4cNuxx0+fJjAwEBXUimluLg4Hn30UT799FP+/PNPHA6H695UqlSJdevW0e6/965OnDgBQPGkEYfTISQkJNWrkEnxhYSEpHlMymQYgMPh4MSJE65j0rrOlO2mVSfl/qSy0NBQtzq1atUCYPny5SxcuJCTJ0+6Bn9/7733iIqKYvr06Tz77LNucYeEhFClShWKFCnCrbfeyogRI9zazrGMgaNHrfXixeEaf8aDgmDGjOsYl+RJQUGwZAm0bw/ffw/nzkGbNjBnjvVfkZzAaZz8eeJPACoWqYjdpr+hioiI5Fb6lM8ENpsNb39vjyxXm/Tq1KkTdrudmTNn8sknn9CrVy9XG6tXr+aee+7hoYceombNmpQvX57ff/893W3XqVOH6OhovL29qVixotuS8rW23r178/333/Pee+/hcDjcZsy7lNq1a7Njxw63svPnz6cag8rLywsAp9MJQHh4OMsu6jIQFRVFeHj4Jc8zduxYWrduTZ06dUhMTMThcLj2JSQkkJiY6Nr+7bff8PHxoXrSoC7pEB4ezrZt29ySTFFRUQQGBlKtWrU0jzl16hSbNm1ylS1fvhyn00mDBg1cdX788UcSUswEFxUVReXKlV2v1V3pXpQrV46QkBC3OjExMaxbt85VJ6lX2MX33W63u+75pSTti4uLS7NOjhIfb3VtGjHCWhfxsIAAq+fd3Xdb23FxcN991muiIjlBQmIC49eMZ/ya8SQkpn9WUxEREcl5lJTK4woUKMADDzzAsGHDOHToED169HDtu/HGG4mKimLNmjXs3LmTRx99NFXvmstp2bIl4eHhtG/fnqVLl7Jv3z7WrFnD888/z8aNG131qlatSsOGDXnmmWfo0qXLJXstpZQ0IHfKpFCbNm3YsGEDL7zwAn/88QebN2+mZ8+ehIWFUbt2bQD69+/PX3/9xdChQ9m1axfvvfces2fP5sknn0x1jh07djBr1ixeeOEFAKpUqYLdbmfKlCl8++237Nq1i1tuucVVf9WqVdx6661usbdo0eKyg6O3atWKatWq8fDDD7N161aWLFnC8OHDGTBggGsMrvXr11OlShUOHDjguletW7emT58+rF+/ntWrVzNw4EA6d+7sGtfqwQcfxNfXl8jISLZv386sWbN466233F6ZGzRoEIsXL2b8+PHs2rWL0aNHs3HjRtfrhjabjSeeeIKxY8cyf/58tm3bRrdu3ShZsiTt27cHrMRW4cKF6d69O1u3buX333/n6aefZu/evbT5r0vGd999x9SpU/ntt9/Yt28f3377Lf3796dx48aXfUUzx8mXz1pEsgl/f/jyS2v8fQCHAx56yMYXX+g5lezPZrMRWjCU0IKhmdrDXERERLKBTJ4FMNdIazrD9ExXn3J6+8x0xfPExxhzbEPyEh9jjDFmzZo1BjB33XWXW/Xjx4+be+65xxQoUMAEBwebYcOGmW7dupl77rnHVadp06Zm0KBBru2wsDDzxhtvuLZjYmLMY489ZkqWLGl8fHxM6dKlTdeuXc3ff//tFuuUKVMMYNavX3/F60xISDAlS5Y0ixcvdiv//PPPTe3atU1AQIApXry4ufvuu83OnTvd6qxYscLUqlXL+Pr6mvLly5upU6emat/pdJrGjRubBQsWuJUvWLDAlClTxpQoUcJMnjzZbV/lypXN559/7lYWFhZmRo0addlr2bdvn7nzzjtNvnz5TLFixcyQIUNMQkLyVK0rVqwwgNm7d6+r7Pjx46ZLly6mQIECJjAw0PTs2dOcOXPGrd2tW7eaJk2aGD8/P3PDDTeY//3vf6nOPXv2bFOpUiXj6+trqlevbr799ttU92HEiBGmRIkSxs/Pz7Ro0cLs3r3brc6GDRtMq1atTJEiRUzBggVNw4YNzXfffefav3z5chMeHm6CgoKMv7+/ufHGG80zzzxjTp48edn7kvJZTs/PmCTL7VPs5qTryw6xOhzG9O5tjPWeqbW89Vbemw47O7adHZ4PyZ70bFy73H7vctr1Zad4PRVLdvgMTLiQYGa2nWlmtp1pEi4kXOLoa2/7WmWnZ0MyT1o5lIvZjLmKUaDzsJiYGIKCgjh9+rRr/ByA2NhY9u7dS7ly5VINvp3EZOGYUpc9T8KZVGNK4VPw+rSdwVhffPFF5syZw6+//pqu4999913mz5/PkiVLMhxLRi1atIghQ4bw66+/4u2tYdquh5TPR1xc3BV/xiSZ0+nkyJEjBAcHp3q1MjfISdeXXWI1Bp58ElIO1/fyyzBsWNacP6vuQ2aeJzPazi7Ph2Q/ejauXW6/dznt+rJTvJ6KJTt8BjpiHa6Z4TvO6Yi3/9V9X9FnoFyrtHIoF9M3aPGos2fP8vfffzNx4kTGjh2b7uP69evHqVOnOHPmDAULpi+xllnOnTvH1KlTlZASkWzJZoM33oACBQwvvWT9UeG55+DMGXjppWsem19EREREJMP0LVo86rHHHuPzzz+nffv29OrVK93HeXt78/zzz2diZOl3//33ezoE8SSHAz77zFp/6CFQclKyIZsNXnjBYLOdZexYK5H/yitw9iy8+Sboj5SSncQnxvPyqpcBeO7W5/D18vVwRCIiIpJZ9L+h4lFTp04lLi6OWbNmuWbLE8lREhNh7VprSTH4vkh2NGDAOSZOTJ4d8513oHdvPbqSvRhjOHTmEIfOHEKjTIiIiORu+pO+iEhGeHlBhw7J6yLZ3COPQIEC0KsXOJ0wdSqcPw+ffgo+Pp6OTkRERETyEiWlREQywtsbWrXydBQiV6V7dwgIgAcfhIQEmDXLSkzNng2aT0BEREREsope3xMREcmD7r8f5s1LTkItWABt21rjTImIiIiIZAUlpUREMsIYOHXKWjT2ieQwd90F331n9ZoCWLbM6vh36pRHwxIRERGRPEJJqbzE7gN+RZIXuwYPEcmw+Hh45hlriY/3dDQiV615c/j+eyhUyNpeu9YqO3TIo2GJiIiISB6gpFRe4uUPBconL14aOETkurDbrUUkh2rYEFauhOLFre0tW6BBA9i2zZNRiYiIiEhup29Rkm4tW7bkiSee8HQYItmLnx+8/761+Pl5OhqRa1azJvz4I4SFWdv//AONG8PSpZ6NS0RERERyLyWl8rAePXpgs9no379/qn0DBgzAZrPRo0cPV9ns2bN58cUXM3zO9u3bZ6iNjJg+fTpNmjQBYO7cubRq1YqiRYtis9nYsmVLqvqxsbEMGDCAokWLUqBAATp06MDhw4ev+rz79++nTZs25M+fn+DgYJ5++mkcDsdljzlx4gRdu3YlMDCQQoUKERkZydmLRiD+9ddfufXWW/H396d06dKMGzcuVTtz5syhSpUq+Pv7U6NGDb777ju3/cYYRo4cSWhoKPny5aNly5b88ccfbnVeeuklGjVqRP78+SmU9I5PGo4fP06pUqWw2Wyc0sA0IjlKlSrw889wyy3W9pkz1rhTkyd7Ni4RERERyZ2UlMrjSpcuzRdffMGFCxdcZbGxscycOZMyZcq41S1SpAgFCxbM6hCvq2+++Ya7774bgHPnztGkSRNeffXVNOs/+eSTLFiwgDlz5vDDDz9w8OBB7rvvvqs6Z2JiIm3atCE+Pp41a9Ywffp0pk2bxsiRIy97XNeuXdm+fTtRUVEsXLiQH3/8kb59+7r2x8TE0KpVK8LCwti0aROvvfYao0ePZtKkSa46a9asoUuXLkRGRvLLL7/Qvn172rdvz2+//eaqM27cON5++20++OAD1q1bR0BAABEREcTGxrrqxMfH07FjRx555JErXm9kZCQ333zz1dwiEclGQkKsV/mS/n6QmAh9+8KwYeB0ejIyEREREcltlJTK4+rUqUPp0qWZO3euq2zu3LmUKVOG2rVru9W9+PW9smXL8vLLL9OrVy8KFixImTJl3BIi1+KHH36gfv36+Pn5ERoayrPPPuvWo+jLL7+kRo0a5MuXj6JFi9KyZUvOnTsHwMqVK6lfvz4BAQEUKlSIxo0b8/fff7uOjY2NZenSpa6k1MMPP8zIkSNp2bLlJWM5ffo0U6ZMYcKECdx+++3UrVuXqVOnsmbNGn7++ed0X9PSpUvZsWMHn332GbVq1eLOO+/kxRdf5N133yU+jYGxd+7cyeLFi/noo49o0KABTZo04Z133uGLL77g4MGDAMyYMYP4+Hg+/vhjqlevTufOnXn88ceZMGGCq5233nqL1q1b8/TTT1O1alVefPFF6tSpw8SJEwGrl9Sbb77J8OHDueeee7j55pv55JNPOHjwIPPmzXO1M2bMGJ588klq1Khx2Wt9//33OXXqFE899VS670+O53DA559byxV6v4nkFPnzw5dfwpNPJpf973/QpQukyFeLiIiIiGSIklKZKM4Rd9WL0yT/GdppnMQ54khITEhXu1fkOA+ndyQvTusLdK9evZg6daqr2scff0zPnj3TdY3jx4+nXr16/PLLLzz66KM88sgj7N69O13HXuzAgQPcdddd3HLLLWzdupX333+fKVOmMHbsWAAOHTpEly5d6NWrFzt37mTlypXcd999GGNwOBy0b9+epk2b8uuvv7J27Vr69u2LzWZztb9s2TJuuOEGqlSpkq54Nm3aREJCglvSqkqVKpQpU4a1a9e6ysqWLcvo0aPTbGft2rXUqFGDEiVKuMoiIiKIiYlh+/btaR5TqFAh6tWr5ypr2bIldruddevWuercdttt+Pr6urW7e/duTp486apzcdItIiLCFf/evXuJjo52qxMUFESDBg3crjE9duzYwQsvvMAnn3yCPS8N+p2YaHUrWbnSWhfJJby8YMIEmDgxeRz/2bOhRQs4etSzsYmIiIhI7uDt6QBys8cXPQ6AwWCcBpvdhg3bZY/pW7cvdUvWBeCXQ78wadMkKhWtxJBGQ1x1nlv2HGfjz6Y69oO2H1w+IJNoJaaSCwB46KGHGDZsmKtX0erVq/niiy9YuXLlFa4Q7rrrLh599FEAnnnmGd544w1WrFhB5cqVr3jsxd577z1Kly7NxIkTsdlsVKlShYMHD/LMM88wcuRIDh06hMPh4L777iPsv5F4k3runDhxgtOnT9O2bVsqVKgAQNWqVd3aT/nqXnpER0fj6+ubagylEiVKEB0d7dquUKECxYoVu2w7KRNSSW0k7UvrmODgYLcyb29vihQp4jomOjqacuXKpdlu4cKF0zx3yjZSHpfWNV5JXFwcXbp04bXXXqNMmTL89ddf6T42x/PygrZtk9dFcpkBA6zBzzt3hnPnYM0aCA+H776DSpU8HZ3kRl52L9pWautaFxERkdxLSSmhePHitGnThmnTpmGMoU2bNpdNsqSUcuwgm81GSEgIR44cuaY4du7cSXh4uFvvpsaNG3P27Fn+/fdfatasSYsWLahRowYRERG0atWK+++/n8KFC1OkSBF69OhBREQEd9xxBy1btqRTp06EhoYC1mtqCxYsYPbs2dcU2+UsW7bsureZ0wwbNoyqVavy0EMPeTqUrOftDe3aeToKkUzVtq01M1/btnDoEOzZYyWm5s2DW2/1dHSS23jbvWlXWb9XRURE8gIlpTLR23e+DeB6vczb29st4XIpPl4+rvXaobV5+863sdvcX4V6ucXL1z3WXr16MXDgQADefffddB/n4+Pjtm2z2XBm0ki4Xl5eREVFsWbNGpYuXco777zD888/z7p16yhXrhxTp07l8ccfZ/HixcyaNYvhw4cTFRVFw4YNWb9+PQ6Hg0aNGqX7fCEhIcTHx3Pq1Cm33lKHDx8mJCTkqtpZv369W1nSDH5ptXOp5J7D4eDEiROuY0JCQlLNBHhxu2nVSbk/qSwpgZe0XatWrXRf4/Lly9m2bRtffvklYD3zAMWKFeP5559nzJgx6W5LRLKnOnVg3Tpo0wa2bYMTJ6BlS5g6FR580NPRiYiIiEhOlIcGfsl6ft5+V72kTEDZbXb8vP3cElWXazcjWrduTXx8PAkJCURERGSorWtVtWpV1q5d60pogPUqYcGCBSlVqhRgJb0aN27MmDFj+OWXX/D19eXrr7921a9duzbDhg1jzZo13HTTTcycOROwXt1r06YNXlfxelXdunXx8fFx6wm1e/du9u/fT3h4eLrbCQ8PZ9u2bW5JpqioKAIDA6lWrVqax5w6dYpNmza5ypYvX47T6aRBgwauOj/++CMJCcljjkVFRVG5cmUKFy7sqnNxT66oqChX/OXKlSMkJMStTkxMDOvWrbuqa/zqq6/YunUrW7ZsYcuWLXz00UcArFq1igEDBqS7nRzJGDh/3lpSPLsiuVHp0vDTT5D0MREfD127wtixevzl+jHGcPDMQQ6eOej2/wQiIiKS+ygpJYDVC2nnzp3s2LHjqhI31+L06dOu5EXS8s8///Doo4/yzz//8Nhjj7Fr1y6++eYbRo0axeDBg10DfL/88sts3LiR/fv3M3fuXI4ePUrVqlXZu3cvw4YNY+3atfz9998sXbqUP/74wzWu1Pz581ONJ3XixAm2bNnCjh07ACvhtGXLFtdYSkFBQURGRjJ48GBWrFjBpk2b6NmzJ+Hh4TRs2NDVTosWLVyz2V1Kq1atqFatGg8//DBbt25lyZIlDB8+nAEDBuDnZyUT169fT5UqVThw4ABgJehat25Nnz59WL9+PatXr2bgwIF07tyZkiVLAvDggw/i6+tLZGQk27dvZ9asWbz11lsMHjzYde5BgwaxePFixo8fz65duxg9ejQbN2509Yqz2Ww88cQTjB07lvnz57Nt2za6detGyZIlaZ80Hzywf/9+tmzZwv79+0lMTHT9u509a41tVqFCBW666SbXkjTWVdWqVVONjZXrxMdbU5Q9+aS1LpLLBQbCggXQp09y2YgR0KuXfgTk+ohPjGfMyjGMWTmG+EQ9VCIiIrmZXt8Tl8DAwCw5z8qVK6lTp45bWWRkJB999BHfffcdTz/9NDVr1qRIkSJERkYyfPhwV3w//vgjb775JjExMYSFhTF+/HjuvPNODh8+zK5du5g+fTrHjx8nNDSUAQMG0K9fP/bs2cOff/6ZqgfY/Pnz3WYZ7Ny5MwCjRo1yzab3xhtvYLfb6dChA3FxcURERPDee++5tbNnzx6OHTuW5vV6eXmxcOFCHnnkEcLDwwkICKB79+688MILrjrnz59n9+7dbr2eZsyYwcCBA2nRooUrhrffftu1PygoiKVLlzJgwADq1q1LsWLFGDlyJH379nXVadSoETNnzmT48OE899xz3HjjjcybN4+bbrrJVWfo0KGcO3eOvn37curUKZo0acLixYvx9/d31Rk5ciTTp093bdeuXRuAFStW0KxZszSvXURyJx8f+PBDqFgRnnnGKps2Dfbvh6++govmhxC5agV8C3g6BBEREckCNqN+0ekSExNDUFAQp0+fdkvexMbGsnfvXsqVK+f2JT6lqxlTKiOueJ6EMxCzO3k7sDL4FLw+bV/vWK+jCRMm8P333/Pdd99l6nnk+kn5fMTFxV3xZ8yjjIGkcdTsdsjk5/lKnE4nR44cITg4GLs993WGzUnXl91izax45syBhx+GuDhru1o1+PZbKFs2c897scw8T2a0nd2eD8k+9Gxcu9x+73La9WWneD0VS3b4DHTEOpjTcQ4AHed0xNv/6vql6DNQrlVaOZSL6QmQXK9UqVIMGzbM02FIbmWzgZeXtXg4ISXiCR07wvLlkDRp644d0LAhbNjg2bhEREREJPtTUkpyvU6dOnGr5iwXEck0jRrBzz9DpUrW9uHD0LQppJiHQkREREQkFSWlREQywuGwBtH56itrXSSPqlAB1q6FpL8BXLgA990Ho0fbXG+4iqRHQmIC49eMZ/ya8SQkJlz5ABEREcmxlJQSEcmIxERYutRaEhM9HY2IRxUpAlFR0LVrctmLL9p4+OHCnDjhubgkZ3EaJ78f/53fj/+O0yijKSIikpspKXWdaLx4kcyR7X+2vLygVStr8fLydDQiHufnB59+Cq++ao39D7B8uR/169vYutWzsYmIiIhI9qKkVAb5+PgAcP78eQ9Hkg7eBaBI7eTFW9MtS/aX9LOV9LOW7Xh7Q4cO1uJ9dbOZiORWNhsMHWp1ICxWzEos791rIzwcPvvMw8GJiIiISLahb1AZ5OXlRaFChThy5AgA+fPnx3bRDFwpp7e/eN/1lJnnud5tZ9U9kZzJGENCQgLx8fEcPXqUQoUK4aVeSCI5TosWsGGDoX17B1u3+nDhAjz8MKxfD+PHQ3bNNYuIiIhI1lBS6joICQkBcCWmLmaMwel0YrfbMz0plVnnud5tZ9U9kZwp5fNRuHBh189YtmQMrlGc7Xari4iIuJQpA/PmHefFF0vw8cfWz8c778Avv8Ds2RAa6uEARURERMRjlJS6Dmw2G6GhoQQHB5OQkHqWGKfTyfHjxylatCh2e+a9MZmZ57nebWfVPZGcKen5CAkJyb6v7SWJj4fHH7fW337bGlBHRNz4+8PkyYaGDW0MHGj92Pz0E9SpA19+CY0bezpCEREREfEEJaWuIy8vr0u+YuR0OvHx8cHf3z/Tk1KZdZ7r3XZW3RPJmZKeD72yJ5K79OkDNWtaQ7D9+y9ER0OzZvDGGzBggDoaioiIiOQ1SkrlJRcOwb/zk7dL3Q359N6ESIb4+lrfqJPWReSy6teHTZugc2dYsQIcDnjsMWucqQ8+gPz5PR1h2oyBnTshOBiKFvV0NCIiIiI5n7qo5CVn9sCG/snLmT2ejkgk57PZrG/R+fOrm4dIOgUHWzPzPfVUctmnn0KjRvDXX56L63JiY+Ghh2xUqwbFisHNN1vJtC+/hDSGlBQRERGRK1BSSkRERLKctze89hrMmgUBAVbZ1q1Qrx4sWuTZ2C529Ch06lSEL75ITjxv2wYTJ0LHjlCiBFStCv37w+efw8GDHgxWREREJAdRUkpEJCMcDliwwFocDk9HI5LjdOoE69bBjTda2ydPQps2MHZs8sSWnrR7NzRubGPDBuv13Pz5oW5da7LNlHbtgg8/hAcfhBtusK6nd2+rB9j+/R4IXERERCQH8GhS6scff6Rdu3aULFkSm83GvHnz3PaPHj2aKlWqEBAQQOHChWnZsiXr1q1L1c63335LgwYNyJcvH4ULF6Z9+/Zu+/fv30+bNm3Inz8/wcHBPP300zj05VFErofERFi40FoSEz0djUiOVL06bNgA99xjbRsDI0ZA+/Zw+rTn4vrhBwgPhz17rB5SoaGGVatg40Y4cQK+/RaGDoWGDa2eXyn9+SdMmQLdukFYGJQtC927w8cfw5491jWKiIiI5HUeTUqdO3eOmjVr8u67715yf6VKlZg4cSLbtm3jp59+omzZsrRq1YqjR4+66nz11Vc8/PDD9OzZk61bt7J69WoefPBB1/7ExETatGlDfHw8a9asYfr06UybNo2RI0dm+vWJSB7g5WVNH9asmbUuItckKAjmzrV6SCUNz7ZgAdxyC/z2W9bH8+mncMcdVs8tgKpVE1i71lCnTnK8d90Fr74Ka9da9ZYuheefhyZNwMfHvb2//4ZPPoHISKhYEcLCbHzwQX4lpy7By+5Fs7LNaFa2GV52/V4VERHJzTw6+96dd97JnXfemeb+lMklgAkTJjBlyhR+/fVXWrRogcPhYNCgQbz22mtERka66lWrVs21vnTpUnbs2MH3339PiRIlqFWrFi+++CLPPPMMo0ePxlezZYlIRnh7Q5cuno5CJFew262kTr161mtwJ07AH39AnToweLC1r2DBzI3BGBgzxlqSREQY3nnnBKVLF0/zuAIFrCTWHXdY2xcuwM8/W72tfvjBWo+NTa5/4ICNMWMCiY01vPKK5klIydvuTZca+r0qIiKSF+SYMaXi4+OZNGkSQUFB1KxZE4DNmzdz4MAB7HY7tWvXJjQ0lDvvvJPfUvxJde3atdSoUYMSJUq4yiIiIoiJiWH79u1Zfh0iIiJyeRER1itytWpZ2wkJVo+kKlVgxozMe/UtLs563S5lQqpfP5g/31Cw4NWdNF8+aN4cRo+GFSvg1Cn48Ud48UVo2TK53quv2hg+XK/ziYiISN7k0Z5S6bFw4UI6d+7M+fPnCQ0NJSoqimLFigHw13/zRo8ePZoJEyZQtmxZxo8fT7Nmzfj9998pUqQI0dHRbgkpwLUdHR2d5nnj4uKIi4tzbcfExADgdDpxXuXIq06nE2PMVR93ta54HuN0y0I6jTPdo8he72vIqnsiOZOej2uX2+9dTrq+7Barp+K51vOGhcFPP8FLL9kYPx7i420cPAgPPQTvv2946y1D7doZP0+SEyegQwcbP/5odVmy2QzjxhmefBKMyfi98/GBxo2t5bnn4L33DI89Zr2a9vLLYLcbxoxRZgrAGMPZ+LMAFPAtgC2PdSPLbr87cpLcfu9y2vVlp3hz2mfg9TxP0r6k9ezwXTY7PRuSedL775vtk1LNmzdny5YtHDt2jMmTJ9OpUyfWrVtHcHCw6yKff/55OnToAMDUqVMpVaoUc+bMoV+/ftd83ldeeYUxKf9U+p+jR48Sm7L/fTo4nU5Onz6NMQb7xdP1XEdXOo/PqZMUTbF98uRJEsyR69L29Y5V8rYc9XzExRH43xh1MS+8AH5+Hg0nR927a5CTri+7xeqpeDJ63scfh3btvBg1qiBRUf4ArF5to359eOihCzzzzBmKFDEZOs++fV489FBh9uyx/rfI398wceIp2rSJ4+jRzLl3993n5PBhO2PHhgAwdqyN2NizDBly7rq0n5PFJcYxfPVwAMY2Houfl2d/r2a17Pa7IyfJ7fcup11fdoo3p34GXo/zOGIdxMVbnS2OHDmCt//VpQAy4xqy07MhmefMmTPpqpftk1IBAQFUrFiRihUr0rBhQ2688UamTJnCsGHDCA0NBdzHkPLz86N8+fLs/2/+5ZCQENavX+/W5uHDh1370jJs2DAGDx7s2o6JiaF06dIUL16cwMDAq7oGp9OJzWajePHimf7L6LLnsRV22yxcuDAUD74+bV/vWCVPy1HPR1wctv8SUf7BwdkiKZVj7t01yEnXl91i9VQ81+O8wcGweDF8952TwYNt/PGHDafTxief5GfBgny8+KKhd+9rO8+aNXDvvTaOHbP9dy7DN98Y6tcPuq7XcDGn08mjjx6lSJFEBg+2eky9/npBChQIYMSI63KKHCvOEUe+fPkACC4ejJ933ktKZaffHTlJbr93Oe36slO8OfkzMKPnccQ68PO1fo8GBwdfU1IqMz4Ds8uzIZnH398/XfWyfVLqYk6n0/VaXd26dfHz82P37t00adIEgISEBPbt20dYWBgA4eHhvPTSSxw5coTgYCsBExUVRWBgoFsy62J+fn74XeLLpd1uv6YfHJvNds3HXrfz2NzL7Da7Nars9Wj7GmTVPZGcKcc8H/7+MG4cADZ//2wxWnGOuXfXKCddX3aL1VPxXK/ztm0LrVrBm29aYzOdPQsnT9oYONDG5Mk2Ro/25e6703+eWbOge3drLCmAatXg229tlC2b+uc4M+6dzWZj0CAbNhs8+aRVNnq0HW9va1D3vCqfbz4mtZvk6TA8Krv97shJcvu9y2nXl53izemfgdd6Hrvd7noNOjt9l81Oz4ZkjvT+23r0CTh79ixbtmxhy5YtAOzdu5ctW7awf/9+zp07x3PPPcfPP//M33//zaZNm+jVqxcHDhygY8eOAAQGBtK/f39GjRrF0qVL2b17N4888giAq06rVq2oVq0aDz/8MFu3bmXJkiUMHz6cAQMGXDLpJCJyVWw2KFTIWrJBQkokt/P1haFDYfdua3ypJFu32rj33qJ07WrjwIHLt2GMNY5T587JCakWLWD1aihbNtNCT9MTT8D48cnbw4fDK69kfRwiIiIiWc2jPaU2btxI8+bNXdtJr8t1796dDz74gF27djF9+nSOHTtG0aJFueWWW1i1ahXVq1d3HfPaa6/h7e3Nww8/zIULF2jQoAHLly+3Xk0DvLy8WLhwIY888gjh4eEEBATQvXt3Xnjhhay92OygQDmoPd59W0REJAcqWRI+/RT694eBA+G/v2/xxRc2FiywEjtPPpn6jdqEBOuYjz9OLuvVCz74wBqM3FMGD7bmHnn6aWv7uefAy8tKwImIiIjkVh5NSjVr1sw1E8ClzJ0794pt+Pj48Prrr/P666+nWScsLIzvvvvummLMVfLfAFUHX7meiKSfwwHLl1vrt98O3jnurWiRHK1xY9i4ESZNcvL883DypJ1z52DYMJgyxXrVr00bq+6pU3D//bBsWfLxL78Mzz6bPTo6PvUUJCZa8QA884z1lv1TT3k2rqyWkJjAx79YWcNetXvh4+XBbKGIiIhkKr3AKSKSEYmJ8NVX1pKY6OloRPIkLy/o1w9Wrz7KI48Y13CJf/5pjUPVtq2VO27cODkh5ecHX3xhJa+yQ0IqyTPPWImyJE8/DRMmeC4eT3AaJ5sPbWbzoc04jaYLFxERyc2UlBIRyQgvLwgPtxYvL09HI5KnFS5smDjRsHkz3Hprcvm331pjRu3YYW0XK2YlqR54wDNxXsmwYdZA7kmGDLF6fImIiIjkNkpKiYhkhLc39OhhLXp1TyRbqFkTfvgBZs6EG25w31epEvz8MzRq5JnY0mv4cBgzJnn7ySfhnXc8F4+IiIhIZlBSSkRERHIdmw26dIFdu6yeR0WKQLt2sHYtVKjg6ejSZ+RIGDUqefvxx+Hddz0Xj4iIiMj1pqRUXnLkJ5hpS16O/OTpiERERDJVgQLWGE3HjsH8+VZyKicZNcrqNZVk4EB4/33PxSMiIiJyPSkpJSKSEXFx8MQT1hIX5+loRCQN2Wkw86ths8ELL8BzzyWXPfoofPih52ISERERuV40AIqISEZduODpCEQkF7PZYOxYa4LPV1+1yvr3B7sd+vTxbGwiIiIiGaGklIhIRvj6Jk+T5evr2VhEJNey2eCVV8DphNdes8r69rUm/ezVy7OxiYiIiFwrJaVERDLCZoPgYE9HISJ5gM1m9ZRyOmH8eKusd284ehQGDLDGzxIRERHJSTSmlIiIiEgOYbNZPaWeeMLaNgaefRZKlYKnnoJ9+zwZnYiIiMjVUVJKRCQjEhNh5UprSUz0dDQikgfYbDBhAgwZklx2+rTVe6pCBejQAVatshJWIiIiItmZklIiIhnhcMDnn1uLw+HpaEQkj7DZ4PXX4ZdfoGfP5CHtnE6YOxduuw3q1oVPPtHEoCIiIpJ9KSklIpIRdjvUqWMtdv1KFZGsVasWfPwx/PMPvPAChIQk7/vlF+jeHcLCYMwYOHzYY2FeFbvNTp3QOtQJrYPdpt+rIiIiuZk+6UVEMsLHB/r1sxYfH09HIyJ5VHAwjBgBf/8Nn34K9eol7zt8GEaPhjJlrCTV5s0eCzNdfLx86FevH/3q9cPHS79XRUREcjMlpURERERyCV9feOghWL8efvoJOnYELy9rX3y89Tpf3brW631z52ooPBEREfEsJaVEREREchmbDRo3htmz4a+/YOhQKFw4ef+qVdaA6BUqWAOknzrlsVBFREQkD1NSKi/xzgcFKyUv3vk8HZFIzhcfD888Yy3x8Z6ORkQklTJl4NVXrXGn3n8fqlRJ3vf33/DUU1CqlPX6X3YYFD3OEUe/Bf3ot6AfcY5sEJCIiIhkGiWl8pIidaHd7uSlSF1PRySS8xljdTE4dUrzr4tIthYQAP37w/btsHgx3Hln8r5z52DsWGvOhvXrPRejiIiI5C3eng5ARCRH8/GB4cOT10VEsjm7HSIirGXXLnj7bfjoI0hIgB07IDzc6j01Zgz4+2d9fL5evrze6nXXuoiIiORe6iklIpIRdjuULm0tdv1KFZGcpUoVeO892LTJGgAdwOmEceOgVi1YuzbrY7LZbBT0K0hBv4LYbLasD0BERESyjL5BiYiIiORxNWrAzz/Dyy9bM/gB7N5tDZY+ZAicP+/Z+ERERCR3UlJKRCQjEhNhzRpr0dzqIpKDeXvDsGHwyy9Qv75VZgxMmAA1a1oz9mUFh9PB59s+5/Ntn+NwOrLmpCIiIuIRSkrlJWf+hPX9kpczf3o6IpGcz+GA6dOtxaEvTyKS81WrBqtXW6/w+flZZX/+CU2bwqBB1qDomSnRmcjKfStZuW8liU4l+0VERHIzJaXykgvR8Oek5OVCtKcjEsn57Ha46SZr0ZhSIpJLeHvD00/Dli3WwOdg9Zp6+224+WZYudKT0YmIiEhuoW9QIiIZ4eMDjz1mLZp9T0RymSpVrNf2JkxInonvr7+geXMYMADOnvVsfCIiIpKzKSklIiIiImny8oInn4Rff4UmTZLL33vP6iS6bJnnYhMREZGcTUkpEREREbmiG2+EH36At96C/Pmtsr//hpYtoV8/iInxbHwiIiKS8ygpJSKSEfHxMGKEtcTHezoaEZFMZbfD449bvaaaNUsunzTJ6jW1ZInHQhMREZEcSEkpEZGMMAaOHLEWYzwdjYhIlqhQwXpt7913ISDAKvvnH2jdGnr0gKNHPRqeiIiI5BBKSomIZISPDwwdai0a6FxE8hC7HR59FH77DVq0SC6fPh0qV4YPPwSn03PxiYiISPanpJSISEbY7VaXgQoVrHURkTymbFmIirKSUEFBVtnJk9C/P4SHw+bNHg1PREREsjF9gxIRERGRDLHZoG9f2L0bHn44uXz9erjlFnjsMTh1ymPhiYiISDalpJSISEY4nbBpk7XoPRURyeNKlIBPPoGVK6FqVavM6YSJE6FKFZgxQ8PviYiISDIlpUREMiIhwZp2atIka11ERGjaFLZsgVdfhfz5rbLDh+Ghh6zxp3bu9Gh4IiIikk0oKSUikhF2O1SqZC0aU0pExMXX15oDYudOuPfe5PIVK6BmTXjuOTh/PvVxdpudSkUrUaloJew2/V4VERHJzbw9HYBkoUI1oMUK920RyRgfHxgyxNNRiIhkW2XKwNy58O231thSe/daHUtfeQVmzoS334a7706u7+Plw5BG+r0qIiKSF+jPT3mJbxCUaJa8+AZ5OCARERHJK9q0gd9+g+HDrV5UAH//DffcYyWl9u3zaHgiIiLiAUpKiYiIiEiWyJ8fXnwRfv3VGlsqyYIFUK0avPwyxMV5Lj4RERHJWkpKiYhkREKC9Q3rxRc10LmISDpVrgxRUfDFFxAaapVduADPPw81asfR8aMhDFkyhDiHMlQiIiK5mZJSIiIZ4XTCv/9ai9Pp6WhERHIMmw0eeAB27YInnkieK+KP3+HLb84y99uzbNvm0RBFREQkkykplZcknIUTm5OXhLOejkgk5/Pxsb5NPfGEtS4iIlclMBDeeAM2bYLwcCDRF34Yxb5po7ilji+dOsH27Z6OUkRERDKDklJ5ycktsLhu8nJyi6cjEsn57HaoWtVa7PqVKiJyrWrVgp9+gsmTbYQWKAlnSgI25syBGjXgwQetXlUiIiKSe+gblIiIiIhkC3Y79O4Ne/ZYvaeCg61yY+Dzz6F6dXj4YfjjD8/GKSIiIteHklIiIhnhdMK2bdaiMaVERDLM4XTw/f4FVLhzAb//6eC116BYMWuf0wmffWZ1Tu3ZE/76y7OxioiISMYoKSUikhEJCTBxorVo9j0RkQxLdCay8PeFLPx9If75EnnqKdi7F/73PyhS5L86iTBtGlSqZPWs2rfPkxGLiIjItVJSSkQkI+x2CAuzFo0pJSKSKQoUgGeesZJTY8dC4cJWeWIiTJkCN94I/fvD/v2ejVNERESujr5BiYhkhI8PPPectWj2PRGRTBUYCM8/byWnxoyBoCCr3OGADz+0klMDBsCBA56NU0RERNJHSSkRERERyVGCgmDkSOu1vZEjoWBBqzw+Ht57DypUgEGD4NAhj4YpIiIiV6CklIiIiIjkSIUKWT2m9u2zOqwGBFjlcXHw9ttQvjw8+yycOePJKEVERCQtSkqJiGREQgKMG2ctGuhcRMQjihSBl16yklPPPAP581vlsbHw6qvWgOjTpmmSVBERkexGSSkRkYxwOmHPHmvRtx0REY8qVsyapW/vXhg8GHx9rfLoaOjZExo0gDVrPBujiIiIJFNSSkQkI3x84JFHrEUDnYuIZAvBwTB+POzcCffdl1y+cSM0bgxdu8K//3ouPhEREbEoKSUikhF2O9SqZS12/UoVEclOypeHr76CZcugRo3k8pkzoXJlePFFuHDBc/GJiIjkdfoGlZf4FYOwzsmLXzFPRyQiIiKS6W6/HTZvtmbmK1rUKjt/3pq5r0oVmDMHjPFsjCIiInmRklJ5SVAVaPx58hJUxdMRieR8Tif8/ru1aEwpEZFsy9vbetP6jz9g0CDw8rLK9++HTp2gaVP45RfPxigiIpLXKCklIpIRCQnWwCXjx2v2PRGRHKBwYXjzTfj1V2jVKrl81SqoWxf69oUjRzwWnoiISJ6ipJSISEbYbBAaai02m6ejERHJ8Ww2G6EFQwktGIotE3+vVqsGixfDggVw441WmTEwebK1PX48xMdn2ulFREQEJaVERDLG1xdGj7aWpLnHRUTkmvl6+TK62WhGNxuNr1fm/l612aBtW/jtN3j9dQgMtMpjYuCpp+Cmm+DbbzXelIiISGZRUkpERERE8jRfXxgyxBoesHfv5I6vf/xhJa3uvNNaFxERketLSam85OQWWHxL8nJyi6cjEhEREck2SpSwXt/buBGaNEkuX7IE6tSBzz/3XGwiIiK5kZJSeUnCWTixMXlJOOvpiERyvoQEa8TcN9/UQOciItdBfGI8o1eOZvTK0cQnemZQpzp14McfYdYsKF3aKjt7Fh58EPr1gwsXPBKWiIhIrqOklIhIRjidsHOntTidno5GRCTHM8Zw6MwhDp05hPHgYE42G3TqBDt2wMMPJ5dPmgQNG8Lu3R4LTUREJNfw9nQAIiI5mo8P9OqVvC4iIhni4+XDkEZDXOueVqAATJ8OzZvDgAFWL6lff4V69eDDD63eUyIiInJt1FNKRCQj7HZo0MBa7PqVKiKSUXabnUpFK1GpaCXstuzxe9Vmg549YcMGqFrVKjt7Frp2hb599TqfiIjItcoen/QiIiIiItlc9epWYqp79+SyyZOtv0vodT4REZGrp6SUiEhGOJ2wb5+1aEwpEZEMS3QmsnLfSlbuW0miM9HT4aQSEADTpsHUqZAvn1W2bRvUrQszZng0NBERkRxHSSkRkYxISIBXXrEWzb4nIpJhDqeDz7d9zufbPsfhdHg6nDT16GH1mqpWzdo+dw4eegj69NHrfCIiIumlpJSISEbYbFC0qLXYbJ6ORkREslD16rB+vTXeVJKPPrJe59u1y3NxiYiI5BRKSomIZISvL7z8srX4+no6GhERyWIBAfDxx9YrffnzW2Xbtlmz8332mUdDExERyfaUlBIRERERyaDu3a3X+apXt7bPnft/e3cer+Wc/3H8dd9nS/u+kUIKaVUqRImSEbJkauxGxtjFEDMp+5Yh2aIZW0O2Cf0sZa1EKKcIRRNCihZtOtt9//64pnOcSdS5zznXfZ/79Xw8vo+u63vd57rf13Xuruucz7mu7wUnnQR//CNs3BhuNkmSkpVFKUmSJKkc7LVXcDvf6aeX9E2Y4O18kiRtjUUpSUpEQQHcfXfQHOhcktJe9epBIerhh0tu5/voo+B2vkceCTebJEnJxqJUOmnYA47/saQ17BF2Iin1xWIwb17QYrGw00iSksRJJ8H778PeewfzGzbAySfD0KHw/ffhZpMkKVlYlEon0UzIql3SoplhJ5JSX2Zm8AzwE08MpiVJ+q8994TZs4NxpTZ77LGg/9FHIR4PL5skScnAopQkJSIjA3r1ClpGRthpJElJpnp1uP9+mDgR6tUL+lauDK6kGjAAvvgi1HiSJIXKopQkSZJUwYYOhU8+gRNOKOl7+eXgaX233w5FRaFFkyQpNBalJCkR8Th8+23QvA9DkvQrmjSBxx+H556DnXYK+jZuhIsugv32gw8/DDefJEmVzaJUOvnpO/j8gZL203dhJ5JSX34+jB4dtPz8sNNIklLAwIGwYAGcc05J37vvQpcuMHJkhE2bwssmSVJlsiiVTtZ9Du+eWdLWfR52IqlqqFkzaJKkclEzuyY1s6v2cbV2bRg3DmbOhD32CPoKC+G66yIcemhDZs4MN58kSZXBR0VJUiJycmDMmLBTSFKVkZOZw5j+6XNc3X9/yM2F66+HG26AggL4/PNMDjoIzj4bbrwxKGBJklQVeaWUJEmSFKKcnOAu8LlzoXv3kvEJ77kH9torGINKkqSqyKKUJEmSlAT23htmzIhz9dVrqVEjKE598w0cdVTw1L7ly0MOKElSObMoJUmJKCiACROCVlAQdhpJSnkFRQWMmTWGMbPGUFCUfsfVjAw488yNzJ8fp3//kv4nnoA994R//tOHvUqSqg6LUpKUiFgseGTSu+8G05KkhMTiMRatXMSilYuIxdP3uNqqFbz4Ijz6KDRoEPStXg2nnw6HHgqf+7waSVIVYFFKkhKRmQmDBwct02dHSFKisjKyGLbPMIbtM4ysjKyw44QqEoE//AE++ST4d7NXXw1u9bv6asjLCy+fJEmJsiglSYnIyIC+fYOWkRF2GklKedFIlH2a78M+zfchGvFHVYBGjYIrpl54AXbeOejLy4OrroIOHYIilSRJqcgzvSRJkpQCBgyABQvgkktK/g6yaBEcckhwJdV334WbT5Kk7RVqUWr69OkMHDiQ5s2bE4lEmDx5cqnlo0aNYo899qBGjRrUq1ePQw45hNmzZ5d6TatWrYhEIqXajTfeWOo18+fPp1evXlSrVo0WLVpw8803V/SmSUoX8TisXBk0R56VpITF4jHmfDuHOd/OSesxpbamZk245RaYOxf226+k/1//gj32gLvugqKi8PJJkrQ9Qi1KbdiwgY4dO3LXXXf94vI2bdowbtw4PvzwQ2bOnEmrVq3o168f33//fanXXX311Sxbtqy4nXfeecXL1q5dS79+/WjZsiVz5szhlltuYdSoUYwfP75Ct01SmsjPhyuuCFp+fthpJCnlFRQVMH7OeMbPGZ+WT9/bVh06wIwZ8MADUL9+0Pfjj3DuudCjB8yZE24+SZK2Raij8g4YMIABAwZsdfnQoUNLzd92221MmDCB+fPn07dv3+L+WrVq0bRp019cx8SJE8nPz+cf//gH2dnZtGvXjtzcXG677TaGDRtWPhsiKb1lZ4edQJKUhqJROOMMOPJI+Mtf4MEHg/7334d994VzzoFrroE6dUKNKUnSVqXMo6Ly8/MZP348derUoWPHjqWW3XjjjVxzzTXsvPPODB06lIsuuojM/z4F6+233+bAAw8k+2e/NPbv35+bbrqJ1atXU69evV98v7y8PPJ+9jiTtWvXAhCLxYht52PfY7EY8Xh8u79ue/3m+1TfGTreVHp+GzOV9zZU1j5Rakqpz0dWFtxxR8l8yJlTat+VQSptX7JlDStP0pwDk2zdyfb5SCaxWIw48eLpdNtHZflsNGgAEybAKafAOedE+PjjCLEY3HknPPVUnDFj4gweHDzNryqr6v+vUm37kilvOp8DNy/bPJ0Mv8sm02dDFWdbv79JX5SaMmUKv//979m4cSPNmjVj2rRpNGzYsHj5+eefT5cuXahfvz6zZs1ixIgRLFu2jNtuuw2A7777jl122aXUOps0aVK8bGtFqRtuuIHRo0dv0f/999+zadOm7dqGWCzGjz/+SDweJxqtuDsmf/t9sqHBySWz64H1K8pp3eWdVenMz0fZVfV9l0rbl2xZw8qTPOfA5Fp3sn0+kkleUR4//fQTACu+X0FORk7IiSpXIp+NPfaAF1+E8eNrMGZMTTZtirBsWYShQyPcd18e11+/ll13rboDTlX1/1eptn3JlDedz4GFmwrJyw8utlixYgWZ1bavBOA5UGW1bt26bXpd0hel+vTpQ25uLj/88AP3338/gwcPZvbs2TRu3BiAiy++uPi1HTp0IDs7m7POOosbbriBnJyy/xAzYsSIUuteu3YtLVq0oFGjRtSuXXu71hWLxYhEIjRq1KjCD0YV9T7lve7K2idKTX4+yq6q77tU2r5kyxpWHs+BlbfOqiKvMI8ddtgBgMaNGpOTmX5FqUQ/G1dfDaefHueCC2DKlODyqDffzOHggxty+eVx/vIXqFatPFMnh6r+/yrVti+Z8qbzObBwUyE52cFxtHHjxmUqSnkOVFlU28YTTdIXpWrUqEHr1q1p3bo1PXr0YPfdd2fChAmMGDHiF1/fvXt3CgsL+eKLL2jbti1NmzZl+fLlpV6zeX5r41AB5OTk/GJRKxqNluk/TiQSKfPXJsv7lPe6K2ufKDWlzOejsBAeeyyYHjIEMsM/rKbMviujVNq+ZMsaVh7PgZW3zqogGo0SIVI8nY77pzw+G7vuCs8/D88+C+edB0uXQl5ehNGjI/zrX3D33XDIIeUYOklU9f9XqbZ9yZQ3Xc+B0WiUSCSxY6rnQJXFtn5vU+4TEIvFSo319L9yc3OJRqPFV1L17NmT6dOnU1BQ8vSWadOm0bZt263euidJ26yoCGbODJrP4JYkJZmjjoKPP4ZLL4WMjKDvs8/g0EODv6V8/XW4+SRJ6S3UotT69evJzc0lNzcXgCVLlpCbm8tXX33Fhg0buOKKK3jnnXf48ssvmTNnDqeffjrffPMNxx9/PBAMYn777bczb948/vOf/zBx4kQuuugiTjzxxOKC09ChQ8nOzuaMM85gwYIFTJo0iTvuuKPUrXmSVGYZGcFP/EcdVfLTviRJSaRmTbj5ZvjgA9h//5L+xx+H1q2DgtXKleHlkySlr1CLUu+//z6dO3emc+fOQDA+VOfOnRk5ciQZGRl8+umnHHvssbRp04aBAweycuVKZsyYQbt27YDgFrvHH3+cgw46iHbt2nHddddx0UUXMX78+OL3qFOnDlOnTmXJkiXss88+DB8+nJEjRzJs2LBQtjlUK2bCY5klbcXMsBNJqS8zEw4/PGhJcOueJElb0749TJ8ePKmvfv2gLy8Pbr01uN3vmmtg/fpwM0qS0kuov0H17t27+PGUv+SZZ5751a/v0qUL77zzzm++T4cOHZgxY8Z256uS4t5eJEmSlK6iUTj99OAC3xtvhDvvDApTa9fCyJEwbhxceSWcdRYk8MwgSZK2ScqNKSVJSSUeh3XrgvYrRXZJkpJJgwZwyy3w+edw5pkld6CvWAEXXABt28JDDzlcoiSpYlmUkqRE5OfDJZcELT8/7DSSJG2XnXaC8eODwdAHDy7p//JLOPVU6NABJk/27y6SpIphUUqSJElKc23awKRJMGcO9O9f0v/xxzBoEPTsCa+/Hl4+SVLV5Ki8kpSInBy4776wU0hSlZGTmcN9Az2uhqVLF3jpJXjjDRgxAjYP3zp7Nhx8MBx6KFx/PXTtGmpMSVIV4ZVSkiRJkkrp3RtmzYJnn4W99y7pnzYNunWD44+HTz8NLZ4kqYqwKCVJkiRpC5EIHHkk5ObCww9Dq1Yly556Ctq1gz/+EZYuDSuhJCnVlakotXTpUr7++uvi+XfffZcLL7yQ8ePHl1swSUoJhYXwxBNBKywMO40kpbyCogLue/8+7nv/PgqKCsKOI4In8510EixcCHfeCU2aBP2xGEyYALvvHix/7bWgT5KkbVWmotTQoUN5/b8jHX733XcceuihvPvuu1x55ZVcffXV5RpQkpJaURG8+mrQfG62JCUsFo8xd9lc5i6bSyxuhSOZZGfDuefC55/DtddC7dpBf14ePPoo9O0Lu+0GV18dPL1PkqTfUqai1EcffcS+++4LwBNPPMHee+/NrFmzmDhxIg8++GB55pOk5JaRAQMGBC0jI+w0kpTyMqOZDGk/hCHth5AZ9Zk8yahmTbjySvjPf+Avf4F69UqWffEFXHUV7LJLMCj6Y4/BTz+FFlWSlOTKVJQqKCggJycHgFdeeYUjjzwSgD322INly5aVXzpJSnaZmXD00UHL9JcnSUpURjSD3q1607tVbzKiFvuTWYMGcNNN8O23MGkS9O8fjEMFEI/DK6/A0KHQvDmccw68/37QL0nSZmUqSrVr1457772XGTNmMG3aNA477DAAvv32Wxo0aFCuAVWOMqpBzd1KWka1sBNJkiQpxVWrBoMHw0svBbftXXst7LpryfI1a+Duu4On9nXsCLffDt9/H1ZaSVIyKVNR6qabbuK+++6jd+/eDBkyhI4dOwLw3HPPFd/WpyTUoCsc+XlJa9A17ERS6ovHg8E08vL8868klYNYPMailYtYtHKRY0qloBYtglv7PvsM3ngDTjkFqlcvWf7hh3DRRbDjjnDssfB//+dzQiQpnZXpXpPevXvzww8/sHbtWur97CbyYcOGUf3nZx1Jqury8+H884PpsWPhv7c2S5LKpqCogDGzxgAwdsBYcjI9rqaiaBQOOihoY8cGD6n9xz/g7beD5QUF8MwzQWvWDE4+GU47Ddq2DTe3JKlylelKqZ9++om8vLzigtSXX37J7bffzsKFC2ncuHG5BpQkSZKUumrXhj/+EWbNgk8+CQZHb9KkZPmyZcHYVHvsATfcEF5OSVLlK1NR6qijjuLhhx8GYM2aNXTv3p0xY8Zw9NFHc88995RrQElKatnZwZ+Ax44NpiVJ0lbtsUdQgFq6FJ57bsvnhFxxBYwbF1o8SVIlK1NRau7cufTq1QuAp556iiZNmvDll1/y8MMPM3bs2HINKElJLRIJbtnLySl55JAkSfpVWVkwcCD8+9/wzTdw2WUly847D/71r/CySZIqT5nGlNq4cSO1atUCYOrUqRxzzDFEo1F69OjBl19+Wa4BVY7WLYZPbyuZ3+NiqLVbeHkkSZKU9ho3hhtvDMah2nz73imnQN26cPjhoUaTJFWwMl0p1bp1ayZPnszSpUt5+eWX6devHwArVqygdu3a5RpQ5einZfDZ3SXtp2VhJ5JSX2EhTJ4cNB8fJElSmV13HZx1VjBdWBg8nW/mzHAzSZIqVpmKUiNHjuSSSy6hVatW7LvvvvTs2RMIrprq3LlzuQaUpKRWVAQvvhi0oqKw00iSlLIiEbjrLhg8OJjftAmOOALmzQs3lySp4pTp9r3jjjuOAw44gGXLltGxY8fi/r59+zJo0KByCydJSS8jA/r2LZmWJElllpEBjzwCP/4IL78c/Nu/P8yYAbvvHnY6SVJ5K1NRCqBp06Y0bdqUr7/+GoCddtqJfffdt9yCSVJKyMws+ZOuJElKWHY2PP00HHoovP02LF8eTL/1Fuy4Y9jpJEnlqUy378ViMa6++mrq1KlDy5YtadmyJXXr1uWaa64hFouVd0ZJkiRJaaRGDZgyBfbeO5j/8kvo1w9Wrgw3lySpfJXpSqkrr7ySCRMmcOONN7L//vsDMHPmTEaNGsWmTZu47rrryjWkJEmSpPRSvz5MnQr77w9LlsDHH8PvfgevvAI1a4adTpJUHspUlHrooYd44IEHOPLII4v7OnTowI477sif//xni1KS0kdeHpx/fjA9dizk5ISbR5KkKqRZM5g2DQ44AL77DmbPhkGDgquoPOVKUuor0+17q1atYo899tiif4899mDVqlUJh5IkSZIkgN12CwY9r1s3mH/lFTjxRB96K0lVQZmKUh07dmTcuHFb9I8bN44OHTokHEqSUkZ2Ntx6a9Cys8NOI0kpLzsjm1v73cqt/W4lO8PjqgIdOsD//R/ssEMw/9RT8Kc/QTwebi5JUmLKdPvezTffzO9+9zteeeUVevbsCcDbb7/N0qVLeeGFF8o1oCQltUgEatUKO4UkVRmRSIRaOR5XtaX99oNnnoEjj4SCAnjggWDcqZtuCjuZJKmsynSl1EEHHcSiRYsYNGgQa9asYc2aNRxzzDEsWLCARx55pLwzSpIkSRKHHQaPPBL8TQjg5puDJklKTWW6UgqgefPmWwxoPm/ePCZMmMD48eMTDiZJKaGwMHg0EATPqs4s82FVkgQUxgp5csGTABzf7ngyox5XVdoJJ8Dq1XD22cH8ZZcFV0ydfnq4uSRJ28+zfDqpuzccPK30vKTEFBXBs88G0337WpSSpAQVxYp444s3ADhmz2MsSukX/elPsHIl/PWvwfxZZ0GdOtCrV7i5JEnbx7N8OsmuC00PCTuFVLVkZATPqd48LUlKSEY0gyPaHFE8LW3NFVfAqlVw220Qi8GJJ0Z45JFsjjsu7GSSpG1lUUqSEpGZCSedFHYKSaoyMqOZDGw7MOwYSgGRSPDw21Wr4MEHIT8/wmmn1aVFC/jvs5gkSUluu4pSxxxzzK8uX7NmTSJZJEmSJGmbRSJw//2wZg1MngwbN0Y54og4p5wCe+wRtLZtoXHjksHRJUnJY7uKUnXq1PnN5SeffHJCgSRJkpS+4vE4y9YvA6BZzWZErCToN2RmwmOPweGHx3n99QirVkX4+99Lv6Zu3ZIC1c//3W03yM4OJbYkie0sSv3zn/+sqByqDIUbYN3ikvlau0FmjfDySFVBXh5cckkwfeutkJMTbh5JSnH5RfmMfmM0AGMHjCUn0+Oqflu1avDvf8c56qh83nxzy8/MmjXwzjtB+7mMDNh119JXVW3+t2HDyskuSenMMaXSyaoP4JWfPZLkkBnQ+IDw8khVRX5+2AkkSUp7tWrBY4+tprCwMYsWRVm4ED79lOJ/v/pqy68pKoLPPgva88+XXta0KZxwApx+OnToUDnbIEnpxqKUJCUiOxuuv75kWpIkhSYSgR13hBYtoG/f0ss2bAiKT59+WrpYtWgRbNy45bq++w7uuCNoXbsGxakhQ4JbASVJ5cOilCQlIhKBBg3CTiFJkn5DjRrQqVPQfi4Wg6+/Ll2o+vRTeOut4C59gPffD9rFF8OxxwYFqt69IRqt5I2QpCrGopQkSZKktBWNws47B61fv5L+1avhX/+Cf/wD5s4N+jZtgokTg7bLLnDaaXDqqcGVWZKk7WdtX5ISUVQEr74atKKisNNIkqRyUq8enHMOzJkDH3wA550X9G22ZAmMHAktW8Jhh8GTT5ZcWSVJ2jYWpSQpEYWF8MQTQSssDDuNJEmqAJ06wdix8O238PjjwRVVkUiwLB6Hl1+GwYOD8awuvBDmzw8zrSSlDotSkpSIaBT23TdoDiwhSVKVVq1a8ES+l18OrpQaPRpatSpZvnJlMDB6x47B4Oj33ANr1oSVVpKSn79BSVIisrLgjDOClpUVdhpJklRJWrYMbt9bvBheeQWGDoWcnJLlc+bAn/8MzZvDLbd4l78k/RKLUpIkSZJURtEo9O0bDH6+bBncdRd06VKy/Kef4C9/gQMPhM8/Dy+nJCUji1KSJEmSVA7q1Quujto8OPqwYSVjT82aFdzWd9ddEIuFm1OSkoVFKUlKRF4eDB8eNB+5I0mS/qtTJ7jvPnjzTdh116Bv40Y499xgoPSvvgo1niQlBYtSkpSo9euDJkmS9D969YJ58+Dss0v6Xn0V2reHf/4zeHqfJKWrzLADqBLlNIAWx5Wel5SY7Gy46qqSaUlSQrIzsrmq91XF01JVULMm3H03DBoEp58OX38Na9cG0888A+PHQ7NmYaeUpMpnUSqd1NkTej0ZdgqpaolEgsfqSJLKRSQSoXktj6uqmg49FD78EC66CB58MOibMgX23jsoWp1wQqjxJKnSefueJEmSJFWSunWD2/aefRaaNAn6Vq2C3/8+KEr98EOo8SSpUlmUkqREFBXBjBlBKyoKO40kpbzCWCHPL3ye5xc+T2GsMOw4UoU58kj46CM4/viSvieeCK6aeu658HJJUmWyKCVJiSgshEcfDVqhvzxJUqKKYkVMWTSFKYumUBSz2K+qrWHDoBD1+ONQv37Qt3w5HHUUnHYa/PhjuPkkqaJZlJKkRESj0LFj0KIeUiUpURnRDHq36k3vVr3JiGaEHUeqFCecEFw1dcQRJX0PPhhcNTVtWmixJKnCOdB5Olk9D979U8n8vvdCvY7h5ZGqgqws+POfw04hSVVGZjSTIe2HhB1DqnTNmgW37T34IFxwAaxbFzylr18/OPtsuPHGsBNKUvnzz/rppGAdrHynpBWsCzuRJEmSpP+KRILb9j76CPr2Lem/5x7o3DlCbq7XFEiqWixKSZIkKWnE43HW5a1jXd464vF42HGkUOy8M0ydCnfdBdWrB33/+U+Eo49uwIQJ4WaTpPJkUUqSEpGfD1dcEbT8/LDTSFLKyy/K55Kpl3DJ1EvIL/K4qvQVjQYjBMybBz16BH15eRGGDYty1lmQlxduPkkqDxalJCkR8TisXBk0/6IvSZLKWevW8OabcM45JT9njB8PBx4IS5eGGEySyoFFKUlKRFYWjBgRtKyssNNIkqQqKDsbxo6NM3bsGqpVC4pT774L++wDr78ecjhJSoBFKUlKRDQKrVoFLeohVZIkVZzjj9/EzJlxWrUK5r//Hg49FMaM8YJtSanJ36AkSZIkKUV07gxz5kD//sF8URFccgn8/vewfn242SRpe1mUkqRExGIwe3bQYrGw00iSpDRQvz783//BX/9a0vfEE8GA6IsWhZdLkraXRSlJSkRBAfzjH0ErKAg7jSRJShMZGXDNNTB5MtSuHfQtWADdusGzz4YaTZK2mUUpSUpENAp77hk0x5SSJEmV7Kij4L33oF27YH7tWjj6aPjb34Jb+yQpmfkblCQlIisLLrwwaD59T5IkhaBNG3jnHRg8uKTv2mvhd7+DVavCyyVJv8WilCRJkiSluJo14fHH4dZbg1v7AF5+Gbp2hdzcUKNJ0lZZlEonDbvDsStLWsPuYSeSJEmSVE4iERg+HKZNg0aNgr4lS6BnT3jkkXCzSdIvsSiVTqJZkFO/pEW91UhKWH4+jBoVtPz8sNNIkiTRpw/MmQP77hvMb9oEJ58M557rjyuSkotFKUlKRDwOy5YFLR4PO40kSRIALVrA9OkwbFhJ3113BQWr5cvDyyVJP5cZdgBJSmlZWcF18punJUkJycrIYvh+w4unJZVdTg7cd19wxdQ550BeHsyaBQccENzi16pV2AklpTuvlJKkRESjwSNv2rQJpiVJCYlGorRp0IY2DdoQjXhclcrDGWfAzJmw007B/Oefw/77w0cfhZtLkjzTp5OflsN/HixpP3ndriRJkpQOunYNrpLaY49g/ttv4cAD4e23w80lKb1ZlEon6z6Dd04raes+CzuRlPpiseA5y7m5wbQkKSFFsSLe+OIN3vjiDYpiRWHHkaqUFi1gxgzo1i2YX70aDjkEXnop3FyS0pdFKUlKREEB3HNP0AoKwk4jSSmvMFbIYx8+xmMfPkZhrDDsOFKV07AhvPpqUIwC2LgRBg6Exx4LN5ek9GRRSpISEY3CbrsFzTGlJClh0UiULs260KVZF8eUkipIrVowZQocd1wwX1gIf/gDjBsXbi5J6cen70lSIrKy4C9/CTuFJFUZWRlZnNX1rLBjSFVeTg48/njwVL777oN4HM47D374Aa66CiKRsBNKSgf++UmSJEmS0lBGRjACwZVXlvSNHh0UpxwqU1JlsCglSZIkSWkqEoFrr4Xbbivpu+suOPFEyM8PL5ek9GBRSpISUVAA118fNAc6l6SE5RXmcdbzZ3HW82eRV5gXdhwpbVx0ETz0UHD1FAQDnx91FGzYEG4uSVWbRSlJSkQsBl9+GTSvc5ckSSns5JPh3/+GatWC+ZdegkMPhVWrws0lqeqyKCVJicjKgnPPDVpWVthpJEmSEjJwIEydCrVrB/Nvvw0HHgjffBNuLklVk0UpSUpENArt2wct6iFVkiSlvl694M03oUmTYH7BAjjgAPjss3BzSap6/A1KkiRJklRKp07w1luwyy7B/BdfBIWpDz4IM5WkqsailCQlIhaDTz4JmmNKSZKkKmS33YLCVPv2wfyKFdC7d3AVlSSVh8ywA6gS1WgJHa8vPS8pMQUFcPvtwfTYsZCTE2ocSZKk8tSsWVCEOuIImDUL1q6F/v3hiSfgyCPDTicp1VmUSic1WkC7EWGnkKqWaBR22qlkWpIkqYqpVw+mTYPjj4cXXoC8PDjmGJgwAU45Jex0klKZRSlJSkRWFvztb2GnkCRJqlDVq8PkyXD66fDoo1BUBKeeCqtXw4UXhhxOUsoK9c/606dPZ+DAgTRv3pxIJMLkyZNLLR81ahR77LEHNWrUoF69ehxyyCHMnj37F9eVl5dHp06diEQi5Obmllo2f/58evXqRbVq1WjRogU333xzBW2RJEmSJFVNWVnw0ENw3nklfRddBCNHQjweXi5JqSvUotSGDRvo2LEjd9111y8ub9OmDePGjePDDz9k5syZtGrVin79+vH9999v8dq//OUvNG/efIv+tWvX0q9fP1q2bMmcOXO45ZZbGDVqFOPHjy/37ZEkSZKkqiwahTvugFGjSvquuSYoVPnMF0nbK9Tb9wYMGMCAAQO2unzo0KGl5m+77TYmTJjA/Pnz6du3b3H/iy++yNSpU3n66ad58cUXS33NxIkTyc/P5x//+AfZ2dm0a9eO3NxcbrvtNoYNG1a+GyQp/RQUBAOcA5x/fvAnREmSpCosEoGrroK6dUtu3bvrruBWvgcf9MchSdsuZcaUys/PZ/z48dSpU4eOHTsW9y9fvpwzzzyTyZMnU7169S2+7u233+bAAw8kOzu7uK9///7cdNNNrF69mnr16v3i++Xl5ZGXl1c8v3btWgBisRix7fwTQCwWIx6Pb/fXba/ffJ/v3yLy+iHFs/E+r0Cj/ctn3dupsvaJUlNKfT4KC4ksXAhAvLAQMjJCjZNS+64MUmn7ki1rWHmS5hyYZOtOts9HMonFYsSJF0+n2z7ys1F2VX3fJeP2nXce1KkDf/xjhKKiCP/6F6xZE+eJJ+Lk5CRP3nQ+B25etnk6GX6XTcbPssrftn5/k74oNWXKFH7/+9+zceNGmjVrxrRp02jYsCEA8XicU089lT/96U907dqVL774Youv/+6779hll11K9TVp0qR42daKUjfccAOjR4/eov/7779n06ZN27UNsViMH3/8kXg8TrQCn871W++TtWYVDWL5xfOrVq+iIL6iXNZd3lmV3lLq8xGLkXnssQAUrl4d+hP4UmrflUEqbV+yZQ0rT7KcA5Nt3cn2+UgmsXiMY1sFx9XVK1cTjaTX/vGzUXZVfd8l6/YddhhMmJDDWWfVJS8vwgsvRDjkkAL++c+VxONrkiJvOp8DCzcVkpcfXGyxYsUKMqttXwnAc6DKat26ddv0uqQvSvXp04fc3Fx++OEH7r//fgYPHszs2bNp3Lgxd955J+vWrWPEiBHl/r4jRozg4osvLp5fu3YtLVq0oFGjRtSuXXu71hWLxYhEIjRq1KjCD0a/+j6R0gW4evXqQaPG5bPu8s6qtJZyn4+mTcNOUCzl9t12SqXtS7asYeVJmnNgkq072T4fyaZpk+Q5rlY2PxtlV9X3XTJv30knwU47xTn6aFi/PsI772QzZEhTHn44SuPGDULPm87nwMJNheRk5wDQuHHjMhWlPAeqLKpVq7ZNr0v6olSNGjVo3bo1rVu3pkePHuy+++5MmDCBESNG8Nprr/H222+Tk5NT6mu6du3KH/7wBx566CGaNm3K8uXLSy3fPN/0V36RzMnJ2WK9ANFotEz/cSKRSJm/ttze53/+0hiNRLfrqo7y3obK2idKTX4+yq6q77tU2r5kyxpWnqQ4BybhupPt86Hk4Wej7Kr6vkvm7evbF15/PbhyauVKyM2NMGhQA155JUqrVuHnTddzYDQaJRKJFE8ny++yyfxZVvnY1u9tyn0CYrFY8VhPY8eOZd68eeTm5pKbm8sLL7wAwKRJk7juuusA6NmzJ9OnT6egoKB4HdOmTaNt27ZbvXVPkrZZLAaLFwfN++IlKWGxeIw5385hzrdziMU9rkqppGtXmDEDdtopmF+8OJNevSJ8+mm4uSQlr1CLUuvXry8uKAEsWbKE3NxcvvrqKzZs2MAVV1zBO++8w5dffsmcOXM4/fTT+eabbzj++OMB2Hnnndl7772LW5s2bQDYbbfd2Om/R8KhQ4eSnZ3NGWecwYIFC5g0aRJ33HFHqVvzJKnMCgrg5puD9rPitySpbAqKChg/Zzzj54ynoMjjqpRq9twTZs6E3XcPBtf++usIvXrBnDkhB5OUlEK9fe/999+nT58+xfObC0WnnHIK9957L59++ikPPfQQP/zwAw0aNKBbt27MmDGDdu3abfN71KlTh6lTp3LOOeewzz770LBhQ0aOHMmwYcPKfXskpaFIBBo3LpmWJCUkGonSpkGb4mlJqadlS3jzzTj9+hXy0UdZ/PAD9OkDzz8PBx0UdjpJySTUolTv3r2LH0/5S5555pntWl+rVq1+cX0dOnRgxowZ251Pkn5TdjZcc03YKSSpysjKyGL4fsPDjiEpQU2awNNPr+KMMxozc2aEdeugf3948kkYODDsdJKShX9+kiRJkiSVu9q147z4YpwBA4L5vDwYNAgefTTcXJKSh0UpSZIkSVKFqF4dJk+GIUOC+aIiOOkkuPPOUGNJShIWpSQpEQUFwU9Vd97pQOeSVA7yCvMY/vJwhr88nLzCvLDjSCoH2dnB1VFnn13Sd/75cPXV8CujuUhKA6GOKSVJKS8Wg48+KpmWJCVsff76sCNIKmfRKNx1F9SvD9ddF/RddRWsXAl//3uwXFL6sSiVTjJyoEbL0vOSEpOZCaecUjItSZKkXxSJwLXXBoWp4f99nsHYsbB2LTzwAGRkhJtPUuXzN6h00qAbHPVF2CmkqiUjA/bbL+wUkiRJKePii6FePfjjH4MLzR98EDZsCG7xy84OO52kyuRFkpIkSZKkSnXaaTBpEmRlBfNPPhk8me+nn8LNJalyWZSSpETEYrB0adAcU0qSJGmbHXccPPssVKsWzL/wAvzud7BuXbi5JFUei1KSlIiCgmBwhGuv9el7kiRJ22nAAHjxRahZM5h//XU49FBYvTrcXJIqh0UpSUpEJAJ16wYtEgk7jSRJUsrp3RteeSUYZwpg9mzo0wdWrAg1lqRK4EDn6WTdYlh4R8l82wug1m7h5ZGqguxsuOmmsFNIkiSltO7d4Y03gqukVqyAefPgwAODYtVOO4WdTlJF8UqpdPLTMlh0Z0n7aVnYiSRJkiQJgA4dYPr0kiLUwoXQqxcsXhxuLkkVx6KUJEmSJCkptG0LM2bAbv+9oeOLL4LC1McfhxpLUgWxKCVJiSgogPvuC5oDnUuSJCWsVaugMNWuXTC/bBkcdBDMnRtqLEkVwKKUJCUiFgt+Qpo7N5iWJElSwpo1C8aY6tIlmP/hBzj4YJg1K9RYksqZA51LUiIyM2HIkJJpSVJCMqOZDGk/pHhaUvpq2BBeew1+9zt46y348cdgIPRnn4VDDgk7naTy4JVSkpSIjIzgOca9ewfTkqSEZEQz6N2qN71b9SYj6nFVSnd16sDLLwfFKICNG4Mi1fPPh5tLUvmwKCVJkiRJSlo1agRFqKOOCubz8+GYY+Dxx8PNJSlxFqUkKRHxOKxYEbR4POw0kpTyYvEYi1YuYtHKRcTijtUnKZCTA08+CUOHBvOFhcH0Aw+Em0tSYixKSVIi8vPhb38LWn5+2GkkKeUVFBUwZtYYxswaQ0GRTzWVVCIrCx5+GIYNC+bjcTjzTLj99lBjSUqAo0dKUqJ22CHsBJJUZUQiEZrValY8LUk/l5EB994LNWvCbbcFfRddBOvXw5VXgocNKbVYlJKkROTk+Oc5SSpH2RnZjOo9KuwYkpJYJAK33gq1asHo0UHf3/4Gy5bBHXf4QGQplXj7niRJkiQppUQiMGpUUJza7O674Ygj4McfQ4slaTtZQ04nddtB75dKz0uSJElSiho+HBo3hjPOgIICePll2H9/mDIFWrUKO52k32JRKp1k14Pm/cNOIVUthYXw6KPB9Ikner24JCUovyif62dcD8AVva4gOyM75ESSkt1JJ0HLljBoEKxaBQsWQPfu8Oyz0KNH2Okk/Rpv35OkRBQVwdtvB62oKOw0kpTy4vE4y9YtY9m6ZcTj8bDjSEoRBx4Is2dDmzbB/IoV0KcPPPFEuLkk/TqLUpKUiIwMOPbYoGVkhJ1GkiQpbbVuHfydsE+fYH7TJjjhBLjhBrDGLSUni1KSlIjMTOjXL2jeuidJkhSq+vXhpZfgtNNK+v761ygXXliHvLzwckn6ZRal0knhBlizoKQVbgg7kSRJkiSVq+xsmDAhuEJqsyee2IHDDouwcmV4uSRtyaJUOln1Abywd0lb9UHYiaTUF4/DmjVB87pwSZKkpBCJwOWXw5NPQrVqwc9o06dH6NEDFi0KOZykYhalJCkR+flw2WVBy88PO40kSZJ+5rjj4PXX4zRqFDyQ5vPPoWdPePPNkINJAixKSVLiotGgSZIkKensuy+88MJK2rcPrphatQoOPRQefDDcXJIsSklSYnJy4J57gpaTE3YaSZIk/YKddooxfXqcAQOC+YKCYDD0K6+EWCzcbFI6syglSZIkSaryateG556Dc88t6bv+ejjhBPjpp/BySenMopQkSZIkKS1kZsKdd8LYsSWjLzz1FPTuDcuXhxpNSksWpSQpEYWF8NhjQSssDDuNJEmStsF558Hzz0PNmsH8u+9C9+7w0Ufh5pLSjUUpSUpEURG88UbQiorCTiNJkqRtdPjh8NZb0KJFMP/ll7DffvDIIxCPh5tNShcWpSQpERkZcMQRQcvICDuNJKW8jGgGR7Q5giPaHEFG1OOqpIrVoQPMng1duwbz69bBySfD738fPKVPUsWyKCVJicjMhIEDg5aZGXYaSUp5mdFMBrYdyMC2A8mMelyVVPGaNYM33wyKUZs98URQsHrllfBySenAopQkSZIkKa1Vrw4PPRQUo+rVC/q++QYOPRQuvNCn80kVxaKUJCUiHoeNG4Pm4AOSlLB4PM63677l23XfEve4KqmSHX88fPhhUIza7I47gtv7cnNDiyVVWRal0klOA9hpUEnLaRB2Iin15efDRRcFLT8/7DSSlPLyi/IZ/cZoRr8xmvwij6uSKt+OO8JLLwXFqJycoO/jj2HffeHmm322jVSeLEqlkzp7woHPlLQ6e4adSJIkaQs1s2tSM7tm2DEkpbFoFM4/H+bMgU6dgr6CArjsMjj44OBJfZIS5+iRkpSI7Gy4++5gOmqdX5ISlZOZw5j+Y8KOIUkAtGsH77wDV10VXCUVj8P06cEg6OPGwYknQiQSdkopdfkblCQlIhKBjIyg+ROJJElSlZOTAzfeCG+8AS1bBn1r1wZP6zvhBFi1KtR4UkqzKCVJkiRJ0m848ECYNw9OOqmk78knoX17eOWV8HJJqcyilCQlorAQnn46aIWFYaeRpJRXUFTAmFljGDNrDAVFBWHHkaRS6tSBhx+GJ56AevWCvm+/DZ7Wd+GF8NNPocaTUo5FqXSyej5MO6CkrZ4fdiIp9RUVwdSpQfNRLJKUsFg8xqKVi1i0chGxeCzsOJL0i44/Hj78MChGbXbHHdC1K+TmhhZLSjkWpdJJwVr4/q2SVrA27ERS6svIgH79gpaREXYaSZIkVZIdd4SXXgqKUTk5Qd/HH8O++8JNN3kRvbQtLEpJUiIyM+HYY4OW6QNNJUmS0kk0CuefD3PmQKdOQV9BAVx+Oey/f4SPP/bnQ+nXWJSSJEmSJCkB7drB7Nlw2WUlD2R+//0I/fs34K9/jbBpU7j5pGRlUUqSEhGPB2NJFRUF05IkSUpL2dlw443w1luw555BX2FhhBtuiNCpE8yYEWo8KSlZlJKkROTnw5//HLT8/LDTSJIkKWQ9e8IHH8DIkXGysoI/Wi5cCAceCGefDWsd2lcqZlFKkiRJkqRylJMDV10VZ9q0lfToUXI1/b33wl57wfPPhxhOSiIWpSQpEdnZ8Pe/By07O+w0kiRJSiJt2xYyfXqcO+6AGjWCvm++gSOPhBNOgOXLw80nhc2ilCQlIhKB6tWDtnlUS0mSJOm/MjKCJ/QtWACHHVbS/8QTwdhTDz3k0KRKXxalJEmSJEmqYC1bwgsvwCOPQIMGQd/q1XDqqdC/PyxZEmo8KRQWpSQpEYWFwaAAzz8fTEuSJElbEYnAiSfCJ5/A0KEl/dOmwd57ByNCFBWFl0+qbBalJCkRRUUwZUrQ/AlCkiRJ26BRI5g4MfgRskWLoG/jRrj44uDpffPnh5tPqiwWpSQpERkZ0Lt30DIywk4jSSkvI5pB71a96d2qNxlRj6uSqrbf/S4Ya+rcc0uGJ33vPdhnH/jb32DTpnDzSRUtM+wAqkQNu8MxK0rms+uGFkWqMjIzYciQsFNIUpWRGc1kSHuPq5LSR61acOedwY+Uf/xjcGtfYSFcey088wy8+io0bRp2SqlieKVUOolmQbVGJS2aFXYiSZIkSRKw337wwQcwciRk/fdXtY8/DopVDl2qqsqilCRJkpJGPB5nXd461uWtI+4z0iWlmZwcGD0a5s6FHXcM+t54I7iVT6qKLEpJUiLy8uDss4OWlxd2GklKeflF+Vwy9RIumXoJ+UX5YceRpFDsvTdMmhSMFAFw443Bw56lqsailCQlKhYLmiRJklRO9t8fbr65ZP7kk2HJkvDySBXBgc7TyaYVsGxqyXyzflCtcXh5pKogOxtuuqlkWpKUkJzMHO4beF/YMSQpKVx4IcycGQx4vmYNHHccvPUWVKsWdjKpfHilVDpZuwjePqmkrV0UdiIp9UUiULdu0DY/x1eSJEkqB5EI/OMf0Lp1MD93Llx0UbiZpPJkUUqSJEmSpCRVpw489VTJ1VH33guPPhpuJqm8WJSSpEQUFsLUqUHzWb2SlLCCogLue/8+7nv/PgqKCsKOI0lJoWNHuPvukvmzzoIFC8LLI5UXi1KSlIiiInj66aAVFYWdRpJSXiweY+6yucxdNpdY3IdISNJmp50Gp58eTG/cCMceC+vWhZtJSpRFKUlKREYG9OwZtIyMsNNIkiSpChs3LrhqCmDhQhg2DOLxcDNJifDpe5KUiMxMOPXUsFNIkiQpDeywQzC+1D77wNq18PjjsP/+wVP5pFTklVKSJEmSJKWI1q3hwQdL5i++OMIHH2SFlkdKhEUpSZIkSZJSyKBBMHx4MF1QEOHMM+uycmW4maSysCglSYnIy4MLLwxaXl7YaSRJkpQmbrghuHUP4JtvMjj55Agxnw+hFGNRSpIS9dNPQZMkSZIqSVYWTJoEjRoFI52/9FKEG24IOZS0nSxKSVIisrPhmmuClp0ddhpJkiSlkR13hIkT40QiQWFq5Eh49dWQQ0nbwaKUJCUiEoHGjYMWiYSdRpIkSWmmb1+49NL1AMRiMGQIfPNNyKGkbZQZdgBVoho7Q4drSs9LkiRJklLaBRdsYP78mrz0UoTvv4cTToDXXwf/ZKpkZ1EqndTYGfb+a9gppKqlqAhmzAime/WCjIxw80iSJCntRKPw8MNx9tknwtKl8NZbMGIE3Hht2MmkX+fte5KUiMJCeOyxoBUWhp1GkiRJaapBA3jyyWAAdIAxY2Dy5FAjSb/JopQkJSIahS5dghb1kCpJiYpGonRp1oUuzboQjXhclaTt0b073HZbyfywYbBhQ3h5pN/i7XuSlIisLDjrrLBTSFKVkZWRxVldPa5KUlmdcw7MnAmTJsG6dfD+HDhg/7BTSb/MPz9JkiRJklRFRCJw//3Qtm0wv3YtfPhR8GQ+KdlYlEon38+CSTVK2vezwk4kSZIkSSpntWrB00/DDjsE80uXwoEHwjvvhJtL+l8WpdJJPAZFG0ta3FK5lLD8fLjssqDl54edRpJSXl5hHmc9fxZnPX8WeYV5YceRpJTVrh3cdVfJ/Jw50LMnnHQSfPtteLmknwu1KDV9+nQGDhxI8+bNiUQiTP6fRwOMGjWKPfbYgxo1alCvXj0OOeQQZs+eXeo1Rx55JDvvvDPVqlWjWbNmnHTSSXz7P//D5s+fT69evahWrRotWrTg5ptvruhNk5Qu4nFYsyZo8XjYaSRJkqRiQ4ZAzx7BlVObPfootGkD118PmzaFl02CkItSGzZsoGPHjtz18/Ltz7Rp04Zx48bx4YcfMnPmTFq1akW/fv34/vvvi1/Tp08fnnjiCRYuXMjTTz/N4sWLOe6444qXr127ln79+tGyZUvmzJnDLbfcwqhRoxg/fnyFb5+kNJCVBX/9a9A2P39XklRm2RnZ3NrvVm7tdyvZGdlhx5GklNewYXDr3t//DvXqBX0bNsCVVwZXU02e7N9WFZ5Qn743YMAABgwYsNXlQ4cOLTV/2223MWHCBObPn0/fvn0BuOiii4qXt2zZkssvv5yjjz6agoICsrKymDhxIvn5+fzjH/8gOzubdu3akZuby2233cawYcMqZsMkpY9oFFq0CDuFJFUZkUiEWjm1fvuFkqRtFo3An/4EQ06Cq66Ce+4JBj7/z39g0CDo2xfuuCMoUkmVKWXGlMrPz2f8+PHUqVOHjh07/uJrVq1axcSJE9lvv/3I+u8VC2+//TYHHngg2dklf2nr378/CxcuZPXq1ZWSXZIkSZKksDVoAOPGQW4u9OlT0v/qq9CxI5x3HqxaFVo8paFQr5TaFlOmTOH3v/89GzdupFmzZkybNo2GDRuWes1ll13GuHHj2LhxIz169GDKlCnFy7777jt22WWXUq9v0qRJ8bJ6m69f/B95eXnk5ZUMrrl27VoAYrEYse18lmYsFiMej2/3122v33yfeKxUFTIWj23zc0HLexsqa58oNaXU56OoCDaPdde9O2RkhBonpfZdGaTS9iVb1rDyJM05MMnWnWyfj2RSGCvkyY+fBOD4vY4nM5r0P66WKz8bZVfV912qbV8y5U3nc+DmZZunN7+mXTuYNg3+/W+49NIIX3wRoagoKFg99lic0aPjnHkmRKOeA1U22/r9TfqzfJ8+fcjNzeWHH37g/vvvZ/DgwcyePZvGjRsXv+bSSy/ljDPO4Msvv2T06NGcfPLJTJkyhUgkUub3veGGGxg9evQW/d9//z2btnM0uFgsxo8//kg8HicarbiL037rfbLWrKbBz+ZXr15NQXxFuay7vLMqvaXU5yMvj9r33QfA2hYtICcn1Dgpte/KIJW2L9myhpUnWc6BybbuZPt8JJO8ojxe+vQlAA5ocAA5GeEeVyubn42yq+r7LtW2L5nypvM5sHBTIXn5wcUWK1asILNa6RLAAQfAa6/BfffVYOzYGvz0U5SVKyOce26Eu+8uYNSoH9l77zWeA7Xd1q1bt02vS/qiVI0aNWjdujWtW7emR48e7L777kyYMIERI0YUv6Zhw4Y0bNiQNm3asOeee9KiRQveeecdevbsSdOmTVm+fHmpdW6eb9q06Vbfd8SIEVx88cXF82vXrqVFixY0atSI2rVrb9c2xGIxIpEIjRo1qvCD0a++T6T0VWH16tWDRo23fF1Z1l3eWZXWUurzUVAA3boBUK1p09AHO0+pfVcGqbR9yZY1rDxJcw5MsnUn2+cjmeQV5rHDDjsA0LhRY3Iy068o5WejbKr6vku17UumvOl8DizcVEhOdnAcbdy48RZFqc2uvx7+/GcYMSLOv/4VXNzx8cdZDB7ckN/9rga3357Frrt6DtS2q1at2ja9LumLUv8rFouVuq3ul5YDxa/p2bMnV155ZfHA5wDTpk2jbdu2W711DyAnJ4ecX7jiIRqNluk/TiQSKfPXltv7REr3RSPRYJDm8lh3GVTWPlFqSpnPR04OnH9+2ClKSZl9V0aptH3JljWsPElxDkzCdSfb5yNZRKNRIkSKp9Nx//jZKLuqvu9SbfuSKW+6ngOj0WjxHUS/lWPnnWHiRDjnnODH2zlzgv7/+78deOWVOJdeGuHyy6FGjYrLq6pjW7+3oX4C1q9fT25uLrm5uQAsWbKE3NxcvvrqKzZs2MAVV1zBO++8w5dffsmcOXM4/fTT+eabbzj++OMBmD17NuPGjSM3N5cvv/yS1157jSFDhrDbbrvRs2dPIHiCX3Z2NmeccQYLFixg0qRJ3HHHHaWugpIkSZIkSbDffvDuuzBhAjRuHIxHlZcX4dproW1bePTRbR6aWPpNoRal3n//fTp37kznzp0BuPjii+ncuTMjR44kIyODTz/9lGOPPZY2bdowcOBAVq5cyYwZM2j33+dUVq9enWeeeYa+ffvStm1bzjjjDDp06MCbb75ZfJVTnTp1mDp1KkuWLGGfffZh+PDhjBw5kmHDhoW23ZIkSZIkJatoFE4/HT79NM7ZZ28gKysoTn3zDZx0EvTsCW+/HXJIVQmh3r7Xu3fv4icB/JJnnnnmV7++ffv2vPbaa7/5Ph06dGDGjBnbna/KiWbDDjuWnpeUmPx8uOaaYPpvf4Ns/19JkiSpaqhTB0aOXMf55+/AJZdE+L//C/rffTe4omrIELjxxuDWP6ksvIEznTTcFwZ9XdIa7ht2Iin1xeOwYkXQfqXILkmSJKWqNm1gyhR4+WX4741LADz2WHBL39/+BuvXh5dPqcuilCQlIisL/vKXoIX85D1JkiSpIvXrB7m5cPfd0KBB0LdpE1x7bVC4eughx5vS9rEoJUmJiEZht92C5tNDJEmSVMVlZsLZZ8Pnn8Pw4SV/l122DE49FfbdF2bODDWiUoi/QUmSJEmSpO1Sty7ceissWABHHVXSP2cO9OoFgwfDkiWhxVOKsCglSYmIxYIz75w5XqssSZKktLP77jB5Mrz6KnToUNL/5JOw555wxRWwbl1o8ZTkLEqlk/X/gTkXl7T1/wk7kZT6Cgpg/PigFRSEnUaSJEkKxcEHw9y5wY/FjRoFfXl5cMMNQeFqwgQoKgo3o5KPRal0svFbWPj3krbx27ATSakvGg1GdWzTxjGlJKkcRCNR2jRoQ5sGbYhGPK5KUirJyIAzz4TPPgueA5SdHfQvXw5//CN07QpvvhluRiWXzLADSFJKy8oKRniUJJWLrIwshu/ncVWSUlmdOnDTTXDWWUFx6umng/7cXDj44CgHH1yPYcPgyCNhhx1CjaqQ+ecnSZIkSZJU7nbdFZ56Ct54Azp3Lul/7bUcfv/7KE2aBE/smzbNW/vSlUUpSZIkSZJUYQ46CN57LxhXaqed4sX969bBQw9Bv36w005w4YXB6+Lxra9LVYtFKUlKREEBXHNN0BzoXJISlleYx/CXhzP85eHkFeaFHUeSVE4yMuD00+E//4nzxBOrOPXUOLVrlyz/7ju44w7Yd19o2xZGjQrGplLVZlFKkhIRi8HXXwctFgs7jSRVCevz17M+f33YMSRJFSAjA3r1ymfChDjLlwe39w0aVDIoOgTFqNGjg2cJ7bsv3H57ULRS1eNA55KUiKys4DrjzdOSpIRkZ2RzVe+riqclSVVXtWpw7LFBW7MmGBB94sRgDKrNt/C9917Qhg+Hvn3hD38Iilg/v8pKqcsrpSQpEdEo7Lln0KIeUiUpUZFIhOa1mtO8VnMikUjYcSRJlaRuXTjjDHjtNfjqK7j11tKDo8diwYDop54KTZrA4MHw8suOP5Xq/A1KkiRJkiQljZ12Cq6MmjsXPv4YrrwSdtmlZPmmTfDkk3DYYdCnD8yeHV5WJcailCQlIhaDDz8MmmNKSVLCCmOFPL/weZ5f+DyFscKw40iSQrbnnnDttbB4McyaBeecAw0blix/803o0QOOPx4WLQovp8rGopQkJaKgAMaNC5pP35OkhBXFipiyaApTFk2hKFYUdhxJUpKIRKBnz+DH7m+/hUmTYPfdS5Y/9RTstRf8+c+wfHl4ObV9LEpJUiKiUWjZMmiOKSVJkiRVuKysYEypBQvg7ruDMaYAiorgnntgt93gqqtg3bpwc+q3+RtUOqmzFxw0paTV2SvsRFLqy8qCK64Imk/fkyRJkipNVhacfTZ8/jmMHg01awb9GzbA1VdD69Zw112Qnx9uTm2dRal0klMfdvxdScupH3YiSZIkSZISUrMmjBwZFKfOOQcyM4P+FSvg3HOD2/qeeMIn9SUji1KSJEmSJCnlNWkSjDn1ySfB7X2bLV4MJ5wA++4Lr78eXj5tyaKUJCWioABuvjloDnQuSZIkha5162Ag9HffhT59Svrffx8OPhgOPxzmzw8vn0pYlJKkRMRiwZ9eFi8OpiVJkiQlhW7d4NVX4cUXoUOHkv4XX4ROneCUU+Crr0KLJyxKpZfCjbB2YUkr3Bh2Iin1bR5d8eyzHehckiRJSjKRCBx2GMydCw8/DDvvHPTH48F8mzZw+eWwaVO4OdOVRal0smouTNmjpK2aG3YiKfVFo8GfWTp1CqYlSZIkJZ2MDDjpJFi4EG69FerVC/rz8uCmm4Lxpj76KNyM6cjfoCRJkiRJUlqoVg2GD4f//Acuuwyys4P+Dz+Erl3hjjsclaMyWZSSpETEYrBoUdA8e0mSJEkpoW5duPHGYPDzvfcO+vLy4MILg4HQly0LM136sCglSYkoKIAxY4Lm0/ckSZKklNK+Pbz3XlCM2uzll4P+yZPDSpU+LEpJUiIiEWjWLGiRSNhpJCnlRSIRmtVqRrNazYh4XJUkVYJq1eDvfw+KUc2aBX0rV8KgQTBsGGzYEG6+qiwz7ACSlNKys2HUqLBTSFKVkZ2Rzajeo8KOIUlKQ/36wfz5QSHq3/8O+u6/H954AyZOhG7dQo1XJXmllCRJkiRJEtCwITz9NDzwANSoEfR99hnstx9cdx0UFYWbr6qxKCVJkiRJkvRfkQiccQZ88AHsu2/QV1gIf/0r9O4NX3wRZrqqxaKUJCWioABuvz1oDnQuSQnLL8pn1BujGPXGKPKL8sOOI0lKY7vvDjNnwt/+BtH/Vk9mzoSOHeHRRyEeDzdfVWBRSpISEYvBJ58ELRYLO40kpbx4PM6ydctYtm4ZcX/alySFLCsLrr4apk+HVq2CvrVr4aSTYOhQWLMmzHSpz4HOJSkRWVlw+ukl05KkhGRlZDF8v+HF05IkJYP994d58+C88+Dhh4O+xx+Ht96CRx6Bgw4KN1+q8kopSUpENArduwct6iFVkhIVjURp06ANbRq0IRrxuCpJSh61a8NDD8GkSVC3btC3dCn06QOXXw753nW+3TzTp5Oc+rDjwJKWUz/sRJIkSZIkpZTBg2H+/GDQcwjGlrrpJujZExYtCjVayrEolU7q7AUHPVfS6uwVdiIp9cViweM3vvjCMaUkqRwUxYp444s3eOOLNyiK+dxtSVJyatECXn0Vbr65ZBSPuXOhSxd48EEHQd9WFqUkKREFBXDDDUHz6XuSlLDCWCGPffgYj334GIWxwrDjSJK0VdEoXHopzJ4NbdsGfRs2wGmnwR/+AD/+GG6+VGBRSpISEYlAgwZBi0TCTiNJkiSpknXuDHPmwBlnlPQ99ljQ/8474eVKBRalJCkR2dlw/fVBy84OO40kSZKkENSoAQ88EAyCXqdO0LdkCRxwQHBTRZF3pP8ii1KSJEmSJEnlYPBgyM0NBj2HoBh1xRXQrx98+22o0ZKSRal0suZDeKV3SVvzYciBJEmSJEmqWlq1gunT4W9/Kxnh47XXoEMHeP75UKMlHYtS6ST/R1jxZknLd9Q1KWEFBXD33UFzoHNJkiRJQGYmXH11UIzaccegb+VKOPJIOP982LQp3HzJwqKUJCUiFoN584IWi4WdRpIkSVIS6d07+FXh6KNL+u68E7p3h08+CStV8rAoJUmJyMyEE08MWmZm2GkkSZIkJZkGDeCZZ4KbK6pVC/rmz4d99oH774d4PNx8YbIoJUmJyMiAXr2ClpERdhpJkiRJSSgSgbPPhvfeg3btgr6ffoJhw4LB0VevDjdfWCxKSZIkSZIkVYK994Z334U//amk76mnoFMneOut0GKFxqKUJCUiHg+e7frtt+l93a0kSZKkbVK9OtxzT3BLX716Qd9XX8GBBwaDoxcVhZuvMlmUkqRE5OfD6NFBy88PO40kSZKkFDFoUDAI+oEHBvOxGFx1FRx8MCxdGm62ymJRSpISVbNm0CRJ5aJmdk1qZntclSRVfS1awGuvBVdIRf9boZk+HV5+OdxclcVHRUlSInJyYMyYsFNIUpWRk5nDmP4eVyVJ6SMjA/72t+AKqaFDoVs3OOOMsFNVDotSkiRJkiRJIdt/f8jNDZ7UF4mEnaZyWJSSJEmSJElKApsHPk8XFqUkKREFBfDww8H0ySdDVla4eSQpxRUUFTB29lgAzu9+PlkZHlclSaqqLEqlkwb7wqBvS+azG4SXRaoqYjF4991g+sQTw80iSVVALB5j0cpFxdOSJKnqsiiVTjKyYYdmYaeQqpbMTBg8uGRakpSQrIwshu0zrHhakiRVXf4GJUmJyMiAvn3DTiFJVUY0EmWf5vuEHUOSJFWCaNgBJEmSJEmSlH68UkqSEhGPw6pVwXT9+unz7FZJqiCxeIwPln0AQOdmnYlG/BuqJElVlUWpdLLpe/julZL5podAtUbh5ZGqgvx8uOKKYHrsWMjJCTePJKW4gqICxs8ZD8DYAWPJyfS4KklSVWVRKp2sXQizhpbMHzLDopRUHrKzw04gSZIkSSnHopQkJSInB+68M+wUkiRJkpRyvElfkiRJkiRJlc6ilCRJkiRJkiqdt+9JUiIKC+Gxx4LpIUMg08OqJEmSJG0Lr5SSpEQUFcHMmUErKgo7jSRJkiSlDP+kL0mJyMiAo44qmZYkSZIkbROLUpKUiMxMOPzwsFNIkiRJUsrx9j1JkiRJkiRVOq+UkqRExOOwfn0wXbMmRCLh5pEkSZKkFGFRSpISkZ8Pl1wSTI8dCzk54eaRJEmSpBRhUWobxeNxANauXbvdXxuLxVi3bh3VqlUjGq24OyZ/833WbYCN/zNfbdu2p7y3obL2iVJTSn0+8vKCwhTA2rWhF6VSat+VQSptX7JlDStP0pwDk2zdyfb5SCZ5hXnkbwyOq2vXriUnM72K/X42yq6q77tU275kypvO58DCTYVsLAh+CVy7di2Z+dtXAvAcqLLaXDvZXEvZmkj8t14hAL7++mtatGgRdgxJkiRJkqSUsHTpUnbaaaetLrcotY1isRjffvsttWrVIlKGMWO6devGe++9VwHJKu99ynPda9eupUWLFixdupTatWuXyzpVtVTW/5mqqKrvu1TavmTLGlYez4Fb8jyoX5Nsx45UUtX3XaptXzLl9RyYPOv2HJge4vE469ato3nz5r96RZy3722jaDT6q9W935KRkVEp/+Eq8n0qYt21a9f2QKRfVFn/Z6qiqr7vUmn7ki1rWHk8B26d50H9kmQ7dqSSqr7vUm37kimv58DkW7fnwKqvTp06v/kab+CsJOecc07Kv09lbYMEft4SUdX3XSptX7JlDSuP50Bp+/h5K7uqvu9SbfuSKa/nwORct+TtewrF2rVrqVOnDj/++KPVcUlS2vE8KElKV54D9XNeKaVQ5OTkcNVVV5ET8pPKJEkKg+dBSVK68hyon/NKKUmSJEmSJFU6r5SSJEmSJElSpbMoJUmSJEmSpEpnUUqSJEmSJEmVzqKUJEmSJEmSKp1FKaWEJUuW0KdPH/baay/at2/Phg0bwo4kSVKlaNWqFR06dKBTp0706dMn7DiSJFWqjRs30rJlSy655JKwo6gCZIYdQNoWp556Ktdeey29evVi1apVPj5UkpRWZs2aRc2aNcOOIUlSpbvuuuvo0aNH2DFUQbxSSklvwYIFZGVl0atXLwDq169PZqb1VEmSJEmqyj777DM+/fRTBgwYEHYUVRCLUkrY9OnTGThwIM2bNycSiTB58uQtXnPXXXfRqlUrqlWrRvfu3Xn33Xe3ef2fffYZNWvWZODAgXTp0oXrr7++HNNLklR2FX0OBIhEIhx00EF069aNiRMnllNySZISUxnnwEsuuYQbbrihnBIrGXm5iRK2YcMGOnbsyOmnn84xxxyzxfJJkyZx8cUXc++999K9e3duv/12+vfvz8KFC2ncuDEAnTp1orCwcIuvnTp1KoWFhcyYMYPc3FwaN27MYYcdRrdu3Tj00EMrfNskSfo1FX0ObN68OTNnzmTHHXdk2bJlHHLIIbRv354OHTpU+LZJkvRrKvoc+N5779GmTRvatGnDrFmzKnx7FI5IPB6Phx1CVUckEuHf//43Rx99dHFf9+7d6datG+PGjQMgFovRokULzjvvPC6//PLfXOfbb7/NqFGjePnllwG45ZZbALj00kvLfwMkSSqjijgH/q9LL72Udu3aceqpp5ZTakmSElcR58ARI0bw6KOPkpGRwfr16ykoKGD48OGMHDmyojZDIfD2PVWo/Px85syZwyGHHFLcF41GOeSQQ3j77be3aR3dunVjxYoVrF69mlgsxvTp09lzzz0rKrIkSeWiPM6BGzZsYN26dQCsX7+e1157jXbt2lVIXkmSykt5nANvuOEGli5dyhdffMGtt97KmWeeaUGqCvL2PVWoH374gaKiIpo0aVKqv0mTJnz66afbtI7MzEyuv/56DjzwQOLxOP369eOII46oiLiSJJWb8jgHLl++nEGDBgFQVFTEmWeeSbdu3co9qyRJ5ak8zoFKDxallBIGDBjgExckSWln1113Zd68eWHHkCQpVN62XnV5+54qVMOGDcnIyGD58uWl+pcvX07Tpk1DSiVJUsXzHChJSleeA7WtLEqpQmVnZ7PPPvvw6quvFvfFYjFeffVVevbsGWIySZIqludASVK68hyobeXte0rY+vXr+fzzz4vnlyxZQm5uLvXr12fnnXfm4osv5pRTTqFr167su+++3H777WzYsIHTTjstxNSSJCXOc6AkKV15DlR5iMTj8XjYIZTa3njjDfr06bNF/ymnnMKDDz4IwLhx47jlllv47rvv6NSpE2PHjqV79+6VnFSSpPLlOVCSlK48B6o8WJSSJEmSJElSpXNMKUmSJEmSJFU6i1KSJEmSJEmqdBalJEmSJEmSVOksSkmSJEmSJKnSWZSSJEmSJElSpbMoJUmSJEmSpEpnUUqSJEmSJEmVzqKUJEmSJEmSKp1FKUmSJEmSJFU6i1KSJClttWrVittvvz3sGKHIz8+ndevWzJo1K+woFW57v8/33nsvAwcOrLhAkiQJsCglSZIq2KmnnsrRRx8ddoxf9N577zFs2LAKf59WrVoRiUSIRCJUr16d9u3b88ADD2z3eiKRCJMnTy6XTPfeey+77LIL++23X4Wsf1stWbKEoUOH0rx5c6pVq8ZOO+3EUUcdxaefflqpOX7u9NNPZ+7cucyYMSO0DJIkpQOLUpIkqcopKCjYptc1atSI6tWrV3CawNVXX82yZcv46KOPOPHEEznzzDN58cUXK+W9/1c8HmfcuHGcccYZobz/ZgUFBRx66KH8+OOPPPPMMyxcuJBJkybRvn171qxZE1qu7Oxshg4dytixY0PLIElSOrAoJUmSQvXRRx8xYMAAatasSZMmTTjppJP44Ycfipe/9NJLHHDAAdStW5cGDRpwxBFHsHjx4uLlX3zxBZFIhEmTJnHQQQdRrVo1Jk6cWHyF1q233kqzZs1o0KAB55xzTqmC1f/e1hWJRHjggQcYNGgQ1atXZ/fdd+e5554rlfe5555j9913p1q1avTp04eHHnqISCTym0WUWrVq0bRpU3bddVcuu+wy6tevz7Rp04qXv/feexx66KE0bNiQOnXqcNBBBzF37txSWQEGDRpEJBIpngd49tln6dKlC9WqVWPXXXdl9OjRFBYWbjXLnDlzWLx4Mb/73e9+NfPPxWIxrr76anbaaSdycnLo1KkTL730UqnXzJo1i06dOlGtWjW6du3K5MmTiUQi5Obm/uI6FyxYwOLFi7n77rvp0aMHLVu2ZP/99+faa6+lR48exa/7+uuvGTJkCPXr16dGjRp07dqV2bNnA7B48WKOOuoomjRpQs2aNenWrRuvvPLKr27LmjVr+OMf/0ijRo2oXbs2Bx98MPPmzSv1moEDB/Lcc8/x008/bfM+kiRJ28eilCRJCs2aNWs4+OCD6dy5M++//z4vvfQSy5cvZ/DgwcWv2bBhAxdffDHvv/8+r776KtFolEGDBhGLxUqt6/LLL+eCCy7gk08+oX///gC8/vrrLF68mNdff52HHnqIBx98kAcffPBXM40ePZrBgwczf/58Dj/8cP7whz+watUqILjV7LjjjuPoo49m3rx5nHXWWVx55ZXbtc2xWIynn36a1atXk52dXdy/bt06TjnlFGbOnMk777zD7rvvzuGHH866deuAoGgF8M9//pNly5YVz8+YMYOTTz6ZCy64gI8//pj77ruPBx98kOuuu26rGWbMmEGbNm2oVavWNue+4447GDNmDLfeeivz58+nf//+HHnkkXz22WcArF27loEDB9K+fXvmzp3LNddcw2WXXfar62zUqBHRaJSnnnqKoqKiX3zN+vXrOeigg/jmm2947rnnmDdvHn/5y1+Kv//r16/n8MMP59VXX+WDDz7gsMMOY+DAgXz11Vdbfd/jjz+eFStW8OKLLzJnzhy6dOlC3759i7/PAF27dqWwsLC4+CVJkipAXJIkqQKdcsop8aOOOuoXl11zzTXxfv36lepbunRpHIgvXLjwF7/m+++/jwPxDz/8MB6Px+NLliyJA/Hbb799i/dt2bJlvLCwsLjv+OOPj59wwgnF8y1btoz//e9/L54H4n/961+L59evXx8H4i+++GI8Ho/HL7vssvjee+9d6n2uvPLKOBBfvXr1L++A/75PdnZ2vEaNGvHMzMw4EK9fv378s88+2+rXFBUVxWvVqhV//vnnS+X797//Xep1ffv2jV9//fWl+h555JF4s2bNtrruCy64IH7wwQdv0f9L69+sefPm8euuu65UX7du3eJ//vOf4/F4PH7PPffEGzRoEP/pp5+Kl99///1xIP7BBx9sNcu4cePi1atXj9eqVSvep0+f+NVXXx1fvHhx8fL77rsvXqtWrfjKlSu3uo7/1a5du/idd95ZPP/z7/OMGTPitWvXjm/atKnU1+y2227x++67r1RfvXr14g8++OA2v68kSdo+XiklSZJCM2/ePF5//XVq1qxZ3PbYYw+A4lv0PvvsM4YMGcKuu+5K7dq1i29b+98rYbp27brF+tu1a0dGRkbxfLNmzVixYsWvZurQoUPxdI0aNahdu3bx1yxcuJBu3bqVev2+++67Tdt66aWXkpuby2uvvUb37t35+9//TuvWrYuXL1++nDPPPJPdd9+dOnXqULt2bdavX/+rV/xAsA+vvvrqUvvwzDPPZNmyZWzcuPEXv+ann36iWrVq25Qbgqugvv32W/bff/9S/fvvvz+ffPIJEOybDh06lFrvtuybc845h++++46JEyfSs2dPnnzySdq1a1d8a2Nubi6dO3emfv36v/j169ev55JLLmHPPfekbt261KxZk08++WSr+23evHmsX7+eBg0alNpnS5YsKXVbKMAOO+yw1X0oSZISlxl2AEmSlL7Wr1/PwIEDuemmm7ZY1qxZMyAY26dly5bcf//9NG/enFgsxt57701+fn6p19eoUWOLdWRlZZWaj0QiW9z2Vx5fsy0aNmxI69atad26NU8++STt27ena9eu7LXXXgCccsoprFy5kjvuuIOWLVuSk5NDz549t9jO/7V+/XpGjx7NMcccs8WyrRWeGjZsyIcffpjwNpWXWrVqMXDgQAYOHMi1115L//79ufbaazn00EPZYYcdfvVrL7nkEqZNm8att95K69at2WGHHTjuuOO2ut/Wr19Ps2bNeOONN7ZYVrdu3VLzq1atolGjRmXdLEmS9BssSkmSpNB06dKFp59+mlatWpGZueWPJStXrmThwoXcf//99OrVC4CZM2dWdsxibdu25YUXXijVt3lsp+3RokULTjjhBEaMGMGzzz4LwFtvvcXdd9/N4YcfDsDSpUtLDfgOQcHsf8de6tKlCwsXLix11dVv6dy5M/fccw/xeJxIJPKbr69duzbNmzfnrbfe4qCDDiruf+utt4qvhmrbti2PPvooeXl55OTkAGXbN5FIhD322INZs2YBwZVrDzzwAKtWrfrFq6XeeustTj31VAYNGgQERacvvvhiq+vv0qUL3333HZmZmaUGi/9fixcvZtOmTXTu3Hm7t0GSJG0bb9+TJEkV7scffyQ3N7dUW7p0Keeccw6rVq1iyJAhvPfeeyxevJiXX36Z0047jaKiIurVq0eDBg0YP348n3/+Oa+99hoXX3xxaNtx1lln8emnn3LZZZexaNEinnjiieKB07eluPNzF1xwAc8//zzvv/8+ALvvvjuPPPIIn3zyCbNnz+YPf/jDFlcJtWrVildffZXvvvuO1atXAzBy5EgefvhhRo8ezYIFC/jkk094/PHH+etf/7rV9+7Tpw/r169nwYIFWyxbsmTJFt+rDRs2cOmll3LTTTcxadIkFi5cyOWXX05ubi4XXHABAEOHDiUWizFs2DA++eQTXn75ZW699dZf3Te5ubkcddRRPPXUU3z88cd8/vnnTJgwgX/84x8cddRRAAwZMoSmTZty9NFH89Zbb/Gf//yHp59+mrfffrt4vz3zzDPk5uYyb9684hxbc8ghh9CzZ0+OPvpopk6dyhdffMGsWbO48sori78XEAwGv+uuu7LbbrttdV2SJCkxFqUkSVKFe+ONN+jcuXOpNnr06OKrb4qKiujXrx/t27fnwgsvpG7dukSjUaLRKI8//jhz5sxh77335qKLLuKWW24JbTt22WUXnnrqKZ555hk6dOjAPffcU/z0vc1XB22rvfbai379+jFy5EgAJkyYwOrVq+nSpQsnnXQS559/Po0bNy71NWPGjGHatGm0aNGi+Aqe/v37M2XKFKZOnUq3bt3o0aMHf//732nZsuVW37tBgwYMGjSIiRMnbrHs4osv3uJ79cEHH3D++edz8cUXM3z4cNq3b89LL73Ec889x+677w4EV1M9//zz5Obm0qlTJ6688sribdvabYQ77bQTrVq1YvTo0XTv3p0uXbpwxx13MHr06OL9mp2dzdSpU2ncuDGHH3447du358YbbyweK+y2226jXr167LfffgwcOJD+/fvTpUuXrW57JBLhhRde4MADD+S0006jTZs2/P73v+fLL7+kSZMmxa977LHHOPPMM7e6HkmSlLhIPB6Phx1CkiQpVV133XXce++9LF26NOwo22X+/PkceuihLF68mJo1a1bIe0ycOJHTTjuNH3/88TfHhkomCxYs4OCDD2bRokXUqVMn7DiSJFVZjiklSZK0He6++266detGgwYNeOutt7jllls499xzw4613Tp06MBNN93EkiVLaN++fbms8+GHH2bXXXdlxx13ZN68eVx22WUMHjw4pQpSAMuWLePhhx+2ICVJUgXzSilJkqTtcNFFFzFp0iRWrVrFzjvvzEknncSIESN+caD2dHPzzTdz9913891339GsWTOOPvporrvuOqpXrx52NEmSlIQsSkmSJEmSJKnSOdC5JEmSJEmSKp1FKUmSJEmSJFU6i1KSJEmSJEmqdBalJEmSJEmSVOksSkmSJEmSJKnSWZSSJEmSJElSpbMoJUmSJEmSpEpnUUqSJEmSJEmVzqKUJEmSJEmSKt3/A1IYHhULOWT2AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "             LR FINDER RESULTS\n",
      "=======================================================\n",
      "  \ud83d\udd34 Steepest Gradient : 0.000003  (aggressive)\n",
      "  \ud83d\udfe0 Steepest / 3      : 0.000001  (balanced) \u2605 DEFAULT\n",
      "  \ud83d\udfe3 Valley (80%)      : 0.000083  (robust)\n",
      "  \ud83d\udfe2 Min Loss / 10     : 0.000014  (conservative)\n",
      "=======================================================\n",
      "  Selected Method: 'recommended' \u2192 LR = 0.000001\n",
      "=======================================================\n",
      "\n",
      "Optimal learning rate: 0.000001\n"
     ]
    }
   ],
   "source": [
    "# LRFinder: Use global BATCH_SIZE via data generator\n",
    "# This ensures optimal LR is found for the actual training batch size (384)\n",
    "NUM_LR_STEPS = 100\n",
    "print(f\"Running LRFinder with BATCH_SIZE={BATCH_SIZE} for {NUM_LR_STEPS} steps...\")\n",
    "\n",
    "# For VAE with custom Lambda layers, save weights instead of cloning\n",
    "initial_weights = vae.model.get_weights()\n",
    "\n",
    "# VAE reconstruction loss\n",
    "def vae_r_loss(y_true, y_pred):\n",
    "    \"\"\"Reconstruction loss for VAE.\"\"\"\n",
    "    return R_LOSS_FACTOR * K.mean(K.square(y_true - y_pred), axis=[1, 2, 3])\n",
    "\n",
    "vae.model.compile(loss=vae_r_loss, optimizer=Adam(learning_rate=1e-6))\n",
    "\n",
    "# Run LRFinder with data_flow to use the global BATCH_SIZE\n",
    "# data_flow yields batches of (x, x) because class_mode='input'\n",
    "lr_finder = LRFinder(min_lr=1e-6, max_lr=1e-2, steps=NUM_LR_STEPS)\n",
    "vae.model.fit(data_flow,\n",
    "             epochs=1,\n",
    "             steps_per_epoch=NUM_LR_STEPS,\n",
    "             callbacks=[lr_finder],\n",
    "             verbose=0)\n",
    "\n",
    "# Plot and get optimal LR\n",
    "lr_finder.plot_loss()\n",
    "optimal_lr = lr_finder.get_optimal_lr()\n",
    "print(f\"\\nOptimal learning rate: {optimal_lr:.6f}\")\n",
    "\n",
    "# Update W&B config\n",
    "wandb.config.update({\"learning_rate\": optimal_lr})\n",
    "\n",
    "# Restore original weights after LRFinder\n",
    "vae.model.set_weights(initial_weights)\n",
    "tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Train the VAE with the optimal learning rate and full callback stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with optimal LR: 0.000001\n",
      "Epochs: 200, Batch size: 384\n",
      "Steps per epoch: 527\n"
     ]
    }
   ],
   "source": [
    "# Compile with optimal LR\n",
    "vae.compile(optimal_lr, R_LOSS_FACTOR)\n",
    "\n",
    "# Define extra callbacks for W&B tracking and training optimization\n",
    "extra_callbacks = [\n",
    "    WandbMetricsLogger(),\n",
    "    get_lr_scheduler(monitor='loss', patience=5, factor=0.5),\n",
    "    get_early_stopping(monitor='loss', patience=15, min_delta=1e-4),\n",
    "    LRLogger(),\n",
    "]\n",
    "\n",
    "print(f\"Training with optimal LR: {optimal_lr:.6f}\")\n",
    "print(f\"Epochs: {EPOCHS}, Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Steps per epoch: {NUM_IMAGES // BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-30 20:50:18.673134: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng28{k2=1,k3=0} for conv (f32[384,32,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[384,3,129,129]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}), window={size=3x3 stride=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "2025-12-30 20:50:18.705553: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 3.263794705s\n",
      "Trying algorithm eng28{k2=1,k3=0} for conv (f32[384,32,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[384,3,129,129]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}), window={size=3x3 stride=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m163/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m5:11\u001b[0m 857ms/step - loss: 1335.6665 - vae_r_loss: 1090.3237"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-30 20:53:09.860808: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-12-30 20:53:10.013543: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-12-30 20:53:10.172426: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-12-30 20:53:10.301971: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-12-30 20:53:10.486346: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-12-30 20:53:16.317477: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng21{k2=2,k4=1,k5=0,k6=0,k7=0} for conv (f32[64,64,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[231,64,33,33]{3,2,1,0}, f32[231,64,16,16]{3,2,1,0}), window={size=3x3 stride=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "2025-12-30 20:53:16.346900: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 3.327221672s\n",
      "Trying algorithm eng21{k2=2,k4=1,k5=0,k6=0,k7=0} for conv (f32[64,64,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[231,64,33,33]{3,2,1,0}, f32[231,64,16,16]{3,2,1,0}), window={size=3x3 stride=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917ms/step - loss: 1322.2744 - vae_r_loss: 1087.0646\n",
      "Epoch 1: saving model to run/vae/0002_faces/weights/weights-001-1307.09.weights.h5\n",
      "\n",
      "Epoch 1: finished saving model to run/vae/0002_faces/weights/weights-001-1307.09.weights.h5\n",
      "\n",
      "Epoch 1: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 1: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 1: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m528s\u001b[0m 920ms/step - loss: 1307.0924 - vae_r_loss: 1084.4130 - learning_rate: 8.3730e-07\n",
      "Epoch 2/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:14\u001b[0m 369ms/step - loss: 1281.7817 - vae_r_loss: 1079.8196\n",
      "Epoch 2: saving model to run/vae/0002_faces/weights/weights-002-1281.78.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cataluna84/Workspace-Antigravity/Generative_Deep_Learning/.venv/lib/python3.13/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: finished saving model to run/vae/0002_faces/weights/weights-002-1281.78.weights.h5\n",
      "\n",
      "Epoch 2: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 2: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 2: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1281.7817 - vae_r_loss: 1079.8196 - learning_rate: 8.3730e-07\n",
      "Epoch 3/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864ms/step - loss: 1275.2747 - vae_r_loss: 1078.7299\n",
      "Epoch 3: saving model to run/vae/0002_faces/weights/weights-003-1269.87.weights.h5\n",
      "\n",
      "Epoch 3: finished saving model to run/vae/0002_faces/weights/weights-003-1269.87.weights.h5\n",
      "\n",
      "Epoch 3: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 3: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 3: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 867ms/step - loss: 1269.8735 - vae_r_loss: 1077.7412 - learning_rate: 8.3730e-07\n",
      "Epoch 4/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m2:59\u001b[0m 341ms/step - loss: 1256.6418 - vae_r_loss: 1071.5573\n",
      "Epoch 4: saving model to run/vae/0002_faces/weights/weights-004-1256.64.weights.h5\n",
      "\n",
      "Epoch 4: finished saving model to run/vae/0002_faces/weights/weights-004-1256.64.weights.h5\n",
      "\n",
      "Epoch 4: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 4: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 4: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1256.6418 - vae_r_loss: 1071.5573 - learning_rate: 8.3730e-07\n",
      "Epoch 5/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842ms/step - loss: 1254.2382 - vae_r_loss: 1072.6105\n",
      "Epoch 5: saving model to run/vae/0002_faces/weights/weights-005-1250.99.weights.h5\n",
      "\n",
      "Epoch 5: finished saving model to run/vae/0002_faces/weights/weights-005-1250.99.weights.h5\n",
      "\n",
      "Epoch 5: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 5: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 5: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 846ms/step - loss: 1250.9910 - vae_r_loss: 1070.3422 - learning_rate: 8.3730e-07\n",
      "Epoch 6/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:35\u001b[0m 410ms/step - loss: 1223.5623 - vae_r_loss: 1047.7053\n",
      "Epoch 6: saving model to run/vae/0002_faces/weights/weights-006-1223.56.weights.h5\n",
      "\n",
      "Epoch 6: finished saving model to run/vae/0002_faces/weights/weights-006-1223.56.weights.h5\n",
      "\n",
      "Epoch 6: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 6: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 6: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1223.5623 - vae_r_loss: 1047.7052 - learning_rate: 8.3730e-07\n",
      "Epoch 7/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814ms/step - loss: 1236.8403 - vae_r_loss: 1064.5648\n",
      "Epoch 7: saving model to run/vae/0002_faces/weights/weights-007-1233.83.weights.h5\n",
      "\n",
      "Epoch 7: finished saving model to run/vae/0002_faces/weights/weights-007-1233.83.weights.h5\n",
      "\n",
      "Epoch 7: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 7: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 7: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 817ms/step - loss: 1233.8291 - vae_r_loss: 1063.0018 - learning_rate: 8.3730e-07\n",
      "Epoch 8/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:01\u001b[0m 345ms/step - loss: 1238.7190 - vae_r_loss: 1070.9404\n",
      "Epoch 8: saving model to run/vae/0002_faces/weights/weights-008-1238.72.weights.h5\n",
      "\n",
      "Epoch 8: finished saving model to run/vae/0002_faces/weights/weights-008-1238.72.weights.h5\n",
      "\n",
      "Epoch 8: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 8: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 8: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1238.7190 - vae_r_loss: 1070.9403 - learning_rate: 8.3730e-07\n",
      "Epoch 9/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875ms/step - loss: 1224.8180 - vae_r_loss: 1058.2332\n",
      "Epoch 9: saving model to run/vae/0002_faces/weights/weights-009-1220.91.weights.h5\n",
      "\n",
      "Epoch 9: finished saving model to run/vae/0002_faces/weights/weights-009-1220.91.weights.h5\n",
      "\n",
      "Epoch 9: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 9: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 9: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 878ms/step - loss: 1220.9070 - vae_r_loss: 1055.2885 - learning_rate: 8.3730e-07\n",
      "Epoch 10/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:38\u001b[0m 416ms/step - loss: 1212.5463 - vae_r_loss: 1050.2012\n",
      "Epoch 10: saving model to run/vae/0002_faces/weights/weights-010-1212.55.weights.h5\n",
      "\n",
      "Epoch 10: finished saving model to run/vae/0002_faces/weights/weights-010-1212.55.weights.h5\n",
      "\n",
      "Epoch 10: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 10: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 10: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1212.5463 - vae_r_loss: 1050.2012 - learning_rate: 8.3730e-07\n",
      "Epoch 11/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853ms/step - loss: 1210.7805 - vae_r_loss: 1048.3692\n",
      "Epoch 11: saving model to run/vae/0002_faces/weights/weights-011-1207.30.weights.h5\n",
      "\n",
      "Epoch 11: finished saving model to run/vae/0002_faces/weights/weights-011-1207.30.weights.h5\n",
      "\n",
      "Epoch 11: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 11: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 11: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m452s\u001b[0m 856ms/step - loss: 1207.3019 - vae_r_loss: 1045.4664 - learning_rate: 8.3730e-07\n",
      "Epoch 12/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m2:58\u001b[0m 339ms/step - loss: 1204.0256 - vae_r_loss: 1043.4110\n",
      "Epoch 12: saving model to run/vae/0002_faces/weights/weights-012-1204.03.weights.h5\n",
      "\n",
      "Epoch 12: finished saving model to run/vae/0002_faces/weights/weights-012-1204.03.weights.h5\n",
      "\n",
      "Epoch 12: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 12: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 12: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1204.0256 - vae_r_loss: 1043.4110 - learning_rate: 8.3730e-07\n",
      "Epoch 13/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846ms/step - loss: 1194.6546 - vae_r_loss: 1034.3623\n",
      "Epoch 13: saving model to run/vae/0002_faces/weights/weights-013-1189.13.weights.h5\n",
      "\n",
      "Epoch 13: finished saving model to run/vae/0002_faces/weights/weights-013-1189.13.weights.h5\n",
      "\n",
      "Epoch 13: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 13: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 13: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 849ms/step - loss: 1189.1300 - vae_r_loss: 1028.8031 - learning_rate: 8.3730e-07\n",
      "Epoch 14/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m4:00\u001b[0m 458ms/step - loss: 1137.5984 - vae_r_loss: 977.9126\n",
      "Epoch 14: saving model to run/vae/0002_faces/weights/weights-014-1137.60.weights.h5\n",
      "\n",
      "Epoch 14: finished saving model to run/vae/0002_faces/weights/weights-014-1137.60.weights.h5\n",
      "\n",
      "Epoch 14: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 14: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 14: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1137.5984 - vae_r_loss: 977.9126 - learning_rate: 8.3730e-07\n",
      "Epoch 15/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - loss: 1168.1696 - vae_r_loss: 1005.9293\n",
      "Epoch 15: saving model to run/vae/0002_faces/weights/weights-015-1158.28.weights.h5\n",
      "\n",
      "Epoch 15: finished saving model to run/vae/0002_faces/weights/weights-015-1158.28.weights.h5\n",
      "\n",
      "Epoch 15: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 15: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 15: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 831ms/step - loss: 1158.2837 - vae_r_loss: 995.2287 - learning_rate: 8.3730e-07\n",
      "Epoch 16/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:22\u001b[0m 385ms/step - loss: 1134.8887 - vae_r_loss: 970.6859\n",
      "Epoch 16: saving model to run/vae/0002_faces/weights/weights-016-1134.89.weights.h5\n",
      "\n",
      "Epoch 16: finished saving model to run/vae/0002_faces/weights/weights-016-1134.89.weights.h5\n",
      "\n",
      "Epoch 16: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 16: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 16: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1134.8887 - vae_r_loss: 970.6859 - learning_rate: 8.3730e-07\n",
      "Epoch 17/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832ms/step - loss: 1130.2437 - vae_r_loss: 965.2986\n",
      "Epoch 17: saving model to run/vae/0002_faces/weights/weights-017-1119.59.weights.h5\n",
      "\n",
      "Epoch 17: finished saving model to run/vae/0002_faces/weights/weights-017-1119.59.weights.h5\n",
      "\n",
      "Epoch 17: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 17: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 17: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 842ms/step - loss: 1119.5912 - vae_r_loss: 954.8312 - learning_rate: 8.3730e-07\n",
      "Epoch 18/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m5:17\u001b[0m 604ms/step - loss: 1097.4097 - vae_r_loss: 933.9415\n",
      "Epoch 18: saving model to run/vae/0002_faces/weights/weights-018-1097.41.weights.h5\n",
      "\n",
      "Epoch 18: finished saving model to run/vae/0002_faces/weights/weights-018-1097.41.weights.h5\n",
      "\n",
      "Epoch 18: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 18: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 18: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1097.4097 - vae_r_loss: 933.9415 - learning_rate: 8.3730e-07\n",
      "Epoch 19/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855ms/step - loss: 1092.0708 - vae_r_loss: 929.3772\n",
      "Epoch 19: saving model to run/vae/0002_faces/weights/weights-019-1082.53.weights.h5\n",
      "\n",
      "Epoch 19: finished saving model to run/vae/0002_faces/weights/weights-019-1082.53.weights.h5\n",
      "\n",
      "Epoch 19: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 19: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 19: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 858ms/step - loss: 1082.5293 - vae_r_loss: 920.9877 - learning_rate: 8.3730e-07\n",
      "Epoch 20/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m5:19\u001b[0m 608ms/step - loss: 1054.6050 - vae_r_loss: 894.4006\n",
      "Epoch 20: saving model to run/vae/0002_faces/weights/weights-020-1054.60.weights.h5\n",
      "\n",
      "Epoch 20: finished saving model to run/vae/0002_faces/weights/weights-020-1054.60.weights.h5\n",
      "\n",
      "Epoch 20: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 20: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 20: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1054.6050 - vae_r_loss: 894.4006 - learning_rate: 8.3730e-07\n",
      "Epoch 21/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856ms/step - loss: 1055.1466 - vae_r_loss: 897.7508\n",
      "Epoch 21: saving model to run/vae/0002_faces/weights/weights-021-1047.20.weights.h5\n",
      "\n",
      "Epoch 21: finished saving model to run/vae/0002_faces/weights/weights-021-1047.20.weights.h5\n",
      "\n",
      "Epoch 21: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 21: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 21: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 859ms/step - loss: 1047.1969 - vae_r_loss: 891.3304 - learning_rate: 8.3730e-07\n",
      "Epoch 22/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:06\u001b[0m 354ms/step - loss: 1024.4104 - vae_r_loss: 872.8574\n",
      "Epoch 22: saving model to run/vae/0002_faces/weights/weights-022-1024.41.weights.h5\n",
      "\n",
      "Epoch 22: finished saving model to run/vae/0002_faces/weights/weights-022-1024.41.weights.h5\n",
      "\n",
      "Epoch 22: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 22: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 22: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1024.4104 - vae_r_loss: 872.8574 - learning_rate: 8.3730e-07\n",
      "Epoch 23/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937ms/step - loss: 1020.4044 - vae_r_loss: 869.0773\n",
      "Epoch 23: saving model to run/vae/0002_faces/weights/weights-023-1011.76.weights.h5\n",
      "\n",
      "Epoch 23: finished saving model to run/vae/0002_faces/weights/weights-023-1011.76.weights.h5\n",
      "\n",
      "Epoch 23: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 23: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 23: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m496s\u001b[0m 940ms/step - loss: 1011.7609 - vae_r_loss: 861.8552 - learning_rate: 8.3730e-07\n",
      "Epoch 24/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m4:04\u001b[0m 464ms/step - loss: 1008.9843 - vae_r_loss: 862.5581\n",
      "Epoch 24: saving model to run/vae/0002_faces/weights/weights-024-1008.98.weights.h5\n",
      "\n",
      "Epoch 24: finished saving model to run/vae/0002_faces/weights/weights-024-1008.98.weights.h5\n",
      "\n",
      "Epoch 24: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 24: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 24: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1008.9842 - vae_r_loss: 862.5581 - learning_rate: 8.3730e-07\n",
      "Epoch 25/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864ms/step - loss: 984.8910 - vae_r_loss: 839.1416\n",
      "Epoch 25: saving model to run/vae/0002_faces/weights/weights-025-975.98.weights.h5\n",
      "\n",
      "Epoch 25: finished saving model to run/vae/0002_faces/weights/weights-025-975.98.weights.h5\n",
      "\n",
      "Epoch 25: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 25: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 25: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 867ms/step - loss: 975.9816 - vae_r_loss: 831.5568 - learning_rate: 8.3730e-07\n",
      "Epoch 26/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:30\u001b[0m 401ms/step - loss: 971.7885 - vae_r_loss: 830.2648\n",
      "Epoch 26: saving model to run/vae/0002_faces/weights/weights-026-971.79.weights.h5\n",
      "\n",
      "Epoch 26: finished saving model to run/vae/0002_faces/weights/weights-026-971.79.weights.h5\n",
      "\n",
      "Epoch 26: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 26: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 26: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 971.7884 - vae_r_loss: 830.2648 - learning_rate: 8.3730e-07\n",
      "Epoch 27/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848ms/step - loss: 948.8401 - vae_r_loss: 808.5206\n",
      "Epoch 27: saving model to run/vae/0002_faces/weights/weights-027-941.24.weights.h5\n",
      "\n",
      "Epoch 27: finished saving model to run/vae/0002_faces/weights/weights-027-941.24.weights.h5\n",
      "\n",
      "Epoch 27: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 27: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 27: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 851ms/step - loss: 941.2445 - vae_r_loss: 802.3417 - learning_rate: 8.3730e-07\n",
      "Epoch 28/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m35:08\u001b[0m 4s/step - loss: 923.4032 - vae_r_loss: 787.3853\n",
      "Epoch 28: saving model to run/vae/0002_faces/weights/weights-028-923.40.weights.h5\n",
      "\n",
      "Epoch 28: finished saving model to run/vae/0002_faces/weights/weights-028-923.40.weights.h5\n",
      "\n",
      "Epoch 28: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 28: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 28: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 923.4031 - vae_r_loss: 787.3853 - learning_rate: 8.3730e-07\n",
      "Epoch 29/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822ms/step - loss: 916.2290 - vae_r_loss: 781.7557\n",
      "Epoch 29: saving model to run/vae/0002_faces/weights/weights-029-908.43.weights.h5\n",
      "\n",
      "Epoch 29: finished saving model to run/vae/0002_faces/weights/weights-029-908.43.weights.h5\n",
      "\n",
      "Epoch 29: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 29: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 29: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 826ms/step - loss: 908.4263 - vae_r_loss: 775.4869 - learning_rate: 8.3730e-07\n",
      "Epoch 30/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m4:41\u001b[0m 535ms/step - loss: 901.3827 - vae_r_loss: 770.7622\n",
      "Epoch 30: saving model to run/vae/0002_faces/weights/weights-030-901.38.weights.h5\n",
      "\n",
      "Epoch 30: finished saving model to run/vae/0002_faces/weights/weights-030-901.38.weights.h5\n",
      "\n",
      "Epoch 30: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 30: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 30: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 901.3826 - vae_r_loss: 770.7622 - learning_rate: 8.3730e-07\n",
      "Epoch 31/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811ms/step - loss: 885.6359 - vae_r_loss: 757.3559\n",
      "Epoch 31: saving model to run/vae/0002_faces/weights/weights-031-877.95.weights.h5\n",
      "\n",
      "Epoch 31: finished saving model to run/vae/0002_faces/weights/weights-031-877.95.weights.h5\n",
      "\n",
      "Epoch 31: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 31: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 31: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 815ms/step - loss: 877.9507 - vae_r_loss: 751.2001 - learning_rate: 8.3730e-07\n",
      "Epoch 32/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m4:27\u001b[0m 508ms/step - loss: 850.9743 - vae_r_loss: 726.3813\n",
      "Epoch 32: saving model to run/vae/0002_faces/weights/weights-032-850.97.weights.h5\n",
      "\n",
      "Epoch 32: finished saving model to run/vae/0002_faces/weights/weights-032-850.97.weights.h5\n",
      "\n",
      "Epoch 32: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 32: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 32: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 850.9743 - vae_r_loss: 726.3813 - learning_rate: 8.3730e-07\n",
      "Epoch 33/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846ms/step - loss: 856.7013 - vae_r_loss: 734.6489\n",
      "Epoch 33: saving model to run/vae/0002_faces/weights/weights-033-849.64.weights.h5\n",
      "\n",
      "Epoch 33: finished saving model to run/vae/0002_faces/weights/weights-033-849.64.weights.h5\n",
      "\n",
      "Epoch 33: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 33: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 33: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m452s\u001b[0m 855ms/step - loss: 849.6372 - vae_r_loss: 729.0426 - learning_rate: 8.3730e-07\n",
      "Epoch 34/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:08\u001b[0m 358ms/step - loss: 835.4019 - vae_r_loss: 717.3300\n",
      "Epoch 34: saving model to run/vae/0002_faces/weights/weights-034-835.40.weights.h5\n",
      "\n",
      "Epoch 34: finished saving model to run/vae/0002_faces/weights/weights-034-835.40.weights.h5\n",
      "\n",
      "Epoch 34: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 34: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 34: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 835.4019 - vae_r_loss: 717.3299 - learning_rate: 8.3730e-07\n",
      "Epoch 35/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835ms/step - loss: 829.6323 - vae_r_loss: 713.4227\n",
      "Epoch 35: saving model to run/vae/0002_faces/weights/weights-035-823.68.weights.h5\n",
      "\n",
      "Epoch 35: finished saving model to run/vae/0002_faces/weights/weights-035-823.68.weights.h5\n",
      "\n",
      "Epoch 35: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 35: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 35: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 839ms/step - loss: 823.6750 - vae_r_loss: 708.8469 - learning_rate: 8.3730e-07\n",
      "Epoch 36/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m4:04\u001b[0m 465ms/step - loss: 805.9261 - vae_r_loss: 693.1128\n",
      "Epoch 36: saving model to run/vae/0002_faces/weights/weights-036-805.93.weights.h5\n",
      "\n",
      "Epoch 36: finished saving model to run/vae/0002_faces/weights/weights-036-805.93.weights.h5\n",
      "\n",
      "Epoch 36: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 36: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 36: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 805.9261 - vae_r_loss: 693.1128 - learning_rate: 8.3730e-07\n",
      "Epoch 37/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834ms/step - loss: 805.4025 - vae_r_loss: 694.4992\n",
      "Epoch 37: saving model to run/vae/0002_faces/weights/weights-037-799.98.weights.h5\n",
      "\n",
      "Epoch 37: finished saving model to run/vae/0002_faces/weights/weights-037-799.98.weights.h5\n",
      "\n",
      "Epoch 37: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 37: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 37: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 837ms/step - loss: 799.9827 - vae_r_loss: 690.2565 - learning_rate: 8.3730e-07\n",
      "Epoch 38/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:14\u001b[0m 369ms/step - loss: 787.8451 - vae_r_loss: 679.0241\n",
      "Epoch 38: saving model to run/vae/0002_faces/weights/weights-038-787.85.weights.h5\n",
      "\n",
      "Epoch 38: finished saving model to run/vae/0002_faces/weights/weights-038-787.85.weights.h5\n",
      "\n",
      "Epoch 38: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 38: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 38: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 787.8450 - vae_r_loss: 679.0241 - learning_rate: 8.3730e-07\n",
      "Epoch 39/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834ms/step - loss: 782.8356 - vae_r_loss: 676.5400\n",
      "Epoch 39: saving model to run/vae/0002_faces/weights/weights-039-778.18.weights.h5\n",
      "\n",
      "Epoch 39: finished saving model to run/vae/0002_faces/weights/weights-039-778.18.weights.h5\n",
      "\n",
      "Epoch 39: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 39: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 39: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 838ms/step - loss: 778.1768 - vae_r_loss: 672.9692 - learning_rate: 8.3730e-07\n",
      "Epoch 40/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m4:56\u001b[0m 564ms/step - loss: 760.6013 - vae_r_loss: 657.2615\n",
      "Epoch 40: saving model to run/vae/0002_faces/weights/weights-040-760.60.weights.h5\n",
      "\n",
      "Epoch 40: finished saving model to run/vae/0002_faces/weights/weights-040-760.60.weights.h5\n",
      "\n",
      "Epoch 40: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 40: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 40: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 760.6013 - vae_r_loss: 657.2615 - learning_rate: 8.3730e-07\n",
      "Epoch 41/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839ms/step - loss: 762.2442 - vae_r_loss: 660.0570\n",
      "Epoch 41: saving model to run/vae/0002_faces/weights/weights-041-758.08.weights.h5\n",
      "\n",
      "Epoch 41: finished saving model to run/vae/0002_faces/weights/weights-041-758.08.weights.h5\n",
      "\n",
      "Epoch 41: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 41: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 41: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 842ms/step - loss: 758.0840 - vae_r_loss: 656.8336 - learning_rate: 8.3730e-07\n",
      "Epoch 42/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:43\u001b[0m 425ms/step - loss: 748.6014 - vae_r_loss: 647.5871\n",
      "Epoch 42: saving model to run/vae/0002_faces/weights/weights-042-748.60.weights.h5\n",
      "\n",
      "Epoch 42: finished saving model to run/vae/0002_faces/weights/weights-042-748.60.weights.h5\n",
      "\n",
      "Epoch 42: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 42: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 42: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 748.6014 - vae_r_loss: 647.5871 - learning_rate: 8.3730e-07\n",
      "Epoch 43/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829ms/step - loss: 744.0973 - vae_r_loss: 645.5242\n",
      "Epoch 43: saving model to run/vae/0002_faces/weights/weights-043-739.37.weights.h5\n",
      "\n",
      "Epoch 43: finished saving model to run/vae/0002_faces/weights/weights-043-739.37.weights.h5\n",
      "\n",
      "Epoch 43: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 43: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 43: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 832ms/step - loss: 739.3682 - vae_r_loss: 641.5996 - learning_rate: 8.3730e-07\n",
      "Epoch 44/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m4:39\u001b[0m 532ms/step - loss: 734.5971 - vae_r_loss: 637.7138\n",
      "Epoch 44: saving model to run/vae/0002_faces/weights/weights-044-734.60.weights.h5\n",
      "\n",
      "Epoch 44: finished saving model to run/vae/0002_faces/weights/weights-044-734.60.weights.h5\n",
      "\n",
      "Epoch 44: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 44: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 44: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 734.5971 - vae_r_loss: 637.7138 - learning_rate: 8.3730e-07\n",
      "Epoch 45/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826ms/step - loss: 725.8505 - vae_r_loss: 630.4528\n",
      "Epoch 45: saving model to run/vae/0002_faces/weights/weights-045-721.98.weights.h5\n",
      "\n",
      "Epoch 45: finished saving model to run/vae/0002_faces/weights/weights-045-721.98.weights.h5\n",
      "\n",
      "Epoch 45: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 45: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 45: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 829ms/step - loss: 721.9777 - vae_r_loss: 627.1935 - learning_rate: 8.3730e-07\n",
      "Epoch 46/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m4:23\u001b[0m 502ms/step - loss: 726.9534 - vae_r_loss: 633.7929\n",
      "Epoch 46: saving model to run/vae/0002_faces/weights/weights-046-726.95.weights.h5\n",
      "\n",
      "Epoch 46: finished saving model to run/vae/0002_faces/weights/weights-046-726.95.weights.h5\n",
      "\n",
      "Epoch 46: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 46: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 46: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 726.9534 - vae_r_loss: 633.7929 - learning_rate: 8.3730e-07\n",
      "Epoch 47/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847ms/step - loss: 709.7864 - vae_r_loss: 616.8956\n",
      "Epoch 47: saving model to run/vae/0002_faces/weights/weights-047-705.97.weights.h5\n",
      "\n",
      "Epoch 47: finished saving model to run/vae/0002_faces/weights/weights-047-705.97.weights.h5\n",
      "\n",
      "Epoch 47: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 47: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 47: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m503s\u001b[0m 850ms/step - loss: 705.9745 - vae_r_loss: 613.6287 - learning_rate: 8.3730e-07\n",
      "Epoch 48/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m4:45\u001b[0m 542ms/step - loss: 701.9015 - vae_r_loss: 611.2448\n",
      "Epoch 48: saving model to run/vae/0002_faces/weights/weights-048-701.90.weights.h5\n",
      "\n",
      "Epoch 48: finished saving model to run/vae/0002_faces/weights/weights-048-701.90.weights.h5\n",
      "\n",
      "Epoch 48: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 48: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 48: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 701.9014 - vae_r_loss: 611.2448 - learning_rate: 8.3730e-07\n",
      "Epoch 49/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825ms/step - loss: 694.7242 - vae_r_loss: 603.9528\n",
      "Epoch 49: saving model to run/vae/0002_faces/weights/weights-049-691.16.weights.h5\n",
      "\n",
      "Epoch 49: finished saving model to run/vae/0002_faces/weights/weights-049-691.16.weights.h5\n",
      "\n",
      "Epoch 49: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 49: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 49: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m440s\u001b[0m 835ms/step - loss: 691.1561 - vae_r_loss: 600.8654 - learning_rate: 8.3730e-07\n",
      "Epoch 50/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m2:55\u001b[0m 334ms/step - loss: 686.3314 - vae_r_loss: 597.6992\n",
      "Epoch 50: saving model to run/vae/0002_faces/weights/weights-050-686.33.weights.h5\n",
      "\n",
      "Epoch 50: finished saving model to run/vae/0002_faces/weights/weights-050-686.33.weights.h5\n",
      "\n",
      "Epoch 50: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 50: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 50: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 686.3314 - vae_r_loss: 597.6992 - learning_rate: 8.3730e-07\n",
      "Epoch 51/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826ms/step - loss: 680.9466 - vae_r_loss: 592.0179\n",
      "Epoch 51: saving model to run/vae/0002_faces/weights/weights-051-677.33.weights.h5\n",
      "\n",
      "Epoch 51: finished saving model to run/vae/0002_faces/weights/weights-051-677.33.weights.h5\n",
      "\n",
      "Epoch 51: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 51: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 51: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 830ms/step - loss: 677.3327 - vae_r_loss: 588.7284 - learning_rate: 8.3730e-07\n",
      "Epoch 52/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m4:03\u001b[0m 463ms/step - loss: 657.0002 - vae_r_loss: 569.0258\n",
      "Epoch 52: saving model to run/vae/0002_faces/weights/weights-052-657.00.weights.h5\n",
      "\n",
      "Epoch 52: finished saving model to run/vae/0002_faces/weights/weights-052-657.00.weights.h5\n",
      "\n",
      "Epoch 52: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 52: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 52: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 657.0002 - vae_r_loss: 569.0258 - learning_rate: 8.3730e-07\n",
      "Epoch 53/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - loss: 667.6123 - vae_r_loss: 580.1430\n",
      "Epoch 53: saving model to run/vae/0002_faces/weights/weights-053-664.29.weights.h5\n",
      "\n",
      "Epoch 53: finished saving model to run/vae/0002_faces/weights/weights-053-664.29.weights.h5\n",
      "\n",
      "Epoch 53: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 53: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 53: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 830ms/step - loss: 664.2946 - vae_r_loss: 577.1542 - learning_rate: 8.3730e-07\n",
      "Epoch 54/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:51\u001b[0m 440ms/step - loss: 658.7767 - vae_r_loss: 571.3732\n",
      "Epoch 54: saving model to run/vae/0002_faces/weights/weights-054-658.78.weights.h5\n",
      "\n",
      "Epoch 54: finished saving model to run/vae/0002_faces/weights/weights-054-658.78.weights.h5\n",
      "\n",
      "Epoch 54: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 54: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 54: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 658.7767 - vae_r_loss: 571.3731 - learning_rate: 8.3730e-07\n",
      "Epoch 55/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844ms/step - loss: 654.6590 - vae_r_loss: 568.4658\n",
      "Epoch 55: saving model to run/vae/0002_faces/weights/weights-055-652.06.weights.h5\n",
      "\n",
      "Epoch 55: finished saving model to run/vae/0002_faces/weights/weights-055-652.06.weights.h5\n",
      "\n",
      "Epoch 55: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 55: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 55: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 847ms/step - loss: 652.0588 - vae_r_loss: 566.1520 - learning_rate: 8.3730e-07\n",
      "Epoch 56/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m4:45\u001b[0m 543ms/step - loss: 646.5167 - vae_r_loss: 560.7297\n",
      "Epoch 56: saving model to run/vae/0002_faces/weights/weights-056-646.52.weights.h5\n",
      "\n",
      "Epoch 56: finished saving model to run/vae/0002_faces/weights/weights-056-646.52.weights.h5\n",
      "\n",
      "Epoch 56: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 56: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 56: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.5167 - vae_r_loss: 560.7297 - learning_rate: 8.3730e-07\n",
      "Epoch 57/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829ms/step - loss: 643.4502 - vae_r_loss: 558.3969\n",
      "Epoch 57: saving model to run/vae/0002_faces/weights/weights-057-640.56.weights.h5\n",
      "\n",
      "Epoch 57: finished saving model to run/vae/0002_faces/weights/weights-057-640.56.weights.h5\n",
      "\n",
      "Epoch 57: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 57: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 57: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m477s\u001b[0m 832ms/step - loss: 640.5608 - vae_r_loss: 555.7573 - learning_rate: 8.3730e-07\n",
      "Epoch 58/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:51\u001b[0m 441ms/step - loss: 648.4597 - vae_r_loss: 562.8400\n",
      "Epoch 58: saving model to run/vae/0002_faces/weights/weights-058-648.46.weights.h5\n",
      "\n",
      "Epoch 58: finished saving model to run/vae/0002_faces/weights/weights-058-648.46.weights.h5\n",
      "\n",
      "Epoch 58: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 58: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 58: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 648.4597 - vae_r_loss: 562.8400 - learning_rate: 8.3730e-07\n",
      "Epoch 59/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - loss: 632.3973 - vae_r_loss: 548.1986\n",
      "Epoch 59: saving model to run/vae/0002_faces/weights/weights-059-629.67.weights.h5\n",
      "\n",
      "Epoch 59: finished saving model to run/vae/0002_faces/weights/weights-059-629.67.weights.h5\n",
      "\n",
      "Epoch 59: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 59: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 59: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 831ms/step - loss: 629.6693 - vae_r_loss: 545.7888 - learning_rate: 8.3730e-07\n",
      "Epoch 60/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m5:48\u001b[0m 662ms/step - loss: 624.5367 - vae_r_loss: 540.8307\n",
      "Epoch 60: saving model to run/vae/0002_faces/weights/weights-060-624.54.weights.h5\n",
      "\n",
      "Epoch 60: finished saving model to run/vae/0002_faces/weights/weights-060-624.54.weights.h5\n",
      "\n",
      "Epoch 60: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 60: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 60: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 624.5367 - vae_r_loss: 540.8306 - learning_rate: 8.3730e-07\n",
      "Epoch 61/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835ms/step - loss: 621.7591 - vae_r_loss: 538.4991\n",
      "Epoch 61: saving model to run/vae/0002_faces/weights/weights-061-619.41.weights.h5\n",
      "\n",
      "Epoch 61: finished saving model to run/vae/0002_faces/weights/weights-061-619.41.weights.h5\n",
      "\n",
      "Epoch 61: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 61: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 61: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 837ms/step - loss: 619.4075 - vae_r_loss: 536.3362 - learning_rate: 8.3730e-07\n",
      "Epoch 62/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:30\u001b[0m 401ms/step - loss: 614.0200 - vae_r_loss: 531.8910\n",
      "Epoch 62: saving model to run/vae/0002_faces/weights/weights-062-614.02.weights.h5\n",
      "\n",
      "Epoch 62: finished saving model to run/vae/0002_faces/weights/weights-062-614.02.weights.h5\n",
      "\n",
      "Epoch 62: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 62: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 62: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 614.0200 - vae_r_loss: 531.8909 - learning_rate: 8.3730e-07\n",
      "Epoch 63/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831ms/step - loss: 612.1244 - vae_r_loss: 529.6385\n",
      "Epoch 63: saving model to run/vae/0002_faces/weights/weights-063-609.68.weights.h5\n",
      "\n",
      "Epoch 63: finished saving model to run/vae/0002_faces/weights/weights-063-609.68.weights.h5\n",
      "\n",
      "Epoch 63: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 63: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 63: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m479s\u001b[0m 834ms/step - loss: 609.6828 - vae_r_loss: 527.3626 - learning_rate: 8.3730e-07\n",
      "Epoch 64/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:41\u001b[0m 421ms/step - loss: 602.1876 - vae_r_loss: 519.3788\n",
      "Epoch 64: saving model to run/vae/0002_faces/weights/weights-064-602.19.weights.h5\n",
      "\n",
      "Epoch 64: finished saving model to run/vae/0002_faces/weights/weights-064-602.19.weights.h5\n",
      "\n",
      "Epoch 64: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 64: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 64: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 602.1876 - vae_r_loss: 519.3787 - learning_rate: 8.3730e-07\n",
      "Epoch 65/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842ms/step - loss: 602.4370 - vae_r_loss: 520.6259\n",
      "Epoch 65: saving model to run/vae/0002_faces/weights/weights-065-600.28.weights.h5\n",
      "\n",
      "Epoch 65: finished saving model to run/vae/0002_faces/weights/weights-065-600.28.weights.h5\n",
      "\n",
      "Epoch 65: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 65: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 65: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 845ms/step - loss: 600.2813 - vae_r_loss: 518.6131 - learning_rate: 8.3730e-07\n",
      "Epoch 66/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:55\u001b[0m 448ms/step - loss: 586.0228 - vae_r_loss: 504.2458\n",
      "Epoch 66: saving model to run/vae/0002_faces/weights/weights-066-586.02.weights.h5\n",
      "\n",
      "Epoch 66: finished saving model to run/vae/0002_faces/weights/weights-066-586.02.weights.h5\n",
      "\n",
      "Epoch 66: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 66: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 66: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 586.0228 - vae_r_loss: 504.2458 - learning_rate: 8.3730e-07\n",
      "Epoch 67/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835ms/step - loss: 593.7662 - vae_r_loss: 512.5390\n",
      "Epoch 67: saving model to run/vae/0002_faces/weights/weights-067-591.58.weights.h5\n",
      "\n",
      "Epoch 67: finished saving model to run/vae/0002_faces/weights/weights-067-591.58.weights.h5\n",
      "\n",
      "Epoch 67: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 67: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 67: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 839ms/step - loss: 591.5848 - vae_r_loss: 510.5242 - learning_rate: 8.3730e-07\n",
      "Epoch 68/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m4:42\u001b[0m 537ms/step - loss: 570.7828 - vae_r_loss: 490.3438\n",
      "Epoch 68: saving model to run/vae/0002_faces/weights/weights-068-570.78.weights.h5\n",
      "\n",
      "Epoch 68: finished saving model to run/vae/0002_faces/weights/weights-068-570.78.weights.h5\n",
      "\n",
      "Epoch 68: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 68: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 68: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 570.7828 - vae_r_loss: 490.3438 - learning_rate: 8.3730e-07\n",
      "Epoch 69/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834ms/step - loss: 584.7459 - vae_r_loss: 504.0964\n",
      "Epoch 69: saving model to run/vae/0002_faces/weights/weights-069-582.88.weights.h5\n",
      "\n",
      "Epoch 69: finished saving model to run/vae/0002_faces/weights/weights-069-582.88.weights.h5\n",
      "\n",
      "Epoch 69: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 69: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 69: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 837ms/step - loss: 582.8822 - vae_r_loss: 502.4295 - learning_rate: 8.3730e-07\n",
      "Epoch 70/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:43\u001b[0m 425ms/step - loss: 568.7026 - vae_r_loss: 488.7532\n",
      "Epoch 70: saving model to run/vae/0002_faces/weights/weights-070-568.70.weights.h5\n",
      "\n",
      "Epoch 70: finished saving model to run/vae/0002_faces/weights/weights-070-568.70.weights.h5\n",
      "\n",
      "Epoch 70: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 70: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 70: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 568.7026 - vae_r_loss: 488.7532 - learning_rate: 8.3730e-07\n",
      "Epoch 71/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832ms/step - loss: 577.3301 - vae_r_loss: 497.2104\n",
      "Epoch 71: saving model to run/vae/0002_faces/weights/weights-071-574.89.weights.h5\n",
      "\n",
      "Epoch 71: finished saving model to run/vae/0002_faces/weights/weights-071-574.89.weights.h5\n",
      "\n",
      "Epoch 71: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 71: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 71: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 834ms/step - loss: 574.8859 - vae_r_loss: 494.8825 - learning_rate: 8.3730e-07\n",
      "Epoch 72/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:54\u001b[0m 445ms/step - loss: 574.3896 - vae_r_loss: 493.8216\n",
      "Epoch 72: saving model to run/vae/0002_faces/weights/weights-072-574.39.weights.h5\n",
      "\n",
      "Epoch 72: finished saving model to run/vae/0002_faces/weights/weights-072-574.39.weights.h5\n",
      "\n",
      "Epoch 72: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 72: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 72: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 574.3896 - vae_r_loss: 493.8216 - learning_rate: 8.3730e-07\n",
      "Epoch 73/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831ms/step - loss: 569.5911 - vae_r_loss: 489.9460\n",
      "Epoch 73: saving model to run/vae/0002_faces/weights/weights-073-567.16.weights.h5\n",
      "\n",
      "Epoch 73: finished saving model to run/vae/0002_faces/weights/weights-073-567.16.weights.h5\n",
      "\n",
      "Epoch 73: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 73: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 73: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m440s\u001b[0m 835ms/step - loss: 567.1588 - vae_r_loss: 487.6237 - learning_rate: 8.3730e-07\n",
      "Epoch 74/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:42\u001b[0m 423ms/step - loss: 565.1339 - vae_r_loss: 486.1358\n",
      "Epoch 74: saving model to run/vae/0002_faces/weights/weights-074-565.13.weights.h5\n",
      "\n",
      "Epoch 74: finished saving model to run/vae/0002_faces/weights/weights-074-565.13.weights.h5\n",
      "\n",
      "Epoch 74: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 74: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 74: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 565.1339 - vae_r_loss: 486.1358 - learning_rate: 8.3730e-07\n",
      "Epoch 75/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852ms/step - loss: 561.4127 - vae_r_loss: 482.2162\n",
      "Epoch 75: saving model to run/vae/0002_faces/weights/weights-075-559.67.weights.h5\n",
      "\n",
      "Epoch 75: finished saving model to run/vae/0002_faces/weights/weights-075-559.67.weights.h5\n",
      "\n",
      "Epoch 75: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 75: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 75: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 855ms/step - loss: 559.6702 - vae_r_loss: 480.5598 - learning_rate: 8.3730e-07\n",
      "Epoch 76/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m4:52\u001b[0m 556ms/step - loss: 570.1340 - vae_r_loss: 490.7534\n",
      "Epoch 76: saving model to run/vae/0002_faces/weights/weights-076-570.13.weights.h5\n",
      "\n",
      "Epoch 76: finished saving model to run/vae/0002_faces/weights/weights-076-570.13.weights.h5\n",
      "\n",
      "Epoch 76: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 76: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 76: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 570.1340 - vae_r_loss: 490.7534 - learning_rate: 8.3730e-07\n",
      "Epoch 77/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858ms/step - loss: 553.9914 - vae_r_loss: 475.2276\n",
      "Epoch 77: saving model to run/vae/0002_faces/weights/weights-077-552.70.weights.h5\n",
      "\n",
      "Epoch 77: finished saving model to run/vae/0002_faces/weights/weights-077-552.70.weights.h5\n",
      "\n",
      "Epoch 77: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 77: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 77: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 861ms/step - loss: 552.6986 - vae_r_loss: 473.9906 - learning_rate: 8.3730e-07\n",
      "Epoch 78/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:41\u001b[0m 421ms/step - loss: 537.2426 - vae_r_loss: 459.3630\n",
      "Epoch 78: saving model to run/vae/0002_faces/weights/weights-078-537.24.weights.h5\n",
      "\n",
      "Epoch 78: finished saving model to run/vae/0002_faces/weights/weights-078-537.24.weights.h5\n",
      "\n",
      "Epoch 78: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 78: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 78: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 537.2426 - vae_r_loss: 459.3630 - learning_rate: 8.3730e-07\n",
      "Epoch 79/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843ms/step - loss: 547.2514 - vae_r_loss: 468.7944\n",
      "Epoch 79: saving model to run/vae/0002_faces/weights/weights-079-545.99.weights.h5\n",
      "\n",
      "Epoch 79: finished saving model to run/vae/0002_faces/weights/weights-079-545.99.weights.h5\n",
      "\n",
      "Epoch 79: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 79: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 79: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 846ms/step - loss: 545.9874 - vae_r_loss: 467.5931 - learning_rate: 8.3730e-07\n",
      "Epoch 80/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m36:13\u001b[0m 4s/step - loss: 543.1115 - vae_r_loss: 465.1220\n",
      "Epoch 80: saving model to run/vae/0002_faces/weights/weights-080-543.11.weights.h5\n",
      "\n",
      "Epoch 80: finished saving model to run/vae/0002_faces/weights/weights-080-543.11.weights.h5\n",
      "\n",
      "Epoch 80: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 80: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 80: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 543.1115 - vae_r_loss: 465.1220 - learning_rate: 8.3730e-07\n",
      "Epoch 81/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851ms/step - loss: 540.9472 - vae_r_loss: 462.9204\n",
      "Epoch 81: saving model to run/vae/0002_faces/weights/weights-081-539.32.weights.h5\n",
      "\n",
      "Epoch 81: finished saving model to run/vae/0002_faces/weights/weights-081-539.32.weights.h5\n",
      "\n",
      "Epoch 81: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 81: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 81: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m451s\u001b[0m 854ms/step - loss: 539.3231 - vae_r_loss: 461.3059 - learning_rate: 8.3730e-07\n",
      "Epoch 82/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:52\u001b[0m 441ms/step - loss: 537.6320 - vae_r_loss: 459.9529\n",
      "Epoch 82: saving model to run/vae/0002_faces/weights/weights-082-537.63.weights.h5\n",
      "\n",
      "Epoch 82: finished saving model to run/vae/0002_faces/weights/weights-082-537.63.weights.h5\n",
      "\n",
      "Epoch 82: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 82: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 82: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 537.6319 - vae_r_loss: 459.9529 - learning_rate: 8.3730e-07\n",
      "Epoch 83/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864ms/step - loss: 534.8023 - vae_r_loss: 457.0394\n",
      "Epoch 83: saving model to run/vae/0002_faces/weights/weights-083-532.97.weights.h5\n",
      "\n",
      "Epoch 83: finished saving model to run/vae/0002_faces/weights/weights-083-532.97.weights.h5\n",
      "\n",
      "Epoch 83: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 83: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 83: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 867ms/step - loss: 532.9682 - vae_r_loss: 455.2463 - learning_rate: 8.3730e-07\n",
      "Epoch 84/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m2:56\u001b[0m 335ms/step - loss: 540.0995 - vae_r_loss: 461.2899\n",
      "Epoch 84: saving model to run/vae/0002_faces/weights/weights-084-540.10.weights.h5\n",
      "\n",
      "Epoch 84: finished saving model to run/vae/0002_faces/weights/weights-084-540.10.weights.h5\n",
      "\n",
      "Epoch 84: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 84: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 84: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 540.0995 - vae_r_loss: 461.2899 - learning_rate: 8.3730e-07\n",
      "Epoch 85/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943ms/step - loss: 528.5192 - vae_r_loss: 451.0820\n",
      "Epoch 85: saving model to run/vae/0002_faces/weights/weights-085-526.95.weights.h5\n",
      "\n",
      "Epoch 85: finished saving model to run/vae/0002_faces/weights/weights-085-526.95.weights.h5\n",
      "\n",
      "Epoch 85: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 85: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 85: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m499s\u001b[0m 946ms/step - loss: 526.9534 - vae_r_loss: 449.5443 - learning_rate: 8.3730e-07\n",
      "Epoch 86/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m4:15\u001b[0m 486ms/step - loss: 529.1071 - vae_r_loss: 450.9826\n",
      "Epoch 86: saving model to run/vae/0002_faces/weights/weights-086-529.11.weights.h5\n",
      "\n",
      "Epoch 86: finished saving model to run/vae/0002_faces/weights/weights-086-529.11.weights.h5\n",
      "\n",
      "Epoch 86: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 86: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 86: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 529.1071 - vae_r_loss: 450.9826 - learning_rate: 8.3730e-07\n",
      "Epoch 87/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833ms/step - loss: 522.8058 - vae_r_loss: 445.6081\n",
      "Epoch 87: saving model to run/vae/0002_faces/weights/weights-087-521.12.weights.h5\n",
      "\n",
      "Epoch 87: finished saving model to run/vae/0002_faces/weights/weights-087-521.12.weights.h5\n",
      "\n",
      "Epoch 87: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 87: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 87: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 836ms/step - loss: 521.1232 - vae_r_loss: 443.9693 - learning_rate: 8.3730e-07\n",
      "Epoch 88/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:06\u001b[0m 354ms/step - loss: 518.1513 - vae_r_loss: 440.9237\n",
      "Epoch 88: saving model to run/vae/0002_faces/weights/weights-088-518.15.weights.h5\n",
      "\n",
      "Epoch 88: finished saving model to run/vae/0002_faces/weights/weights-088-518.15.weights.h5\n",
      "\n",
      "Epoch 88: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 88: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 88: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 518.1513 - vae_r_loss: 440.9237 - learning_rate: 8.3730e-07\n",
      "Epoch 89/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821ms/step - loss: 516.5067 - vae_r_loss: 439.4792\n",
      "Epoch 89: saving model to run/vae/0002_faces/weights/weights-089-515.63.weights.h5\n",
      "\n",
      "Epoch 89: finished saving model to run/vae/0002_faces/weights/weights-089-515.63.weights.h5\n",
      "\n",
      "Epoch 89: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 89: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 89: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 823ms/step - loss: 515.6265 - vae_r_loss: 438.6552 - learning_rate: 8.3730e-07\n",
      "Epoch 90/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m2:48\u001b[0m 321ms/step - loss: 499.1460 - vae_r_loss: 423.4207\n",
      "Epoch 90: saving model to run/vae/0002_faces/weights/weights-090-499.15.weights.h5\n",
      "\n",
      "Epoch 90: finished saving model to run/vae/0002_faces/weights/weights-090-499.15.weights.h5\n",
      "\n",
      "Epoch 90: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 90: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 90: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 499.1460 - vae_r_loss: 423.4207 - learning_rate: 8.3730e-07\n",
      "Epoch 91/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753ms/step - loss: 511.3078 - vae_r_loss: 434.4942\n",
      "Epoch 91: saving model to run/vae/0002_faces/weights/weights-091-510.18.weights.h5\n",
      "\n",
      "Epoch 91: finished saving model to run/vae/0002_faces/weights/weights-091-510.18.weights.h5\n",
      "\n",
      "Epoch 91: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 91: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 91: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m398s\u001b[0m 755ms/step - loss: 510.1816 - vae_r_loss: 433.4162 - learning_rate: 8.3730e-07\n",
      "Epoch 92/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:23\u001b[0m 386ms/step - loss: 499.1794 - vae_r_loss: 422.0278\n",
      "Epoch 92: saving model to run/vae/0002_faces/weights/weights-092-499.18.weights.h5\n",
      "\n",
      "Epoch 92: finished saving model to run/vae/0002_faces/weights/weights-092-499.18.weights.h5\n",
      "\n",
      "Epoch 92: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 92: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 92: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 499.1794 - vae_r_loss: 422.0278 - learning_rate: 8.3730e-07\n",
      "Epoch 93/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776ms/step - loss: 506.1846 - vae_r_loss: 429.5394\n",
      "Epoch 93: saving model to run/vae/0002_faces/weights/weights-093-505.06.weights.h5\n",
      "\n",
      "Epoch 93: finished saving model to run/vae/0002_faces/weights/weights-093-505.06.weights.h5\n",
      "\n",
      "Epoch 93: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 93: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 93: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 779ms/step - loss: 505.0635 - vae_r_loss: 428.4400 - learning_rate: 8.3730e-07\n",
      "Epoch 94/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m2:52\u001b[0m 328ms/step - loss: 510.6076 - vae_r_loss: 434.0012\n",
      "Epoch 94: saving model to run/vae/0002_faces/weights/weights-094-510.61.weights.h5\n",
      "\n",
      "Epoch 94: finished saving model to run/vae/0002_faces/weights/weights-094-510.61.weights.h5\n",
      "\n",
      "Epoch 94: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 94: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 94: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 510.6076 - vae_r_loss: 434.0011 - learning_rate: 8.3730e-07\n",
      "Epoch 95/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894ms/step - loss: 501.0975 - vae_r_loss: 424.6347\n",
      "Epoch 95: saving model to run/vae/0002_faces/weights/weights-095-499.92.weights.h5\n",
      "\n",
      "Epoch 95: finished saving model to run/vae/0002_faces/weights/weights-095-499.92.weights.h5\n",
      "\n",
      "Epoch 95: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 95: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 95: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 898ms/step - loss: 499.9195 - vae_r_loss: 423.4604 - learning_rate: 8.3730e-07\n",
      "Epoch 96/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m5:05\u001b[0m 581ms/step - loss: 490.5963 - vae_r_loss: 413.6312\n",
      "Epoch 96: saving model to run/vae/0002_faces/weights/weights-096-490.60.weights.h5\n",
      "\n",
      "Epoch 96: finished saving model to run/vae/0002_faces/weights/weights-096-490.60.weights.h5\n",
      "\n",
      "Epoch 96: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 96: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 96: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 490.5963 - vae_r_loss: 413.6312 - learning_rate: 8.3730e-07\n",
      "Epoch 97/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975ms/step - loss: 496.4356 - vae_r_loss: 420.0352\n",
      "Epoch 97: saving model to run/vae/0002_faces/weights/weights-097-495.02.weights.h5\n",
      "\n",
      "Epoch 97: finished saving model to run/vae/0002_faces/weights/weights-097-495.02.weights.h5\n",
      "\n",
      "Epoch 97: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 97: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 97: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m517s\u001b[0m 979ms/step - loss: 495.0220 - vae_r_loss: 418.6968 - learning_rate: 8.3730e-07\n",
      "Epoch 98/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m5:37\u001b[0m 642ms/step - loss: 505.9841 - vae_r_loss: 430.5802\n",
      "Epoch 98: saving model to run/vae/0002_faces/weights/weights-098-505.98.weights.h5\n",
      "\n",
      "Epoch 98: finished saving model to run/vae/0002_faces/weights/weights-098-505.98.weights.h5\n",
      "\n",
      "Epoch 98: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 98: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 98: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 505.9841 - vae_r_loss: 430.5802 - learning_rate: 8.3730e-07\n",
      "Epoch 99/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915ms/step - loss: 491.3424 - vae_r_loss: 415.1050\n",
      "Epoch 99: saving model to run/vae/0002_faces/weights/weights-099-490.40.weights.h5\n",
      "\n",
      "Epoch 99: finished saving model to run/vae/0002_faces/weights/weights-099-490.40.weights.h5\n",
      "\n",
      "Epoch 99: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 99: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 99: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m489s\u001b[0m 925ms/step - loss: 490.4040 - vae_r_loss: 414.1791 - learning_rate: 8.3730e-07\n",
      "Epoch 100/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m2:58\u001b[0m 339ms/step - loss: 475.6079 - vae_r_loss: 400.6759\n",
      "Epoch 100: saving model to run/vae/0002_faces/weights/weights-100-475.61.weights.h5\n",
      "\n",
      "Epoch 100: finished saving model to run/vae/0002_faces/weights/weights-100-475.61.weights.h5\n",
      "\n",
      "Epoch 100: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 100: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 100: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 475.6079 - vae_r_loss: 400.6759 - learning_rate: 8.3730e-07\n",
      "Epoch 101/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814ms/step - loss: 486.8571 - vae_r_loss: 410.7141\n",
      "Epoch 101: saving model to run/vae/0002_faces/weights/weights-101-486.01.weights.h5\n",
      "\n",
      "Epoch 101: finished saving model to run/vae/0002_faces/weights/weights-101-486.01.weights.h5\n",
      "\n",
      "Epoch 101: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 101: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 101: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 817ms/step - loss: 486.0149 - vae_r_loss: 409.8630 - learning_rate: 8.3730e-07\n",
      "Epoch 102/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:04\u001b[0m 350ms/step - loss: 479.8416 - vae_r_loss: 402.7695\n",
      "Epoch 102: saving model to run/vae/0002_faces/weights/weights-102-479.84.weights.h5\n",
      "\n",
      "Epoch 102: finished saving model to run/vae/0002_faces/weights/weights-102-479.84.weights.h5\n",
      "\n",
      "Epoch 102: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 102: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 102: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 479.8416 - vae_r_loss: 402.7695 - learning_rate: 8.3730e-07\n",
      "Epoch 103/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837ms/step - loss: 482.4928 - vae_r_loss: 406.4840\n",
      "Epoch 103: saving model to run/vae/0002_faces/weights/weights-103-481.58.weights.h5\n",
      "\n",
      "Epoch 103: finished saving model to run/vae/0002_faces/weights/weights-103-481.58.weights.h5\n",
      "\n",
      "Epoch 103: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 103: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 103: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 840ms/step - loss: 481.5807 - vae_r_loss: 405.5008 - learning_rate: 8.3730e-07\n",
      "Epoch 104/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:36\u001b[0m 412ms/step - loss: 474.8333 - vae_r_loss: 399.1223\n",
      "Epoch 104: saving model to run/vae/0002_faces/weights/weights-104-474.83.weights.h5\n",
      "\n",
      "Epoch 104: finished saving model to run/vae/0002_faces/weights/weights-104-474.83.weights.h5\n",
      "\n",
      "Epoch 104: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 104: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 104: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 474.8333 - vae_r_loss: 399.1223 - learning_rate: 8.3730e-07\n",
      "Epoch 105/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815ms/step - loss: 477.9983 - vae_r_loss: 402.1173\n",
      "Epoch 105: saving model to run/vae/0002_faces/weights/weights-105-477.27.weights.h5\n",
      "\n",
      "Epoch 105: finished saving model to run/vae/0002_faces/weights/weights-105-477.27.weights.h5\n",
      "\n",
      "Epoch 105: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 105: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 105: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 818ms/step - loss: 477.2669 - vae_r_loss: 401.3066 - learning_rate: 8.3730e-07\n",
      "Epoch 106/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:11\u001b[0m 363ms/step - loss: 479.6855 - vae_r_loss: 404.4646\n",
      "Epoch 106: saving model to run/vae/0002_faces/weights/weights-106-479.69.weights.h5\n",
      "\n",
      "Epoch 106: finished saving model to run/vae/0002_faces/weights/weights-106-479.69.weights.h5\n",
      "\n",
      "Epoch 106: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 106: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 106: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 479.6855 - vae_r_loss: 404.4646 - learning_rate: 8.3730e-07\n",
      "Epoch 107/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809ms/step - loss: 474.1930 - vae_r_loss: 398.2204\n",
      "Epoch 107: saving model to run/vae/0002_faces/weights/weights-107-473.29.weights.h5\n",
      "\n",
      "Epoch 107: finished saving model to run/vae/0002_faces/weights/weights-107-473.29.weights.h5\n",
      "\n",
      "Epoch 107: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 107: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 107: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m478s\u001b[0m 811ms/step - loss: 473.2898 - vae_r_loss: 397.3425 - learning_rate: 8.3730e-07\n",
      "Epoch 108/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m2:58\u001b[0m 340ms/step - loss: 480.5987 - vae_r_loss: 404.2365\n",
      "Epoch 108: saving model to run/vae/0002_faces/weights/weights-108-480.60.weights.h5\n",
      "\n",
      "Epoch 108: finished saving model to run/vae/0002_faces/weights/weights-108-480.60.weights.h5\n",
      "\n",
      "Epoch 108: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 108: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 108: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 480.5987 - vae_r_loss: 404.2365 - learning_rate: 8.3730e-07\n",
      "Epoch 109/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785ms/step - loss: 470.8508 - vae_r_loss: 394.9218\n",
      "Epoch 109: saving model to run/vae/0002_faces/weights/weights-109-469.38.weights.h5\n",
      "\n",
      "Epoch 109: finished saving model to run/vae/0002_faces/weights/weights-109-469.38.weights.h5\n",
      "\n",
      "Epoch 109: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 109: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 109: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m478s\u001b[0m 788ms/step - loss: 469.3756 - vae_r_loss: 393.4435 - learning_rate: 8.3730e-07\n",
      "Epoch 110/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m2:54\u001b[0m 331ms/step - loss: 468.3083 - vae_r_loss: 391.2611\n",
      "Epoch 110: saving model to run/vae/0002_faces/weights/weights-110-468.31.weights.h5\n",
      "\n",
      "Epoch 110: finished saving model to run/vae/0002_faces/weights/weights-110-468.31.weights.h5\n",
      "\n",
      "Epoch 110: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 110: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 110: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 468.3083 - vae_r_loss: 391.2611 - learning_rate: 8.3730e-07\n",
      "Epoch 111/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835ms/step - loss: 466.1966 - vae_r_loss: 390.2789\n",
      "Epoch 111: saving model to run/vae/0002_faces/weights/weights-111-465.74.weights.h5\n",
      "\n",
      "Epoch 111: finished saving model to run/vae/0002_faces/weights/weights-111-465.74.weights.h5\n",
      "\n",
      "Epoch 111: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 111: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 111: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 845ms/step - loss: 465.7386 - vae_r_loss: 389.8025 - learning_rate: 8.3730e-07\n",
      "Epoch 112/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:28\u001b[0m 396ms/step - loss: 460.9510 - vae_r_loss: 384.9937\n",
      "Epoch 112: saving model to run/vae/0002_faces/weights/weights-112-460.95.weights.h5\n",
      "\n",
      "Epoch 112: finished saving model to run/vae/0002_faces/weights/weights-112-460.95.weights.h5\n",
      "\n",
      "Epoch 112: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 112: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 112: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 460.9510 - vae_r_loss: 384.9937 - learning_rate: 8.3730e-07\n",
      "Epoch 113/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849ms/step - loss: 462.9629 - vae_r_loss: 386.9996\n",
      "Epoch 113: saving model to run/vae/0002_faces/weights/weights-113-462.02.weights.h5\n",
      "\n",
      "Epoch 113: finished saving model to run/vae/0002_faces/weights/weights-113-462.02.weights.h5\n",
      "\n",
      "Epoch 113: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 113: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 113: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m451s\u001b[0m 854ms/step - loss: 462.0173 - vae_r_loss: 386.0761 - learning_rate: 8.3730e-07\n",
      "Epoch 114/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m6:09\u001b[0m 703ms/step - loss: 461.7392 - vae_r_loss: 384.9153\n",
      "Epoch 114: saving model to run/vae/0002_faces/weights/weights-114-461.74.weights.h5\n",
      "\n",
      "Epoch 114: finished saving model to run/vae/0002_faces/weights/weights-114-461.74.weights.h5\n",
      "\n",
      "Epoch 114: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 114: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 114: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 461.7392 - vae_r_loss: 384.9153 - learning_rate: 8.3730e-07\n",
      "Epoch 115/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798ms/step - loss: 459.0458 - vae_r_loss: 383.1460\n",
      "Epoch 115: saving model to run/vae/0002_faces/weights/weights-115-458.49.weights.h5\n",
      "\n",
      "Epoch 115: finished saving model to run/vae/0002_faces/weights/weights-115-458.49.weights.h5\n",
      "\n",
      "Epoch 115: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 115: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 115: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 800ms/step - loss: 458.4875 - vae_r_loss: 382.5579 - learning_rate: 8.3730e-07\n",
      "Epoch 116/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m2:51\u001b[0m 326ms/step - loss: 465.3965 - vae_r_loss: 388.4793\n",
      "Epoch 116: saving model to run/vae/0002_faces/weights/weights-116-465.40.weights.h5\n",
      "\n",
      "Epoch 116: finished saving model to run/vae/0002_faces/weights/weights-116-465.40.weights.h5\n",
      "\n",
      "Epoch 116: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 116: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 116: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 465.3965 - vae_r_loss: 388.4793 - learning_rate: 8.3730e-07\n",
      "Epoch 117/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698ms/step - loss: 455.6788 - vae_r_loss: 379.7000\n",
      "Epoch 117: saving model to run/vae/0002_faces/weights/weights-117-455.03.weights.h5\n",
      "\n",
      "Epoch 117: finished saving model to run/vae/0002_faces/weights/weights-117-455.03.weights.h5\n",
      "\n",
      "Epoch 117: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 117: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 117: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 701ms/step - loss: 455.0308 - vae_r_loss: 379.1053 - learning_rate: 8.3730e-07\n",
      "Epoch 118/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m36:33\u001b[0m 4s/step - loss: 444.8937 - vae_r_loss: 369.8542\n",
      "Epoch 118: saving model to run/vae/0002_faces/weights/weights-118-444.89.weights.h5\n",
      "\n",
      "Epoch 118: finished saving model to run/vae/0002_faces/weights/weights-118-444.89.weights.h5\n",
      "\n",
      "Epoch 118: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 118: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 118: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 444.8937 - vae_r_loss: 369.8542 - learning_rate: 8.3730e-07\n",
      "Epoch 119/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - loss: 451.8563 - vae_r_loss: 376.0098\n",
      "Epoch 119: saving model to run/vae/0002_faces/weights/weights-119-451.76.weights.h5\n",
      "\n",
      "Epoch 119: finished saving model to run/vae/0002_faces/weights/weights-119-451.76.weights.h5\n",
      "\n",
      "Epoch 119: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 119: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 119: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m435s\u001b[0m 822ms/step - loss: 451.7596 - vae_r_loss: 375.8880 - learning_rate: 8.3730e-07\n",
      "Epoch 120/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m2:26\u001b[0m 278ms/step - loss: 438.2048 - vae_r_loss: 364.7006\n",
      "Epoch 120: saving model to run/vae/0002_faces/weights/weights-120-438.20.weights.h5\n",
      "\n",
      "Epoch 120: finished saving model to run/vae/0002_faces/weights/weights-120-438.20.weights.h5\n",
      "\n",
      "Epoch 120: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 120: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 120: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 438.2048 - vae_r_loss: 364.7006 - learning_rate: 8.3730e-07\n",
      "Epoch 121/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685ms/step - loss: 449.1888 - vae_r_loss: 373.2627\n",
      "Epoch 121: saving model to run/vae/0002_faces/weights/weights-121-448.49.weights.h5\n",
      "\n",
      "Epoch 121: finished saving model to run/vae/0002_faces/weights/weights-121-448.49.weights.h5\n",
      "\n",
      "Epoch 121: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 121: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 121: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 687ms/step - loss: 448.4862 - vae_r_loss: 372.5627 - learning_rate: 8.3730e-07\n",
      "Epoch 122/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m2:37\u001b[0m 300ms/step - loss: 441.0249 - vae_r_loss: 365.0352\n",
      "Epoch 122: saving model to run/vae/0002_faces/weights/weights-122-441.02.weights.h5\n",
      "\n",
      "Epoch 122: finished saving model to run/vae/0002_faces/weights/weights-122-441.02.weights.h5\n",
      "\n",
      "Epoch 122: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 122: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 122: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 441.0249 - vae_r_loss: 365.0352 - learning_rate: 8.3730e-07\n",
      "Epoch 123/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724ms/step - loss: 446.1446 - vae_r_loss: 370.1951\n",
      "Epoch 123: saving model to run/vae/0002_faces/weights/weights-123-445.51.weights.h5\n",
      "\n",
      "Epoch 123: finished saving model to run/vae/0002_faces/weights/weights-123-445.51.weights.h5\n",
      "\n",
      "Epoch 123: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 123: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 123: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 727ms/step - loss: 445.5105 - vae_r_loss: 369.5348 - learning_rate: 8.3730e-07\n",
      "Epoch 124/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:21\u001b[0m 383ms/step - loss: 449.7722 - vae_r_loss: 373.6888\n",
      "Epoch 124: saving model to run/vae/0002_faces/weights/weights-124-449.77.weights.h5\n",
      "\n",
      "Epoch 124: finished saving model to run/vae/0002_faces/weights/weights-124-449.77.weights.h5\n",
      "\n",
      "Epoch 124: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 124: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 124: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 449.7722 - vae_r_loss: 373.6888 - learning_rate: 8.3730e-07\n",
      "Epoch 125/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685ms/step - loss: 443.1964 - vae_r_loss: 367.1735\n",
      "Epoch 125: saving model to run/vae/0002_faces/weights/weights-125-442.63.weights.h5\n",
      "\n",
      "Epoch 125: finished saving model to run/vae/0002_faces/weights/weights-125-442.63.weights.h5\n",
      "\n",
      "Epoch 125: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 125: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 125: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 689ms/step - loss: 442.6280 - vae_r_loss: 366.6425 - learning_rate: 8.3730e-07\n",
      "Epoch 126/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m5:49\u001b[0m 665ms/step - loss: 436.0098 - vae_r_loss: 360.6147\n",
      "Epoch 126: saving model to run/vae/0002_faces/weights/weights-126-436.01.weights.h5\n",
      "\n",
      "Epoch 126: finished saving model to run/vae/0002_faces/weights/weights-126-436.01.weights.h5\n",
      "\n",
      "Epoch 126: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 126: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 126: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 436.0098 - vae_r_loss: 360.6147 - learning_rate: 8.3730e-07\n",
      "Epoch 127/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697ms/step - loss: 439.9647 - vae_r_loss: 363.8857\n",
      "Epoch 127: saving model to run/vae/0002_faces/weights/weights-127-439.53.weights.h5\n",
      "\n",
      "Epoch 127: finished saving model to run/vae/0002_faces/weights/weights-127-439.53.weights.h5\n",
      "\n",
      "Epoch 127: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 127: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 127: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 700ms/step - loss: 439.5323 - vae_r_loss: 363.4877 - learning_rate: 8.3730e-07\n",
      "Epoch 128/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m4:29\u001b[0m 513ms/step - loss: 431.4369 - vae_r_loss: 354.5995\n",
      "Epoch 128: saving model to run/vae/0002_faces/weights/weights-128-431.44.weights.h5\n",
      "\n",
      "Epoch 128: finished saving model to run/vae/0002_faces/weights/weights-128-431.44.weights.h5\n",
      "\n",
      "Epoch 128: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 128: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 128: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 431.4369 - vae_r_loss: 354.5995 - learning_rate: 8.3730e-07\n",
      "Epoch 129/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606ms/step - loss: 437.9265 - vae_r_loss: 361.8753\n",
      "Epoch 129: saving model to run/vae/0002_faces/weights/weights-129-436.84.weights.h5\n",
      "\n",
      "Epoch 129: finished saving model to run/vae/0002_faces/weights/weights-129-436.84.weights.h5\n",
      "\n",
      "Epoch 129: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 129: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 129: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 608ms/step - loss: 436.8370 - vae_r_loss: 360.7645 - learning_rate: 8.3730e-07\n",
      "Epoch 130/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m2:23\u001b[0m 273ms/step - loss: 423.1606 - vae_r_loss: 347.0090\n",
      "Epoch 130: saving model to run/vae/0002_faces/weights/weights-130-423.16.weights.h5\n",
      "\n",
      "Epoch 130: finished saving model to run/vae/0002_faces/weights/weights-130-423.16.weights.h5\n",
      "\n",
      "Epoch 130: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 130: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 130: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 423.1606 - vae_r_loss: 347.0090 - learning_rate: 8.3730e-07\n",
      "Epoch 131/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650ms/step - loss: 434.4161 - vae_r_loss: 358.3090\n",
      "Epoch 131: saving model to run/vae/0002_faces/weights/weights-131-434.04.weights.h5\n",
      "\n",
      "Epoch 131: finished saving model to run/vae/0002_faces/weights/weights-131-434.04.weights.h5\n",
      "\n",
      "Epoch 131: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 131: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 131: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 651ms/step - loss: 434.0406 - vae_r_loss: 357.9660 - learning_rate: 8.3730e-07\n",
      "Epoch 132/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m2:38\u001b[0m 300ms/step - loss: 441.1418 - vae_r_loss: 366.1605\n",
      "Epoch 132: saving model to run/vae/0002_faces/weights/weights-132-441.14.weights.h5\n",
      "\n",
      "Epoch 132: finished saving model to run/vae/0002_faces/weights/weights-132-441.14.weights.h5\n",
      "\n",
      "Epoch 132: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 132: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 132: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 441.1418 - vae_r_loss: 366.1605 - learning_rate: 8.3730e-07\n",
      "Epoch 133/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824ms/step - loss: 432.2592 - vae_r_loss: 356.0965\n",
      "Epoch 133: saving model to run/vae/0002_faces/weights/weights-133-431.50.weights.h5\n",
      "\n",
      "Epoch 133: finished saving model to run/vae/0002_faces/weights/weights-133-431.50.weights.h5\n",
      "\n",
      "Epoch 133: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 133: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 133: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 828ms/step - loss: 431.4987 - vae_r_loss: 355.3613 - learning_rate: 8.3730e-07\n",
      "Epoch 134/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m5:21\u001b[0m 612ms/step - loss: 433.8961 - vae_r_loss: 355.9404\n",
      "Epoch 134: saving model to run/vae/0002_faces/weights/weights-134-433.90.weights.h5\n",
      "\n",
      "Epoch 134: finished saving model to run/vae/0002_faces/weights/weights-134-433.90.weights.h5\n",
      "\n",
      "Epoch 134: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 134: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 134: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 433.8961 - vae_r_loss: 355.9403 - learning_rate: 8.3730e-07\n",
      "Epoch 135/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980ms/step - loss: 429.7989 - vae_r_loss: 353.5789\n",
      "Epoch 135: saving model to run/vae/0002_faces/weights/weights-135-429.01.weights.h5\n",
      "\n",
      "Epoch 135: finished saving model to run/vae/0002_faces/weights/weights-135-429.01.weights.h5\n",
      "\n",
      "Epoch 135: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 135: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 135: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m519s\u001b[0m 983ms/step - loss: 429.0098 - vae_r_loss: 352.7880 - learning_rate: 8.3730e-07\n",
      "Epoch 136/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m2:27\u001b[0m 281ms/step - loss: 421.7307 - vae_r_loss: 344.8638\n",
      "Epoch 136: saving model to run/vae/0002_faces/weights/weights-136-421.73.weights.h5\n",
      "\n",
      "Epoch 136: finished saving model to run/vae/0002_faces/weights/weights-136-421.73.weights.h5\n",
      "\n",
      "Epoch 136: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 136: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 136: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 421.7307 - vae_r_loss: 344.8638 - learning_rate: 8.3730e-07\n",
      "Epoch 137/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638ms/step - loss: 426.9513 - vae_r_loss: 350.7518\n",
      "Epoch 137: saving model to run/vae/0002_faces/weights/weights-137-426.43.weights.h5\n",
      "\n",
      "Epoch 137: finished saving model to run/vae/0002_faces/weights/weights-137-426.43.weights.h5\n",
      "\n",
      "Epoch 137: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 137: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 137: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 640ms/step - loss: 426.4302 - vae_r_loss: 350.2136 - learning_rate: 8.3730e-07\n",
      "Epoch 138/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m2:48\u001b[0m 320ms/step - loss: 425.1572 - vae_r_loss: 350.2543\n",
      "Epoch 138: saving model to run/vae/0002_faces/weights/weights-138-425.16.weights.h5\n",
      "\n",
      "Epoch 138: finished saving model to run/vae/0002_faces/weights/weights-138-425.16.weights.h5\n",
      "\n",
      "Epoch 138: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 138: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 138: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 425.1572 - vae_r_loss: 350.2543 - learning_rate: 8.3730e-07\n",
      "Epoch 139/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617ms/step - loss: 424.8567 - vae_r_loss: 348.5503\n",
      "Epoch 139: saving model to run/vae/0002_faces/weights/weights-139-424.07.weights.h5\n",
      "\n",
      "Epoch 139: finished saving model to run/vae/0002_faces/weights/weights-139-424.07.weights.h5\n",
      "\n",
      "Epoch 139: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 139: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 139: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 619ms/step - loss: 424.0737 - vae_r_loss: 347.7588 - learning_rate: 8.3730e-07\n",
      "Epoch 140/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m2:31\u001b[0m 289ms/step - loss: 419.5421 - vae_r_loss: 343.0430\n",
      "Epoch 140: saving model to run/vae/0002_faces/weights/weights-140-419.54.weights.h5\n",
      "\n",
      "Epoch 140: finished saving model to run/vae/0002_faces/weights/weights-140-419.54.weights.h5\n",
      "\n",
      "Epoch 140: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 140: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 140: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 419.5421 - vae_r_loss: 343.0430 - learning_rate: 8.3730e-07\n",
      "Epoch 141/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662ms/step - loss: 422.5637 - vae_r_loss: 346.1917\n",
      "Epoch 141: saving model to run/vae/0002_faces/weights/weights-141-421.70.weights.h5\n",
      "\n",
      "Epoch 141: finished saving model to run/vae/0002_faces/weights/weights-141-421.70.weights.h5\n",
      "\n",
      "Epoch 141: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 141: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 141: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 663ms/step - loss: 421.6967 - vae_r_loss: 345.3378 - learning_rate: 8.3730e-07\n",
      "Epoch 142/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m2:32\u001b[0m 290ms/step - loss: 431.6098 - vae_r_loss: 354.3842\n",
      "Epoch 142: saving model to run/vae/0002_faces/weights/weights-142-431.61.weights.h5\n",
      "\n",
      "Epoch 142: finished saving model to run/vae/0002_faces/weights/weights-142-431.61.weights.h5\n",
      "\n",
      "Epoch 142: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 142: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 142: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 431.6098 - vae_r_loss: 354.3842 - learning_rate: 8.3730e-07\n",
      "Epoch 143/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671ms/step - loss: 419.9502 - vae_r_loss: 343.6182\n",
      "Epoch 143: saving model to run/vae/0002_faces/weights/weights-143-419.46.weights.h5\n",
      "\n",
      "Epoch 143: finished saving model to run/vae/0002_faces/weights/weights-143-419.46.weights.h5\n",
      "\n",
      "Epoch 143: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 143: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 143: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 673ms/step - loss: 419.4581 - vae_r_loss: 343.0686 - learning_rate: 8.3730e-07\n",
      "Epoch 144/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m2:19\u001b[0m 264ms/step - loss: 420.9452 - vae_r_loss: 344.7670\n",
      "Epoch 144: saving model to run/vae/0002_faces/weights/weights-144-420.95.weights.h5\n",
      "\n",
      "Epoch 144: finished saving model to run/vae/0002_faces/weights/weights-144-420.95.weights.h5\n",
      "\n",
      "Epoch 144: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 144: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 144: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 420.9452 - vae_r_loss: 344.7670 - learning_rate: 8.3730e-07\n",
      "Epoch 145/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743ms/step - loss: 417.7459 - vae_r_loss: 341.3942\n",
      "Epoch 145: saving model to run/vae/0002_faces/weights/weights-145-417.30.weights.h5\n",
      "\n",
      "Epoch 145: finished saving model to run/vae/0002_faces/weights/weights-145-417.30.weights.h5\n",
      "\n",
      "Epoch 145: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 145: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 145: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 748ms/step - loss: 417.2962 - vae_r_loss: 340.8717 - learning_rate: 8.3730e-07\n",
      "Epoch 146/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m4:05\u001b[0m 467ms/step - loss: 418.2251 - vae_r_loss: 340.3715\n",
      "Epoch 146: saving model to run/vae/0002_faces/weights/weights-146-418.23.weights.h5\n",
      "\n",
      "Epoch 146: finished saving model to run/vae/0002_faces/weights/weights-146-418.23.weights.h5\n",
      "\n",
      "Epoch 146: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 146: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 146: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 418.2251 - vae_r_loss: 340.3715 - learning_rate: 8.3730e-07\n",
      "Epoch 147/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764ms/step - loss: 415.6101 - vae_r_loss: 339.1498\n",
      "Epoch 147: saving model to run/vae/0002_faces/weights/weights-147-415.14.weights.h5\n",
      "\n",
      "Epoch 147: finished saving model to run/vae/0002_faces/weights/weights-147-415.14.weights.h5\n",
      "\n",
      "Epoch 147: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 147: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 147: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 766ms/step - loss: 415.1400 - vae_r_loss: 338.6773 - learning_rate: 8.3730e-07\n",
      "Epoch 148/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m2:33\u001b[0m 292ms/step - loss: 418.1476 - vae_r_loss: 340.6729\n",
      "Epoch 148: saving model to run/vae/0002_faces/weights/weights-148-418.15.weights.h5\n",
      "\n",
      "Epoch 148: finished saving model to run/vae/0002_faces/weights/weights-148-418.15.weights.h5\n",
      "\n",
      "Epoch 148: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 148: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 148: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 418.1476 - vae_r_loss: 340.6728 - learning_rate: 8.3730e-07\n",
      "Epoch 149/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 413.3320 - vae_r_loss: 336.9046\n",
      "Epoch 149: saving model to run/vae/0002_faces/weights/weights-149-413.06.weights.h5\n",
      "\n",
      "Epoch 149: finished saving model to run/vae/0002_faces/weights/weights-149-413.06.weights.h5\n",
      "\n",
      "Epoch 149: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 149: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 149: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m544s\u001b[0m 1s/step - loss: 413.0621 - vae_r_loss: 336.5800 - learning_rate: 8.3730e-07\n",
      "Epoch 150/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m5:59\u001b[0m 684ms/step - loss: 415.9960 - vae_r_loss: 338.8513\n",
      "Epoch 150: saving model to run/vae/0002_faces/weights/weights-150-416.00.weights.h5\n",
      "\n",
      "Epoch 150: finished saving model to run/vae/0002_faces/weights/weights-150-416.00.weights.h5\n",
      "\n",
      "Epoch 150: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 150: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 150: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 415.9960 - vae_r_loss: 338.8513 - learning_rate: 8.3730e-07\n",
      "Epoch 151/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566ms/step - loss: 411.7036 - vae_r_loss: 335.1978\n",
      "Epoch 151: saving model to run/vae/0002_faces/weights/weights-151-411.08.weights.h5\n",
      "\n",
      "Epoch 151: finished saving model to run/vae/0002_faces/weights/weights-151-411.08.weights.h5\n",
      "\n",
      "Epoch 151: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 151: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 151: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 568ms/step - loss: 411.0833 - vae_r_loss: 334.5278 - learning_rate: 8.3730e-07\n",
      "Epoch 152/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m2:22\u001b[0m 270ms/step - loss: 415.3755 - vae_r_loss: 337.6632\n",
      "Epoch 152: saving model to run/vae/0002_faces/weights/weights-152-415.38.weights.h5\n",
      "\n",
      "Epoch 152: finished saving model to run/vae/0002_faces/weights/weights-152-415.38.weights.h5\n",
      "\n",
      "Epoch 152: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 152: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 152: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 415.3755 - vae_r_loss: 337.6632 - learning_rate: 8.3730e-07\n",
      "Epoch 153/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559ms/step - loss: 409.2770 - vae_r_loss: 332.7111\n",
      "Epoch 153: saving model to run/vae/0002_faces/weights/weights-153-409.04.weights.h5\n",
      "\n",
      "Epoch 153: finished saving model to run/vae/0002_faces/weights/weights-153-409.04.weights.h5\n",
      "\n",
      "Epoch 153: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 153: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 153: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 561ms/step - loss: 409.0432 - vae_r_loss: 332.4703 - learning_rate: 8.3730e-07\n",
      "Epoch 154/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m2:39\u001b[0m 302ms/step - loss: 409.1753 - vae_r_loss: 332.3158\n",
      "Epoch 154: saving model to run/vae/0002_faces/weights/weights-154-409.18.weights.h5\n",
      "\n",
      "Epoch 154: finished saving model to run/vae/0002_faces/weights/weights-154-409.18.weights.h5\n",
      "\n",
      "Epoch 154: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 154: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 154: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 409.1753 - vae_r_loss: 332.3158 - learning_rate: 8.3730e-07\n",
      "Epoch 155/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706ms/step - loss: 407.6670 - vae_r_loss: 331.0717\n",
      "Epoch 155: saving model to run/vae/0002_faces/weights/weights-155-407.20.weights.h5\n",
      "\n",
      "Epoch 155: finished saving model to run/vae/0002_faces/weights/weights-155-407.20.weights.h5\n",
      "\n",
      "Epoch 155: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 155: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 155: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 709ms/step - loss: 407.2010 - vae_r_loss: 330.6077 - learning_rate: 8.3730e-07\n",
      "Epoch 156/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:45\u001b[0m 429ms/step - loss: 405.7297 - vae_r_loss: 328.1895\n",
      "Epoch 156: saving model to run/vae/0002_faces/weights/weights-156-405.73.weights.h5\n",
      "\n",
      "Epoch 156: finished saving model to run/vae/0002_faces/weights/weights-156-405.73.weights.h5\n",
      "\n",
      "Epoch 156: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 156: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 156: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 405.7297 - vae_r_loss: 328.1895 - learning_rate: 8.3730e-07\n",
      "Epoch 157/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675ms/step - loss: 406.1774 - vae_r_loss: 329.5155\n",
      "Epoch 157: saving model to run/vae/0002_faces/weights/weights-157-405.29.weights.h5\n",
      "\n",
      "Epoch 157: finished saving model to run/vae/0002_faces/weights/weights-157-405.29.weights.h5\n",
      "\n",
      "Epoch 157: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 157: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 157: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 677ms/step - loss: 405.2883 - vae_r_loss: 328.6686 - learning_rate: 8.3730e-07\n",
      "Epoch 158/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m2:19\u001b[0m 265ms/step - loss: 404.9617 - vae_r_loss: 326.9983\n",
      "Epoch 158: saving model to run/vae/0002_faces/weights/weights-158-404.96.weights.h5\n",
      "\n",
      "Epoch 158: finished saving model to run/vae/0002_faces/weights/weights-158-404.96.weights.h5\n",
      "\n",
      "Epoch 158: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 158: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 158: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 404.9617 - vae_r_loss: 326.9983 - learning_rate: 8.3730e-07\n",
      "Epoch 159/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774ms/step - loss: 403.6577 - vae_r_loss: 327.0303\n",
      "Epoch 159: saving model to run/vae/0002_faces/weights/weights-159-403.60.weights.h5\n",
      "\n",
      "Epoch 159: finished saving model to run/vae/0002_faces/weights/weights-159-403.60.weights.h5\n",
      "\n",
      "Epoch 159: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 159: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 159: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 777ms/step - loss: 403.6016 - vae_r_loss: 326.9385 - learning_rate: 8.3730e-07\n",
      "Epoch 160/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:56\u001b[0m 450ms/step - loss: 400.2899 - vae_r_loss: 322.3860\n",
      "Epoch 160: saving model to run/vae/0002_faces/weights/weights-160-400.29.weights.h5\n",
      "\n",
      "Epoch 160: finished saving model to run/vae/0002_faces/weights/weights-160-400.29.weights.h5\n",
      "\n",
      "Epoch 160: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 160: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 160: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 400.2899 - vae_r_loss: 322.3860 - learning_rate: 8.3730e-07\n",
      "Epoch 161/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777ms/step - loss: 402.3957 - vae_r_loss: 325.6802\n",
      "Epoch 161: saving model to run/vae/0002_faces/weights/weights-161-401.79.weights.h5\n",
      "\n",
      "Epoch 161: finished saving model to run/vae/0002_faces/weights/weights-161-401.79.weights.h5\n",
      "\n",
      "Epoch 161: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 161: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 161: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 779ms/step - loss: 401.7912 - vae_r_loss: 325.0987 - learning_rate: 8.3730e-07\n",
      "Epoch 162/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m4:54\u001b[0m 560ms/step - loss: 398.7697 - vae_r_loss: 321.4152\n",
      "Epoch 162: saving model to run/vae/0002_faces/weights/weights-162-398.77.weights.h5\n",
      "\n",
      "Epoch 162: finished saving model to run/vae/0002_faces/weights/weights-162-398.77.weights.h5\n",
      "\n",
      "Epoch 162: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 162: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 162: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 398.7697 - vae_r_loss: 321.4152 - learning_rate: 8.3730e-07\n",
      "Epoch 163/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783ms/step - loss: 400.1735 - vae_r_loss: 323.4875\n",
      "Epoch 163: saving model to run/vae/0002_faces/weights/weights-163-399.93.weights.h5\n",
      "\n",
      "Epoch 163: finished saving model to run/vae/0002_faces/weights/weights-163-399.93.weights.h5\n",
      "\n",
      "Epoch 163: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 163: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 163: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 786ms/step - loss: 399.9283 - vae_r_loss: 323.2138 - learning_rate: 8.3730e-07\n",
      "Epoch 164/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m2:58\u001b[0m 340ms/step - loss: 394.5554 - vae_r_loss: 318.3296\n",
      "Epoch 164: saving model to run/vae/0002_faces/weights/weights-164-394.56.weights.h5\n",
      "\n",
      "Epoch 164: finished saving model to run/vae/0002_faces/weights/weights-164-394.56.weights.h5\n",
      "\n",
      "Epoch 164: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 164: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 164: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 394.5554 - vae_r_loss: 318.3296 - learning_rate: 8.3730e-07\n",
      "Epoch 165/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802ms/step - loss: 398.2733 - vae_r_loss: 321.6006\n",
      "Epoch 165: saving model to run/vae/0002_faces/weights/weights-165-398.20.weights.h5\n",
      "\n",
      "Epoch 165: finished saving model to run/vae/0002_faces/weights/weights-165-398.20.weights.h5\n",
      "\n",
      "Epoch 165: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 165: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 165: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m485s\u001b[0m 804ms/step - loss: 398.1990 - vae_r_loss: 321.4508 - learning_rate: 8.3730e-07\n",
      "Epoch 166/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m4:01\u001b[0m 458ms/step - loss: 393.8426 - vae_r_loss: 317.2393\n",
      "Epoch 166: saving model to run/vae/0002_faces/weights/weights-166-393.84.weights.h5\n",
      "\n",
      "Epoch 166: finished saving model to run/vae/0002_faces/weights/weights-166-393.84.weights.h5\n",
      "\n",
      "Epoch 166: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 166: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 166: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 393.8426 - vae_r_loss: 317.2393 - learning_rate: 8.3730e-07\n",
      "Epoch 167/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823ms/step - loss: 397.3141 - vae_r_loss: 320.5799\n",
      "Epoch 167: saving model to run/vae/0002_faces/weights/weights-167-396.59.weights.h5\n",
      "\n",
      "Epoch 167: finished saving model to run/vae/0002_faces/weights/weights-167-396.59.weights.h5\n",
      "\n",
      "Epoch 167: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 167: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 167: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m489s\u001b[0m 825ms/step - loss: 396.5946 - vae_r_loss: 319.9025 - learning_rate: 8.3730e-07\n",
      "Epoch 168/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:36\u001b[0m 411ms/step - loss: 397.8784 - vae_r_loss: 321.0885\n",
      "Epoch 168: saving model to run/vae/0002_faces/weights/weights-168-397.88.weights.h5\n",
      "\n",
      "Epoch 168: finished saving model to run/vae/0002_faces/weights/weights-168-397.88.weights.h5\n",
      "\n",
      "Epoch 168: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 168: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 168: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 397.8784 - vae_r_loss: 321.0885 - learning_rate: 8.3730e-07\n",
      "Epoch 169/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833ms/step - loss: 395.2313 - vae_r_loss: 318.4647\n",
      "Epoch 169: saving model to run/vae/0002_faces/weights/weights-169-394.94.weights.h5\n",
      "\n",
      "Epoch 169: finished saving model to run/vae/0002_faces/weights/weights-169-394.94.weights.h5\n",
      "\n",
      "Epoch 169: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 169: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 169: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 836ms/step - loss: 394.9383 - vae_r_loss: 318.1785 - learning_rate: 8.3730e-07\n",
      "Epoch 170/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m4:24\u001b[0m 503ms/step - loss: 389.7011 - vae_r_loss: 312.6060\n",
      "Epoch 170: saving model to run/vae/0002_faces/weights/weights-170-389.70.weights.h5\n",
      "\n",
      "Epoch 170: finished saving model to run/vae/0002_faces/weights/weights-170-389.70.weights.h5\n",
      "\n",
      "Epoch 170: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 170: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 170: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 389.7011 - vae_r_loss: 312.6060 - learning_rate: 8.3730e-07\n",
      "Epoch 171/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809ms/step - loss: 393.4524 - vae_r_loss: 316.6558\n",
      "Epoch 171: saving model to run/vae/0002_faces/weights/weights-171-393.30.weights.h5\n",
      "\n",
      "Epoch 171: finished saving model to run/vae/0002_faces/weights/weights-171-393.30.weights.h5\n",
      "\n",
      "Epoch 171: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 171: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 171: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 812ms/step - loss: 393.2984 - vae_r_loss: 316.5532 - learning_rate: 8.3730e-07\n",
      "Epoch 172/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m4:07\u001b[0m 471ms/step - loss: 391.4639 - vae_r_loss: 315.1391\n",
      "Epoch 172: saving model to run/vae/0002_faces/weights/weights-172-391.46.weights.h5\n",
      "\n",
      "Epoch 172: finished saving model to run/vae/0002_faces/weights/weights-172-391.46.weights.h5\n",
      "\n",
      "Epoch 172: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 172: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 172: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 391.4639 - vae_r_loss: 315.1391 - learning_rate: 8.3730e-07\n",
      "Epoch 173/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - loss: 392.2227 - vae_r_loss: 315.5685\n",
      "Epoch 173: saving model to run/vae/0002_faces/weights/weights-173-391.74.weights.h5\n",
      "\n",
      "Epoch 173: finished saving model to run/vae/0002_faces/weights/weights-173-391.74.weights.h5\n",
      "\n",
      "Epoch 173: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 173: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 173: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 820ms/step - loss: 391.7408 - vae_r_loss: 315.0263 - learning_rate: 8.3730e-07\n",
      "Epoch 174/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m4:49\u001b[0m 550ms/step - loss: 398.0456 - vae_r_loss: 320.8530\n",
      "Epoch 174: saving model to run/vae/0002_faces/weights/weights-174-398.05.weights.h5\n",
      "\n",
      "Epoch 174: finished saving model to run/vae/0002_faces/weights/weights-174-398.05.weights.h5\n",
      "\n",
      "Epoch 174: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 174: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 174: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 398.0456 - vae_r_loss: 320.8530 - learning_rate: 8.3730e-07\n",
      "Epoch 175/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829ms/step - loss: 390.8131 - vae_r_loss: 314.1222\n",
      "Epoch 175: saving model to run/vae/0002_faces/weights/weights-175-390.18.weights.h5\n",
      "\n",
      "Epoch 175: finished saving model to run/vae/0002_faces/weights/weights-175-390.18.weights.h5\n",
      "\n",
      "Epoch 175: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 175: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 175: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 833ms/step - loss: 390.1810 - vae_r_loss: 313.4565 - learning_rate: 8.3730e-07\n",
      "Epoch 176/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m4:33\u001b[0m 521ms/step - loss: 386.3321 - vae_r_loss: 309.1853\n",
      "Epoch 176: saving model to run/vae/0002_faces/weights/weights-176-386.33.weights.h5\n",
      "\n",
      "Epoch 176: finished saving model to run/vae/0002_faces/weights/weights-176-386.33.weights.h5\n",
      "\n",
      "Epoch 176: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 176: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 176: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 386.3321 - vae_r_loss: 309.1853 - learning_rate: 8.3730e-07\n",
      "Epoch 177/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793ms/step - loss: 388.9496 - vae_r_loss: 312.1738\n",
      "Epoch 177: saving model to run/vae/0002_faces/weights/weights-177-388.73.weights.h5\n",
      "\n",
      "Epoch 177: finished saving model to run/vae/0002_faces/weights/weights-177-388.73.weights.h5\n",
      "\n",
      "Epoch 177: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 177: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 177: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 796ms/step - loss: 388.7336 - vae_r_loss: 311.9901 - learning_rate: 8.3730e-07\n",
      "Epoch 178/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:09\u001b[0m 361ms/step - loss: 381.3566 - vae_r_loss: 306.4079\n",
      "Epoch 178: saving model to run/vae/0002_faces/weights/weights-178-381.36.weights.h5\n",
      "\n",
      "Epoch 178: finished saving model to run/vae/0002_faces/weights/weights-178-381.36.weights.h5\n",
      "\n",
      "Epoch 178: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 178: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 178: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 381.3566 - vae_r_loss: 306.4079 - learning_rate: 8.3730e-07\n",
      "Epoch 179/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800ms/step - loss: 387.3021 - vae_r_loss: 310.6329\n",
      "Epoch 179: saving model to run/vae/0002_faces/weights/weights-179-387.15.weights.h5\n",
      "\n",
      "Epoch 179: finished saving model to run/vae/0002_faces/weights/weights-179-387.15.weights.h5\n",
      "\n",
      "Epoch 179: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 179: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 179: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 802ms/step - loss: 387.1488 - vae_r_loss: 310.4560 - learning_rate: 8.3730e-07\n",
      "Epoch 180/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:26\u001b[0m 393ms/step - loss: 393.1693 - vae_r_loss: 317.3156\n",
      "Epoch 180: saving model to run/vae/0002_faces/weights/weights-180-393.17.weights.h5\n",
      "\n",
      "Epoch 180: finished saving model to run/vae/0002_faces/weights/weights-180-393.17.weights.h5\n",
      "\n",
      "Epoch 180: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 180: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 180: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 393.1693 - vae_r_loss: 317.3156 - learning_rate: 8.3730e-07\n",
      "Epoch 181/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833ms/step - loss: 386.0463 - vae_r_loss: 309.3440\n",
      "Epoch 181: saving model to run/vae/0002_faces/weights/weights-181-385.76.weights.h5\n",
      "\n",
      "Epoch 181: finished saving model to run/vae/0002_faces/weights/weights-181-385.76.weights.h5\n",
      "\n",
      "Epoch 181: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 181: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 181: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 835ms/step - loss: 385.7644 - vae_r_loss: 309.0610 - learning_rate: 8.3730e-07\n",
      "Epoch 182/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:15\u001b[0m 372ms/step - loss: 384.0737 - vae_r_loss: 308.7452\n",
      "Epoch 182: saving model to run/vae/0002_faces/weights/weights-182-384.07.weights.h5\n",
      "\n",
      "Epoch 182: finished saving model to run/vae/0002_faces/weights/weights-182-384.07.weights.h5\n",
      "\n",
      "Epoch 182: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 182: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 182: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 384.0737 - vae_r_loss: 308.7452 - learning_rate: 8.3730e-07\n",
      "Epoch 183/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812ms/step - loss: 384.8292 - vae_r_loss: 308.1241\n",
      "Epoch 183: saving model to run/vae/0002_faces/weights/weights-183-384.28.weights.h5\n",
      "\n",
      "Epoch 183: finished saving model to run/vae/0002_faces/weights/weights-183-384.28.weights.h5\n",
      "\n",
      "Epoch 183: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 183: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 183: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 815ms/step - loss: 384.2833 - vae_r_loss: 307.6246 - learning_rate: 8.3730e-07\n",
      "Epoch 184/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:02\u001b[0m 347ms/step - loss: 368.5479 - vae_r_loss: 292.3882\n",
      "Epoch 184: saving model to run/vae/0002_faces/weights/weights-184-368.55.weights.h5\n",
      "\n",
      "Epoch 184: finished saving model to run/vae/0002_faces/weights/weights-184-368.55.weights.h5\n",
      "\n",
      "Epoch 184: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 184: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 184: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 368.5479 - vae_r_loss: 292.3882 - learning_rate: 8.3730e-07\n",
      "Epoch 185/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853ms/step - loss: 383.0158 - vae_r_loss: 306.3977\n",
      "Epoch 185: saving model to run/vae/0002_faces/weights/weights-185-382.85.weights.h5\n",
      "\n",
      "Epoch 185: finished saving model to run/vae/0002_faces/weights/weights-185-382.85.weights.h5\n",
      "\n",
      "Epoch 185: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 185: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 185: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m452s\u001b[0m 855ms/step - loss: 382.8530 - vae_r_loss: 306.2135 - learning_rate: 8.3730e-07\n",
      "Epoch 186/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m4:55\u001b[0m 562ms/step - loss: 386.8373 - vae_r_loss: 310.0089\n",
      "Epoch 186: saving model to run/vae/0002_faces/weights/weights-186-386.84.weights.h5\n",
      "\n",
      "Epoch 186: finished saving model to run/vae/0002_faces/weights/weights-186-386.84.weights.h5\n",
      "\n",
      "Epoch 186: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 186: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 186: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 386.8373 - vae_r_loss: 310.0089 - learning_rate: 8.3730e-07\n",
      "Epoch 187/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809ms/step - loss: 382.3520 - vae_r_loss: 305.7073\n",
      "Epoch 187: saving model to run/vae/0002_faces/weights/weights-187-381.61.weights.h5\n",
      "\n",
      "Epoch 187: finished saving model to run/vae/0002_faces/weights/weights-187-381.61.weights.h5\n",
      "\n",
      "Epoch 187: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 187: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 187: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 811ms/step - loss: 381.6056 - vae_r_loss: 304.9312 - learning_rate: 8.3730e-07\n",
      "Epoch 188/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m2:55\u001b[0m 335ms/step - loss: 384.6969 - vae_r_loss: 308.5115\n",
      "Epoch 188: saving model to run/vae/0002_faces/weights/weights-188-384.70.weights.h5\n",
      "\n",
      "Epoch 188: finished saving model to run/vae/0002_faces/weights/weights-188-384.70.weights.h5\n",
      "\n",
      "Epoch 188: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 188: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 188: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 384.6969 - vae_r_loss: 308.5115 - learning_rate: 8.3730e-07\n",
      "Epoch 189/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809ms/step - loss: 380.7898 - vae_r_loss: 304.1226\n",
      "Epoch 189: saving model to run/vae/0002_faces/weights/weights-189-380.18.weights.h5\n",
      "\n",
      "Epoch 189: finished saving model to run/vae/0002_faces/weights/weights-189-380.18.weights.h5\n",
      "\n",
      "Epoch 189: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 189: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 189: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 812ms/step - loss: 380.1780 - vae_r_loss: 303.5479 - learning_rate: 8.3730e-07\n",
      "Epoch 190/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m4:10\u001b[0m 477ms/step - loss: 379.6384 - vae_r_loss: 301.5004\n",
      "Epoch 190: saving model to run/vae/0002_faces/weights/weights-190-379.64.weights.h5\n",
      "\n",
      "Epoch 190: finished saving model to run/vae/0002_faces/weights/weights-190-379.64.weights.h5\n",
      "\n",
      "Epoch 190: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 190: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 190: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 379.6384 - vae_r_loss: 301.5004 - learning_rate: 8.3730e-07\n",
      "Epoch 191/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809ms/step - loss: 378.7831 - vae_r_loss: 302.2590\n",
      "Epoch 191: saving model to run/vae/0002_faces/weights/weights-191-378.80.weights.h5\n",
      "\n",
      "Epoch 191: finished saving model to run/vae/0002_faces/weights/weights-191-378.80.weights.h5\n",
      "\n",
      "Epoch 191: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 191: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 191: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 811ms/step - loss: 378.7985 - vae_r_loss: 302.2036 - learning_rate: 8.3730e-07\n",
      "Epoch 192/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m4:18\u001b[0m 491ms/step - loss: 380.8351 - vae_r_loss: 304.3788\n",
      "Epoch 192: saving model to run/vae/0002_faces/weights/weights-192-380.84.weights.h5\n",
      "\n",
      "Epoch 192: finished saving model to run/vae/0002_faces/weights/weights-192-380.84.weights.h5\n",
      "\n",
      "Epoch 192: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 192: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 192: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 380.8351 - vae_r_loss: 304.3788 - learning_rate: 8.3730e-07\n",
      "Epoch 193/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840ms/step - loss: 377.4841 - vae_r_loss: 300.9512\n",
      "Epoch 193: saving model to run/vae/0002_faces/weights/weights-193-377.54.weights.h5\n",
      "\n",
      "Epoch 193: finished saving model to run/vae/0002_faces/weights/weights-193-377.54.weights.h5\n",
      "\n",
      "Epoch 193: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 193: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 193: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 843ms/step - loss: 377.5448 - vae_r_loss: 300.9834 - learning_rate: 8.3730e-07\n",
      "Epoch 194/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:24\u001b[0m 389ms/step - loss: 379.4239 - vae_r_loss: 301.9125\n",
      "Epoch 194: saving model to run/vae/0002_faces/weights/weights-194-379.42.weights.h5\n",
      "\n",
      "Epoch 194: finished saving model to run/vae/0002_faces/weights/weights-194-379.42.weights.h5\n",
      "\n",
      "Epoch 194: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 194: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 194: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 379.4239 - vae_r_loss: 301.9125 - learning_rate: 8.3730e-07\n",
      "Epoch 195/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841ms/step - loss: 376.4704 - vae_r_loss: 299.9538\n",
      "Epoch 195: saving model to run/vae/0002_faces/weights/weights-195-376.12.weights.h5\n",
      "\n",
      "Epoch 195: finished saving model to run/vae/0002_faces/weights/weights-195-376.12.weights.h5\n",
      "\n",
      "Epoch 195: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 195: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 195: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m483s\u001b[0m 843ms/step - loss: 376.1157 - vae_r_loss: 299.6011 - learning_rate: 8.3730e-07\n",
      "Epoch 196/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m5:32\u001b[0m 633ms/step - loss: 376.2955 - vae_r_loss: 300.0745\n",
      "Epoch 196: saving model to run/vae/0002_faces/weights/weights-196-376.30.weights.h5\n",
      "\n",
      "Epoch 196: finished saving model to run/vae/0002_faces/weights/weights-196-376.30.weights.h5\n",
      "\n",
      "Epoch 196: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 196: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 196: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 376.2955 - vae_r_loss: 300.0745 - learning_rate: 8.3730e-07\n",
      "Epoch 197/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808ms/step - loss: 375.1700 - vae_r_loss: 298.7523\n",
      "Epoch 197: saving model to run/vae/0002_faces/weights/weights-197-374.88.weights.h5\n",
      "\n",
      "Epoch 197: finished saving model to run/vae/0002_faces/weights/weights-197-374.88.weights.h5\n",
      "\n",
      "Epoch 197: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 197: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 197: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 811ms/step - loss: 374.8751 - vae_r_loss: 298.4301 - learning_rate: 8.3730e-07\n",
      "Epoch 198/200\n",
      "\u001b[1m  1/527\u001b[0m \u001b[37m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[1m3:06\u001b[0m 354ms/step - loss: 368.7825 - vae_r_loss: 293.7776\n",
      "Epoch 198: saving model to run/vae/0002_faces/weights/weights-198-368.78.weights.h5\n",
      "\n",
      "Epoch 198: finished saving model to run/vae/0002_faces/weights/weights-198-368.78.weights.h5\n",
      "\n",
      "Epoch 198: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 198: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 198: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 368.7825 - vae_r_loss: 293.7776 - learning_rate: 8.3730e-07\n",
      "Epoch 199/200\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - loss: 374.0951 - vae_r_loss: 297.6210\n",
      "Epoch 199: saving model to run/vae/0002_faces/weights/weights-199-373.66.weights.h5\n",
      "\n",
      "Epoch 199: finished saving model to run/vae/0002_faces/weights/weights-199-373.66.weights.h5\n",
      "\n",
      "Epoch 199: saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "\n",
      "Epoch 199: finished saving model to run/vae/0002_faces/weights/weights.weights.h5\n",
      "Epoch 199: Learning Rate is 8.37e-07\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 830ms/step - loss: 373.6559 - vae_r_loss: 297.2281 - learning_rate: 8.3730e-07\n",
      "Epoch 199: early stopping\n",
      "Restoring model weights from the end of the best epoch: 184.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "vae.train_with_generator(\n",
    "    data_flow,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=NUM_IMAGES // BATCH_SIZE,\n",
    "    run_folder=RUN_FOLDER,\n",
    "    print_every_n_batches=PRINT_EVERY_N_BATCHES,\n",
    "    initial_epoch=INITIAL_EPOCH,\n",
    "    extra_callbacks=extra_callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial Loss: 1307.0924\n",
      "Final Loss: 373.6559\n",
      "\n",
      "Training history saved to: run/vae/0002_faces/viz/training_history.png\n"
     ]
    }
   ],
   "source": [
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# POST-TRAINING VISUALIZATION\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "history = vae.model.history.history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(history['loss'], 'b-', linewidth=2)\n",
    "axes[0].set_title('Training Loss', fontsize=14)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate plot (log scale)\n",
    "if 'learning_rate' in history:\n",
    "    axes[1].semilogy(history['learning_rate'], 'r-', linewidth=2)\n",
    "    axes[1].set_title('Learning Rate Schedule', fontsize=14)\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Learning Rate')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "else:\n",
    "    axes[1].text(0.5, 0.5, 'LR history not available', \n",
    "                 ha='center', va='center', fontsize=12)\n",
    "    axes[1].set_title('Learning Rate Schedule', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RUN_FOLDER, 'viz/training_history.png'), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nInitial Loss: {history['loss'][0]:.4f}\")\n",
    "print(f\"Final Loss: {history['loss'][-1]:.4f}\")\n",
    "print(f\"\\nTraining history saved to: {RUN_FOLDER}/viz/training_history.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>\u2581\u2581\u2581\u2581\u2582\u2582\u2582\u2582\u2582\u2583\u2583\u2583\u2583\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2585\u2585\u2585\u2585\u2586\u2586\u2586\u2586\u2586\u2586\u2587\u2587\u2587\u2587\u2587\u2587\u2587\u2587\u2588\u2588</td></tr><tr><td>epoch/learning_rate</td><td>\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581</td></tr><tr><td>epoch/loss</td><td>\u2588\u2588\u2587\u2586\u2586\u2585\u2585\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2583\u2583\u2583\u2583\u2583\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581</td></tr><tr><td>epoch/vae_r_loss</td><td>\u2588\u2588\u2588\u2587\u2587\u2586\u2586\u2585\u2583\u2583\u2583\u2583\u2583\u2583\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2581\u2582\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581</td></tr><tr><td>learning_rate</td><td>\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>198</td></tr><tr><td>epoch/learning_rate</td><td>0.0</td></tr><tr><td>epoch/loss</td><td>373.65588</td></tr><tr><td>epoch/vae_r_loss</td><td>297.22815</td></tr><tr><td>learning_rate</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vae-faces-0002</strong> at: <a href='https://wandb.ai/cataluna84/generative-deep-learning/runs/x0hjafbf' target=\"_blank\">https://wandb.ai/cataluna84/generative-deep-learning/runs/x0hjafbf</a><br> View project at: <a href='https://wandb.ai/cataluna84/generative-deep-learning' target=\"_blank\">https://wandb.ai/cataluna84/generative-deep-learning</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251230_204855-x0hjafbf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B run finished. Check your dashboard at https://wandb.ai\n"
     ]
    }
   ],
   "source": [
    "wandb.finish()\n",
    "print(\"W&B run finished. Check your dashboard at https://wandb.ai\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}