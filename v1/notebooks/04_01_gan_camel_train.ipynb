{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Training - Camel Dataset\n",
    "\n",
    "This notebook trains a Generative Adversarial Network (GAN) on the Camel\n",
    "dataset (Quick, Draw!) to generate hand-drawn camel sketches.\n",
    "\n",
    "## Features\n",
    "\n",
    "- **Dynamic Configuration**: Batch size and epochs adjust based on GPU VRAM\n",
    "- **W&B Integration**: Full experiment tracking with Weights & Biases\n",
    "- **LR Scheduling**: Step decay learning rate for stable training\n",
    "- **Enhanced Visualization**: Loss, accuracy, and LR history plots\n",
    "\n",
    "## Architecture\n",
    "\n",
    "- **Discriminator**: 4-layer CNN with strided convolutions\n",
    "- **Generator**: 4-layer deconvolution network with upsampling\n",
    "\n",
    "## References\n",
    "\n",
    "- Goodfellow et al. \"Generative Adversarial Networks\" (2014)\n",
    "- Chapter 4 of \"Generative Deep Learning\" book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Memory Setup\n",
    "\n",
    "Configure TensorFlow to use memory growth, preventing OOM errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 15:33:00.838884: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/cataluna84/Workspace-Antigravity/Generative_Deep_Learning/.venv/lib/python3.13/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ GPU(s) available: ['/physical_device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# GPU MEMORY CONFIGURATION\n",
    "# =============================================================================\n",
    "# Enable memory growth to prevent TensorFlow from allocating all GPU memory\n",
    "# at once. This must be done BEFORE any other TensorFlow operations.\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Get list of available GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    # Enable memory growth for each GPU\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(f\"✓ GPU(s) available: {[gpu.name for gpu in gpus]}\")\n",
    "else:\n",
    "    print(\"⚠ WARNING: No GPU detected, running on CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import all required modules including project utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS\n",
    "# =============================================================================\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Path Configuration\n",
    "# -----------------------------------------------------------------------------\n",
    "# Add parent directories to path for importing project modules\n",
    "# - '..' gives access to v1/src modules\n",
    "# - '../..' gives access to project root utils/ directory\n",
    "import sys\n",
    "sys.path.insert(0, '..')      # For v1/src modules\n",
    "sys.path.insert(0, '../..')   # For project root utils/\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Standard Library\n",
    "# -----------------------------------------------------------------------------\n",
    "import os\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Third-Party Libraries\n",
    "# -----------------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Project Modules\n",
    "# -----------------------------------------------------------------------------\n",
    "from src.models.GAN import GAN\n",
    "from src.utils.loaders import load_safari\n",
    "\n",
    "# GPU utilities for dynamic batch size and epoch scaling\n",
    "# Located in project root: utils/gpu_utils.py\n",
    "from utils.gpu_utils import (\n",
    "    get_optimal_batch_size,\n",
    "    calculate_adjusted_epochs,\n",
    "    get_gpu_vram_gb,\n",
    "    print_training_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Configuration\n",
    "\n",
    "Central configuration cell with all training hyperparameters.\n",
    "Batch size and epochs are automatically optimized based on GPU VRAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "════════════════════════════════════════════════════════════════════\n",
      "TRAINING CONFIGURATION\n",
      "════════════════════════════════════════════════════════════════════\n",
      "Model Type:     GAN\n",
      "GPU VRAM:       8 GB\n",
      "Batch Size:     1024 (reference: 256)\n",
      "Epochs:         1500 (reference: 6000)\n",
      "Scale Factor:   0.25x epochs\n",
      "════════════════════════════════════════════════════════════════════\n",
      "LR Decay: ×0.5 every 375 epochs\n",
      "Checkpoints: Every 12 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1767367992.286248   59894 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6094 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# GLOBAL CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Run Identification\n",
    "# -----------------------------------------------------------------------------\n",
    "SECTION = 'gan'\n",
    "RUN_ID = '0001'\n",
    "DATA_NAME = 'camel'\n",
    "RUN_FOLDER = f'../run/{SECTION}/{RUN_ID}_{DATA_NAME}'\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Create Run Directories\n",
    "# -----------------------------------------------------------------------------\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.makedirs(RUN_FOLDER)\n",
    "    os.makedirs(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.makedirs(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.makedirs(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Reference Training Configuration\n",
    "# These are the original notebook values used as baseline\n",
    "# -----------------------------------------------------------------------------\n",
    "REFERENCE_BATCH_SIZE = 256\n",
    "REFERENCE_EPOCHS = 6000\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Dynamic Training Configuration\n",
    "# Automatically optimized based on available GPU VRAM\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# VRAM Override: Set to specific value (e.g., 8) or None for auto-detection\n",
    "# Use this when you want to force a specific configuration\n",
    "TARGET_VRAM_GB = None  # Options: None, 6, 8, 12, 16, 24\n",
    "\n",
    "# Detect GPU VRAM or use manual override\n",
    "GPU_VRAM_GB = TARGET_VRAM_GB if TARGET_VRAM_GB else get_gpu_vram_gb()\n",
    "\n",
    "# Calculate optimal batch size for detected VRAM\n",
    "# Larger VRAM = larger batch size = faster training\n",
    "BATCH_SIZE = get_optimal_batch_size('gan', vram_gb=GPU_VRAM_GB)\n",
    "\n",
    "# Scale epochs to maintain equivalent total training updates\n",
    "# Formula: reference_epochs × (reference_batch / actual_batch)\n",
    "EPOCHS = calculate_adjusted_epochs(\n",
    "    REFERENCE_EPOCHS,\n",
    "    REFERENCE_BATCH_SIZE,\n",
    "    BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Adjust checkpoint frequency proportionally\n",
    "PRINT_EVERY_N_BATCHES = max(50 * REFERENCE_BATCH_SIZE // BATCH_SIZE, 10)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Learning Rate Scheduler Configuration\n",
    "# Step decay: Reduce LR at fixed intervals for stable late-stage training\n",
    "# -----------------------------------------------------------------------------\n",
    "LR_DECAY_FACTOR = 0.5  # Multiply LR by this factor at each decay point\n",
    "LR_DECAY_EPOCHS = EPOCHS // 4  # Decay 4 times during training\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Training Mode\n",
    "# -----------------------------------------------------------------------------\n",
    "MODE = 'build'  # Options: 'build' (new training), 'load' (resume from weights)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Print Configuration Summary\n",
    "# -----------------------------------------------------------------------------\n",
    "print_training_config(\n",
    "    'gan',\n",
    "    BATCH_SIZE,\n",
    "    EPOCHS,\n",
    "    REFERENCE_BATCH_SIZE,\n",
    "    REFERENCE_EPOCHS,\n",
    "    GPU_VRAM_GB\n",
    ")\n",
    "print(f\"LR Decay: ×{LR_DECAY_FACTOR} every {LR_DECAY_EPOCHS} epochs\")\n",
    "print(f\"Checkpoints: Every {PRINT_EVERY_N_BATCHES} epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Load the Camel dataset from Quick, Draw! collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: camel\n",
      "Training samples: 80,000\n",
      "Image dimensions: (28, 28, 1)\n",
      "Data type: float32\n",
      "Value range: [-1.00, 1.00]\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DATA LOADING\n",
    "# =============================================================================\n",
    "# Load the camel dataset from the Quick, Draw! collection\n",
    "# Images are 28x28 grayscale drawings\n",
    "\n",
    "(x_train, y_train) = load_safari(DATA_NAME)\n",
    "\n",
    "# Print dataset information\n",
    "print(f\"Dataset: {DATA_NAME}\")\n",
    "print(f\"Training samples: {x_train.shape[0]:,}\")\n",
    "print(f\"Image dimensions: {x_train.shape[1:]}\")\n",
    "print(f\"Data type: {x_train.dtype}\")\n",
    "print(f\"Value range: [{x_train.min():.2f}, {x_train.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SAMPLE VISUALIZATION\n",
    "# =============================================================================\n",
    "# Display a sample image from the dataset\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(12, 3))\n",
    "fig.suptitle('Sample Camel Drawings', fontsize=14)\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    idx = np.random.randint(0, x_train.shape[0])\n",
    "    ax.imshow(x_train[idx, :, :, 0], cmap='gray_r')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'Sample {idx}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "Build the GAN with discriminator and generator networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ GAN model built successfully\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MODEL ARCHITECTURE\n",
    "# =============================================================================\n",
    "# Build the GAN with configurable discriminator and generator\n",
    "#\n",
    "# Discriminator Architecture:\n",
    "#   Input (28, 28, 1) → Conv layers → Flatten → Dense(1, sigmoid)\n",
    "#\n",
    "# Generator Architecture:\n",
    "#   Input (z_dim,) → Dense → Reshape → ConvTranspose layers → Output (28, 28, 1)\n",
    "\n",
    "gan = GAN(\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Input Configuration\n",
    "    # -------------------------------------------------------------------------\n",
    "    input_dim=(28, 28, 1),  # 28x28 grayscale images\n",
    "    z_dim=100,              # Latent space dimension\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Discriminator Configuration\n",
    "    # 4 convolutional layers with increasing filters\n",
    "    # -------------------------------------------------------------------------\n",
    "    discriminator_conv_filters=[64, 64, 128, 128],\n",
    "    discriminator_conv_kernel_size=[5, 5, 5, 5],\n",
    "    discriminator_conv_strides=[2, 2, 2, 1],\n",
    "    discriminator_batch_norm_momentum=None,  # No batch norm in discriminator\n",
    "    discriminator_activation='relu',\n",
    "    discriminator_dropout_rate=0.4,\n",
    "    discriminator_learning_rate=0.0008,\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Generator Configuration\n",
    "    # 4 upsampling layers to generate 28x28 output\n",
    "    # -------------------------------------------------------------------------\n",
    "    generator_initial_dense_layer_size=(7, 7, 64),  # Start from 7x7\n",
    "    generator_upsample=[2, 2, 1, 1],  # Upsample to 14x14, then 28x28\n",
    "    generator_conv_filters=[128, 64, 64, 1],\n",
    "    generator_conv_kernel_size=[5, 5, 5, 5],\n",
    "    generator_conv_strides=[1, 1, 1, 1],\n",
    "    generator_batch_norm_momentum=0.9,\n",
    "    generator_activation='relu',\n",
    "    generator_dropout_rate=None,  # No dropout in generator\n",
    "    generator_learning_rate=0.0004,\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Optimizer\n",
    "    # -------------------------------------------------------------------------\n",
    "    optimiser='rmsprop'  # RMSprop works well for GANs\n",
    ")\n",
    "\n",
    "print(\"✓ GAN model built successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"discriminator\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"discriminator\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ discriminator_input             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ discriminator_conv_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ discriminator_conv_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ discriminator_conv_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">204,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ discriminator_conv_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">409,728</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ discriminator_input             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ discriminator_conv_0 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m1,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ discriminator_conv_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │       \u001b[38;5;34m102,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ discriminator_conv_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m204,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ discriminator_conv_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m409,728\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m2,049\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">720,833</span> (2.75 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m720,833\u001b[0m (2.75 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">720,833</span> (2.75 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m720,833\u001b[0m (2.75 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DISCRIMINATOR ARCHITECTURE\n",
    "# =============================================================================\n",
    "gan.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"generator\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"generator\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ generator_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">316,736</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,544</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ generator_conv_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">204,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ generator_conv_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">204,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ generator_conv_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ generator_conv_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,601</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ generator_input (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m)           │       \u001b[38;5;34m316,736\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m)           │        \u001b[38;5;34m12,544\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d (\u001b[38;5;33mUpSampling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ generator_conv_0 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m204,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_1 (\u001b[38;5;33mUpSampling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ generator_conv_1 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │       \u001b[38;5;34m204,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ generator_conv_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │       \u001b[38;5;34m102,464\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_7 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ generator_conv_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │         \u001b[38;5;34m1,601\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_8 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">844,161</span> (3.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m844,161\u001b[0m (3.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">837,377</span> (3.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m837,377\u001b[0m (3.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,784</span> (26.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m6,784\u001b[0m (26.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# GENERATOR ARCHITECTURE\n",
    "# =============================================================================\n",
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W&B Initialization\n",
    "\n",
    "Initialize Weights & Biases for experiment tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcataluna84\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/cataluna84/Workspace-Antigravity/Generative_Deep_Learning/v1/notebooks/wandb/run-20260102_153319-uexhdo3y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cataluna84/generative-deep-learning/runs/uexhdo3y' target=\"_blank\">gan-camel-bs1024</a></strong> to <a href='https://wandb.ai/cataluna84/generative-deep-learning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cataluna84/generative-deep-learning' target=\"_blank\">https://wandb.ai/cataluna84/generative-deep-learning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cataluna84/generative-deep-learning/runs/uexhdo3y' target=\"_blank\">https://wandb.ai/cataluna84/generative-deep-learning/runs/uexhdo3y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ W&B initialized\n",
      "  Project: generative-deep-learning\n",
      "  Run: gan-camel-bs1024\n",
      "  URL: https://wandb.ai/cataluna84/generative-deep-learning/runs/uexhdo3y\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# W&B INITIALIZATION\n",
    "# =============================================================================\n",
    "# Initialize Weights & Biases for experiment tracking\n",
    "# This logs all training metrics, sample images, and hyperparameters\n",
    "\n",
    "wandb.init(\n",
    "    project=\"generative-deep-learning\",\n",
    "    name=f\"gan-{DATA_NAME}-bs{BATCH_SIZE}\",\n",
    "    config={\n",
    "        # Model Configuration\n",
    "        \"model\": \"GAN\",\n",
    "        \"dataset\": DATA_NAME,\n",
    "        \"input_dim\": gan.input_dim,\n",
    "        \"z_dim\": gan.z_dim,\n",
    "        \n",
    "        # Training Configuration\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"reference_batch_size\": REFERENCE_BATCH_SIZE,\n",
    "        \"reference_epochs\": REFERENCE_EPOCHS,\n",
    "        \n",
    "        # Optimizer Configuration\n",
    "        \"discriminator_lr\": gan.discriminator_learning_rate,\n",
    "        \"generator_lr\": gan.generator_learning_rate,\n",
    "        \"optimizer\": gan.optimiser,\n",
    "        \n",
    "        # LR Scheduler Configuration\n",
    "        \"lr_decay_factor\": LR_DECAY_FACTOR,\n",
    "        \"lr_decay_epochs\": LR_DECAY_EPOCHS,\n",
    "        \n",
    "        # Environment\n",
    "        \"gpu_vram_gb\": GPU_VRAM_GB,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"✓ W&B initialized\")\n",
    "print(f\"  Project: generative-deep-learning\")\n",
    "print(f\"  Run: gan-{DATA_NAME}-bs{BATCH_SIZE}\")\n",
    "print(f\"  URL: {wandb.run.url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Train the GAN with W&B logging and LR scheduling enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 15:33:22.221501: I external/local_xla/xla/service/service.cc:163] XLA service 0x78e54c0031e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2026-01-02 15:33:22.221564: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 2070, Compute Capability 7.5\n",
      "2026-01-02 15:33:22.326019: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2026-01-02 15:33:22.508566: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91701\n",
      "2026-01-02 15:33:24.005233: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[32,128,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,14,14]{3,2,1,0}, f32[128,64,5,5]{3,2,1,0}, f32[128]{0}), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "2026-01-02 15:33:25.474621: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[32,64,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,28,28]{3,2,1,0}, f32[64,128,5,5]{3,2,1,0}, f32[64]{0}), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "I0000 00:00:1767368007.810357   60027 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2026-01-02 15:33:50.275204: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[1024,128,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[1024,64,14,14]{3,2,1,0}, f32[128,64,5,5]{3,2,1,0}, f32[128]{0}), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "2026-01-02 15:33:52.299022: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[1024,64,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[1024,128,28,28]{3,2,1,0}, f32[64,128,5,5]{3,2,1,0}, f32[64]{0}), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "2026-01-02 15:33:55.491943: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng11{k2=3,k3=0} for conv (f32[1024,64,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[1024,128,28,28]{3,2,1,0}, f32[64,128,5,5]{3,2,1,0}, f32[64]{0}), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "2026-01-02 15:33:55.508303: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.01657703s\n",
      "Trying algorithm eng11{k2=3,k3=0} for conv (f32[1024,64,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[1024,128,28,28]{3,2,1,0}, f32[64,128,5,5]{3,2,1,0}, f32[64]{0}), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "2026-01-02 15:33:58.178313: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng0{} for conv (f32[1024,64,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[1024,128,28,28]{3,2,1,0}, f32[64,128,5,5]{3,2,1,0}, f32[64]{0}), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "2026-01-02 15:33:58.673942: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.495928036s\n",
      "Trying algorithm eng0{} for conv (f32[1024,64,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[1024,128,28,28]{3,2,1,0}, f32[64,128,5,5]{3,2,1,0}, f32[64]{0}), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "2026-01-02 15:34:08.367238: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:382] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2026-01-02 15:34:09.367337: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng7{k25=2} for conv (f32[1024,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[1024,64,28,28]{3,2,1,0}, f32[64,128,5,5]{3,2,1,0}), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "2026-01-02 15:34:09.469708: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.102575402s\n",
      "Trying algorithm eng7{k25=2} for conv (f32[1024,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[1024,64,28,28]{3,2,1,0}, f32[64,128,5,5]{3,2,1,0}), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: (0.703)(R 0.700, F 0.705)] [D acc: (0.179)(0.239, 0.120)] [G loss: 0.666] [G acc: 1.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 15:34:35.745366: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[25,128,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[25,64,14,14]{3,2,1,0}, f32[128,64,5,5]{3,2,1,0}, f32[128]{0}), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "2026-01-02 15:34:35.842051: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{k25=2} for conv (f32[25,64,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[25,128,28,28]{3,2,1,0}, f32[64,128,5,5]{3,2,1,0}, f32[64]{0}), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [D loss: (0.721)(R 0.637, F 0.804)] [D acc: (0.361)(0.413, 0.310)] [G loss: 0.598] [G acc: 1.000]\n",
      "2 [D loss: (0.725)(R 0.678, F 0.773)] [D acc: (0.411)(0.448, 0.373)] [G loss: 0.501] [G acc: 1.000]\n",
      "3 [D loss: (0.692)(R 0.671, F 0.714)] [D acc: (0.434)(0.463, 0.405)] [G loss: 0.411] [G acc: 1.000]\n",
      "4 [D loss: (0.662)(R 0.638, F 0.686)] [D acc: (0.447)(0.471, 0.424)] [G loss: 0.379] [G acc: 1.000]\n",
      "5 [D loss: (0.654)(R 0.630, F 0.678)] [D acc: (0.456)(0.476, 0.437)] [G loss: 0.374] [G acc: 1.000]\n",
      "6 [D loss: (0.656)(R 0.636, F 0.677)] [D acc: (0.463)(0.480, 0.446)] [G loss: 0.377] [G acc: 1.000]\n",
      "7 [D loss: (0.660)(R 0.642, F 0.677)] [D acc: (0.468)(0.483, 0.452)] [G loss: 0.385] [G acc: 1.000]\n",
      "8 [D loss: (0.661)(R 0.647, F 0.674)] [D acc: (0.471)(0.485, 0.458)] [G loss: 0.396] [G acc: 1.000]\n",
      "9 [D loss: (0.659)(R 0.648, F 0.670)] [D acc: (0.474)(0.486, 0.462)] [G loss: 0.408] [G acc: 1.000]\n",
      "10 [D loss: (0.654)(R 0.646, F 0.663)] [D acc: (0.477)(0.488, 0.465)] [G loss: 0.422] [G acc: 1.000]\n",
      "11 [D loss: (0.647)(R 0.640, F 0.653)] [D acc: (0.478)(0.489, 0.468)] [G loss: 0.435] [G acc: 1.000]\n",
      "12 [D loss: (0.636)(R 0.631, F 0.642)] [D acc: (0.480)(0.490, 0.471)] [G loss: 0.449] [G acc: 1.000]\n",
      "13 [D loss: (0.624)(R 0.620, F 0.628)] [D acc: (0.482)(0.490, 0.473)] [G loss: 0.462] [G acc: 1.000]\n",
      "14 [D loss: (0.611)(R 0.608, F 0.615)] [D acc: (0.483)(0.491, 0.475)] [G loss: 0.474] [G acc: 1.000]\n",
      "15 [D loss: (0.599)(R 0.596, F 0.601)] [D acc: (0.484)(0.492, 0.476)] [G loss: 0.486] [G acc: 1.000]\n",
      "16 [D loss: (0.586)(R 0.584, F 0.588)] [D acc: (0.485)(0.492, 0.478)] [G loss: 0.498] [G acc: 1.000]\n",
      "17 [D loss: (0.574)(R 0.572, F 0.576)] [D acc: (0.486)(0.493, 0.479)] [G loss: 0.508] [G acc: 1.000]\n",
      "18 [D loss: (0.563)(R 0.561, F 0.565)] [D acc: (0.486)(0.493, 0.480)] [G loss: 0.518] [G acc: 0.972]\n",
      "19 [D loss: (0.552)(R 0.551, F 0.554)] [D acc: (0.488)(0.493, 0.482)] [G loss: 0.527] [G acc: 0.925]\n",
      "20 [D loss: (0.543)(R 0.541, F 0.544)] [D acc: (0.497)(0.495, 0.500)] [G loss: 0.535] [G acc: 0.881]\n",
      "21 [D loss: (0.534)(R 0.532, F 0.535)] [D acc: (0.517)(0.512, 0.522)] [G loss: 0.542] [G acc: 0.841]\n",
      "22 [D loss: (0.525)(R 0.524, F 0.527)] [D acc: (0.537)(0.532, 0.542)] [G loss: 0.549] [G acc: 0.804]\n",
      "23 [D loss: (0.518)(R 0.516, F 0.520)] [D acc: (0.557)(0.552, 0.561)] [G loss: 0.555] [G acc: 0.771]\n",
      "24 [D loss: (0.511)(R 0.509, F 0.513)] [D acc: (0.575)(0.570, 0.579)] [G loss: 0.561] [G acc: 0.740]\n",
      "25 [D loss: (0.505)(R 0.503, F 0.506)] [D acc: (0.591)(0.587, 0.595)] [G loss: 0.566] [G acc: 0.711]\n",
      "26 [D loss: (0.499)(R 0.497, F 0.500)] [D acc: (0.606)(0.603, 0.610)] [G loss: 0.571] [G acc: 0.685]\n",
      "27 [D loss: (0.493)(R 0.491, F 0.495)] [D acc: (0.621)(0.617, 0.624)] [G loss: 0.576] [G acc: 0.661]\n",
      "28 [D loss: (0.488)(R 0.486, F 0.490)] [D acc: (0.634)(0.631, 0.637)] [G loss: 0.580] [G acc: 0.638]\n",
      "29 [D loss: (0.483)(R 0.481, F 0.485)] [D acc: (0.646)(0.643, 0.649)] [G loss: 0.584] [G acc: 0.617]\n",
      "30 [D loss: (0.478)(R 0.477, F 0.480)] [D acc: (0.658)(0.655, 0.660)] [G loss: 0.588] [G acc: 0.597]\n",
      "31 [D loss: (0.474)(R 0.473, F 0.476)] [D acc: (0.668)(0.666, 0.671)] [G loss: 0.591] [G acc: 0.578]\n",
      "32 [D loss: (0.470)(R 0.469, F 0.472)] [D acc: (0.678)(0.676, 0.681)] [G loss: 0.594] [G acc: 0.561]\n",
      "33 [D loss: (0.466)(R 0.465, F 0.468)] [D acc: (0.688)(0.686, 0.690)] [G loss: 0.598] [G acc: 0.544]\n",
      "34 [D loss: (0.463)(R 0.461, F 0.465)] [D acc: (0.697)(0.695, 0.699)] [G loss: 0.601] [G acc: 0.529]\n",
      "35 [D loss: (0.460)(R 0.458, F 0.461)] [D acc: (0.705)(0.703, 0.708)] [G loss: 0.603] [G acc: 0.514]\n",
      "36 [D loss: (0.456)(R 0.455, F 0.458)] [D acc: (0.713)(0.712, 0.715)] [G loss: 0.606] [G acc: 0.500]\n",
      "37 [D loss: (0.453)(R 0.452, F 0.455)] [D acc: (0.721)(0.719, 0.723)] [G loss: 0.609] [G acc: 0.487]\n",
      "38 [D loss: (0.450)(R 0.449, F 0.452)] [D acc: (0.728)(0.726, 0.730)] [G loss: 0.611] [G acc: 0.474]\n",
      "39 [D loss: (0.448)(R 0.446, F 0.449)] [D acc: (0.735)(0.733, 0.737)] [G loss: 0.614] [G acc: 0.462]\n",
      "40 [D loss: (0.445)(R 0.444, F 0.447)] [D acc: (0.742)(0.740, 0.743)] [G loss: 0.616] [G acc: 0.451]\n",
      "41 [D loss: (0.443)(R 0.441, F 0.444)] [D acc: (0.748)(0.746, 0.749)] [G loss: 0.618] [G acc: 0.440]\n",
      "42 [D loss: (0.440)(R 0.439, F 0.442)] [D acc: (0.754)(0.752, 0.755)] [G loss: 0.620] [G acc: 0.430]\n",
      "43 [D loss: (0.438)(R 0.437, F 0.439)] [D acc: (0.759)(0.758, 0.761)] [G loss: 0.622] [G acc: 0.420]\n",
      "44 [D loss: (0.436)(R 0.434, F 0.437)] [D acc: (0.765)(0.763, 0.766)] [G loss: 0.624] [G acc: 0.411]\n",
      "45 [D loss: (0.434)(R 0.432, F 0.435)] [D acc: (0.770)(0.769, 0.771)] [G loss: 0.626] [G acc: 0.402]\n",
      "46 [D loss: (0.432)(R 0.430, F 0.433)] [D acc: (0.775)(0.774, 0.776)] [G loss: 0.628] [G acc: 0.394]\n",
      "47 [D loss: (0.430)(R 0.428, F 0.431)] [D acc: (0.779)(0.778, 0.781)] [G loss: 0.630] [G acc: 0.385]\n",
      "48 [D loss: (0.428)(R 0.426, F 0.430)] [D acc: (0.779)(0.783, 0.775)] [G loss: 0.632] [G acc: 0.378]\n",
      "49 [D loss: (0.427)(R 0.426, F 0.429)] [D acc: (0.778)(0.777, 0.779)] [G loss: 0.633] [G acc: 0.370]\n",
      "50 [D loss: (0.426)(R 0.424, F 0.427)] [D acc: (0.783)(0.782, 0.784)] [G loss: 0.635] [G acc: 0.363]\n",
      "51 [D loss: (0.424)(R 0.423, F 0.425)] [D acc: (0.787)(0.786, 0.788)] [G loss: 0.637] [G acc: 0.356]\n",
      "52 [D loss: (0.422)(R 0.421, F 0.423)] [D acc: (0.791)(0.790, 0.792)] [G loss: 0.639] [G acc: 0.349]\n",
      "53 [D loss: (0.420)(R 0.419, F 0.422)] [D acc: (0.795)(0.794, 0.796)] [G loss: 0.640] [G acc: 0.343]\n",
      "54 [D loss: (0.419)(R 0.418, F 0.420)] [D acc: (0.799)(0.798, 0.799)] [G loss: 0.642] [G acc: 0.336]\n",
      "55 [D loss: (0.417)(R 0.416, F 0.418)] [D acc: (0.802)(0.801, 0.803)] [G loss: 0.644] [G acc: 0.330]\n",
      "56 [D loss: (0.416)(R 0.415, F 0.417)] [D acc: (0.806)(0.805, 0.806)] [G loss: 0.645] [G acc: 0.325]\n",
      "57 [D loss: (0.414)(R 0.413, F 0.415)] [D acc: (0.809)(0.808, 0.810)] [G loss: 0.647] [G acc: 0.319]\n",
      "58 [D loss: (0.413)(R 0.412, F 0.414)] [D acc: (0.812)(0.811, 0.813)] [G loss: 0.649] [G acc: 0.314]\n",
      "59 [D loss: (0.411)(R 0.410, F 0.412)] [D acc: (0.815)(0.815, 0.816)] [G loss: 0.651] [G acc: 0.308]\n",
      "60 [D loss: (0.410)(R 0.409, F 0.411)] [D acc: (0.818)(0.818, 0.819)] [G loss: 0.653] [G acc: 0.303]\n",
      "61 [D loss: (0.408)(R 0.407, F 0.409)] [D acc: (0.821)(0.821, 0.822)] [G loss: 0.655] [G acc: 0.298]\n",
      "62 [D loss: (0.407)(R 0.406, F 0.407)] [D acc: (0.824)(0.824, 0.825)] [G loss: 0.657] [G acc: 0.294]\n",
      "63 [D loss: (0.405)(R 0.404, F 0.406)] [D acc: (0.827)(0.826, 0.828)] [G loss: 0.660] [G acc: 0.289]\n",
      "64 [D loss: (0.403)(R 0.403, F 0.404)] [D acc: (0.830)(0.829, 0.830)] [G loss: 0.662] [G acc: 0.285]\n",
      "65 [D loss: (0.402)(R 0.401, F 0.403)] [D acc: (0.832)(0.832, 0.833)] [G loss: 0.665] [G acc: 0.280]\n",
      "66 [D loss: (0.400)(R 0.399, F 0.401)] [D acc: (0.835)(0.834, 0.835)] [G loss: 0.669] [G acc: 0.276]\n",
      "67 [D loss: (0.398)(R 0.398, F 0.399)] [D acc: (0.837)(0.837, 0.838)] [G loss: 0.672] [G acc: 0.272]\n",
      "68 [D loss: (0.397)(R 0.396, F 0.397)] [D acc: (0.840)(0.839, 0.840)] [G loss: 0.676] [G acc: 0.268]\n",
      "69 [D loss: (0.395)(R 0.394, F 0.395)] [D acc: (0.842)(0.841, 0.842)] [G loss: 0.680] [G acc: 0.264]\n",
      "70 [D loss: (0.393)(R 0.392, F 0.393)] [D acc: (0.844)(0.844, 0.845)] [G loss: 0.686] [G acc: 0.261]\n",
      "71 [D loss: (0.391)(R 0.390, F 0.391)] [D acc: (0.846)(0.846, 0.847)] [G loss: 0.692] [G acc: 0.257]\n",
      "72 [D loss: (0.389)(R 0.388, F 0.389)] [D acc: (0.848)(0.848, 0.849)] [G loss: 0.706] [G acc: 0.253]\n",
      "73 [D loss: (0.389)(R 0.388, F 0.389)] [D acc: (0.849)(0.850, 0.849)] [G loss: 0.712] [G acc: 0.250]\n",
      "74 [D loss: (0.387)(R 0.387, F 0.387)] [D acc: (0.850)(0.850, 0.851)] [G loss: 0.719] [G acc: 0.247]\n",
      "75 [D loss: (0.385)(R 0.385, F 0.385)] [D acc: (0.852)(0.852, 0.852)] [G loss: 0.728] [G acc: 0.243]\n",
      "76 [D loss: (0.382)(R 0.382, F 0.382)] [D acc: (0.854)(0.853, 0.854)] [G loss: 0.737] [G acc: 0.240]\n",
      "77 [D loss: (0.381)(R 0.379, F 0.383)] [D acc: (0.853)(0.855, 0.851)] [G loss: 0.772] [G acc: 0.237]\n",
      "78 [D loss: (0.381)(R 0.381, F 0.381)] [D acc: (0.853)(0.852, 0.853)] [G loss: 0.785] [G acc: 0.234]\n",
      "79 [D loss: (0.378)(R 0.378, F 0.377)] [D acc: (0.855)(0.854, 0.855)] [G loss: 0.800] [G acc: 0.231]\n",
      "80 [D loss: (0.376)(R 0.375, F 0.376)] [D acc: (0.856)(0.856, 0.856)] [G loss: 0.815] [G acc: 0.228]\n",
      "81 [D loss: (0.375)(R 0.374, F 0.377)] [D acc: (0.855)(0.857, 0.854)] [G loss: 0.836] [G acc: 0.226]\n",
      "82 [D loss: (0.385)(R 0.378, F 0.392)] [D acc: (0.850)(0.853, 0.848)] [G loss: 0.836] [G acc: 0.225]\n",
      "83 [D loss: (0.391)(R 0.390, F 0.392)] [D acc: (0.848)(0.848, 0.849)] [G loss: 0.831] [G acc: 0.234]\n",
      "84 [D loss: (0.399)(R 0.389, F 0.408)] [D acc: (0.847)(0.849, 0.844)] [G loss: 0.829] [G acc: 0.240]\n",
      "85 [D loss: (0.410)(R 0.407, F 0.413)] [D acc: (0.843)(0.845, 0.840)] [G loss: 0.826] [G acc: 0.249]\n",
      "86 [D loss: (0.415)(R 0.412, F 0.418)] [D acc: (0.839)(0.841, 0.836)] [G loss: 0.824] [G acc: 0.257]\n",
      "87 [D loss: (0.420)(R 0.417, F 0.423)] [D acc: (0.835)(0.837, 0.833)] [G loss: 0.821] [G acc: 0.264]\n",
      "88 [D loss: (0.425)(R 0.422, F 0.428)] [D acc: (0.831)(0.834, 0.829)] [G loss: 0.819] [G acc: 0.270]\n",
      "89 [D loss: (0.429)(R 0.427, F 0.432)] [D acc: (0.828)(0.830, 0.825)] [G loss: 0.818] [G acc: 0.275]\n",
      "90 [D loss: (0.433)(R 0.431, F 0.436)] [D acc: (0.824)(0.826, 0.822)] [G loss: 0.816] [G acc: 0.279]\n",
      "91 [D loss: (0.437)(R 0.435, F 0.439)] [D acc: (0.820)(0.823, 0.818)] [G loss: 0.815] [G acc: 0.283]\n",
      "92 [D loss: (0.441)(R 0.439, F 0.443)] [D acc: (0.817)(0.819, 0.815)] [G loss: 0.813] [G acc: 0.285]\n",
      "93 [D loss: (0.445)(R 0.443, F 0.446)] [D acc: (0.814)(0.816, 0.811)] [G loss: 0.812] [G acc: 0.287]\n",
      "94 [D loss: (0.448)(R 0.446, F 0.450)] [D acc: (0.810)(0.812, 0.808)] [G loss: 0.811] [G acc: 0.289]\n",
      "95 [D loss: (0.451)(R 0.450, F 0.453)] [D acc: (0.807)(0.809, 0.805)] [G loss: 0.809] [G acc: 0.292]\n",
      "96 [D loss: (0.455)(R 0.453, F 0.456)] [D acc: (0.804)(0.806, 0.802)] [G loss: 0.808] [G acc: 0.295]\n",
      "97 [D loss: (0.458)(R 0.456, F 0.460)] [D acc: (0.801)(0.803, 0.799)] [G loss: 0.807] [G acc: 0.300]\n",
      "98 [D loss: (0.461)(R 0.460, F 0.463)] [D acc: (0.798)(0.800, 0.796)] [G loss: 0.805] [G acc: 0.305]\n",
      "99 [D loss: (0.465)(R 0.463, F 0.466)] [D acc: (0.795)(0.797, 0.793)] [G loss: 0.803] [G acc: 0.312]\n",
      "100 [D loss: (0.468)(R 0.466, F 0.469)] [D acc: (0.792)(0.794, 0.790)] [G loss: 0.801] [G acc: 0.318]\n",
      "101 [D loss: (0.471)(R 0.470, F 0.473)] [D acc: (0.789)(0.791, 0.787)] [G loss: 0.799] [G acc: 0.325]\n",
      "102 [D loss: (0.474)(R 0.473, F 0.476)] [D acc: (0.786)(0.788, 0.784)] [G loss: 0.797] [G acc: 0.331]\n",
      "103 [D loss: (0.477)(R 0.476, F 0.479)] [D acc: (0.783)(0.785, 0.781)] [G loss: 0.796] [G acc: 0.337]\n",
      "104 [D loss: (0.480)(R 0.479, F 0.482)] [D acc: (0.781)(0.782, 0.779)] [G loss: 0.794] [G acc: 0.344]\n",
      "105 [D loss: (0.483)(R 0.482, F 0.484)] [D acc: (0.778)(0.780, 0.776)] [G loss: 0.792] [G acc: 0.350]\n",
      "106 [D loss: (0.486)(R 0.485, F 0.487)] [D acc: (0.775)(0.777, 0.773)] [G loss: 0.791] [G acc: 0.356]\n",
      "107 [D loss: (0.488)(R 0.487, F 0.490)] [D acc: (0.773)(0.774, 0.771)] [G loss: 0.789] [G acc: 0.362]\n",
      "108 [D loss: (0.491)(R 0.490, F 0.492)] [D acc: (0.770)(0.772, 0.768)] [G loss: 0.787] [G acc: 0.367]\n",
      "109 [D loss: (0.493)(R 0.492, F 0.494)] [D acc: (0.768)(0.769, 0.766)] [G loss: 0.786] [G acc: 0.373]\n",
      "110 [D loss: (0.496)(R 0.495, F 0.497)] [D acc: (0.765)(0.767, 0.764)] [G loss: 0.785] [G acc: 0.378]\n",
      "111 [D loss: (0.498)(R 0.497, F 0.499)] [D acc: (0.763)(0.765, 0.761)] [G loss: 0.783] [G acc: 0.384]\n",
      "112 [D loss: (0.500)(R 0.499, F 0.501)] [D acc: (0.761)(0.762, 0.759)] [G loss: 0.782] [G acc: 0.389]\n",
      "113 [D loss: (0.502)(R 0.501, F 0.503)] [D acc: (0.758)(0.760, 0.757)] [G loss: 0.781] [G acc: 0.394]\n",
      "114 [D loss: (0.504)(R 0.503, F 0.505)] [D acc: (0.756)(0.758, 0.754)] [G loss: 0.779] [G acc: 0.399]\n",
      "115 [D loss: (0.506)(R 0.505, F 0.507)] [D acc: (0.754)(0.755, 0.752)] [G loss: 0.778] [G acc: 0.404]\n",
      "116 [D loss: (0.508)(R 0.507, F 0.509)] [D acc: (0.752)(0.753, 0.750)] [G loss: 0.777] [G acc: 0.409]\n",
      "117 [D loss: (0.510)(R 0.509, F 0.511)] [D acc: (0.749)(0.751, 0.748)] [G loss: 0.776] [G acc: 0.414]\n",
      "118 [D loss: (0.512)(R 0.511, F 0.513)] [D acc: (0.747)(0.749, 0.746)] [G loss: 0.775] [G acc: 0.418]\n",
      "119 [D loss: (0.514)(R 0.513, F 0.515)] [D acc: (0.745)(0.747, 0.744)] [G loss: 0.774] [G acc: 0.423]\n",
      "120 [D loss: (0.516)(R 0.515, F 0.516)] [D acc: (0.743)(0.745, 0.742)] [G loss: 0.773] [G acc: 0.427]\n",
      "121 [D loss: (0.518)(R 0.517, F 0.518)] [D acc: (0.741)(0.743, 0.740)] [G loss: 0.772] [G acc: 0.431]\n",
      "122 [D loss: (0.519)(R 0.519, F 0.520)] [D acc: (0.739)(0.741, 0.738)] [G loss: 0.771] [G acc: 0.436]\n",
      "123 [D loss: (0.521)(R 0.520, F 0.522)] [D acc: (0.737)(0.739, 0.736)] [G loss: 0.770] [G acc: 0.440]\n",
      "124 [D loss: (0.523)(R 0.522, F 0.523)] [D acc: (0.735)(0.737, 0.734)] [G loss: 0.769] [G acc: 0.444]\n",
      "125 [D loss: (0.524)(R 0.524, F 0.525)] [D acc: (0.733)(0.735, 0.732)] [G loss: 0.768] [G acc: 0.448]\n",
      "126 [D loss: (0.526)(R 0.525, F 0.527)] [D acc: (0.732)(0.733, 0.730)] [G loss: 0.767] [G acc: 0.452]\n",
      "127 [D loss: (0.527)(R 0.527, F 0.528)] [D acc: (0.730)(0.731, 0.728)] [G loss: 0.766] [G acc: 0.456]\n",
      "128 [D loss: (0.529)(R 0.528, F 0.530)] [D acc: (0.728)(0.729, 0.727)] [G loss: 0.765] [G acc: 0.460]\n",
      "129 [D loss: (0.530)(R 0.530, F 0.531)] [D acc: (0.726)(0.728, 0.725)] [G loss: 0.764] [G acc: 0.464]\n",
      "130 [D loss: (0.532)(R 0.531, F 0.532)] [D acc: (0.724)(0.726, 0.723)] [G loss: 0.763] [G acc: 0.468]\n",
      "131 [D loss: (0.533)(R 0.533, F 0.534)] [D acc: (0.723)(0.724, 0.721)] [G loss: 0.762] [G acc: 0.472]\n",
      "132 [D loss: (0.535)(R 0.534, F 0.535)] [D acc: (0.721)(0.722, 0.720)] [G loss: 0.761] [G acc: 0.476]\n",
      "133 [D loss: (0.536)(R 0.536, F 0.537)] [D acc: (0.719)(0.721, 0.718)] [G loss: 0.760] [G acc: 0.480]\n",
      "134 [D loss: (0.538)(R 0.537, F 0.539)] [D acc: (0.718)(0.719, 0.716)] [G loss: 0.759] [G acc: 0.483]\n",
      "135 [D loss: (0.539)(R 0.539, F 0.540)] [D acc: (0.716)(0.717, 0.715)] [G loss: 0.758] [G acc: 0.487]\n",
      "136 [D loss: (0.541)(R 0.540, F 0.541)] [D acc: (0.715)(0.716, 0.713)] [G loss: 0.757] [G acc: 0.491]\n",
      "137 [D loss: (0.542)(R 0.542, F 0.543)] [D acc: (0.713)(0.714, 0.712)] [G loss: 0.756] [G acc: 0.494]\n",
      "138 [D loss: (0.544)(R 0.543, F 0.544)] [D acc: (0.711)(0.713, 0.710)] [G loss: 0.756] [G acc: 0.498]\n",
      "139 [D loss: (0.545)(R 0.544, F 0.545)] [D acc: (0.710)(0.711, 0.709)] [G loss: 0.755] [G acc: 0.501]\n",
      "140 [D loss: (0.546)(R 0.546, F 0.547)] [D acc: (0.708)(0.710, 0.707)] [G loss: 0.754] [G acc: 0.504]\n",
      "141 [D loss: (0.547)(R 0.547, F 0.548)] [D acc: (0.707)(0.708, 0.706)] [G loss: 0.753] [G acc: 0.507]\n",
      "142 [D loss: (0.549)(R 0.548, F 0.549)] [D acc: (0.705)(0.707, 0.704)] [G loss: 0.753] [G acc: 0.510]\n",
      "143 [D loss: (0.550)(R 0.549, F 0.550)] [D acc: (0.704)(0.705, 0.703)] [G loss: 0.752] [G acc: 0.512]\n",
      "144 [D loss: (0.551)(R 0.550, F 0.551)] [D acc: (0.703)(0.704, 0.701)] [G loss: 0.751] [G acc: 0.515]\n",
      "145 [D loss: (0.552)(R 0.552, F 0.553)] [D acc: (0.701)(0.702, 0.700)] [G loss: 0.751] [G acc: 0.519]\n",
      "146 [D loss: (0.553)(R 0.553, F 0.554)] [D acc: (0.700)(0.701, 0.699)] [G loss: 0.750] [G acc: 0.522]\n",
      "147 [D loss: (0.554)(R 0.554, F 0.555)] [D acc: (0.698)(0.700, 0.697)] [G loss: 0.749] [G acc: 0.524]\n",
      "148 [D loss: (0.555)(R 0.555, F 0.556)] [D acc: (0.697)(0.698, 0.696)] [G loss: 0.749] [G acc: 0.527]\n",
      "149 [D loss: (0.556)(R 0.556, F 0.557)] [D acc: (0.696)(0.697, 0.695)] [G loss: 0.748] [G acc: 0.530]\n",
      "150 [D loss: (0.557)(R 0.557, F 0.558)] [D acc: (0.694)(0.696, 0.693)] [G loss: 0.747] [G acc: 0.533]\n",
      "151 [D loss: (0.558)(R 0.558, F 0.559)] [D acc: (0.693)(0.694, 0.692)] [G loss: 0.747] [G acc: 0.536]\n",
      "152 [D loss: (0.560)(R 0.559, F 0.560)] [D acc: (0.692)(0.693, 0.691)] [G loss: 0.746] [G acc: 0.538]\n",
      "153 [D loss: (0.561)(R 0.560, F 0.561)] [D acc: (0.691)(0.692, 0.690)] [G loss: 0.745] [G acc: 0.541]\n",
      "154 [D loss: (0.562)(R 0.561, F 0.562)] [D acc: (0.689)(0.691, 0.688)] [G loss: 0.745] [G acc: 0.544]\n",
      "155 [D loss: (0.563)(R 0.562, F 0.563)] [D acc: (0.688)(0.689, 0.687)] [G loss: 0.744] [G acc: 0.547]\n",
      "156 [D loss: (0.564)(R 0.563, F 0.564)] [D acc: (0.687)(0.688, 0.686)] [G loss: 0.743] [G acc: 0.550]\n",
      "157 [D loss: (0.565)(R 0.564, F 0.565)] [D acc: (0.686)(0.687, 0.685)] [G loss: 0.743] [G acc: 0.553]\n",
      "158 [D loss: (0.566)(R 0.565, F 0.566)] [D acc: (0.685)(0.686, 0.684)] [G loss: 0.742] [G acc: 0.555]\n",
      "159 [D loss: (0.567)(R 0.566, F 0.567)] [D acc: (0.683)(0.685, 0.682)] [G loss: 0.741] [G acc: 0.558]\n",
      "160 [D loss: (0.568)(R 0.567, F 0.568)] [D acc: (0.682)(0.683, 0.681)] [G loss: 0.740] [G acc: 0.561]\n",
      "161 [D loss: (0.569)(R 0.568, F 0.569)] [D acc: (0.681)(0.682, 0.680)] [G loss: 0.740] [G acc: 0.563]\n",
      "162 [D loss: (0.570)(R 0.569, F 0.570)] [D acc: (0.680)(0.681, 0.679)] [G loss: 0.739] [G acc: 0.566]\n",
      "163 [D loss: (0.571)(R 0.570, F 0.571)] [D acc: (0.679)(0.680, 0.678)] [G loss: 0.738] [G acc: 0.569]\n",
      "164 [D loss: (0.572)(R 0.571, F 0.572)] [D acc: (0.678)(0.679, 0.677)] [G loss: 0.738] [G acc: 0.571]\n",
      "165 [D loss: (0.573)(R 0.572, F 0.573)] [D acc: (0.677)(0.678, 0.676)] [G loss: 0.737] [G acc: 0.574]\n",
      "166 [D loss: (0.573)(R 0.573, F 0.574)] [D acc: (0.676)(0.677, 0.675)] [G loss: 0.736] [G acc: 0.576]\n",
      "167 [D loss: (0.574)(R 0.574, F 0.575)] [D acc: (0.675)(0.676, 0.674)] [G loss: 0.736] [G acc: 0.579]\n",
      "168 [D loss: (0.575)(R 0.575, F 0.576)] [D acc: (0.674)(0.675, 0.673)] [G loss: 0.735] [G acc: 0.581]\n",
      "169 [D loss: (0.576)(R 0.576, F 0.576)] [D acc: (0.673)(0.674, 0.672)] [G loss: 0.734] [G acc: 0.584]\n",
      "170 [D loss: (0.577)(R 0.576, F 0.577)] [D acc: (0.672)(0.673, 0.671)] [G loss: 0.734] [G acc: 0.586]\n",
      "171 [D loss: (0.578)(R 0.577, F 0.578)] [D acc: (0.671)(0.672, 0.670)] [G loss: 0.733] [G acc: 0.588]\n",
      "172 [D loss: (0.579)(R 0.578, F 0.579)] [D acc: (0.670)(0.671, 0.669)] [G loss: 0.732] [G acc: 0.591]\n",
      "173 [D loss: (0.580)(R 0.579, F 0.580)] [D acc: (0.669)(0.670, 0.668)] [G loss: 0.731] [G acc: 0.593]\n",
      "174 [D loss: (0.580)(R 0.580, F 0.581)] [D acc: (0.668)(0.669, 0.667)] [G loss: 0.731] [G acc: 0.595]\n",
      "175 [D loss: (0.581)(R 0.581, F 0.582)] [D acc: (0.667)(0.668, 0.666)] [G loss: 0.730] [G acc: 0.598]\n",
      "176 [D loss: (0.582)(R 0.582, F 0.583)] [D acc: (0.666)(0.667, 0.665)] [G loss: 0.729] [G acc: 0.600]\n",
      "177 [D loss: (0.583)(R 0.583, F 0.583)] [D acc: (0.665)(0.666, 0.664)] [G loss: 0.729] [G acc: 0.602]\n",
      "178 [D loss: (0.584)(R 0.583, F 0.584)] [D acc: (0.664)(0.665, 0.663)] [G loss: 0.728] [G acc: 0.604]\n",
      "179 [D loss: (0.585)(R 0.584, F 0.585)] [D acc: (0.663)(0.664, 0.662)] [G loss: 0.727] [G acc: 0.607]\n",
      "180 [D loss: (0.585)(R 0.585, F 0.586)] [D acc: (0.662)(0.663, 0.661)] [G loss: 0.726] [G acc: 0.609]\n",
      "181 [D loss: (0.586)(R 0.586, F 0.587)] [D acc: (0.661)(0.662, 0.660)] [G loss: 0.726] [G acc: 0.611]\n",
      "182 [D loss: (0.587)(R 0.587, F 0.587)] [D acc: (0.660)(0.661, 0.659)] [G loss: 0.725] [G acc: 0.613]\n",
      "183 [D loss: (0.588)(R 0.587, F 0.588)] [D acc: (0.659)(0.660, 0.659)] [G loss: 0.724] [G acc: 0.615]\n",
      "184 [D loss: (0.589)(R 0.588, F 0.589)] [D acc: (0.659)(0.659, 0.658)] [G loss: 0.724] [G acc: 0.617]\n",
      "185 [D loss: (0.589)(R 0.589, F 0.590)] [D acc: (0.658)(0.659, 0.657)] [G loss: 0.723] [G acc: 0.619]\n",
      "186 [D loss: (0.590)(R 0.590, F 0.591)] [D acc: (0.657)(0.658, 0.656)] [G loss: 0.722] [G acc: 0.621]\n",
      "187 [D loss: (0.591)(R 0.590, F 0.591)] [D acc: (0.656)(0.657, 0.655)] [G loss: 0.722] [G acc: 0.623]\n",
      "188 [D loss: (0.592)(R 0.591, F 0.592)] [D acc: (0.655)(0.656, 0.654)] [G loss: 0.721] [G acc: 0.625]\n",
      "189 [D loss: (0.593)(R 0.592, F 0.593)] [D acc: (0.654)(0.655, 0.654)] [G loss: 0.720] [G acc: 0.627]\n",
      "190 [D loss: (0.593)(R 0.593, F 0.594)] [D acc: (0.654)(0.654, 0.653)] [G loss: 0.719] [G acc: 0.629]\n",
      "191 [D loss: (0.594)(R 0.594, F 0.594)] [D acc: (0.653)(0.654, 0.652)] [G loss: 0.719] [G acc: 0.631]\n",
      "192 [D loss: (0.595)(R 0.594, F 0.595)] [D acc: (0.652)(0.653, 0.651)] [G loss: 0.718] [G acc: 0.633]\n",
      "193 [D loss: (0.595)(R 0.595, F 0.596)] [D acc: (0.651)(0.652, 0.650)] [G loss: 0.718] [G acc: 0.635]\n",
      "194 [D loss: (0.596)(R 0.596, F 0.597)] [D acc: (0.650)(0.651, 0.650)] [G loss: 0.717] [G acc: 0.637]\n",
      "195 [D loss: (0.597)(R 0.597, F 0.597)] [D acc: (0.650)(0.650, 0.649)] [G loss: 0.716] [G acc: 0.639]\n",
      "196 [D loss: (0.598)(R 0.597, F 0.598)] [D acc: (0.649)(0.650, 0.648)] [G loss: 0.716] [G acc: 0.641]\n",
      "197 [D loss: (0.598)(R 0.598, F 0.599)] [D acc: (0.648)(0.649, 0.647)] [G loss: 0.715] [G acc: 0.642]\n",
      "198 [D loss: (0.599)(R 0.599, F 0.599)] [D acc: (0.647)(0.648, 0.647)] [G loss: 0.715] [G acc: 0.644]\n",
      "199 [D loss: (0.600)(R 0.599, F 0.600)] [D acc: (0.647)(0.647, 0.646)] [G loss: 0.714] [G acc: 0.646]\n",
      "200 [D loss: (0.600)(R 0.600, F 0.601)] [D acc: (0.646)(0.647, 0.645)] [G loss: 0.713] [G acc: 0.648]\n",
      "201 [D loss: (0.601)(R 0.601, F 0.601)] [D acc: (0.645)(0.646, 0.644)] [G loss: 0.713] [G acc: 0.649]\n",
      "202 [D loss: (0.602)(R 0.601, F 0.602)] [D acc: (0.644)(0.645, 0.644)] [G loss: 0.712] [G acc: 0.651]\n",
      "203 [D loss: (0.602)(R 0.602, F 0.603)] [D acc: (0.644)(0.645, 0.643)] [G loss: 0.712] [G acc: 0.653]\n",
      "204 [D loss: (0.603)(R 0.603, F 0.603)] [D acc: (0.643)(0.644, 0.642)] [G loss: 0.711] [G acc: 0.655]\n",
      "205 [D loss: (0.604)(R 0.603, F 0.604)] [D acc: (0.642)(0.643, 0.642)] [G loss: 0.711] [G acc: 0.656]\n",
      "206 [D loss: (0.604)(R 0.604, F 0.604)] [D acc: (0.642)(0.642, 0.641)] [G loss: 0.710] [G acc: 0.658]\n",
      "207 [D loss: (0.605)(R 0.604, F 0.605)] [D acc: (0.641)(0.642, 0.640)] [G loss: 0.710] [G acc: 0.660]\n",
      "208 [D loss: (0.605)(R 0.605, F 0.606)] [D acc: (0.640)(0.641, 0.640)] [G loss: 0.709] [G acc: 0.661]\n",
      "209 [D loss: (0.606)(R 0.606, F 0.606)] [D acc: (0.640)(0.640, 0.639)] [G loss: 0.709] [G acc: 0.663]\n",
      "210 [D loss: (0.606)(R 0.606, F 0.607)] [D acc: (0.639)(0.640, 0.638)] [G loss: 0.708] [G acc: 0.664]\n",
      "211 [D loss: (0.607)(R 0.607, F 0.607)] [D acc: (0.638)(0.639, 0.638)] [G loss: 0.708] [G acc: 0.666]\n",
      "212 [D loss: (0.608)(R 0.607, F 0.608)] [D acc: (0.638)(0.638, 0.637)] [G loss: 0.707] [G acc: 0.668]\n",
      "213 [D loss: (0.608)(R 0.608, F 0.609)] [D acc: (0.637)(0.638, 0.636)] [G loss: 0.706] [G acc: 0.669]\n",
      "214 [D loss: (0.609)(R 0.608, F 0.609)] [D acc: (0.636)(0.637, 0.636)] [G loss: 0.706] [G acc: 0.671]\n",
      "215 [D loss: (0.609)(R 0.609, F 0.610)] [D acc: (0.636)(0.637, 0.635)] [G loss: 0.705] [G acc: 0.672]\n",
      "216 [D loss: (0.610)(R 0.610, F 0.610)] [D acc: (0.635)(0.636, 0.634)] [G loss: 0.705] [G acc: 0.674]\n",
      "217 [D loss: (0.610)(R 0.610, F 0.611)] [D acc: (0.635)(0.635, 0.634)] [G loss: 0.704] [G acc: 0.675]\n",
      "218 [D loss: (0.611)(R 0.611, F 0.611)] [D acc: (0.634)(0.635, 0.633)] [G loss: 0.704] [G acc: 0.677]\n",
      "219 [D loss: (0.612)(R 0.611, F 0.612)] [D acc: (0.633)(0.634, 0.633)] [G loss: 0.703] [G acc: 0.678]\n",
      "220 [D loss: (0.612)(R 0.612, F 0.612)] [D acc: (0.633)(0.633, 0.632)] [G loss: 0.703] [G acc: 0.680]\n",
      "221 [D loss: (0.613)(R 0.612, F 0.613)] [D acc: (0.632)(0.633, 0.631)] [G loss: 0.703] [G acc: 0.681]\n",
      "222 [D loss: (0.613)(R 0.613, F 0.613)] [D acc: (0.632)(0.632, 0.631)] [G loss: 0.702] [G acc: 0.682]\n",
      "223 [D loss: (0.613)(R 0.613, F 0.614)] [D acc: (0.631)(0.632, 0.630)] [G loss: 0.702] [G acc: 0.684]\n",
      "224 [D loss: (0.614)(R 0.614, F 0.614)] [D acc: (0.630)(0.631, 0.630)] [G loss: 0.702] [G acc: 0.685]\n",
      "225 [D loss: (0.614)(R 0.614, F 0.615)] [D acc: (0.630)(0.630, 0.629)] [G loss: 0.701] [G acc: 0.687]\n",
      "226 [D loss: (0.615)(R 0.615, F 0.615)] [D acc: (0.629)(0.630, 0.628)] [G loss: 0.701] [G acc: 0.688]\n",
      "227 [D loss: (0.615)(R 0.615, F 0.615)] [D acc: (0.629)(0.629, 0.628)] [G loss: 0.701] [G acc: 0.689]\n",
      "228 [D loss: (0.616)(R 0.615, F 0.616)] [D acc: (0.628)(0.629, 0.627)] [G loss: 0.700] [G acc: 0.691]\n",
      "229 [D loss: (0.616)(R 0.616, F 0.616)] [D acc: (0.627)(0.628, 0.627)] [G loss: 0.700] [G acc: 0.692]\n",
      "230 [D loss: (0.616)(R 0.616, F 0.617)] [D acc: (0.627)(0.628, 0.626)] [G loss: 0.700] [G acc: 0.693]\n",
      "231 [D loss: (0.617)(R 0.617, F 0.617)] [D acc: (0.626)(0.627, 0.626)] [G loss: 0.699] [G acc: 0.695]\n",
      "232 [D loss: (0.617)(R 0.617, F 0.618)] [D acc: (0.626)(0.627, 0.625)] [G loss: 0.699] [G acc: 0.696]\n",
      "233 [D loss: (0.618)(R 0.617, F 0.618)] [D acc: (0.625)(0.626, 0.625)] [G loss: 0.699] [G acc: 0.697]\n",
      "234 [D loss: (0.618)(R 0.618, F 0.618)] [D acc: (0.625)(0.625, 0.624)] [G loss: 0.698] [G acc: 0.698]\n",
      "235 [D loss: (0.619)(R 0.618, F 0.619)] [D acc: (0.624)(0.625, 0.624)] [G loss: 0.698] [G acc: 0.700]\n",
      "236 [D loss: (0.619)(R 0.619, F 0.619)] [D acc: (0.624)(0.624, 0.623)] [G loss: 0.697] [G acc: 0.701]\n",
      "237 [D loss: (0.619)(R 0.619, F 0.620)] [D acc: (0.623)(0.624, 0.623)] [G loss: 0.697] [G acc: 0.702]\n",
      "238 [D loss: (0.620)(R 0.619, F 0.620)] [D acc: (0.623)(0.623, 0.622)] [G loss: 0.697] [G acc: 0.704]\n",
      "239 [D loss: (0.620)(R 0.620, F 0.621)] [D acc: (0.622)(0.623, 0.622)] [G loss: 0.696] [G acc: 0.705]\n",
      "240 [D loss: (0.621)(R 0.620, F 0.621)] [D acc: (0.622)(0.622, 0.621)] [G loss: 0.695] [G acc: 0.706]\n",
      "241 [D loss: (0.621)(R 0.621, F 0.622)] [D acc: (0.621)(0.622, 0.621)] [G loss: 0.695] [G acc: 0.707]\n",
      "242 [D loss: (0.622)(R 0.621, F 0.622)] [D acc: (0.621)(0.621, 0.620)] [G loss: 0.694] [G acc: 0.708]\n",
      "243 [D loss: (0.622)(R 0.622, F 0.623)] [D acc: (0.620)(0.621, 0.620)] [G loss: 0.694] [G acc: 0.710]\n",
      "244 [D loss: (0.623)(R 0.622, F 0.623)] [D acc: (0.620)(0.620, 0.619)] [G loss: 0.694] [G acc: 0.711]\n",
      "245 [D loss: (0.623)(R 0.623, F 0.624)] [D acc: (0.619)(0.620, 0.619)] [G loss: 0.693] [G acc: 0.712]\n",
      "246 [D loss: (0.624)(R 0.623, F 0.624)] [D acc: (0.619)(0.619, 0.618)] [G loss: 0.693] [G acc: 0.713]\n",
      "247 [D loss: (0.624)(R 0.624, F 0.624)] [D acc: (0.618)(0.619, 0.618)] [G loss: 0.692] [G acc: 0.714]\n",
      "248 [D loss: (0.625)(R 0.624, F 0.625)] [D acc: (0.618)(0.618, 0.617)] [G loss: 0.692] [G acc: 0.715]\n",
      "249 [D loss: (0.625)(R 0.625, F 0.625)] [D acc: (0.617)(0.618, 0.617)] [G loss: 0.691] [G acc: 0.717]\n",
      "250 [D loss: (0.625)(R 0.625, F 0.626)] [D acc: (0.617)(0.617, 0.616)] [G loss: 0.691] [G acc: 0.718]\n",
      "251 [D loss: (0.626)(R 0.626, F 0.626)] [D acc: (0.616)(0.617, 0.616)] [G loss: 0.690] [G acc: 0.719]\n",
      "252 [D loss: (0.626)(R 0.626, F 0.627)] [D acc: (0.616)(0.616, 0.615)] [G loss: 0.690] [G acc: 0.720]\n",
      "253 [D loss: (0.627)(R 0.626, F 0.627)] [D acc: (0.615)(0.616, 0.615)] [G loss: 0.690] [G acc: 0.721]\n",
      "254 [D loss: (0.627)(R 0.627, F 0.627)] [D acc: (0.615)(0.616, 0.614)] [G loss: 0.689] [G acc: 0.722]\n",
      "255 [D loss: (0.627)(R 0.627, F 0.628)] [D acc: (0.615)(0.615, 0.614)] [G loss: 0.689] [G acc: 0.723]\n",
      "256 [D loss: (0.628)(R 0.628, F 0.628)] [D acc: (0.614)(0.615, 0.613)] [G loss: 0.689] [G acc: 0.724]\n",
      "257 [D loss: (0.628)(R 0.628, F 0.628)] [D acc: (0.614)(0.614, 0.613)] [G loss: 0.688] [G acc: 0.725]\n",
      "258 [D loss: (0.629)(R 0.628, F 0.629)] [D acc: (0.613)(0.614, 0.613)] [G loss: 0.688] [G acc: 0.726]\n",
      "259 [D loss: (0.629)(R 0.629, F 0.629)] [D acc: (0.613)(0.613, 0.612)] [G loss: 0.688] [G acc: 0.727]\n",
      "260 [D loss: (0.629)(R 0.629, F 0.630)] [D acc: (0.612)(0.613, 0.612)] [G loss: 0.687] [G acc: 0.728]\n",
      "261 [D loss: (0.630)(R 0.629, F 0.630)] [D acc: (0.612)(0.612, 0.611)] [G loss: 0.687] [G acc: 0.730]\n",
      "262 [D loss: (0.630)(R 0.630, F 0.630)] [D acc: (0.611)(0.612, 0.611)] [G loss: 0.687] [G acc: 0.731]\n",
      "263 [D loss: (0.630)(R 0.630, F 0.631)] [D acc: (0.611)(0.612, 0.610)] [G loss: 0.686] [G acc: 0.732]\n",
      "264 [D loss: (0.631)(R 0.631, F 0.631)] [D acc: (0.611)(0.611, 0.610)] [G loss: 0.686] [G acc: 0.733]\n",
      "265 [D loss: (0.631)(R 0.631, F 0.631)] [D acc: (0.610)(0.611, 0.610)] [G loss: 0.686] [G acc: 0.734]\n",
      "266 [D loss: (0.631)(R 0.631, F 0.632)] [D acc: (0.610)(0.610, 0.609)] [G loss: 0.685] [G acc: 0.735]\n",
      "267 [D loss: (0.632)(R 0.632, F 0.632)] [D acc: (0.609)(0.610, 0.609)] [G loss: 0.685] [G acc: 0.736]\n",
      "268 [D loss: (0.632)(R 0.632, F 0.632)] [D acc: (0.609)(0.610, 0.608)] [G loss: 0.685] [G acc: 0.737]\n",
      "269 [D loss: (0.632)(R 0.632, F 0.633)] [D acc: (0.609)(0.609, 0.608)] [G loss: 0.684] [G acc: 0.738]\n",
      "270 [D loss: (0.633)(R 0.633, F 0.633)] [D acc: (0.608)(0.609, 0.608)] [G loss: 0.684] [G acc: 0.739]\n",
      "271 [D loss: (0.633)(R 0.633, F 0.633)] [D acc: (0.608)(0.608, 0.607)] [G loss: 0.684] [G acc: 0.739]\n",
      "272 [D loss: (0.633)(R 0.633, F 0.634)] [D acc: (0.607)(0.608, 0.607)] [G loss: 0.683] [G acc: 0.740]\n",
      "273 [D loss: (0.634)(R 0.633, F 0.634)] [D acc: (0.607)(0.608, 0.606)] [G loss: 0.683] [G acc: 0.741]\n",
      "274 [D loss: (0.634)(R 0.634, F 0.634)] [D acc: (0.607)(0.607, 0.606)] [G loss: 0.683] [G acc: 0.742]\n",
      "275 [D loss: (0.634)(R 0.634, F 0.635)] [D acc: (0.606)(0.607, 0.606)] [G loss: 0.682] [G acc: 0.743]\n",
      "276 [D loss: (0.635)(R 0.634, F 0.635)] [D acc: (0.606)(0.606, 0.605)] [G loss: 0.682] [G acc: 0.744]\n",
      "277 [D loss: (0.635)(R 0.635, F 0.635)] [D acc: (0.605)(0.606, 0.605)] [G loss: 0.682] [G acc: 0.745]\n",
      "278 [D loss: (0.635)(R 0.635, F 0.635)] [D acc: (0.605)(0.606, 0.605)] [G loss: 0.681] [G acc: 0.746]\n",
      "279 [D loss: (0.636)(R 0.635, F 0.636)] [D acc: (0.605)(0.605, 0.604)] [G loss: 0.681] [G acc: 0.747]\n",
      "280 [D loss: (0.636)(R 0.636, F 0.636)] [D acc: (0.604)(0.605, 0.604)] [G loss: 0.681] [G acc: 0.748]\n",
      "281 [D loss: (0.636)(R 0.636, F 0.636)] [D acc: (0.604)(0.604, 0.603)] [G loss: 0.680] [G acc: 0.749]\n",
      "282 [D loss: (0.637)(R 0.636, F 0.637)] [D acc: (0.604)(0.604, 0.603)] [G loss: 0.680] [G acc: 0.750]\n",
      "283 [D loss: (0.637)(R 0.637, F 0.637)] [D acc: (0.603)(0.604, 0.603)] [G loss: 0.680] [G acc: 0.750]\n",
      "284 [D loss: (0.637)(R 0.637, F 0.637)] [D acc: (0.603)(0.603, 0.602)] [G loss: 0.679] [G acc: 0.751]\n",
      "285 [D loss: (0.637)(R 0.637, F 0.638)] [D acc: (0.602)(0.603, 0.602)] [G loss: 0.679] [G acc: 0.752]\n",
      "286 [D loss: (0.638)(R 0.637, F 0.638)] [D acc: (0.602)(0.603, 0.602)] [G loss: 0.679] [G acc: 0.753]\n",
      "287 [D loss: (0.638)(R 0.638, F 0.638)] [D acc: (0.602)(0.602, 0.601)] [G loss: 0.678] [G acc: 0.754]\n",
      "288 [D loss: (0.638)(R 0.638, F 0.638)] [D acc: (0.601)(0.602, 0.601)] [G loss: 0.678] [G acc: 0.755]\n",
      "289 [D loss: (0.639)(R 0.638, F 0.639)] [D acc: (0.601)(0.602, 0.601)] [G loss: 0.678] [G acc: 0.756]\n",
      "290 [D loss: (0.639)(R 0.639, F 0.639)] [D acc: (0.601)(0.601, 0.600)] [G loss: 0.678] [G acc: 0.756]\n",
      "291 [D loss: (0.639)(R 0.639, F 0.639)] [D acc: (0.600)(0.601, 0.600)] [G loss: 0.677] [G acc: 0.757]\n",
      "292 [D loss: (0.639)(R 0.639, F 0.640)] [D acc: (0.600)(0.601, 0.600)] [G loss: 0.677] [G acc: 0.758]\n",
      "293 [D loss: (0.640)(R 0.639, F 0.640)] [D acc: (0.600)(0.600, 0.599)] [G loss: 0.677] [G acc: 0.759]\n",
      "294 [D loss: (0.640)(R 0.640, F 0.640)] [D acc: (0.599)(0.600, 0.599)] [G loss: 0.676] [G acc: 0.760]\n",
      "295 [D loss: (0.640)(R 0.640, F 0.640)] [D acc: (0.599)(0.600, 0.599)] [G loss: 0.676] [G acc: 0.761]\n",
      "296 [D loss: (0.640)(R 0.640, F 0.641)] [D acc: (0.599)(0.599, 0.598)] [G loss: 0.676] [G acc: 0.761]\n",
      "297 [D loss: (0.641)(R 0.640, F 0.641)] [D acc: (0.598)(0.599, 0.598)] [G loss: 0.676] [G acc: 0.762]\n",
      "298 [D loss: (0.641)(R 0.641, F 0.641)] [D acc: (0.598)(0.599, 0.598)] [G loss: 0.675] [G acc: 0.763]\n",
      "299 [D loss: (0.641)(R 0.641, F 0.641)] [D acc: (0.598)(0.598, 0.597)] [G loss: 0.675] [G acc: 0.764]\n",
      "300 [D loss: (0.641)(R 0.641, F 0.642)] [D acc: (0.597)(0.598, 0.597)] [G loss: 0.675] [G acc: 0.765]\n",
      "301 [D loss: (0.642)(R 0.641, F 0.642)] [D acc: (0.597)(0.598, 0.597)] [G loss: 0.674] [G acc: 0.765]\n",
      "302 [D loss: (0.642)(R 0.642, F 0.642)] [D acc: (0.597)(0.597, 0.596)] [G loss: 0.674] [G acc: 0.766]\n",
      "303 [D loss: (0.642)(R 0.642, F 0.642)] [D acc: (0.596)(0.597, 0.596)] [G loss: 0.674] [G acc: 0.767]\n",
      "304 [D loss: (0.642)(R 0.642, F 0.643)] [D acc: (0.596)(0.597, 0.596)] [G loss: 0.674] [G acc: 0.768]\n",
      "305 [D loss: (0.643)(R 0.642, F 0.643)] [D acc: (0.596)(0.596, 0.595)] [G loss: 0.673] [G acc: 0.768]\n",
      "306 [D loss: (0.643)(R 0.643, F 0.643)] [D acc: (0.595)(0.596, 0.595)] [G loss: 0.673] [G acc: 0.769]\n",
      "307 [D loss: (0.643)(R 0.643, F 0.643)] [D acc: (0.595)(0.596, 0.595)] [G loss: 0.673] [G acc: 0.770]\n",
      "308 [D loss: (0.643)(R 0.643, F 0.644)] [D acc: (0.595)(0.595, 0.594)] [G loss: 0.672] [G acc: 0.771]\n",
      "309 [D loss: (0.644)(R 0.643, F 0.644)] [D acc: (0.595)(0.595, 0.594)] [G loss: 0.672] [G acc: 0.771]\n",
      "310 [D loss: (0.644)(R 0.644, F 0.644)] [D acc: (0.594)(0.595, 0.594)] [G loss: 0.671] [G acc: 0.772]\n",
      "311 [D loss: (0.644)(R 0.644, F 0.645)] [D acc: (0.594)(0.594, 0.593)] [G loss: 0.671] [G acc: 0.773]\n",
      "312 [D loss: (0.645)(R 0.644, F 0.645)] [D acc: (0.594)(0.594, 0.593)] [G loss: 0.671] [G acc: 0.774]\n",
      "313 [D loss: (0.645)(R 0.645, F 0.645)] [D acc: (0.593)(0.594, 0.593)] [G loss: 0.670] [G acc: 0.774]\n",
      "314 [D loss: (0.645)(R 0.645, F 0.645)] [D acc: (0.593)(0.594, 0.593)] [G loss: 0.670] [G acc: 0.775]\n",
      "315 [D loss: (0.645)(R 0.645, F 0.646)] [D acc: (0.593)(0.593, 0.592)] [G loss: 0.670] [G acc: 0.776]\n",
      "316 [D loss: (0.646)(R 0.646, F 0.646)] [D acc: (0.592)(0.593, 0.592)] [G loss: 0.669] [G acc: 0.776]\n",
      "317 [D loss: (0.646)(R 0.646, F 0.646)] [D acc: (0.592)(0.593, 0.592)] [G loss: 0.669] [G acc: 0.777]\n",
      "318 [D loss: (0.646)(R 0.646, F 0.647)] [D acc: (0.592)(0.592, 0.591)] [G loss: 0.669] [G acc: 0.778]\n",
      "319 [D loss: (0.647)(R 0.646, F 0.647)] [D acc: (0.592)(0.592, 0.591)] [G loss: 0.668] [G acc: 0.779]\n",
      "320 [D loss: (0.647)(R 0.647, F 0.647)] [D acc: (0.591)(0.592, 0.591)] [G loss: 0.668] [G acc: 0.779]\n",
      "321 [D loss: (0.647)(R 0.647, F 0.647)] [D acc: (0.591)(0.591, 0.591)] [G loss: 0.668] [G acc: 0.780]\n",
      "322 [D loss: (0.647)(R 0.647, F 0.647)] [D acc: (0.591)(0.591, 0.590)] [G loss: 0.667] [G acc: 0.781]\n",
      "323 [D loss: (0.648)(R 0.647, F 0.648)] [D acc: (0.590)(0.591, 0.590)] [G loss: 0.667] [G acc: 0.781]\n",
      "324 [D loss: (0.648)(R 0.648, F 0.648)] [D acc: (0.590)(0.591, 0.590)] [G loss: 0.667] [G acc: 0.782]\n",
      "325 [D loss: (0.648)(R 0.648, F 0.648)] [D acc: (0.590)(0.590, 0.589)] [G loss: 0.666] [G acc: 0.783]\n",
      "326 [D loss: (0.648)(R 0.648, F 0.648)] [D acc: (0.590)(0.590, 0.589)] [G loss: 0.666] [G acc: 0.783]\n",
      "327 [D loss: (0.649)(R 0.648, F 0.649)] [D acc: (0.589)(0.590, 0.589)] [G loss: 0.666] [G acc: 0.784]\n",
      "328 [D loss: (0.649)(R 0.649, F 0.649)] [D acc: (0.589)(0.590, 0.589)] [G loss: 0.665] [G acc: 0.785]\n",
      "329 [D loss: (0.649)(R 0.649, F 0.649)] [D acc: (0.589)(0.589, 0.588)] [G loss: 0.665] [G acc: 0.785]\n",
      "330 [D loss: (0.649)(R 0.649, F 0.649)] [D acc: (0.589)(0.589, 0.588)] [G loss: 0.665] [G acc: 0.786]\n",
      "331 [D loss: (0.649)(R 0.649, F 0.650)] [D acc: (0.588)(0.589, 0.588)] [G loss: 0.665] [G acc: 0.787]\n",
      "332 [D loss: (0.650)(R 0.649, F 0.650)] [D acc: (0.588)(0.588, 0.588)] [G loss: 0.664] [G acc: 0.787]\n",
      "333 [D loss: (0.650)(R 0.650, F 0.650)] [D acc: (0.588)(0.588, 0.587)] [G loss: 0.664] [G acc: 0.788]\n",
      "334 [D loss: (0.650)(R 0.650, F 0.650)] [D acc: (0.587)(0.588, 0.587)] [G loss: 0.664] [G acc: 0.788]\n",
      "335 [D loss: (0.650)(R 0.650, F 0.650)] [D acc: (0.587)(0.588, 0.587)] [G loss: 0.664] [G acc: 0.789]\n",
      "336 [D loss: (0.650)(R 0.650, F 0.651)] [D acc: (0.587)(0.587, 0.587)] [G loss: 0.663] [G acc: 0.790]\n",
      "337 [D loss: (0.651)(R 0.651, F 0.651)] [D acc: (0.587)(0.587, 0.586)] [G loss: 0.663] [G acc: 0.790]\n",
      "338 [D loss: (0.651)(R 0.651, F 0.651)] [D acc: (0.586)(0.587, 0.586)] [G loss: 0.663] [G acc: 0.791]\n",
      "339 [D loss: (0.651)(R 0.651, F 0.651)] [D acc: (0.586)(0.587, 0.586)] [G loss: 0.662] [G acc: 0.792]\n",
      "340 [D loss: (0.651)(R 0.651, F 0.652)] [D acc: (0.586)(0.586, 0.586)] [G loss: 0.662] [G acc: 0.792]\n",
      "341 [D loss: (0.652)(R 0.651, F 0.652)] [D acc: (0.586)(0.586, 0.585)] [G loss: 0.662] [G acc: 0.793]\n",
      "342 [D loss: (0.652)(R 0.652, F 0.652)] [D acc: (0.585)(0.586, 0.585)] [G loss: 0.662] [G acc: 0.793]\n",
      "343 [D loss: (0.652)(R 0.652, F 0.652)] [D acc: (0.585)(0.586, 0.585)] [G loss: 0.661] [G acc: 0.794]\n",
      "344 [D loss: (0.652)(R 0.652, F 0.652)] [D acc: (0.585)(0.585, 0.585)] [G loss: 0.661] [G acc: 0.795]\n",
      "345 [D loss: (0.652)(R 0.652, F 0.653)] [D acc: (0.585)(0.585, 0.584)] [G loss: 0.661] [G acc: 0.795]\n",
      "346 [D loss: (0.653)(R 0.652, F 0.653)] [D acc: (0.584)(0.585, 0.584)] [G loss: 0.661] [G acc: 0.796]\n",
      "347 [D loss: (0.653)(R 0.653, F 0.653)] [D acc: (0.584)(0.585, 0.584)] [G loss: 0.660] [G acc: 0.796]\n",
      "348 [D loss: (0.653)(R 0.653, F 0.653)] [D acc: (0.584)(0.584, 0.584)] [G loss: 0.660] [G acc: 0.797]\n",
      "349 [D loss: (0.653)(R 0.653, F 0.653)] [D acc: (0.584)(0.584, 0.583)] [G loss: 0.660] [G acc: 0.798]\n",
      "350 [D loss: (0.653)(R 0.653, F 0.653)] [D acc: (0.584)(0.584, 0.583)] [G loss: 0.660] [G acc: 0.798]\n",
      "351 [D loss: (0.653)(R 0.653, F 0.654)] [D acc: (0.583)(0.584, 0.583)] [G loss: 0.659] [G acc: 0.799]\n",
      "352 [D loss: (0.654)(R 0.653, F 0.654)] [D acc: (0.583)(0.583, 0.583)] [G loss: 0.659] [G acc: 0.799]\n",
      "353 [D loss: (0.654)(R 0.654, F 0.654)] [D acc: (0.583)(0.583, 0.582)] [G loss: 0.659] [G acc: 0.800]\n",
      "354 [D loss: (0.654)(R 0.654, F 0.654)] [D acc: (0.583)(0.583, 0.582)] [G loss: 0.658] [G acc: 0.800]\n",
      "355 [D loss: (0.654)(R 0.654, F 0.654)] [D acc: (0.582)(0.583, 0.582)] [G loss: 0.658] [G acc: 0.801]\n",
      "356 [D loss: (0.654)(R 0.654, F 0.655)] [D acc: (0.582)(0.583, 0.582)] [G loss: 0.658] [G acc: 0.802]\n",
      "357 [D loss: (0.655)(R 0.654, F 0.655)] [D acc: (0.582)(0.582, 0.581)] [G loss: 0.658] [G acc: 0.802]\n",
      "358 [D loss: (0.655)(R 0.655, F 0.655)] [D acc: (0.582)(0.582, 0.581)] [G loss: 0.657] [G acc: 0.803]\n",
      "359 [D loss: (0.655)(R 0.655, F 0.655)] [D acc: (0.581)(0.582, 0.581)] [G loss: 0.657] [G acc: 0.803]\n",
      "360 [D loss: (0.655)(R 0.655, F 0.655)] [D acc: (0.581)(0.582, 0.581)] [G loss: 0.657] [G acc: 0.804]\n",
      "361 [D loss: (0.655)(R 0.655, F 0.655)] [D acc: (0.581)(0.581, 0.581)] [G loss: 0.657] [G acc: 0.804]\n",
      "362 [D loss: (0.655)(R 0.655, F 0.656)] [D acc: (0.581)(0.581, 0.580)] [G loss: 0.656] [G acc: 0.805]\n",
      "363 [D loss: (0.656)(R 0.655, F 0.656)] [D acc: (0.581)(0.581, 0.580)] [G loss: 0.656] [G acc: 0.805]\n",
      "364 [D loss: (0.656)(R 0.655, F 0.656)] [D acc: (0.580)(0.581, 0.580)] [G loss: 0.656] [G acc: 0.806]\n",
      "365 [D loss: (0.656)(R 0.656, F 0.656)] [D acc: (0.580)(0.580, 0.580)] [G loss: 0.656] [G acc: 0.806]\n",
      "366 [D loss: (0.656)(R 0.656, F 0.656)] [D acc: (0.580)(0.580, 0.579)] [G loss: 0.656] [G acc: 0.807]\n",
      "367 [D loss: (0.656)(R 0.656, F 0.656)] [D acc: (0.580)(0.580, 0.579)] [G loss: 0.655] [G acc: 0.807]\n",
      "368 [D loss: (0.656)(R 0.656, F 0.656)] [D acc: (0.579)(0.580, 0.579)] [G loss: 0.655] [G acc: 0.808]\n",
      "369 [D loss: (0.656)(R 0.656, F 0.657)] [D acc: (0.579)(0.580, 0.579)] [G loss: 0.655] [G acc: 0.808]\n",
      "370 [D loss: (0.657)(R 0.656, F 0.657)] [D acc: (0.579)(0.579, 0.579)] [G loss: 0.654] [G acc: 0.809]\n",
      "371 [D loss: (0.657)(R 0.657, F 0.657)] [D acc: (0.579)(0.579, 0.578)] [G loss: 0.654] [G acc: 0.810]\n",
      "372 [D loss: (0.657)(R 0.657, F 0.657)] [D acc: (0.579)(0.579, 0.578)] [G loss: 0.654] [G acc: 0.810]\n",
      "373 [D loss: (0.657)(R 0.657, F 0.657)] [D acc: (0.578)(0.579, 0.578)] [G loss: 0.654] [G acc: 0.811]\n",
      "374 [D loss: (0.657)(R 0.657, F 0.658)] [D acc: (0.578)(0.579, 0.578)] [G loss: 0.653] [G acc: 0.811]\n",
      "\n",
      ">>> LR Decay at epoch 375: D_LR=4.00e-04, G_LR=2.00e-04\n",
      "\n",
      "375 [D loss: (0.658)(R 0.657, F 0.658)] [D acc: (0.578)(0.578, 0.578)] [G loss: 0.653] [G acc: 0.812]\n",
      "376 [D loss: (0.658)(R 0.658, F 0.658)] [D acc: (0.578)(0.578, 0.577)] [G loss: 0.652] [G acc: 0.812]\n",
      "377 [D loss: (0.658)(R 0.658, F 0.658)] [D acc: (0.578)(0.578, 0.577)] [G loss: 0.652] [G acc: 0.813]\n",
      "378 [D loss: (0.658)(R 0.658, F 0.659)] [D acc: (0.577)(0.578, 0.577)] [G loss: 0.652] [G acc: 0.813]\n",
      "379 [D loss: (0.659)(R 0.658, F 0.659)] [D acc: (0.577)(0.578, 0.577)] [G loss: 0.651] [G acc: 0.814]\n",
      "380 [D loss: (0.659)(R 0.658, F 0.659)] [D acc: (0.577)(0.577, 0.577)] [G loss: 0.651] [G acc: 0.814]\n",
      "381 [D loss: (0.659)(R 0.659, F 0.659)] [D acc: (0.577)(0.577, 0.576)] [G loss: 0.650] [G acc: 0.814]\n",
      "382 [D loss: (0.659)(R 0.659, F 0.659)] [D acc: (0.577)(0.577, 0.576)] [G loss: 0.650] [G acc: 0.815]\n",
      "383 [D loss: (0.659)(R 0.659, F 0.660)] [D acc: (0.576)(0.577, 0.576)] [G loss: 0.650] [G acc: 0.815]\n",
      "384 [D loss: (0.660)(R 0.659, F 0.660)] [D acc: (0.576)(0.576, 0.576)] [G loss: 0.649] [G acc: 0.816]\n",
      "385 [D loss: (0.660)(R 0.660, F 0.660)] [D acc: (0.576)(0.576, 0.576)] [G loss: 0.649] [G acc: 0.816]\n",
      "386 [D loss: (0.660)(R 0.660, F 0.660)] [D acc: (0.576)(0.576, 0.575)] [G loss: 0.648] [G acc: 0.817]\n",
      "387 [D loss: (0.660)(R 0.660, F 0.660)] [D acc: (0.576)(0.576, 0.575)] [G loss: 0.648] [G acc: 0.817]\n",
      "388 [D loss: (0.660)(R 0.660, F 0.660)] [D acc: (0.575)(0.576, 0.575)] [G loss: 0.648] [G acc: 0.818]\n",
      "389 [D loss: (0.660)(R 0.660, F 0.661)] [D acc: (0.575)(0.576, 0.575)] [G loss: 0.647] [G acc: 0.818]\n",
      "390 [D loss: (0.661)(R 0.660, F 0.661)] [D acc: (0.575)(0.575, 0.575)] [G loss: 0.647] [G acc: 0.819]\n",
      "391 [D loss: (0.661)(R 0.661, F 0.661)] [D acc: (0.575)(0.575, 0.574)] [G loss: 0.647] [G acc: 0.819]\n",
      "392 [D loss: (0.661)(R 0.661, F 0.661)] [D acc: (0.575)(0.575, 0.574)] [G loss: 0.646] [G acc: 0.820]\n",
      "393 [D loss: (0.661)(R 0.661, F 0.661)] [D acc: (0.574)(0.575, 0.574)] [G loss: 0.646] [G acc: 0.820]\n",
      "394 [D loss: (0.661)(R 0.661, F 0.661)] [D acc: (0.574)(0.575, 0.574)] [G loss: 0.646] [G acc: 0.821]\n",
      "395 [D loss: (0.661)(R 0.661, F 0.662)] [D acc: (0.574)(0.574, 0.574)] [G loss: 0.645] [G acc: 0.821]\n",
      "396 [D loss: (0.662)(R 0.661, F 0.662)] [D acc: (0.574)(0.574, 0.573)] [G loss: 0.645] [G acc: 0.822]\n",
      "397 [D loss: (0.662)(R 0.662, F 0.662)] [D acc: (0.574)(0.574, 0.573)] [G loss: 0.645] [G acc: 0.822]\n",
      "398 [D loss: (0.662)(R 0.662, F 0.662)] [D acc: (0.573)(0.574, 0.573)] [G loss: 0.644] [G acc: 0.822]\n",
      "399 [D loss: (0.662)(R 0.662, F 0.662)] [D acc: (0.573)(0.574, 0.573)] [G loss: 0.644] [G acc: 0.823]\n",
      "400 [D loss: (0.662)(R 0.662, F 0.662)] [D acc: (0.573)(0.573, 0.573)] [G loss: 0.644] [G acc: 0.823]\n",
      "401 [D loss: (0.662)(R 0.662, F 0.663)] [D acc: (0.573)(0.573, 0.573)] [G loss: 0.644] [G acc: 0.824]\n",
      "402 [D loss: (0.663)(R 0.662, F 0.663)] [D acc: (0.573)(0.573, 0.572)] [G loss: 0.643] [G acc: 0.824]\n",
      "403 [D loss: (0.663)(R 0.662, F 0.663)] [D acc: (0.573)(0.573, 0.572)] [G loss: 0.643] [G acc: 0.825]\n",
      "404 [D loss: (0.663)(R 0.663, F 0.663)] [D acc: (0.572)(0.573, 0.572)] [G loss: 0.643] [G acc: 0.825]\n",
      "405 [D loss: (0.663)(R 0.663, F 0.663)] [D acc: (0.572)(0.573, 0.572)] [G loss: 0.642] [G acc: 0.825]\n",
      "406 [D loss: (0.663)(R 0.663, F 0.663)] [D acc: (0.572)(0.572, 0.572)] [G loss: 0.642] [G acc: 0.826]\n",
      "407 [D loss: (0.663)(R 0.663, F 0.663)] [D acc: (0.572)(0.572, 0.571)] [G loss: 0.642] [G acc: 0.826]\n",
      "408 [D loss: (0.663)(R 0.663, F 0.664)] [D acc: (0.572)(0.572, 0.571)] [G loss: 0.641] [G acc: 0.827]\n",
      "409 [D loss: (0.664)(R 0.663, F 0.664)] [D acc: (0.571)(0.572, 0.571)] [G loss: 0.641] [G acc: 0.827]\n",
      "410 [D loss: (0.664)(R 0.664, F 0.664)] [D acc: (0.571)(0.572, 0.571)] [G loss: 0.641] [G acc: 0.828]\n",
      "411 [D loss: (0.664)(R 0.664, F 0.664)] [D acc: (0.571)(0.571, 0.571)] [G loss: 0.641] [G acc: 0.828]\n",
      "412 [D loss: (0.664)(R 0.664, F 0.664)] [D acc: (0.571)(0.571, 0.571)] [G loss: 0.640] [G acc: 0.828]\n",
      "413 [D loss: (0.664)(R 0.664, F 0.664)] [D acc: (0.571)(0.571, 0.570)] [G loss: 0.640] [G acc: 0.829]\n",
      "414 [D loss: (0.664)(R 0.664, F 0.664)] [D acc: (0.571)(0.571, 0.570)] [G loss: 0.640] [G acc: 0.829]\n",
      "415 [D loss: (0.664)(R 0.664, F 0.665)] [D acc: (0.570)(0.571, 0.570)] [G loss: 0.639] [G acc: 0.830]\n",
      "416 [D loss: (0.665)(R 0.664, F 0.665)] [D acc: (0.570)(0.571, 0.570)] [G loss: 0.639] [G acc: 0.830]\n",
      "417 [D loss: (0.665)(R 0.665, F 0.665)] [D acc: (0.570)(0.570, 0.570)] [G loss: 0.639] [G acc: 0.830]\n",
      "418 [D loss: (0.665)(R 0.665, F 0.665)] [D acc: (0.570)(0.570, 0.570)] [G loss: 0.638] [G acc: 0.831]\n",
      "419 [D loss: (0.665)(R 0.665, F 0.665)] [D acc: (0.570)(0.570, 0.569)] [G loss: 0.638] [G acc: 0.831]\n",
      "420 [D loss: (0.665)(R 0.665, F 0.665)] [D acc: (0.570)(0.570, 0.569)] [G loss: 0.638] [G acc: 0.832]\n",
      "421 [D loss: (0.665)(R 0.665, F 0.665)] [D acc: (0.569)(0.570, 0.569)] [G loss: 0.638] [G acc: 0.832]\n",
      "422 [D loss: (0.665)(R 0.665, F 0.666)] [D acc: (0.569)(0.570, 0.569)] [G loss: 0.637] [G acc: 0.832]\n",
      "423 [D loss: (0.666)(R 0.665, F 0.666)] [D acc: (0.569)(0.569, 0.569)] [G loss: 0.637] [G acc: 0.833]\n",
      "424 [D loss: (0.666)(R 0.665, F 0.666)] [D acc: (0.569)(0.569, 0.569)] [G loss: 0.637] [G acc: 0.833]\n",
      "425 [D loss: (0.666)(R 0.666, F 0.666)] [D acc: (0.569)(0.569, 0.568)] [G loss: 0.637] [G acc: 0.834]\n",
      "426 [D loss: (0.666)(R 0.666, F 0.666)] [D acc: (0.569)(0.569, 0.568)] [G loss: 0.636] [G acc: 0.834]\n",
      "427 [D loss: (0.666)(R 0.666, F 0.666)] [D acc: (0.568)(0.569, 0.568)] [G loss: 0.636] [G acc: 0.834]\n",
      "428 [D loss: (0.666)(R 0.666, F 0.666)] [D acc: (0.568)(0.569, 0.568)] [G loss: 0.636] [G acc: 0.835]\n",
      "429 [D loss: (0.666)(R 0.666, F 0.666)] [D acc: (0.568)(0.568, 0.568)] [G loss: 0.635] [G acc: 0.835]\n",
      "430 [D loss: (0.666)(R 0.666, F 0.667)] [D acc: (0.568)(0.568, 0.568)] [G loss: 0.635] [G acc: 0.836]\n",
      "431 [D loss: (0.667)(R 0.666, F 0.667)] [D acc: (0.568)(0.568, 0.568)] [G loss: 0.635] [G acc: 0.836]\n",
      "432 [D loss: (0.667)(R 0.667, F 0.667)] [D acc: (0.568)(0.568, 0.567)] [G loss: 0.635] [G acc: 0.836]\n",
      "433 [D loss: (0.667)(R 0.667, F 0.667)] [D acc: (0.568)(0.568, 0.567)] [G loss: 0.634] [G acc: 0.837]\n",
      "434 [D loss: (0.667)(R 0.667, F 0.667)] [D acc: (0.567)(0.568, 0.567)] [G loss: 0.634] [G acc: 0.837]\n",
      "435 [D loss: (0.667)(R 0.667, F 0.667)] [D acc: (0.567)(0.568, 0.567)] [G loss: 0.634] [G acc: 0.837]\n",
      "436 [D loss: (0.667)(R 0.667, F 0.667)] [D acc: (0.567)(0.567, 0.567)] [G loss: 0.633] [G acc: 0.838]\n",
      "437 [D loss: (0.667)(R 0.667, F 0.668)] [D acc: (0.567)(0.567, 0.567)] [G loss: 0.633] [G acc: 0.838]\n",
      "438 [D loss: (0.667)(R 0.667, F 0.668)] [D acc: (0.567)(0.567, 0.566)] [G loss: 0.633] [G acc: 0.839]\n",
      "439 [D loss: (0.668)(R 0.667, F 0.668)] [D acc: (0.567)(0.567, 0.566)] [G loss: 0.633] [G acc: 0.839]\n",
      "440 [D loss: (0.668)(R 0.668, F 0.668)] [D acc: (0.566)(0.567, 0.566)] [G loss: 0.632] [G acc: 0.839]\n",
      "441 [D loss: (0.668)(R 0.668, F 0.668)] [D acc: (0.566)(0.567, 0.566)] [G loss: 0.632] [G acc: 0.840]\n",
      "442 [D loss: (0.668)(R 0.668, F 0.668)] [D acc: (0.566)(0.566, 0.566)] [G loss: 0.632] [G acc: 0.840]\n",
      "443 [D loss: (0.668)(R 0.668, F 0.668)] [D acc: (0.566)(0.566, 0.566)] [G loss: 0.632] [G acc: 0.840]\n",
      "444 [D loss: (0.668)(R 0.668, F 0.668)] [D acc: (0.566)(0.566, 0.566)] [G loss: 0.631] [G acc: 0.841]\n",
      "445 [D loss: (0.668)(R 0.668, F 0.669)] [D acc: (0.566)(0.566, 0.565)] [G loss: 0.631] [G acc: 0.841]\n",
      "446 [D loss: (0.668)(R 0.668, F 0.669)] [D acc: (0.566)(0.566, 0.565)] [G loss: 0.631] [G acc: 0.841]\n",
      "447 [D loss: (0.669)(R 0.668, F 0.669)] [D acc: (0.565)(0.566, 0.565)] [G loss: 0.631] [G acc: 0.842]\n",
      "448 [D loss: (0.669)(R 0.669, F 0.669)] [D acc: (0.565)(0.566, 0.565)] [G loss: 0.630] [G acc: 0.842]\n",
      "449 [D loss: (0.669)(R 0.669, F 0.669)] [D acc: (0.565)(0.565, 0.565)] [G loss: 0.630] [G acc: 0.843]\n",
      "450 [D loss: (0.669)(R 0.669, F 0.669)] [D acc: (0.565)(0.565, 0.565)] [G loss: 0.630] [G acc: 0.843]\n",
      "451 [D loss: (0.669)(R 0.669, F 0.669)] [D acc: (0.565)(0.565, 0.565)] [G loss: 0.629] [G acc: 0.843]\n",
      "452 [D loss: (0.669)(R 0.669, F 0.669)] [D acc: (0.565)(0.565, 0.564)] [G loss: 0.629] [G acc: 0.844]\n",
      "453 [D loss: (0.669)(R 0.669, F 0.669)] [D acc: (0.565)(0.565, 0.564)] [G loss: 0.629] [G acc: 0.844]\n",
      "454 [D loss: (0.669)(R 0.669, F 0.670)] [D acc: (0.564)(0.565, 0.564)] [G loss: 0.629] [G acc: 0.844]\n",
      "455 [D loss: (0.670)(R 0.669, F 0.670)] [D acc: (0.564)(0.565, 0.564)] [G loss: 0.628] [G acc: 0.845]\n",
      "456 [D loss: (0.670)(R 0.669, F 0.670)] [D acc: (0.564)(0.564, 0.564)] [G loss: 0.628] [G acc: 0.845]\n",
      "457 [D loss: (0.670)(R 0.670, F 0.670)] [D acc: (0.564)(0.564, 0.564)] [G loss: 0.628] [G acc: 0.845]\n",
      "458 [D loss: (0.670)(R 0.670, F 0.670)] [D acc: (0.564)(0.564, 0.564)] [G loss: 0.628] [G acc: 0.846]\n",
      "459 [D loss: (0.670)(R 0.670, F 0.670)] [D acc: (0.564)(0.564, 0.563)] [G loss: 0.627] [G acc: 0.846]\n",
      "460 [D loss: (0.670)(R 0.670, F 0.670)] [D acc: (0.564)(0.564, 0.563)] [G loss: 0.627] [G acc: 0.846]\n",
      "461 [D loss: (0.670)(R 0.670, F 0.670)] [D acc: (0.563)(0.564, 0.563)] [G loss: 0.627] [G acc: 0.847]\n",
      "462 [D loss: (0.670)(R 0.670, F 0.671)] [D acc: (0.563)(0.564, 0.563)] [G loss: 0.627] [G acc: 0.847]\n",
      "463 [D loss: (0.670)(R 0.670, F 0.671)] [D acc: (0.563)(0.563, 0.563)] [G loss: 0.627] [G acc: 0.847]\n",
      "464 [D loss: (0.671)(R 0.670, F 0.671)] [D acc: (0.563)(0.563, 0.563)] [G loss: 0.626] [G acc: 0.848]\n",
      "465 [D loss: (0.671)(R 0.671, F 0.671)] [D acc: (0.563)(0.563, 0.563)] [G loss: 0.626] [G acc: 0.848]\n",
      "466 [D loss: (0.671)(R 0.671, F 0.671)] [D acc: (0.563)(0.563, 0.562)] [G loss: 0.626] [G acc: 0.848]\n",
      "467 [D loss: (0.671)(R 0.671, F 0.671)] [D acc: (0.563)(0.563, 0.562)] [G loss: 0.626] [G acc: 0.849]\n",
      "468 [D loss: (0.671)(R 0.671, F 0.671)] [D acc: (0.562)(0.563, 0.562)] [G loss: 0.625] [G acc: 0.849]\n",
      "469 [D loss: (0.671)(R 0.671, F 0.671)] [D acc: (0.562)(0.563, 0.562)] [G loss: 0.625] [G acc: 0.849]\n",
      "470 [D loss: (0.671)(R 0.671, F 0.671)] [D acc: (0.562)(0.563, 0.562)] [G loss: 0.625] [G acc: 0.850]\n",
      "471 [D loss: (0.671)(R 0.671, F 0.672)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.625] [G acc: 0.850]\n",
      "472 [D loss: (0.671)(R 0.671, F 0.672)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.624] [G acc: 0.850]\n",
      "473 [D loss: (0.672)(R 0.671, F 0.672)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.624] [G acc: 0.850]\n",
      "474 [D loss: (0.672)(R 0.672, F 0.672)] [D acc: (0.562)(0.562, 0.561)] [G loss: 0.624] [G acc: 0.851]\n",
      "475 [D loss: (0.672)(R 0.672, F 0.672)] [D acc: (0.562)(0.562, 0.561)] [G loss: 0.624] [G acc: 0.851]\n",
      "476 [D loss: (0.672)(R 0.672, F 0.672)] [D acc: (0.561)(0.562, 0.561)] [G loss: 0.623] [G acc: 0.851]\n",
      "477 [D loss: (0.672)(R 0.672, F 0.672)] [D acc: (0.561)(0.562, 0.561)] [G loss: 0.623] [G acc: 0.852]\n",
      "478 [D loss: (0.672)(R 0.672, F 0.672)] [D acc: (0.561)(0.561, 0.561)] [G loss: 0.623] [G acc: 0.852]\n",
      "479 [D loss: (0.672)(R 0.672, F 0.672)] [D acc: (0.561)(0.561, 0.561)] [G loss: 0.623] [G acc: 0.852]\n",
      "480 [D loss: (0.672)(R 0.672, F 0.673)] [D acc: (0.561)(0.561, 0.561)] [G loss: 0.623] [G acc: 0.853]\n",
      "481 [D loss: (0.672)(R 0.672, F 0.673)] [D acc: (0.561)(0.561, 0.561)] [G loss: 0.622] [G acc: 0.853]\n",
      "482 [D loss: (0.673)(R 0.672, F 0.673)] [D acc: (0.561)(0.561, 0.560)] [G loss: 0.622] [G acc: 0.853]\n",
      "483 [D loss: (0.673)(R 0.673, F 0.673)] [D acc: (0.561)(0.561, 0.560)] [G loss: 0.622] [G acc: 0.854]\n",
      "484 [D loss: (0.673)(R 0.673, F 0.673)] [D acc: (0.560)(0.561, 0.560)] [G loss: 0.622] [G acc: 0.854]\n",
      "485 [D loss: (0.673)(R 0.673, F 0.673)] [D acc: (0.560)(0.561, 0.560)] [G loss: 0.621] [G acc: 0.854]\n",
      "486 [D loss: (0.673)(R 0.673, F 0.673)] [D acc: (0.560)(0.560, 0.560)] [G loss: 0.621] [G acc: 0.854]\n",
      "487 [D loss: (0.673)(R 0.673, F 0.673)] [D acc: (0.560)(0.560, 0.560)] [G loss: 0.621] [G acc: 0.855]\n",
      "488 [D loss: (0.673)(R 0.673, F 0.673)] [D acc: (0.560)(0.560, 0.560)] [G loss: 0.621] [G acc: 0.855]\n",
      "489 [D loss: (0.673)(R 0.673, F 0.673)] [D acc: (0.560)(0.560, 0.560)] [G loss: 0.621] [G acc: 0.855]\n",
      "490 [D loss: (0.673)(R 0.673, F 0.674)] [D acc: (0.560)(0.560, 0.559)] [G loss: 0.620] [G acc: 0.856]\n",
      "491 [D loss: (0.674)(R 0.673, F 0.674)] [D acc: (0.560)(0.560, 0.559)] [G loss: 0.620] [G acc: 0.856]\n",
      "492 [D loss: (0.674)(R 0.673, F 0.674)] [D acc: (0.559)(0.560, 0.559)] [G loss: 0.620] [G acc: 0.856]\n",
      "493 [D loss: (0.674)(R 0.674, F 0.674)] [D acc: (0.559)(0.560, 0.559)] [G loss: 0.620] [G acc: 0.857]\n",
      "494 [D loss: (0.674)(R 0.674, F 0.674)] [D acc: (0.559)(0.559, 0.559)] [G loss: 0.619] [G acc: 0.857]\n",
      "495 [D loss: (0.674)(R 0.674, F 0.674)] [D acc: (0.559)(0.559, 0.559)] [G loss: 0.619] [G acc: 0.857]\n",
      "496 [D loss: (0.674)(R 0.674, F 0.674)] [D acc: (0.559)(0.559, 0.559)] [G loss: 0.619] [G acc: 0.857]\n",
      "497 [D loss: (0.674)(R 0.674, F 0.674)] [D acc: (0.559)(0.559, 0.559)] [G loss: 0.619] [G acc: 0.858]\n",
      "498 [D loss: (0.674)(R 0.674, F 0.674)] [D acc: (0.559)(0.559, 0.558)] [G loss: 0.619] [G acc: 0.858]\n",
      "499 [D loss: (0.674)(R 0.674, F 0.674)] [D acc: (0.559)(0.559, 0.558)] [G loss: 0.618] [G acc: 0.858]\n",
      "500 [D loss: (0.674)(R 0.674, F 0.675)] [D acc: (0.558)(0.559, 0.558)] [G loss: 0.618] [G acc: 0.859]\n",
      "501 [D loss: (0.675)(R 0.674, F 0.675)] [D acc: (0.558)(0.559, 0.558)] [G loss: 0.618] [G acc: 0.859]\n",
      "502 [D loss: (0.675)(R 0.674, F 0.675)] [D acc: (0.558)(0.559, 0.558)] [G loss: 0.618] [G acc: 0.859]\n",
      "503 [D loss: (0.675)(R 0.675, F 0.675)] [D acc: (0.558)(0.558, 0.558)] [G loss: 0.617] [G acc: 0.859]\n",
      "504 [D loss: (0.675)(R 0.675, F 0.675)] [D acc: (0.558)(0.558, 0.558)] [G loss: 0.617] [G acc: 0.860]\n",
      "505 [D loss: (0.675)(R 0.675, F 0.675)] [D acc: (0.558)(0.558, 0.558)] [G loss: 0.617] [G acc: 0.860]\n",
      "506 [D loss: (0.675)(R 0.675, F 0.675)] [D acc: (0.558)(0.558, 0.558)] [G loss: 0.617] [G acc: 0.860]\n",
      "507 [D loss: (0.675)(R 0.675, F 0.675)] [D acc: (0.558)(0.558, 0.557)] [G loss: 0.617] [G acc: 0.861]\n",
      "508 [D loss: (0.675)(R 0.675, F 0.675)] [D acc: (0.558)(0.558, 0.557)] [G loss: 0.616] [G acc: 0.861]\n",
      "509 [D loss: (0.675)(R 0.675, F 0.675)] [D acc: (0.557)(0.558, 0.557)] [G loss: 0.616] [G acc: 0.861]\n",
      "510 [D loss: (0.675)(R 0.675, F 0.676)] [D acc: (0.557)(0.558, 0.557)] [G loss: 0.616] [G acc: 0.861]\n",
      "511 [D loss: (0.675)(R 0.675, F 0.676)] [D acc: (0.557)(0.558, 0.557)] [G loss: 0.616] [G acc: 0.862]\n",
      "512 [D loss: (0.676)(R 0.675, F 0.676)] [D acc: (0.557)(0.557, 0.557)] [G loss: 0.616] [G acc: 0.862]\n",
      "513 [D loss: (0.676)(R 0.676, F 0.676)] [D acc: (0.557)(0.557, 0.557)] [G loss: 0.615] [G acc: 0.862]\n",
      "514 [D loss: (0.676)(R 0.676, F 0.676)] [D acc: (0.557)(0.557, 0.557)] [G loss: 0.615] [G acc: 0.862]\n",
      "515 [D loss: (0.676)(R 0.676, F 0.676)] [D acc: (0.557)(0.557, 0.557)] [G loss: 0.615] [G acc: 0.863]\n",
      "516 [D loss: (0.676)(R 0.676, F 0.676)] [D acc: (0.557)(0.557, 0.556)] [G loss: 0.615] [G acc: 0.863]\n",
      "517 [D loss: (0.676)(R 0.676, F 0.676)] [D acc: (0.557)(0.557, 0.556)] [G loss: 0.615] [G acc: 0.863]\n",
      "518 [D loss: (0.676)(R 0.676, F 0.676)] [D acc: (0.556)(0.557, 0.556)] [G loss: 0.614] [G acc: 0.863]\n",
      "519 [D loss: (0.676)(R 0.676, F 0.676)] [D acc: (0.556)(0.557, 0.556)] [G loss: 0.614] [G acc: 0.864]\n",
      "520 [D loss: (0.676)(R 0.676, F 0.676)] [D acc: (0.556)(0.557, 0.556)] [G loss: 0.614] [G acc: 0.864]\n",
      "521 [D loss: (0.676)(R 0.676, F 0.677)] [D acc: (0.556)(0.556, 0.556)] [G loss: 0.614] [G acc: 0.864]\n",
      "522 [D loss: (0.677)(R 0.676, F 0.677)] [D acc: (0.556)(0.556, 0.556)] [G loss: 0.614] [G acc: 0.865]\n",
      "523 [D loss: (0.677)(R 0.676, F 0.677)] [D acc: (0.556)(0.556, 0.556)] [G loss: 0.613] [G acc: 0.865]\n",
      "524 [D loss: (0.677)(R 0.677, F 0.677)] [D acc: (0.556)(0.556, 0.556)] [G loss: 0.613] [G acc: 0.865]\n",
      "525 [D loss: (0.677)(R 0.677, F 0.677)] [D acc: (0.556)(0.556, 0.555)] [G loss: 0.613] [G acc: 0.865]\n",
      "526 [D loss: (0.677)(R 0.677, F 0.677)] [D acc: (0.556)(0.556, 0.555)] [G loss: 0.613] [G acc: 0.866]\n",
      "527 [D loss: (0.677)(R 0.677, F 0.677)] [D acc: (0.555)(0.556, 0.555)] [G loss: 0.613] [G acc: 0.866]\n",
      "528 [D loss: (0.677)(R 0.677, F 0.677)] [D acc: (0.555)(0.556, 0.555)] [G loss: 0.612] [G acc: 0.866]\n",
      "529 [D loss: (0.677)(R 0.677, F 0.677)] [D acc: (0.555)(0.556, 0.555)] [G loss: 0.612] [G acc: 0.866]\n",
      "530 [D loss: (0.677)(R 0.677, F 0.677)] [D acc: (0.555)(0.555, 0.555)] [G loss: 0.612] [G acc: 0.867]\n",
      "531 [D loss: (0.677)(R 0.677, F 0.677)] [D acc: (0.555)(0.555, 0.555)] [G loss: 0.612] [G acc: 0.867]\n",
      "532 [D loss: (0.677)(R 0.677, F 0.678)] [D acc: (0.555)(0.555, 0.555)] [G loss: 0.612] [G acc: 0.867]\n",
      "533 [D loss: (0.677)(R 0.677, F 0.678)] [D acc: (0.555)(0.555, 0.555)] [G loss: 0.611] [G acc: 0.867]\n",
      "534 [D loss: (0.678)(R 0.677, F 0.678)] [D acc: (0.555)(0.555, 0.555)] [G loss: 0.611] [G acc: 0.868]\n",
      "535 [D loss: (0.678)(R 0.678, F 0.678)] [D acc: (0.555)(0.555, 0.554)] [G loss: 0.611] [G acc: 0.868]\n",
      "536 [D loss: (0.678)(R 0.678, F 0.678)] [D acc: (0.555)(0.555, 0.554)] [G loss: 0.611] [G acc: 0.868]\n",
      "537 [D loss: (0.678)(R 0.678, F 0.678)] [D acc: (0.554)(0.555, 0.554)] [G loss: 0.611] [G acc: 0.868]\n",
      "538 [D loss: (0.678)(R 0.678, F 0.678)] [D acc: (0.554)(0.555, 0.554)] [G loss: 0.610] [G acc: 0.869]\n",
      "539 [D loss: (0.678)(R 0.678, F 0.678)] [D acc: (0.554)(0.555, 0.554)] [G loss: 0.610] [G acc: 0.869]\n",
      "540 [D loss: (0.678)(R 0.678, F 0.678)] [D acc: (0.554)(0.554, 0.554)] [G loss: 0.610] [G acc: 0.869]\n",
      "541 [D loss: (0.678)(R 0.678, F 0.678)] [D acc: (0.554)(0.554, 0.554)] [G loss: 0.610] [G acc: 0.869]\n",
      "542 [D loss: (0.678)(R 0.678, F 0.678)] [D acc: (0.554)(0.554, 0.554)] [G loss: 0.610] [G acc: 0.869]\n",
      "543 [D loss: (0.678)(R 0.678, F 0.678)] [D acc: (0.554)(0.554, 0.554)] [G loss: 0.610] [G acc: 0.870]\n",
      "544 [D loss: (0.678)(R 0.678, F 0.679)] [D acc: (0.554)(0.554, 0.554)] [G loss: 0.609] [G acc: 0.870]\n",
      "545 [D loss: (0.679)(R 0.678, F 0.679)] [D acc: (0.554)(0.554, 0.553)] [G loss: 0.609] [G acc: 0.870]\n",
      "546 [D loss: (0.679)(R 0.678, F 0.679)] [D acc: (0.554)(0.554, 0.553)] [G loss: 0.609] [G acc: 0.870]\n",
      "547 [D loss: (0.679)(R 0.679, F 0.679)] [D acc: (0.553)(0.554, 0.553)] [G loss: 0.609] [G acc: 0.871]\n",
      "548 [D loss: (0.679)(R 0.679, F 0.679)] [D acc: (0.553)(0.554, 0.553)] [G loss: 0.609] [G acc: 0.871]\n",
      "549 [D loss: (0.679)(R 0.679, F 0.679)] [D acc: (0.553)(0.554, 0.553)] [G loss: 0.608] [G acc: 0.871]\n",
      "550 [D loss: (0.679)(R 0.679, F 0.679)] [D acc: (0.553)(0.553, 0.553)] [G loss: 0.608] [G acc: 0.871]\n",
      "551 [D loss: (0.679)(R 0.679, F 0.679)] [D acc: (0.553)(0.553, 0.553)] [G loss: 0.608] [G acc: 0.872]\n",
      "552 [D loss: (0.679)(R 0.679, F 0.679)] [D acc: (0.553)(0.553, 0.553)] [G loss: 0.608] [G acc: 0.872]\n",
      "553 [D loss: (0.679)(R 0.679, F 0.679)] [D acc: (0.553)(0.553, 0.553)] [G loss: 0.608] [G acc: 0.872]\n",
      "554 [D loss: (0.679)(R 0.679, F 0.679)] [D acc: (0.553)(0.553, 0.553)] [G loss: 0.608] [G acc: 0.872]\n",
      "555 [D loss: (0.679)(R 0.679, F 0.679)] [D acc: (0.553)(0.553, 0.552)] [G loss: 0.607] [G acc: 0.873]\n",
      "556 [D loss: (0.679)(R 0.679, F 0.680)] [D acc: (0.553)(0.553, 0.552)] [G loss: 0.607] [G acc: 0.873]\n",
      "557 [D loss: (0.679)(R 0.679, F 0.680)] [D acc: (0.553)(0.553, 0.552)] [G loss: 0.607] [G acc: 0.873]\n",
      "558 [D loss: (0.680)(R 0.679, F 0.680)] [D acc: (0.552)(0.553, 0.552)] [G loss: 0.607] [G acc: 0.873]\n",
      "559 [D loss: (0.680)(R 0.679, F 0.680)] [D acc: (0.552)(0.553, 0.552)] [G loss: 0.607] [G acc: 0.873]\n",
      "560 [D loss: (0.680)(R 0.680, F 0.680)] [D acc: (0.552)(0.552, 0.552)] [G loss: 0.607] [G acc: 0.874]\n",
      "561 [D loss: (0.680)(R 0.680, F 0.680)] [D acc: (0.552)(0.552, 0.552)] [G loss: 0.606] [G acc: 0.874]\n",
      "562 [D loss: (0.680)(R 0.680, F 0.680)] [D acc: (0.552)(0.552, 0.552)] [G loss: 0.606] [G acc: 0.874]\n",
      "563 [D loss: (0.680)(R 0.680, F 0.680)] [D acc: (0.552)(0.552, 0.552)] [G loss: 0.606] [G acc: 0.874]\n",
      "564 [D loss: (0.680)(R 0.680, F 0.680)] [D acc: (0.552)(0.552, 0.552)] [G loss: 0.606] [G acc: 0.875]\n",
      "565 [D loss: (0.680)(R 0.680, F 0.680)] [D acc: (0.552)(0.552, 0.552)] [G loss: 0.606] [G acc: 0.875]\n",
      "566 [D loss: (0.680)(R 0.680, F 0.680)] [D acc: (0.552)(0.552, 0.551)] [G loss: 0.605] [G acc: 0.875]\n",
      "567 [D loss: (0.680)(R 0.680, F 0.680)] [D acc: (0.552)(0.552, 0.551)] [G loss: 0.605] [G acc: 0.875]\n",
      "568 [D loss: (0.680)(R 0.680, F 0.680)] [D acc: (0.551)(0.552, 0.551)] [G loss: 0.605] [G acc: 0.875]\n",
      "569 [D loss: (0.680)(R 0.680, F 0.681)] [D acc: (0.551)(0.552, 0.551)] [G loss: 0.605] [G acc: 0.876]\n",
      "570 [D loss: (0.680)(R 0.680, F 0.681)] [D acc: (0.551)(0.552, 0.551)] [G loss: 0.605] [G acc: 0.876]\n",
      "571 [D loss: (0.681)(R 0.680, F 0.681)] [D acc: (0.551)(0.551, 0.551)] [G loss: 0.605] [G acc: 0.876]\n",
      "572 [D loss: (0.681)(R 0.680, F 0.681)] [D acc: (0.551)(0.551, 0.551)] [G loss: 0.604] [G acc: 0.876]\n",
      "573 [D loss: (0.681)(R 0.681, F 0.681)] [D acc: (0.551)(0.551, 0.551)] [G loss: 0.604] [G acc: 0.877]\n",
      "574 [D loss: (0.681)(R 0.681, F 0.681)] [D acc: (0.551)(0.551, 0.551)] [G loss: 0.604] [G acc: 0.877]\n",
      "575 [D loss: (0.681)(R 0.681, F 0.681)] [D acc: (0.551)(0.551, 0.551)] [G loss: 0.604] [G acc: 0.877]\n",
      "576 [D loss: (0.681)(R 0.681, F 0.681)] [D acc: (0.551)(0.551, 0.551)] [G loss: 0.604] [G acc: 0.877]\n",
      "577 [D loss: (0.681)(R 0.681, F 0.681)] [D acc: (0.551)(0.551, 0.550)] [G loss: 0.604] [G acc: 0.877]\n",
      "578 [D loss: (0.681)(R 0.681, F 0.681)] [D acc: (0.551)(0.551, 0.550)] [G loss: 0.603] [G acc: 0.878]\n",
      "579 [D loss: (0.681)(R 0.681, F 0.681)] [D acc: (0.551)(0.551, 0.550)] [G loss: 0.603] [G acc: 0.878]\n",
      "580 [D loss: (0.681)(R 0.681, F 0.681)] [D acc: (0.550)(0.551, 0.550)] [G loss: 0.603] [G acc: 0.878]\n",
      "581 [D loss: (0.681)(R 0.681, F 0.681)] [D acc: (0.550)(0.551, 0.550)] [G loss: 0.603] [G acc: 0.878]\n",
      "582 [D loss: (0.681)(R 0.681, F 0.681)] [D acc: (0.550)(0.550, 0.550)] [G loss: 0.603] [G acc: 0.878]\n",
      "583 [D loss: (0.681)(R 0.681, F 0.682)] [D acc: (0.550)(0.550, 0.550)] [G loss: 0.603] [G acc: 0.879]\n",
      "584 [D loss: (0.681)(R 0.681, F 0.682)] [D acc: (0.550)(0.550, 0.550)] [G loss: 0.603] [G acc: 0.879]\n",
      "585 [D loss: (0.682)(R 0.681, F 0.682)] [D acc: (0.550)(0.550, 0.550)] [G loss: 0.602] [G acc: 0.879]\n",
      "586 [D loss: (0.682)(R 0.681, F 0.682)] [D acc: (0.550)(0.550, 0.550)] [G loss: 0.602] [G acc: 0.879]\n",
      "587 [D loss: (0.682)(R 0.682, F 0.682)] [D acc: (0.550)(0.550, 0.550)] [G loss: 0.602] [G acc: 0.879]\n",
      "588 [D loss: (0.682)(R 0.682, F 0.682)] [D acc: (0.550)(0.550, 0.550)] [G loss: 0.602] [G acc: 0.880]\n",
      "589 [D loss: (0.682)(R 0.682, F 0.682)] [D acc: (0.550)(0.550, 0.549)] [G loss: 0.602] [G acc: 0.880]\n",
      "590 [D loss: (0.682)(R 0.682, F 0.682)] [D acc: (0.550)(0.550, 0.549)] [G loss: 0.602] [G acc: 0.880]\n",
      "591 [D loss: (0.682)(R 0.682, F 0.682)] [D acc: (0.549)(0.550, 0.549)] [G loss: 0.601] [G acc: 0.880]\n",
      "592 [D loss: (0.682)(R 0.682, F 0.682)] [D acc: (0.549)(0.550, 0.549)] [G loss: 0.601] [G acc: 0.881]\n",
      "593 [D loss: (0.682)(R 0.682, F 0.682)] [D acc: (0.549)(0.550, 0.549)] [G loss: 0.601] [G acc: 0.881]\n",
      "594 [D loss: (0.682)(R 0.682, F 0.682)] [D acc: (0.549)(0.549, 0.549)] [G loss: 0.601] [G acc: 0.881]\n",
      "595 [D loss: (0.682)(R 0.682, F 0.682)] [D acc: (0.549)(0.549, 0.549)] [G loss: 0.601] [G acc: 0.881]\n",
      "596 [D loss: (0.682)(R 0.682, F 0.682)] [D acc: (0.549)(0.549, 0.549)] [G loss: 0.601] [G acc: 0.881]\n",
      "597 [D loss: (0.682)(R 0.682, F 0.682)] [D acc: (0.549)(0.549, 0.549)] [G loss: 0.601] [G acc: 0.881]\n",
      "598 [D loss: (0.682)(R 0.682, F 0.683)] [D acc: (0.549)(0.549, 0.549)] [G loss: 0.600] [G acc: 0.882]\n",
      "599 [D loss: (0.683)(R 0.682, F 0.683)] [D acc: (0.549)(0.549, 0.549)] [G loss: 0.600] [G acc: 0.882]\n",
      "600 [D loss: (0.683)(R 0.682, F 0.683)] [D acc: (0.549)(0.549, 0.549)] [G loss: 0.600] [G acc: 0.882]\n",
      "601 [D loss: (0.683)(R 0.683, F 0.683)] [D acc: (0.549)(0.549, 0.548)] [G loss: 0.600] [G acc: 0.882]\n",
      "602 [D loss: (0.683)(R 0.683, F 0.683)] [D acc: (0.549)(0.549, 0.548)] [G loss: 0.600] [G acc: 0.882]\n",
      "603 [D loss: (0.683)(R 0.683, F 0.683)] [D acc: (0.549)(0.549, 0.548)] [G loss: 0.600] [G acc: 0.883]\n",
      "604 [D loss: (0.683)(R 0.683, F 0.683)] [D acc: (0.548)(0.549, 0.548)] [G loss: 0.599] [G acc: 0.883]\n",
      "605 [D loss: (0.683)(R 0.683, F 0.683)] [D acc: (0.548)(0.549, 0.548)] [G loss: 0.599] [G acc: 0.883]\n",
      "606 [D loss: (0.683)(R 0.683, F 0.683)] [D acc: (0.548)(0.548, 0.548)] [G loss: 0.599] [G acc: 0.883]\n",
      "607 [D loss: (0.683)(R 0.683, F 0.683)] [D acc: (0.548)(0.548, 0.548)] [G loss: 0.599] [G acc: 0.883]\n",
      "608 [D loss: (0.683)(R 0.683, F 0.683)] [D acc: (0.548)(0.548, 0.548)] [G loss: 0.599] [G acc: 0.884]\n",
      "609 [D loss: (0.683)(R 0.683, F 0.683)] [D acc: (0.548)(0.548, 0.548)] [G loss: 0.599] [G acc: 0.884]\n",
      "610 [D loss: (0.683)(R 0.683, F 0.683)] [D acc: (0.548)(0.548, 0.548)] [G loss: 0.599] [G acc: 0.884]\n",
      "611 [D loss: (0.683)(R 0.683, F 0.683)] [D acc: (0.548)(0.548, 0.548)] [G loss: 0.598] [G acc: 0.884]\n",
      "612 [D loss: (0.683)(R 0.683, F 0.683)] [D acc: (0.548)(0.548, 0.548)] [G loss: 0.598] [G acc: 0.884]\n",
      "613 [D loss: (0.683)(R 0.683, F 0.684)] [D acc: (0.548)(0.548, 0.547)] [G loss: 0.598] [G acc: 0.885]\n",
      "614 [D loss: (0.684)(R 0.683, F 0.684)] [D acc: (0.548)(0.548, 0.547)] [G loss: 0.598] [G acc: 0.885]\n",
      "615 [D loss: (0.684)(R 0.683, F 0.684)] [D acc: (0.548)(0.548, 0.547)] [G loss: 0.598] [G acc: 0.885]\n",
      "616 [D loss: (0.684)(R 0.684, F 0.684)] [D acc: (0.547)(0.548, 0.547)] [G loss: 0.598] [G acc: 0.885]\n",
      "617 [D loss: (0.684)(R 0.684, F 0.684)] [D acc: (0.547)(0.548, 0.547)] [G loss: 0.598] [G acc: 0.885]\n",
      "618 [D loss: (0.684)(R 0.684, F 0.684)] [D acc: (0.547)(0.548, 0.547)] [G loss: 0.597] [G acc: 0.886]\n",
      "619 [D loss: (0.684)(R 0.684, F 0.684)] [D acc: (0.547)(0.547, 0.547)] [G loss: 0.597] [G acc: 0.886]\n",
      "620 [D loss: (0.684)(R 0.684, F 0.684)] [D acc: (0.547)(0.547, 0.547)] [G loss: 0.597] [G acc: 0.886]\n",
      "621 [D loss: (0.684)(R 0.684, F 0.684)] [D acc: (0.547)(0.547, 0.547)] [G loss: 0.597] [G acc: 0.886]\n",
      "622 [D loss: (0.684)(R 0.684, F 0.684)] [D acc: (0.547)(0.547, 0.547)] [G loss: 0.597] [G acc: 0.886]\n",
      "623 [D loss: (0.684)(R 0.684, F 0.684)] [D acc: (0.547)(0.547, 0.547)] [G loss: 0.597] [G acc: 0.886]\n",
      "624 [D loss: (0.684)(R 0.684, F 0.684)] [D acc: (0.547)(0.547, 0.547)] [G loss: 0.597] [G acc: 0.887]\n",
      "625 [D loss: (0.684)(R 0.684, F 0.684)] [D acc: (0.547)(0.547, 0.547)] [G loss: 0.596] [G acc: 0.887]\n",
      "626 [D loss: (0.684)(R 0.684, F 0.684)] [D acc: (0.547)(0.547, 0.547)] [G loss: 0.596] [G acc: 0.887]\n",
      "627 [D loss: (0.684)(R 0.684, F 0.684)] [D acc: (0.547)(0.547, 0.546)] [G loss: 0.596] [G acc: 0.887]\n",
      "628 [D loss: (0.684)(R 0.684, F 0.684)] [D acc: (0.547)(0.547, 0.546)] [G loss: 0.596] [G acc: 0.887]\n",
      "629 [D loss: (0.684)(R 0.684, F 0.685)] [D acc: (0.547)(0.547, 0.546)] [G loss: 0.596] [G acc: 0.888]\n",
      "630 [D loss: (0.685)(R 0.684, F 0.685)] [D acc: (0.546)(0.547, 0.546)] [G loss: 0.596] [G acc: 0.888]\n",
      "631 [D loss: (0.685)(R 0.684, F 0.685)] [D acc: (0.546)(0.547, 0.546)] [G loss: 0.596] [G acc: 0.888]\n",
      "632 [D loss: (0.685)(R 0.685, F 0.685)] [D acc: (0.546)(0.547, 0.546)] [G loss: 0.595] [G acc: 0.888]\n",
      "633 [D loss: (0.685)(R 0.685, F 0.685)] [D acc: (0.546)(0.546, 0.546)] [G loss: 0.595] [G acc: 0.888]\n",
      "634 [D loss: (0.685)(R 0.685, F 0.685)] [D acc: (0.546)(0.546, 0.546)] [G loss: 0.595] [G acc: 0.888]\n",
      "635 [D loss: (0.685)(R 0.685, F 0.685)] [D acc: (0.546)(0.546, 0.546)] [G loss: 0.595] [G acc: 0.889]\n",
      "636 [D loss: (0.685)(R 0.685, F 0.685)] [D acc: (0.546)(0.546, 0.546)] [G loss: 0.595] [G acc: 0.889]\n",
      "637 [D loss: (0.685)(R 0.685, F 0.685)] [D acc: (0.546)(0.546, 0.546)] [G loss: 0.595] [G acc: 0.889]\n",
      "638 [D loss: (0.685)(R 0.685, F 0.685)] [D acc: (0.546)(0.546, 0.546)] [G loss: 0.595] [G acc: 0.889]\n",
      "639 [D loss: (0.685)(R 0.685, F 0.685)] [D acc: (0.546)(0.546, 0.546)] [G loss: 0.594] [G acc: 0.889]\n",
      "640 [D loss: (0.685)(R 0.685, F 0.685)] [D acc: (0.546)(0.546, 0.545)] [G loss: 0.594] [G acc: 0.889]\n",
      "641 [D loss: (0.685)(R 0.685, F 0.685)] [D acc: (0.546)(0.546, 0.545)] [G loss: 0.594] [G acc: 0.890]\n",
      "642 [D loss: (0.685)(R 0.685, F 0.685)] [D acc: (0.546)(0.546, 0.545)] [G loss: 0.594] [G acc: 0.890]\n",
      "643 [D loss: (0.685)(R 0.685, F 0.685)] [D acc: (0.545)(0.546, 0.545)] [G loss: 0.594] [G acc: 0.890]\n",
      "644 [D loss: (0.685)(R 0.685, F 0.685)] [D acc: (0.545)(0.546, 0.545)] [G loss: 0.594] [G acc: 0.890]\n",
      "645 [D loss: (0.685)(R 0.685, F 0.686)] [D acc: (0.545)(0.546, 0.545)] [G loss: 0.594] [G acc: 0.890]\n",
      "646 [D loss: (0.685)(R 0.685, F 0.686)] [D acc: (0.545)(0.545, 0.545)] [G loss: 0.593] [G acc: 0.890]\n",
      "647 [D loss: (0.686)(R 0.685, F 0.686)] [D acc: (0.545)(0.545, 0.545)] [G loss: 0.593] [G acc: 0.891]\n",
      "648 [D loss: (0.686)(R 0.685, F 0.686)] [D acc: (0.545)(0.545, 0.545)] [G loss: 0.593] [G acc: 0.891]\n",
      "649 [D loss: (0.686)(R 0.686, F 0.686)] [D acc: (0.545)(0.545, 0.545)] [G loss: 0.593] [G acc: 0.891]\n",
      "650 [D loss: (0.686)(R 0.686, F 0.686)] [D acc: (0.545)(0.545, 0.545)] [G loss: 0.593] [G acc: 0.891]\n",
      "651 [D loss: (0.686)(R 0.686, F 0.686)] [D acc: (0.545)(0.545, 0.545)] [G loss: 0.593] [G acc: 0.891]\n",
      "652 [D loss: (0.686)(R 0.686, F 0.686)] [D acc: (0.545)(0.545, 0.545)] [G loss: 0.593] [G acc: 0.891]\n",
      "653 [D loss: (0.686)(R 0.686, F 0.686)] [D acc: (0.545)(0.545, 0.545)] [G loss: 0.592] [G acc: 0.892]\n",
      "654 [D loss: (0.686)(R 0.686, F 0.686)] [D acc: (0.545)(0.545, 0.545)] [G loss: 0.592] [G acc: 0.892]\n",
      "655 [D loss: (0.686)(R 0.686, F 0.686)] [D acc: (0.545)(0.545, 0.544)] [G loss: 0.592] [G acc: 0.892]\n",
      "656 [D loss: (0.686)(R 0.686, F 0.686)] [D acc: (0.545)(0.545, 0.544)] [G loss: 0.592] [G acc: 0.892]\n",
      "657 [D loss: (0.686)(R 0.686, F 0.686)] [D acc: (0.545)(0.545, 0.544)] [G loss: 0.592] [G acc: 0.892]\n",
      "658 [D loss: (0.686)(R 0.686, F 0.686)] [D acc: (0.544)(0.545, 0.544)] [G loss: 0.592] [G acc: 0.892]\n",
      "659 [D loss: (0.686)(R 0.686, F 0.686)] [D acc: (0.544)(0.545, 0.544)] [G loss: 0.592] [G acc: 0.893]\n",
      "660 [D loss: (0.686)(R 0.686, F 0.686)] [D acc: (0.544)(0.545, 0.544)] [G loss: 0.592] [G acc: 0.893]\n",
      "661 [D loss: (0.686)(R 0.686, F 0.686)] [D acc: (0.544)(0.544, 0.544)] [G loss: 0.591] [G acc: 0.893]\n",
      "662 [D loss: (0.686)(R 0.686, F 0.687)] [D acc: (0.544)(0.544, 0.544)] [G loss: 0.591] [G acc: 0.893]\n",
      "663 [D loss: (0.686)(R 0.686, F 0.687)] [D acc: (0.544)(0.544, 0.544)] [G loss: 0.591] [G acc: 0.893]\n",
      "664 [D loss: (0.687)(R 0.686, F 0.687)] [D acc: (0.544)(0.544, 0.544)] [G loss: 0.591] [G acc: 0.893]\n",
      "665 [D loss: (0.687)(R 0.686, F 0.687)] [D acc: (0.544)(0.544, 0.544)] [G loss: 0.591] [G acc: 0.894]\n",
      "666 [D loss: (0.687)(R 0.687, F 0.687)] [D acc: (0.544)(0.544, 0.544)] [G loss: 0.591] [G acc: 0.894]\n",
      "667 [D loss: (0.687)(R 0.687, F 0.687)] [D acc: (0.544)(0.544, 0.544)] [G loss: 0.591] [G acc: 0.894]\n",
      "668 [D loss: (0.687)(R 0.687, F 0.687)] [D acc: (0.544)(0.544, 0.544)] [G loss: 0.591] [G acc: 0.894]\n",
      "669 [D loss: (0.687)(R 0.687, F 0.687)] [D acc: (0.544)(0.544, 0.544)] [G loss: 0.590] [G acc: 0.894]\n",
      "670 [D loss: (0.687)(R 0.687, F 0.687)] [D acc: (0.544)(0.544, 0.543)] [G loss: 0.590] [G acc: 0.894]\n",
      "671 [D loss: (0.687)(R 0.687, F 0.687)] [D acc: (0.544)(0.544, 0.543)] [G loss: 0.590] [G acc: 0.895]\n",
      "672 [D loss: (0.687)(R 0.687, F 0.687)] [D acc: (0.544)(0.544, 0.543)] [G loss: 0.590] [G acc: 0.895]\n",
      "673 [D loss: (0.687)(R 0.687, F 0.687)] [D acc: (0.543)(0.544, 0.543)] [G loss: 0.590] [G acc: 0.895]\n",
      "674 [D loss: (0.687)(R 0.687, F 0.687)] [D acc: (0.543)(0.544, 0.543)] [G loss: 0.590] [G acc: 0.895]\n",
      "675 [D loss: (0.687)(R 0.687, F 0.687)] [D acc: (0.543)(0.544, 0.543)] [G loss: 0.590] [G acc: 0.895]\n",
      "676 [D loss: (0.687)(R 0.687, F 0.687)] [D acc: (0.543)(0.543, 0.543)] [G loss: 0.590] [G acc: 0.895]\n",
      "677 [D loss: (0.687)(R 0.687, F 0.687)] [D acc: (0.543)(0.543, 0.543)] [G loss: 0.589] [G acc: 0.895]\n",
      "678 [D loss: (0.687)(R 0.687, F 0.687)] [D acc: (0.543)(0.543, 0.543)] [G loss: 0.589] [G acc: 0.896]\n",
      "679 [D loss: (0.687)(R 0.687, F 0.687)] [D acc: (0.543)(0.543, 0.543)] [G loss: 0.589] [G acc: 0.896]\n",
      "680 [D loss: (0.687)(R 0.687, F 0.688)] [D acc: (0.543)(0.543, 0.543)] [G loss: 0.589] [G acc: 0.896]\n",
      "681 [D loss: (0.687)(R 0.687, F 0.688)] [D acc: (0.543)(0.543, 0.543)] [G loss: 0.589] [G acc: 0.896]\n",
      "682 [D loss: (0.688)(R 0.687, F 0.688)] [D acc: (0.543)(0.543, 0.543)] [G loss: 0.589] [G acc: 0.896]\n",
      "683 [D loss: (0.688)(R 0.687, F 0.688)] [D acc: (0.543)(0.543, 0.543)] [G loss: 0.589] [G acc: 0.896]\n",
      "684 [D loss: (0.688)(R 0.688, F 0.688)] [D acc: (0.543)(0.543, 0.543)] [G loss: 0.589] [G acc: 0.897]\n",
      "685 [D loss: (0.688)(R 0.688, F 0.688)] [D acc: (0.543)(0.543, 0.543)] [G loss: 0.588] [G acc: 0.897]\n",
      "686 [D loss: (0.688)(R 0.688, F 0.688)] [D acc: (0.543)(0.543, 0.542)] [G loss: 0.588] [G acc: 0.897]\n",
      "687 [D loss: (0.688)(R 0.688, F 0.688)] [D acc: (0.543)(0.543, 0.542)] [G loss: 0.588] [G acc: 0.897]\n",
      "688 [D loss: (0.688)(R 0.688, F 0.688)] [D acc: (0.543)(0.543, 0.542)] [G loss: 0.588] [G acc: 0.897]\n",
      "689 [D loss: (0.688)(R 0.688, F 0.688)] [D acc: (0.542)(0.543, 0.542)] [G loss: 0.588] [G acc: 0.897]\n",
      "690 [D loss: (0.688)(R 0.688, F 0.688)] [D acc: (0.542)(0.543, 0.542)] [G loss: 0.588] [G acc: 0.897]\n",
      "691 [D loss: (0.688)(R 0.688, F 0.688)] [D acc: (0.542)(0.543, 0.542)] [G loss: 0.588] [G acc: 0.898]\n",
      "692 [D loss: (0.688)(R 0.688, F 0.688)] [D acc: (0.542)(0.542, 0.542)] [G loss: 0.588] [G acc: 0.898]\n",
      "693 [D loss: (0.688)(R 0.688, F 0.688)] [D acc: (0.542)(0.542, 0.542)] [G loss: 0.587] [G acc: 0.898]\n",
      "694 [D loss: (0.688)(R 0.688, F 0.688)] [D acc: (0.542)(0.542, 0.542)] [G loss: 0.587] [G acc: 0.898]\n",
      "695 [D loss: (0.688)(R 0.688, F 0.688)] [D acc: (0.542)(0.542, 0.542)] [G loss: 0.587] [G acc: 0.898]\n",
      "696 [D loss: (0.688)(R 0.688, F 0.688)] [D acc: (0.542)(0.542, 0.542)] [G loss: 0.587] [G acc: 0.898]\n",
      "697 [D loss: (0.688)(R 0.688, F 0.688)] [D acc: (0.542)(0.542, 0.542)] [G loss: 0.587] [G acc: 0.898]\n",
      "698 [D loss: (0.688)(R 0.688, F 0.688)] [D acc: (0.542)(0.542, 0.542)] [G loss: 0.587] [G acc: 0.899]\n",
      "699 [D loss: (0.688)(R 0.688, F 0.689)] [D acc: (0.542)(0.542, 0.542)] [G loss: 0.587] [G acc: 0.899]\n",
      "700 [D loss: (0.688)(R 0.688, F 0.689)] [D acc: (0.542)(0.542, 0.542)] [G loss: 0.587] [G acc: 0.899]\n",
      "701 [D loss: (0.689)(R 0.688, F 0.689)] [D acc: (0.542)(0.542, 0.542)] [G loss: 0.586] [G acc: 0.899]\n",
      "702 [D loss: (0.689)(R 0.688, F 0.689)] [D acc: (0.542)(0.542, 0.541)] [G loss: 0.586] [G acc: 0.899]\n",
      "703 [D loss: (0.689)(R 0.689, F 0.689)] [D acc: (0.542)(0.542, 0.541)] [G loss: 0.586] [G acc: 0.899]\n",
      "704 [D loss: (0.689)(R 0.689, F 0.689)] [D acc: (0.542)(0.542, 0.541)] [G loss: 0.586] [G acc: 0.899]\n",
      "705 [D loss: (0.689)(R 0.689, F 0.689)] [D acc: (0.541)(0.542, 0.541)] [G loss: 0.586] [G acc: 0.900]\n",
      "706 [D loss: (0.689)(R 0.689, F 0.689)] [D acc: (0.541)(0.542, 0.541)] [G loss: 0.586] [G acc: 0.900]\n",
      "707 [D loss: (0.689)(R 0.689, F 0.689)] [D acc: (0.541)(0.542, 0.541)] [G loss: 0.586] [G acc: 0.900]\n",
      "708 [D loss: (0.689)(R 0.689, F 0.689)] [D acc: (0.541)(0.542, 0.541)] [G loss: 0.586] [G acc: 0.900]\n",
      "709 [D loss: (0.689)(R 0.689, F 0.689)] [D acc: (0.541)(0.541, 0.541)] [G loss: 0.586] [G acc: 0.900]\n",
      "710 [D loss: (0.689)(R 0.689, F 0.689)] [D acc: (0.541)(0.541, 0.541)] [G loss: 0.585] [G acc: 0.900]\n",
      "711 [D loss: (0.689)(R 0.689, F 0.689)] [D acc: (0.541)(0.541, 0.541)] [G loss: 0.585] [G acc: 0.900]\n",
      "712 [D loss: (0.689)(R 0.689, F 0.689)] [D acc: (0.541)(0.541, 0.541)] [G loss: 0.585] [G acc: 0.901]\n",
      "713 [D loss: (0.689)(R 0.689, F 0.689)] [D acc: (0.541)(0.541, 0.541)] [G loss: 0.585] [G acc: 0.901]\n",
      "714 [D loss: (0.689)(R 0.689, F 0.689)] [D acc: (0.541)(0.541, 0.541)] [G loss: 0.585] [G acc: 0.901]\n",
      "715 [D loss: (0.689)(R 0.689, F 0.689)] [D acc: (0.541)(0.541, 0.541)] [G loss: 0.585] [G acc: 0.901]\n",
      "716 [D loss: (0.689)(R 0.689, F 0.689)] [D acc: (0.541)(0.541, 0.541)] [G loss: 0.585] [G acc: 0.901]\n",
      "717 [D loss: (0.689)(R 0.689, F 0.689)] [D acc: (0.541)(0.541, 0.541)] [G loss: 0.585] [G acc: 0.901]\n",
      "718 [D loss: (0.689)(R 0.689, F 0.689)] [D acc: (0.541)(0.541, 0.541)] [G loss: 0.585] [G acc: 0.901]\n",
      "719 [D loss: (0.689)(R 0.689, F 0.689)] [D acc: (0.541)(0.541, 0.541)] [G loss: 0.584] [G acc: 0.902]\n",
      "720 [D loss: (0.689)(R 0.689, F 0.690)] [D acc: (0.541)(0.541, 0.540)] [G loss: 0.584] [G acc: 0.902]\n",
      "721 [D loss: (0.689)(R 0.689, F 0.690)] [D acc: (0.541)(0.541, 0.540)] [G loss: 0.584] [G acc: 0.902]\n",
      "722 [D loss: (0.690)(R 0.689, F 0.690)] [D acc: (0.541)(0.541, 0.540)] [G loss: 0.584] [G acc: 0.902]\n",
      "723 [D loss: (0.690)(R 0.689, F 0.690)] [D acc: (0.540)(0.541, 0.540)] [G loss: 0.584] [G acc: 0.902]\n",
      "724 [D loss: (0.690)(R 0.690, F 0.690)] [D acc: (0.540)(0.541, 0.540)] [G loss: 0.584] [G acc: 0.902]\n",
      "725 [D loss: (0.690)(R 0.690, F 0.690)] [D acc: (0.540)(0.541, 0.540)] [G loss: 0.584] [G acc: 0.902]\n",
      "726 [D loss: (0.690)(R 0.690, F 0.690)] [D acc: (0.540)(0.540, 0.540)] [G loss: 0.584] [G acc: 0.903]\n",
      "727 [D loss: (0.690)(R 0.690, F 0.690)] [D acc: (0.540)(0.540, 0.540)] [G loss: 0.584] [G acc: 0.903]\n",
      "728 [D loss: (0.690)(R 0.690, F 0.690)] [D acc: (0.540)(0.540, 0.540)] [G loss: 0.583] [G acc: 0.903]\n",
      "729 [D loss: (0.690)(R 0.690, F 0.690)] [D acc: (0.540)(0.540, 0.540)] [G loss: 0.583] [G acc: 0.903]\n",
      "730 [D loss: (0.690)(R 0.690, F 0.690)] [D acc: (0.540)(0.540, 0.540)] [G loss: 0.583] [G acc: 0.903]\n",
      "731 [D loss: (0.690)(R 0.690, F 0.690)] [D acc: (0.540)(0.540, 0.540)] [G loss: 0.583] [G acc: 0.903]\n",
      "732 [D loss: (0.690)(R 0.690, F 0.690)] [D acc: (0.540)(0.540, 0.540)] [G loss: 0.583] [G acc: 0.903]\n",
      "733 [D loss: (0.690)(R 0.690, F 0.690)] [D acc: (0.540)(0.540, 0.540)] [G loss: 0.583] [G acc: 0.903]\n",
      "734 [D loss: (0.690)(R 0.690, F 0.690)] [D acc: (0.540)(0.540, 0.540)] [G loss: 0.583] [G acc: 0.904]\n",
      "735 [D loss: (0.690)(R 0.690, F 0.690)] [D acc: (0.540)(0.540, 0.540)] [G loss: 0.583] [G acc: 0.904]\n",
      "736 [D loss: (0.690)(R 0.690, F 0.690)] [D acc: (0.540)(0.540, 0.540)] [G loss: 0.583] [G acc: 0.904]\n",
      "737 [D loss: (0.690)(R 0.690, F 0.690)] [D acc: (0.540)(0.540, 0.540)] [G loss: 0.583] [G acc: 0.904]\n",
      "738 [D loss: (0.690)(R 0.690, F 0.690)] [D acc: (0.540)(0.540, 0.539)] [G loss: 0.582] [G acc: 0.904]\n",
      "739 [D loss: (0.690)(R 0.690, F 0.690)] [D acc: (0.540)(0.540, 0.539)] [G loss: 0.582] [G acc: 0.904]\n",
      "740 [D loss: (0.690)(R 0.690, F 0.690)] [D acc: (0.540)(0.540, 0.539)] [G loss: 0.582] [G acc: 0.904]\n",
      "741 [D loss: (0.690)(R 0.690, F 0.690)] [D acc: (0.539)(0.540, 0.539)] [G loss: 0.582] [G acc: 0.904]\n",
      "742 [D loss: (0.690)(R 0.690, F 0.691)] [D acc: (0.539)(0.540, 0.539)] [G loss: 0.582] [G acc: 0.905]\n",
      "743 [D loss: (0.690)(R 0.690, F 0.691)] [D acc: (0.539)(0.540, 0.539)] [G loss: 0.582] [G acc: 0.905]\n",
      "744 [D loss: (0.691)(R 0.690, F 0.691)] [D acc: (0.539)(0.540, 0.539)] [G loss: 0.582] [G acc: 0.905]\n",
      "745 [D loss: (0.691)(R 0.690, F 0.691)] [D acc: (0.539)(0.539, 0.539)] [G loss: 0.582] [G acc: 0.905]\n",
      "746 [D loss: (0.691)(R 0.691, F 0.691)] [D acc: (0.539)(0.539, 0.539)] [G loss: 0.582] [G acc: 0.905]\n",
      "747 [D loss: (0.691)(R 0.691, F 0.691)] [D acc: (0.539)(0.539, 0.539)] [G loss: 0.581] [G acc: 0.905]\n",
      "748 [D loss: (0.691)(R 0.691, F 0.691)] [D acc: (0.539)(0.539, 0.539)] [G loss: 0.581] [G acc: 0.905]\n",
      "749 [D loss: (0.691)(R 0.691, F 0.691)] [D acc: (0.539)(0.539, 0.539)] [G loss: 0.581] [G acc: 0.906]\n",
      "\n",
      ">>> LR Decay at epoch 750: D_LR=2.00e-04, G_LR=1.00e-04\n",
      "\n",
      "750 [D loss: (0.691)(R 0.691, F 0.691)] [D acc: (0.539)(0.539, 0.539)] [G loss: 0.581] [G acc: 0.906]\n",
      "751 [D loss: (0.691)(R 0.691, F 0.691)] [D acc: (0.539)(0.539, 0.539)] [G loss: 0.581] [G acc: 0.906]\n",
      "752 [D loss: (0.691)(R 0.691, F 0.691)] [D acc: (0.539)(0.539, 0.539)] [G loss: 0.581] [G acc: 0.906]\n",
      "753 [D loss: (0.691)(R 0.691, F 0.691)] [D acc: (0.539)(0.539, 0.539)] [G loss: 0.581] [G acc: 0.906]\n",
      "754 [D loss: (0.691)(R 0.691, F 0.691)] [D acc: (0.539)(0.539, 0.539)] [G loss: 0.581] [G acc: 0.906]\n",
      "755 [D loss: (0.691)(R 0.691, F 0.691)] [D acc: (0.539)(0.539, 0.539)] [G loss: 0.581] [G acc: 0.906]\n",
      "756 [D loss: (0.691)(R 0.691, F 0.691)] [D acc: (0.539)(0.539, 0.539)] [G loss: 0.581] [G acc: 0.906]\n",
      "757 [D loss: (0.691)(R 0.691, F 0.691)] [D acc: (0.539)(0.539, 0.538)] [G loss: 0.580] [G acc: 0.907]\n",
      "758 [D loss: (0.691)(R 0.691, F 0.691)] [D acc: (0.539)(0.539, 0.538)] [G loss: 0.580] [G acc: 0.907]\n",
      "759 [D loss: (0.691)(R 0.691, F 0.691)] [D acc: (0.539)(0.539, 0.538)] [G loss: 0.580] [G acc: 0.907]\n",
      "760 [D loss: (0.691)(R 0.691, F 0.691)] [D acc: (0.538)(0.539, 0.538)] [G loss: 0.580] [G acc: 0.907]\n",
      "761 [D loss: (0.691)(R 0.691, F 0.691)] [D acc: (0.538)(0.539, 0.538)] [G loss: 0.580] [G acc: 0.907]\n",
      "762 [D loss: (0.691)(R 0.691, F 0.691)] [D acc: (0.538)(0.539, 0.538)] [G loss: 0.580] [G acc: 0.907]\n",
      "763 [D loss: (0.691)(R 0.691, F 0.691)] [D acc: (0.538)(0.539, 0.538)] [G loss: 0.580] [G acc: 0.907]\n",
      "764 [D loss: (0.691)(R 0.691, F 0.691)] [D acc: (0.538)(0.538, 0.538)] [G loss: 0.580] [G acc: 0.907]\n",
      "765 [D loss: (0.691)(R 0.691, F 0.691)] [D acc: (0.538)(0.538, 0.538)] [G loss: 0.579] [G acc: 0.907]\n",
      "766 [D loss: (0.691)(R 0.691, F 0.691)] [D acc: (0.538)(0.538, 0.538)] [G loss: 0.579] [G acc: 0.908]\n",
      "767 [D loss: (0.691)(R 0.691, F 0.691)] [D acc: (0.538)(0.538, 0.538)] [G loss: 0.579] [G acc: 0.908]\n",
      "768 [D loss: (0.691)(R 0.691, F 0.692)] [D acc: (0.538)(0.538, 0.538)] [G loss: 0.579] [G acc: 0.908]\n",
      "769 [D loss: (0.691)(R 0.691, F 0.692)] [D acc: (0.538)(0.538, 0.538)] [G loss: 0.579] [G acc: 0.908]\n",
      "770 [D loss: (0.691)(R 0.691, F 0.692)] [D acc: (0.538)(0.538, 0.538)] [G loss: 0.579] [G acc: 0.908]\n",
      "771 [D loss: (0.692)(R 0.691, F 0.692)] [D acc: (0.538)(0.538, 0.538)] [G loss: 0.579] [G acc: 0.908]\n",
      "772 [D loss: (0.692)(R 0.691, F 0.692)] [D acc: (0.538)(0.538, 0.538)] [G loss: 0.579] [G acc: 0.908]\n",
      "773 [D loss: (0.692)(R 0.692, F 0.692)] [D acc: (0.538)(0.538, 0.538)] [G loss: 0.579] [G acc: 0.908]\n",
      "774 [D loss: (0.692)(R 0.692, F 0.692)] [D acc: (0.538)(0.538, 0.538)] [G loss: 0.578] [G acc: 0.909]\n",
      "775 [D loss: (0.692)(R 0.692, F 0.692)] [D acc: (0.538)(0.538, 0.538)] [G loss: 0.578] [G acc: 0.909]\n",
      "776 [D loss: (0.692)(R 0.692, F 0.692)] [D acc: (0.538)(0.538, 0.538)] [G loss: 0.578] [G acc: 0.909]\n",
      "777 [D loss: (0.692)(R 0.692, F 0.692)] [D acc: (0.538)(0.538, 0.537)] [G loss: 0.578] [G acc: 0.909]\n",
      "778 [D loss: (0.692)(R 0.692, F 0.692)] [D acc: (0.538)(0.538, 0.537)] [G loss: 0.578] [G acc: 0.909]\n",
      "779 [D loss: (0.692)(R 0.692, F 0.692)] [D acc: (0.538)(0.538, 0.537)] [G loss: 0.578] [G acc: 0.909]\n",
      "780 [D loss: (0.692)(R 0.692, F 0.692)] [D acc: (0.538)(0.538, 0.537)] [G loss: 0.578] [G acc: 0.909]\n",
      "781 [D loss: (0.692)(R 0.692, F 0.692)] [D acc: (0.537)(0.538, 0.537)] [G loss: 0.578] [G acc: 0.909]\n",
      "782 [D loss: (0.692)(R 0.692, F 0.692)] [D acc: (0.537)(0.538, 0.537)] [G loss: 0.578] [G acc: 0.909]\n",
      "783 [D loss: (0.692)(R 0.692, F 0.692)] [D acc: (0.537)(0.538, 0.537)] [G loss: 0.577] [G acc: 0.910]\n",
      "784 [D loss: (0.692)(R 0.692, F 0.692)] [D acc: (0.537)(0.537, 0.537)] [G loss: 0.577] [G acc: 0.910]\n",
      "785 [D loss: (0.692)(R 0.692, F 0.692)] [D acc: (0.537)(0.537, 0.537)] [G loss: 0.577] [G acc: 0.910]\n",
      "786 [D loss: (0.692)(R 0.692, F 0.692)] [D acc: (0.537)(0.537, 0.537)] [G loss: 0.577] [G acc: 0.910]\n",
      "787 [D loss: (0.692)(R 0.692, F 0.692)] [D acc: (0.537)(0.537, 0.537)] [G loss: 0.577] [G acc: 0.910]\n",
      "788 [D loss: (0.692)(R 0.692, F 0.692)] [D acc: (0.537)(0.537, 0.537)] [G loss: 0.577] [G acc: 0.910]\n",
      "789 [D loss: (0.692)(R 0.692, F 0.692)] [D acc: (0.537)(0.537, 0.537)] [G loss: 0.577] [G acc: 0.910]\n",
      "790 [D loss: (0.692)(R 0.692, F 0.692)] [D acc: (0.537)(0.537, 0.537)] [G loss: 0.577] [G acc: 0.910]\n",
      "791 [D loss: (0.692)(R 0.692, F 0.692)] [D acc: (0.537)(0.537, 0.537)] [G loss: 0.577] [G acc: 0.911]\n",
      "792 [D loss: (0.692)(R 0.692, F 0.692)] [D acc: (0.537)(0.537, 0.537)] [G loss: 0.576] [G acc: 0.911]\n",
      "793 [D loss: (0.692)(R 0.692, F 0.692)] [D acc: (0.537)(0.537, 0.537)] [G loss: 0.576] [G acc: 0.911]\n",
      "794 [D loss: (0.692)(R 0.692, F 0.692)] [D acc: (0.537)(0.537, 0.537)] [G loss: 0.576] [G acc: 0.911]\n",
      "795 [D loss: (0.692)(R 0.692, F 0.692)] [D acc: (0.537)(0.537, 0.537)] [G loss: 0.576] [G acc: 0.911]\n",
      "796 [D loss: (0.692)(R 0.692, F 0.693)] [D acc: (0.537)(0.537, 0.537)] [G loss: 0.576] [G acc: 0.911]\n",
      "797 [D loss: (0.692)(R 0.692, F 0.693)] [D acc: (0.537)(0.537, 0.537)] [G loss: 0.576] [G acc: 0.911]\n",
      "798 [D loss: (0.693)(R 0.692, F 0.693)] [D acc: (0.537)(0.537, 0.536)] [G loss: 0.576] [G acc: 0.911]\n",
      "799 [D loss: (0.693)(R 0.692, F 0.693)] [D acc: (0.537)(0.537, 0.536)] [G loss: 0.576] [G acc: 0.911]\n",
      "800 [D loss: (0.693)(R 0.692, F 0.693)] [D acc: (0.537)(0.537, 0.536)] [G loss: 0.576] [G acc: 0.912]\n",
      "801 [D loss: (0.693)(R 0.693, F 0.693)] [D acc: (0.537)(0.537, 0.536)] [G loss: 0.575] [G acc: 0.912]\n",
      "802 [D loss: (0.693)(R 0.693, F 0.693)] [D acc: (0.536)(0.537, 0.536)] [G loss: 0.575] [G acc: 0.912]\n",
      "803 [D loss: (0.693)(R 0.693, F 0.693)] [D acc: (0.536)(0.537, 0.536)] [G loss: 0.575] [G acc: 0.912]\n",
      "804 [D loss: (0.693)(R 0.693, F 0.693)] [D acc: (0.536)(0.537, 0.536)] [G loss: 0.575] [G acc: 0.912]\n",
      "805 [D loss: (0.693)(R 0.693, F 0.693)] [D acc: (0.536)(0.537, 0.536)] [G loss: 0.575] [G acc: 0.912]\n",
      "806 [D loss: (0.693)(R 0.693, F 0.693)] [D acc: (0.536)(0.536, 0.536)] [G loss: 0.575] [G acc: 0.912]\n",
      "807 [D loss: (0.693)(R 0.693, F 0.693)] [D acc: (0.536)(0.536, 0.536)] [G loss: 0.575] [G acc: 0.912]\n",
      "808 [D loss: (0.693)(R 0.693, F 0.693)] [D acc: (0.536)(0.536, 0.536)] [G loss: 0.575] [G acc: 0.912]\n",
      "809 [D loss: (0.693)(R 0.693, F 0.693)] [D acc: (0.536)(0.536, 0.536)] [G loss: 0.575] [G acc: 0.913]\n",
      "810 [D loss: (0.693)(R 0.693, F 0.693)] [D acc: (0.536)(0.536, 0.536)] [G loss: 0.574] [G acc: 0.913]\n",
      "811 [D loss: (0.693)(R 0.693, F 0.693)] [D acc: (0.536)(0.536, 0.536)] [G loss: 0.574] [G acc: 0.913]\n",
      "812 [D loss: (0.693)(R 0.693, F 0.693)] [D acc: (0.536)(0.536, 0.536)] [G loss: 0.574] [G acc: 0.913]\n",
      "813 [D loss: (0.693)(R 0.693, F 0.693)] [D acc: (0.536)(0.536, 0.536)] [G loss: 0.574] [G acc: 0.913]\n",
      "814 [D loss: (0.693)(R 0.693, F 0.693)] [D acc: (0.536)(0.536, 0.536)] [G loss: 0.574] [G acc: 0.913]\n",
      "815 [D loss: (0.693)(R 0.693, F 0.693)] [D acc: (0.536)(0.536, 0.536)] [G loss: 0.574] [G acc: 0.913]\n",
      "816 [D loss: (0.693)(R 0.693, F 0.693)] [D acc: (0.536)(0.536, 0.536)] [G loss: 0.574] [G acc: 0.913]\n",
      "817 [D loss: (0.693)(R 0.693, F 0.693)] [D acc: (0.536)(0.536, 0.536)] [G loss: 0.574] [G acc: 0.913]\n",
      "818 [D loss: (0.693)(R 0.693, F 0.693)] [D acc: (0.536)(0.536, 0.536)] [G loss: 0.574] [G acc: 0.913]\n",
      "819 [D loss: (0.693)(R 0.693, F 0.693)] [D acc: (0.536)(0.536, 0.536)] [G loss: 0.574] [G acc: 0.914]\n",
      "820 [D loss: (0.693)(R 0.693, F 0.693)] [D acc: (0.536)(0.536, 0.536)] [G loss: 0.573] [G acc: 0.914]\n",
      "821 [D loss: (0.693)(R 0.693, F 0.693)] [D acc: (0.536)(0.536, 0.535)] [G loss: 0.573] [G acc: 0.914]\n",
      "822 [D loss: (0.693)(R 0.693, F 0.693)] [D acc: (0.536)(0.536, 0.535)] [G loss: 0.573] [G acc: 0.914]\n",
      "823 [D loss: (0.693)(R 0.693, F 0.693)] [D acc: (0.536)(0.536, 0.535)] [G loss: 0.573] [G acc: 0.914]\n",
      "824 [D loss: (0.693)(R 0.693, F 0.693)] [D acc: (0.536)(0.536, 0.535)] [G loss: 0.573] [G acc: 0.914]\n",
      "825 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.535)(0.536, 0.535)] [G loss: 0.573] [G acc: 0.914]\n",
      "826 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.535)(0.536, 0.535)] [G loss: 0.573] [G acc: 0.914]\n",
      "827 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.535)(0.536, 0.535)] [G loss: 0.573] [G acc: 0.914]\n",
      "828 [D loss: (0.694)(R 0.693, F 0.694)] [D acc: (0.535)(0.536, 0.535)] [G loss: 0.573] [G acc: 0.915]\n",
      "829 [D loss: (0.694)(R 0.693, F 0.694)] [D acc: (0.535)(0.535, 0.535)] [G loss: 0.572] [G acc: 0.915]\n",
      "830 [D loss: (0.694)(R 0.694, F 0.694)] [D acc: (0.535)(0.535, 0.535)] [G loss: 0.572] [G acc: 0.915]\n",
      "831 [D loss: (0.694)(R 0.694, F 0.694)] [D acc: (0.535)(0.535, 0.535)] [G loss: 0.572] [G acc: 0.915]\n",
      "832 [D loss: (0.694)(R 0.694, F 0.694)] [D acc: (0.535)(0.535, 0.535)] [G loss: 0.572] [G acc: 0.915]\n",
      "833 [D loss: (0.694)(R 0.694, F 0.694)] [D acc: (0.535)(0.535, 0.535)] [G loss: 0.572] [G acc: 0.915]\n",
      "834 [D loss: (0.694)(R 0.694, F 0.694)] [D acc: (0.535)(0.535, 0.535)] [G loss: 0.572] [G acc: 0.915]\n",
      "835 [D loss: (0.694)(R 0.694, F 0.694)] [D acc: (0.535)(0.535, 0.535)] [G loss: 0.572] [G acc: 0.915]\n",
      "836 [D loss: (0.694)(R 0.694, F 0.694)] [D acc: (0.535)(0.535, 0.535)] [G loss: 0.572] [G acc: 0.915]\n",
      "837 [D loss: (0.694)(R 0.694, F 0.694)] [D acc: (0.535)(0.535, 0.535)] [G loss: 0.572] [G acc: 0.915]\n",
      "838 [D loss: (0.694)(R 0.694, F 0.694)] [D acc: (0.535)(0.535, 0.535)] [G loss: 0.572] [G acc: 0.916]\n",
      "839 [D loss: (0.694)(R 0.694, F 0.694)] [D acc: (0.535)(0.535, 0.535)] [G loss: 0.571] [G acc: 0.916]\n",
      "840 [D loss: (0.694)(R 0.694, F 0.694)] [D acc: (0.535)(0.535, 0.535)] [G loss: 0.571] [G acc: 0.916]\n",
      "841 [D loss: (0.694)(R 0.694, F 0.694)] [D acc: (0.535)(0.535, 0.535)] [G loss: 0.571] [G acc: 0.916]\n",
      "842 [D loss: (0.694)(R 0.694, F 0.694)] [D acc: (0.535)(0.535, 0.535)] [G loss: 0.571] [G acc: 0.916]\n",
      "843 [D loss: (0.694)(R 0.694, F 0.694)] [D acc: (0.535)(0.535, 0.535)] [G loss: 0.571] [G acc: 0.916]\n",
      "844 [D loss: (0.694)(R 0.694, F 0.694)] [D acc: (0.535)(0.535, 0.535)] [G loss: 0.571] [G acc: 0.916]\n",
      "845 [D loss: (0.694)(R 0.694, F 0.694)] [D acc: (0.535)(0.535, 0.534)] [G loss: 0.571] [G acc: 0.916]\n",
      "846 [D loss: (0.694)(R 0.694, F 0.694)] [D acc: (0.535)(0.535, 0.534)] [G loss: 0.571] [G acc: 0.916]\n",
      "847 [D loss: (0.694)(R 0.694, F 0.694)] [D acc: (0.535)(0.535, 0.534)] [G loss: 0.571] [G acc: 0.916]\n",
      "848 [D loss: (0.694)(R 0.694, F 0.694)] [D acc: (0.535)(0.535, 0.534)] [G loss: 0.571] [G acc: 0.917]\n",
      "849 [D loss: (0.694)(R 0.694, F 0.694)] [D acc: (0.534)(0.535, 0.534)] [G loss: 0.570] [G acc: 0.917]\n",
      "850 [D loss: (0.694)(R 0.694, F 0.694)] [D acc: (0.534)(0.535, 0.534)] [G loss: 0.570] [G acc: 0.917]\n",
      "851 [D loss: (0.694)(R 0.694, F 0.694)] [D acc: (0.534)(0.535, 0.534)] [G loss: 0.570] [G acc: 0.917]\n",
      "852 [D loss: (0.694)(R 0.694, F 0.694)] [D acc: (0.534)(0.535, 0.534)] [G loss: 0.570] [G acc: 0.917]\n",
      "853 [D loss: (0.694)(R 0.694, F 0.694)] [D acc: (0.534)(0.534, 0.534)] [G loss: 0.570] [G acc: 0.917]\n",
      "854 [D loss: (0.694)(R 0.694, F 0.694)] [D acc: (0.534)(0.534, 0.534)] [G loss: 0.570] [G acc: 0.917]\n",
      "855 [D loss: (0.694)(R 0.694, F 0.695)] [D acc: (0.534)(0.534, 0.534)] [G loss: 0.570] [G acc: 0.917]\n",
      "856 [D loss: (0.694)(R 0.694, F 0.695)] [D acc: (0.534)(0.534, 0.534)] [G loss: 0.570] [G acc: 0.917]\n",
      "857 [D loss: (0.694)(R 0.694, F 0.695)] [D acc: (0.534)(0.534, 0.534)] [G loss: 0.570] [G acc: 0.917]\n",
      "858 [D loss: (0.695)(R 0.694, F 0.695)] [D acc: (0.534)(0.534, 0.534)] [G loss: 0.570] [G acc: 0.918]\n",
      "859 [D loss: (0.695)(R 0.694, F 0.695)] [D acc: (0.534)(0.534, 0.534)] [G loss: 0.569] [G acc: 0.918]\n",
      "860 [D loss: (0.695)(R 0.695, F 0.695)] [D acc: (0.534)(0.534, 0.534)] [G loss: 0.569] [G acc: 0.918]\n",
      "861 [D loss: (0.695)(R 0.695, F 0.695)] [D acc: (0.534)(0.534, 0.534)] [G loss: 0.569] [G acc: 0.918]\n",
      "862 [D loss: (0.695)(R 0.695, F 0.695)] [D acc: (0.534)(0.534, 0.534)] [G loss: 0.569] [G acc: 0.918]\n",
      "863 [D loss: (0.695)(R 0.695, F 0.695)] [D acc: (0.534)(0.534, 0.534)] [G loss: 0.569] [G acc: 0.918]\n",
      "864 [D loss: (0.695)(R 0.695, F 0.695)] [D acc: (0.534)(0.534, 0.534)] [G loss: 0.569] [G acc: 0.918]\n",
      "865 [D loss: (0.695)(R 0.695, F 0.695)] [D acc: (0.534)(0.534, 0.534)] [G loss: 0.569] [G acc: 0.918]\n",
      "866 [D loss: (0.695)(R 0.695, F 0.695)] [D acc: (0.534)(0.534, 0.534)] [G loss: 0.569] [G acc: 0.918]\n",
      "867 [D loss: (0.695)(R 0.695, F 0.695)] [D acc: (0.534)(0.534, 0.534)] [G loss: 0.569] [G acc: 0.918]\n",
      "868 [D loss: (0.695)(R 0.695, F 0.695)] [D acc: (0.534)(0.534, 0.534)] [G loss: 0.569] [G acc: 0.918]\n",
      "869 [D loss: (0.695)(R 0.695, F 0.695)] [D acc: (0.534)(0.534, 0.534)] [G loss: 0.568] [G acc: 0.919]\n",
      "870 [D loss: (0.695)(R 0.695, F 0.695)] [D acc: (0.534)(0.534, 0.533)] [G loss: 0.568] [G acc: 0.919]\n",
      "871 [D loss: (0.695)(R 0.695, F 0.695)] [D acc: (0.534)(0.534, 0.533)] [G loss: 0.568] [G acc: 0.919]\n",
      "872 [D loss: (0.695)(R 0.695, F 0.695)] [D acc: (0.534)(0.534, 0.533)] [G loss: 0.568] [G acc: 0.919]\n",
      "873 [D loss: (0.695)(R 0.695, F 0.695)] [D acc: (0.534)(0.534, 0.533)] [G loss: 0.568] [G acc: 0.919]\n",
      "874 [D loss: (0.695)(R 0.695, F 0.695)] [D acc: (0.533)(0.534, 0.533)] [G loss: 0.568] [G acc: 0.919]\n",
      "875 [D loss: (0.695)(R 0.695, F 0.695)] [D acc: (0.533)(0.534, 0.533)] [G loss: 0.568] [G acc: 0.919]\n",
      "876 [D loss: (0.695)(R 0.695, F 0.695)] [D acc: (0.533)(0.534, 0.533)] [G loss: 0.568] [G acc: 0.919]\n",
      "877 [D loss: (0.695)(R 0.695, F 0.695)] [D acc: (0.533)(0.534, 0.533)] [G loss: 0.568] [G acc: 0.919]\n",
      "878 [D loss: (0.695)(R 0.695, F 0.695)] [D acc: (0.533)(0.533, 0.533)] [G loss: 0.568] [G acc: 0.919]\n",
      "879 [D loss: (0.695)(R 0.695, F 0.695)] [D acc: (0.533)(0.533, 0.533)] [G loss: 0.568] [G acc: 0.919]\n",
      "880 [D loss: (0.695)(R 0.695, F 0.695)] [D acc: (0.533)(0.533, 0.533)] [G loss: 0.567] [G acc: 0.920]\n",
      "881 [D loss: (0.695)(R 0.695, F 0.695)] [D acc: (0.533)(0.533, 0.533)] [G loss: 0.567] [G acc: 0.920]\n",
      "882 [D loss: (0.695)(R 0.695, F 0.695)] [D acc: (0.533)(0.533, 0.533)] [G loss: 0.567] [G acc: 0.920]\n",
      "883 [D loss: (0.695)(R 0.695, F 0.695)] [D acc: (0.533)(0.533, 0.533)] [G loss: 0.567] [G acc: 0.920]\n",
      "884 [D loss: (0.695)(R 0.695, F 0.695)] [D acc: (0.533)(0.533, 0.533)] [G loss: 0.567] [G acc: 0.920]\n",
      "885 [D loss: (0.695)(R 0.695, F 0.695)] [D acc: (0.533)(0.533, 0.533)] [G loss: 0.567] [G acc: 0.920]\n",
      "886 [D loss: (0.695)(R 0.695, F 0.695)] [D acc: (0.533)(0.533, 0.533)] [G loss: 0.567] [G acc: 0.920]\n",
      "887 [D loss: (0.695)(R 0.695, F 0.696)] [D acc: (0.533)(0.533, 0.533)] [G loss: 0.567] [G acc: 0.920]\n",
      "888 [D loss: (0.695)(R 0.695, F 0.696)] [D acc: (0.533)(0.533, 0.533)] [G loss: 0.567] [G acc: 0.920]\n",
      "889 [D loss: (0.695)(R 0.695, F 0.696)] [D acc: (0.533)(0.533, 0.533)] [G loss: 0.567] [G acc: 0.920]\n",
      "890 [D loss: (0.696)(R 0.695, F 0.696)] [D acc: (0.533)(0.533, 0.533)] [G loss: 0.567] [G acc: 0.920]\n",
      "891 [D loss: (0.696)(R 0.695, F 0.696)] [D acc: (0.533)(0.533, 0.533)] [G loss: 0.566] [G acc: 0.921]\n",
      "892 [D loss: (0.696)(R 0.695, F 0.696)] [D acc: (0.533)(0.533, 0.533)] [G loss: 0.566] [G acc: 0.921]\n",
      "893 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.533)(0.533, 0.533)] [G loss: 0.566] [G acc: 0.921]\n",
      "894 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.533)(0.533, 0.533)] [G loss: 0.566] [G acc: 0.921]\n",
      "895 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.533)(0.533, 0.533)] [G loss: 0.566] [G acc: 0.921]\n",
      "896 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.533)(0.533, 0.533)] [G loss: 0.566] [G acc: 0.921]\n",
      "897 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.533)(0.533, 0.532)] [G loss: 0.566] [G acc: 0.921]\n",
      "898 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.533)(0.533, 0.532)] [G loss: 0.566] [G acc: 0.921]\n",
      "899 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.533)(0.533, 0.532)] [G loss: 0.566] [G acc: 0.921]\n",
      "900 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.533)(0.533, 0.532)] [G loss: 0.566] [G acc: 0.921]\n",
      "901 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.532)(0.533, 0.532)] [G loss: 0.566] [G acc: 0.921]\n",
      "902 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.532)(0.533, 0.532)] [G loss: 0.565] [G acc: 0.922]\n",
      "903 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.532)(0.533, 0.532)] [G loss: 0.565] [G acc: 0.922]\n",
      "904 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.532)(0.533, 0.532)] [G loss: 0.565] [G acc: 0.922]\n",
      "905 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.532)(0.532, 0.532)] [G loss: 0.565] [G acc: 0.922]\n",
      "906 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.532)(0.532, 0.532)] [G loss: 0.565] [G acc: 0.922]\n",
      "907 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.532)(0.532, 0.532)] [G loss: 0.565] [G acc: 0.922]\n",
      "908 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.532)(0.532, 0.532)] [G loss: 0.565] [G acc: 0.922]\n",
      "909 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.532)(0.532, 0.532)] [G loss: 0.565] [G acc: 0.922]\n",
      "910 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.532)(0.532, 0.532)] [G loss: 0.565] [G acc: 0.922]\n",
      "911 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.532)(0.532, 0.532)] [G loss: 0.565] [G acc: 0.922]\n",
      "912 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.532)(0.532, 0.532)] [G loss: 0.565] [G acc: 0.922]\n",
      "913 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.532)(0.532, 0.532)] [G loss: 0.564] [G acc: 0.922]\n",
      "914 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.532)(0.532, 0.532)] [G loss: 0.564] [G acc: 0.923]\n",
      "915 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.532)(0.532, 0.532)] [G loss: 0.564] [G acc: 0.923]\n",
      "916 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.532)(0.532, 0.532)] [G loss: 0.564] [G acc: 0.923]\n",
      "917 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.532)(0.532, 0.532)] [G loss: 0.564] [G acc: 0.923]\n",
      "918 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.532)(0.532, 0.532)] [G loss: 0.564] [G acc: 0.923]\n",
      "919 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.532)(0.532, 0.532)] [G loss: 0.564] [G acc: 0.923]\n",
      "920 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.532)(0.532, 0.532)] [G loss: 0.564] [G acc: 0.923]\n",
      "921 [D loss: (0.696)(R 0.696, F 0.696)] [D acc: (0.532)(0.532, 0.532)] [G loss: 0.564] [G acc: 0.923]\n",
      "922 [D loss: (0.696)(R 0.696, F 0.697)] [D acc: (0.532)(0.532, 0.532)] [G loss: 0.564] [G acc: 0.923]\n",
      "923 [D loss: (0.696)(R 0.696, F 0.697)] [D acc: (0.532)(0.532, 0.532)] [G loss: 0.564] [G acc: 0.923]\n",
      "924 [D loss: (0.697)(R 0.696, F 0.697)] [D acc: (0.532)(0.532, 0.532)] [G loss: 0.564] [G acc: 0.923]\n",
      "925 [D loss: (0.697)(R 0.696, F 0.697)] [D acc: (0.532)(0.532, 0.531)] [G loss: 0.563] [G acc: 0.923]\n",
      "926 [D loss: (0.697)(R 0.696, F 0.697)] [D acc: (0.532)(0.532, 0.531)] [G loss: 0.563] [G acc: 0.924]\n",
      "927 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.532)(0.532, 0.531)] [G loss: 0.563] [G acc: 0.924]\n",
      "928 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.532)(0.532, 0.531)] [G loss: 0.563] [G acc: 0.924]\n",
      "929 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.532)(0.532, 0.531)] [G loss: 0.563] [G acc: 0.924]\n",
      "930 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.532, 0.531)] [G loss: 0.563] [G acc: 0.924]\n",
      "931 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.532, 0.531)] [G loss: 0.563] [G acc: 0.924]\n",
      "932 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.532, 0.531)] [G loss: 0.563] [G acc: 0.924]\n",
      "933 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.532, 0.531)] [G loss: 0.563] [G acc: 0.924]\n",
      "934 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.531, 0.531)] [G loss: 0.563] [G acc: 0.924]\n",
      "935 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.531, 0.531)] [G loss: 0.563] [G acc: 0.924]\n",
      "936 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.531, 0.531)] [G loss: 0.563] [G acc: 0.924]\n",
      "937 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.531, 0.531)] [G loss: 0.562] [G acc: 0.924]\n",
      "938 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.531, 0.531)] [G loss: 0.562] [G acc: 0.925]\n",
      "939 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.531, 0.531)] [G loss: 0.562] [G acc: 0.925]\n",
      "940 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.531, 0.531)] [G loss: 0.562] [G acc: 0.925]\n",
      "941 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.531, 0.531)] [G loss: 0.562] [G acc: 0.925]\n",
      "942 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.531, 0.531)] [G loss: 0.562] [G acc: 0.925]\n",
      "943 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.531, 0.531)] [G loss: 0.562] [G acc: 0.925]\n",
      "944 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.531, 0.531)] [G loss: 0.562] [G acc: 0.925]\n",
      "945 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.531, 0.531)] [G loss: 0.562] [G acc: 0.925]\n",
      "946 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.531, 0.531)] [G loss: 0.562] [G acc: 0.925]\n",
      "947 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.531, 0.531)] [G loss: 0.562] [G acc: 0.925]\n",
      "948 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.531, 0.531)] [G loss: 0.562] [G acc: 0.925]\n",
      "949 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.531, 0.531)] [G loss: 0.561] [G acc: 0.925]\n",
      "950 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.531, 0.531)] [G loss: 0.561] [G acc: 0.925]\n",
      "951 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.531, 0.531)] [G loss: 0.561] [G acc: 0.926]\n",
      "952 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.531, 0.531)] [G loss: 0.561] [G acc: 0.926]\n",
      "953 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.531, 0.531)] [G loss: 0.561] [G acc: 0.926]\n",
      "954 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.531, 0.531)] [G loss: 0.561] [G acc: 0.926]\n",
      "955 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.531, 0.531)] [G loss: 0.561] [G acc: 0.926]\n",
      "956 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.531, 0.530)] [G loss: 0.561] [G acc: 0.926]\n",
      "957 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.531, 0.530)] [G loss: 0.561] [G acc: 0.926]\n",
      "958 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.531, 0.530)] [G loss: 0.561] [G acc: 0.926]\n",
      "959 [D loss: (0.697)(R 0.697, F 0.697)] [D acc: (0.531)(0.531, 0.530)] [G loss: 0.561] [G acc: 0.926]\n",
      "960 [D loss: (0.697)(R 0.697, F 0.698)] [D acc: (0.530)(0.531, 0.530)] [G loss: 0.561] [G acc: 0.926]\n",
      "961 [D loss: (0.697)(R 0.697, F 0.698)] [D acc: (0.530)(0.531, 0.530)] [G loss: 0.561] [G acc: 0.926]\n",
      "962 [D loss: (0.698)(R 0.697, F 0.698)] [D acc: (0.530)(0.531, 0.530)] [G loss: 0.560] [G acc: 0.926]\n",
      "963 [D loss: (0.698)(R 0.697, F 0.698)] [D acc: (0.530)(0.531, 0.530)] [G loss: 0.560] [G acc: 0.926]\n",
      "964 [D loss: (0.698)(R 0.697, F 0.698)] [D acc: (0.530)(0.530, 0.530)] [G loss: 0.560] [G acc: 0.927]\n",
      "965 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.530)(0.530, 0.530)] [G loss: 0.560] [G acc: 0.927]\n",
      "966 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.530)(0.530, 0.530)] [G loss: 0.560] [G acc: 0.927]\n",
      "967 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.530)(0.530, 0.530)] [G loss: 0.560] [G acc: 0.927]\n",
      "968 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.530)(0.530, 0.530)] [G loss: 0.560] [G acc: 0.927]\n",
      "969 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.530)(0.530, 0.530)] [G loss: 0.560] [G acc: 0.927]\n",
      "970 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.530)(0.530, 0.530)] [G loss: 0.560] [G acc: 0.927]\n",
      "971 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.530)(0.530, 0.530)] [G loss: 0.560] [G acc: 0.927]\n",
      "972 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.530)(0.530, 0.530)] [G loss: 0.560] [G acc: 0.927]\n",
      "973 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.530)(0.530, 0.530)] [G loss: 0.560] [G acc: 0.927]\n",
      "974 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.530)(0.530, 0.530)] [G loss: 0.560] [G acc: 0.927]\n",
      "975 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.530)(0.530, 0.530)] [G loss: 0.559] [G acc: 0.927]\n",
      "976 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.530)(0.530, 0.530)] [G loss: 0.559] [G acc: 0.927]\n",
      "977 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.530)(0.530, 0.530)] [G loss: 0.559] [G acc: 0.928]\n",
      "978 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.530)(0.530, 0.530)] [G loss: 0.559] [G acc: 0.928]\n",
      "979 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.530)(0.530, 0.530)] [G loss: 0.559] [G acc: 0.928]\n",
      "980 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.530)(0.530, 0.530)] [G loss: 0.559] [G acc: 0.928]\n",
      "981 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.530)(0.530, 0.530)] [G loss: 0.559] [G acc: 0.928]\n",
      "982 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.530)(0.530, 0.530)] [G loss: 0.559] [G acc: 0.928]\n",
      "983 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.530)(0.530, 0.530)] [G loss: 0.559] [G acc: 0.928]\n",
      "984 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.530)(0.530, 0.530)] [G loss: 0.559] [G acc: 0.928]\n",
      "985 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.530)(0.530, 0.530)] [G loss: 0.559] [G acc: 0.928]\n",
      "986 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.530)(0.530, 0.530)] [G loss: 0.559] [G acc: 0.928]\n",
      "987 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.530)(0.530, 0.530)] [G loss: 0.559] [G acc: 0.928]\n",
      "988 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.530)(0.530, 0.529)] [G loss: 0.558] [G acc: 0.928]\n",
      "989 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.530)(0.530, 0.529)] [G loss: 0.558] [G acc: 0.928]\n",
      "990 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.530)(0.530, 0.529)] [G loss: 0.558] [G acc: 0.928]\n",
      "991 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.530)(0.530, 0.529)] [G loss: 0.558] [G acc: 0.929]\n",
      "992 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.530)(0.530, 0.529)] [G loss: 0.558] [G acc: 0.929]\n",
      "993 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.529)(0.530, 0.529)] [G loss: 0.558] [G acc: 0.929]\n",
      "994 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.529)(0.530, 0.529)] [G loss: 0.558] [G acc: 0.929]\n",
      "995 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.529)(0.530, 0.529)] [G loss: 0.558] [G acc: 0.929]\n",
      "996 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.529)(0.530, 0.529)] [G loss: 0.558] [G acc: 0.929]\n",
      "997 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.529)(0.529, 0.529)] [G loss: 0.558] [G acc: 0.929]\n",
      "998 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.529)(0.529, 0.529)] [G loss: 0.558] [G acc: 0.929]\n",
      "999 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.529)(0.529, 0.529)] [G loss: 0.558] [G acc: 0.929]\n",
      "1000 [D loss: (0.698)(R 0.698, F 0.698)] [D acc: (0.529)(0.529, 0.529)] [G loss: 0.558] [G acc: 0.929]\n",
      "1001 [D loss: (0.698)(R 0.698, F 0.699)] [D acc: (0.529)(0.529, 0.529)] [G loss: 0.558] [G acc: 0.929]\n",
      "1002 [D loss: (0.698)(R 0.698, F 0.699)] [D acc: (0.529)(0.529, 0.529)] [G loss: 0.557] [G acc: 0.929]\n",
      "1003 [D loss: (0.698)(R 0.698, F 0.699)] [D acc: (0.529)(0.529, 0.529)] [G loss: 0.557] [G acc: 0.929]\n",
      "1004 [D loss: (0.699)(R 0.698, F 0.699)] [D acc: (0.529)(0.529, 0.529)] [G loss: 0.557] [G acc: 0.929]\n",
      "1005 [D loss: (0.699)(R 0.698, F 0.699)] [D acc: (0.529)(0.529, 0.529)] [G loss: 0.557] [G acc: 0.930]\n",
      "1006 [D loss: (0.699)(R 0.698, F 0.699)] [D acc: (0.529)(0.529, 0.529)] [G loss: 0.557] [G acc: 0.930]\n",
      "1007 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.529)(0.529, 0.529)] [G loss: 0.557] [G acc: 0.930]\n",
      "1008 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.529)(0.529, 0.529)] [G loss: 0.557] [G acc: 0.930]\n",
      "1009 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.529)(0.529, 0.529)] [G loss: 0.557] [G acc: 0.930]\n",
      "1010 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.529)(0.529, 0.529)] [G loss: 0.557] [G acc: 0.930]\n",
      "1011 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.529)(0.529, 0.529)] [G loss: 0.557] [G acc: 0.930]\n",
      "1012 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.529)(0.529, 0.529)] [G loss: 0.557] [G acc: 0.930]\n",
      "1013 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.529)(0.529, 0.529)] [G loss: 0.557] [G acc: 0.930]\n",
      "1014 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.529)(0.529, 0.529)] [G loss: 0.557] [G acc: 0.930]\n",
      "1015 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.529)(0.529, 0.529)] [G loss: 0.557] [G acc: 0.930]\n",
      "1016 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.529)(0.529, 0.529)] [G loss: 0.557] [G acc: 0.930]\n",
      "1017 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.529)(0.529, 0.529)] [G loss: 0.556] [G acc: 0.930]\n",
      "1018 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.529)(0.529, 0.529)] [G loss: 0.556] [G acc: 0.930]\n",
      "1019 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.529)(0.529, 0.529)] [G loss: 0.556] [G acc: 0.931]\n",
      "1020 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.529)(0.529, 0.529)] [G loss: 0.556] [G acc: 0.931]\n",
      "1021 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.529)(0.529, 0.529)] [G loss: 0.556] [G acc: 0.931]\n",
      "1022 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.529)(0.529, 0.529)] [G loss: 0.556] [G acc: 0.931]\n",
      "1023 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.529)(0.529, 0.528)] [G loss: 0.556] [G acc: 0.931]\n",
      "1024 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.529)(0.529, 0.528)] [G loss: 0.556] [G acc: 0.931]\n",
      "1025 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.529)(0.529, 0.528)] [G loss: 0.556] [G acc: 0.931]\n",
      "1026 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.529)(0.529, 0.528)] [G loss: 0.556] [G acc: 0.931]\n",
      "1027 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.528)(0.529, 0.528)] [G loss: 0.556] [G acc: 0.931]\n",
      "1028 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.528)(0.529, 0.528)] [G loss: 0.556] [G acc: 0.931]\n",
      "1029 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.528)(0.529, 0.528)] [G loss: 0.556] [G acc: 0.931]\n",
      "1030 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.528)(0.529, 0.528)] [G loss: 0.556] [G acc: 0.931]\n",
      "1031 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.528)(0.529, 0.528)] [G loss: 0.556] [G acc: 0.931]\n",
      "1032 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.528)(0.528, 0.528)] [G loss: 0.555] [G acc: 0.931]\n",
      "1033 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.528)(0.528, 0.528)] [G loss: 0.555] [G acc: 0.931]\n",
      "1034 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.528)(0.528, 0.528)] [G loss: 0.555] [G acc: 0.932]\n",
      "1035 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.528)(0.528, 0.528)] [G loss: 0.555] [G acc: 0.932]\n",
      "1036 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.528)(0.528, 0.528)] [G loss: 0.555] [G acc: 0.932]\n",
      "1037 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.528)(0.528, 0.528)] [G loss: 0.555] [G acc: 0.932]\n",
      "1038 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.528)(0.528, 0.528)] [G loss: 0.555] [G acc: 0.932]\n",
      "1039 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.528)(0.528, 0.528)] [G loss: 0.555] [G acc: 0.932]\n",
      "1040 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.528)(0.528, 0.528)] [G loss: 0.555] [G acc: 0.932]\n",
      "1041 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.528)(0.528, 0.528)] [G loss: 0.555] [G acc: 0.932]\n",
      "1042 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.528)(0.528, 0.528)] [G loss: 0.555] [G acc: 0.932]\n",
      "1043 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.528)(0.528, 0.528)] [G loss: 0.555] [G acc: 0.932]\n",
      "1044 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.528)(0.528, 0.528)] [G loss: 0.555] [G acc: 0.932]\n",
      "1045 [D loss: (0.699)(R 0.699, F 0.699)] [D acc: (0.528)(0.528, 0.528)] [G loss: 0.555] [G acc: 0.932]\n",
      "1046 [D loss: (0.699)(R 0.699, F 0.700)] [D acc: (0.528)(0.528, 0.528)] [G loss: 0.555] [G acc: 0.932]\n",
      "1047 [D loss: (0.699)(R 0.699, F 0.700)] [D acc: (0.528)(0.528, 0.528)] [G loss: 0.554] [G acc: 0.932]\n",
      "1048 [D loss: (0.699)(R 0.699, F 0.700)] [D acc: (0.528)(0.528, 0.528)] [G loss: 0.554] [G acc: 0.932]\n",
      "1049 [D loss: (0.700)(R 0.699, F 0.700)] [D acc: (0.528)(0.528, 0.528)] [G loss: 0.554] [G acc: 0.933]\n",
      "1050 [D loss: (0.700)(R 0.699, F 0.700)] [D acc: (0.528)(0.528, 0.528)] [G loss: 0.554] [G acc: 0.933]\n",
      "1051 [D loss: (0.700)(R 0.699, F 0.700)] [D acc: (0.528)(0.528, 0.528)] [G loss: 0.554] [G acc: 0.933]\n",
      "1052 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.528)(0.528, 0.528)] [G loss: 0.554] [G acc: 0.933]\n",
      "1053 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.528)(0.528, 0.528)] [G loss: 0.554] [G acc: 0.933]\n",
      "1054 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.528)(0.528, 0.528)] [G loss: 0.554] [G acc: 0.933]\n",
      "1055 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.528)(0.528, 0.528)] [G loss: 0.554] [G acc: 0.933]\n",
      "1056 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.528)(0.528, 0.528)] [G loss: 0.554] [G acc: 0.933]\n",
      "1057 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.528)(0.528, 0.528)] [G loss: 0.554] [G acc: 0.933]\n",
      "1058 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.528)(0.528, 0.528)] [G loss: 0.554] [G acc: 0.933]\n",
      "1059 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.528)(0.528, 0.528)] [G loss: 0.554] [G acc: 0.933]\n",
      "1060 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.528)(0.528, 0.527)] [G loss: 0.554] [G acc: 0.933]\n",
      "1061 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.528)(0.528, 0.527)] [G loss: 0.554] [G acc: 0.933]\n",
      "1062 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.528)(0.528, 0.527)] [G loss: 0.554] [G acc: 0.933]\n",
      "1063 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.528)(0.528, 0.527)] [G loss: 0.553] [G acc: 0.933]\n",
      "1064 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.528)(0.528, 0.527)] [G loss: 0.553] [G acc: 0.933]\n",
      "1065 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.528, 0.527)] [G loss: 0.553] [G acc: 0.934]\n",
      "1066 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.528, 0.527)] [G loss: 0.553] [G acc: 0.934]\n",
      "1067 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.528, 0.527)] [G loss: 0.553] [G acc: 0.934]\n",
      "1068 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.528, 0.527)] [G loss: 0.553] [G acc: 0.934]\n",
      "1069 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.528, 0.527)] [G loss: 0.553] [G acc: 0.934]\n",
      "1070 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.553] [G acc: 0.934]\n",
      "1071 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.553] [G acc: 0.934]\n",
      "1072 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.553] [G acc: 0.934]\n",
      "1073 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.553] [G acc: 0.934]\n",
      "1074 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.553] [G acc: 0.934]\n",
      "1075 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.553] [G acc: 0.934]\n",
      "1076 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.553] [G acc: 0.934]\n",
      "1077 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.553] [G acc: 0.934]\n",
      "1078 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.553] [G acc: 0.934]\n",
      "1079 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.552] [G acc: 0.934]\n",
      "1080 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.552] [G acc: 0.934]\n",
      "1081 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.552] [G acc: 0.935]\n",
      "1082 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.552] [G acc: 0.935]\n",
      "1083 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.552] [G acc: 0.935]\n",
      "1084 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.552] [G acc: 0.935]\n",
      "1085 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.552] [G acc: 0.935]\n",
      "1086 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.552] [G acc: 0.935]\n",
      "1087 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.552] [G acc: 0.935]\n",
      "1088 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.552] [G acc: 0.935]\n",
      "1089 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.552] [G acc: 0.935]\n",
      "1090 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.552] [G acc: 0.935]\n",
      "1091 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.552] [G acc: 0.935]\n",
      "1092 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.552] [G acc: 0.935]\n",
      "1093 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.552] [G acc: 0.935]\n",
      "1094 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.552] [G acc: 0.935]\n",
      "1095 [D loss: (0.700)(R 0.700, F 0.700)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.552] [G acc: 0.935]\n",
      "1096 [D loss: (0.700)(R 0.700, F 0.701)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.551] [G acc: 0.935]\n",
      "1097 [D loss: (0.700)(R 0.700, F 0.701)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.551] [G acc: 0.935]\n",
      "1098 [D loss: (0.700)(R 0.700, F 0.701)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.551] [G acc: 0.936]\n",
      "1099 [D loss: (0.701)(R 0.700, F 0.701)] [D acc: (0.527)(0.527, 0.527)] [G loss: 0.551] [G acc: 0.936]\n",
      "1100 [D loss: (0.701)(R 0.700, F 0.701)] [D acc: (0.527)(0.527, 0.526)] [G loss: 0.551] [G acc: 0.936]\n",
      "1101 [D loss: (0.701)(R 0.700, F 0.701)] [D acc: (0.527)(0.527, 0.526)] [G loss: 0.551] [G acc: 0.936]\n",
      "1102 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.527)(0.527, 0.526)] [G loss: 0.551] [G acc: 0.936]\n",
      "1103 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.527)(0.527, 0.526)] [G loss: 0.551] [G acc: 0.936]\n",
      "1104 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.527)(0.527, 0.526)] [G loss: 0.551] [G acc: 0.936]\n",
      "1105 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.527, 0.526)] [G loss: 0.551] [G acc: 0.936]\n",
      "1106 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.527, 0.526)] [G loss: 0.551] [G acc: 0.936]\n",
      "1107 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.527, 0.526)] [G loss: 0.551] [G acc: 0.936]\n",
      "1108 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.527, 0.526)] [G loss: 0.551] [G acc: 0.936]\n",
      "1109 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.527, 0.526)] [G loss: 0.551] [G acc: 0.936]\n",
      "1110 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.551] [G acc: 0.936]\n",
      "1111 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.551] [G acc: 0.936]\n",
      "1112 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.551] [G acc: 0.936]\n",
      "1113 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.551] [G acc: 0.936]\n",
      "1114 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.550] [G acc: 0.936]\n",
      "1115 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.550] [G acc: 0.937]\n",
      "1116 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.550] [G acc: 0.937]\n",
      "1117 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.550] [G acc: 0.937]\n",
      "1118 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.550] [G acc: 0.937]\n",
      "1119 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.550] [G acc: 0.937]\n",
      "1120 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.550] [G acc: 0.937]\n",
      "1121 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.550] [G acc: 0.937]\n",
      "1122 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.550] [G acc: 0.937]\n",
      "1123 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.550] [G acc: 0.937]\n",
      "1124 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.550] [G acc: 0.937]\n",
      "\n",
      ">>> LR Decay at epoch 1125: D_LR=1.00e-04, G_LR=5.00e-05\n",
      "\n",
      "1125 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.550] [G acc: 0.937]\n",
      "1126 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.550] [G acc: 0.937]\n",
      "1127 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.550] [G acc: 0.937]\n",
      "1128 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.550] [G acc: 0.937]\n",
      "1129 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.550] [G acc: 0.937]\n",
      "1130 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.550] [G acc: 0.937]\n",
      "1131 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.549] [G acc: 0.937]\n",
      "1132 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.549] [G acc: 0.937]\n",
      "1133 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.549] [G acc: 0.938]\n",
      "1134 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.549] [G acc: 0.938]\n",
      "1135 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.549] [G acc: 0.938]\n",
      "1136 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.549] [G acc: 0.938]\n",
      "1137 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.549] [G acc: 0.938]\n",
      "1138 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.549] [G acc: 0.938]\n",
      "1139 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.549] [G acc: 0.938]\n",
      "1140 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.549] [G acc: 0.938]\n",
      "1141 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.549] [G acc: 0.938]\n",
      "1142 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.526)] [G loss: 0.549] [G acc: 0.938]\n",
      "1143 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.525)] [G loss: 0.549] [G acc: 0.938]\n",
      "1144 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.525)] [G loss: 0.549] [G acc: 0.938]\n",
      "1145 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.525)] [G loss: 0.549] [G acc: 0.938]\n",
      "1146 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.525)] [G loss: 0.549] [G acc: 0.938]\n",
      "1147 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.526)(0.526, 0.525)] [G loss: 0.549] [G acc: 0.938]\n",
      "1148 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.525)(0.526, 0.525)] [G loss: 0.548] [G acc: 0.938]\n",
      "1149 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.525)(0.526, 0.525)] [G loss: 0.548] [G acc: 0.938]\n",
      "1150 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.525)(0.526, 0.525)] [G loss: 0.548] [G acc: 0.938]\n",
      "1151 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.525)(0.526, 0.525)] [G loss: 0.548] [G acc: 0.938]\n",
      "1152 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.525)(0.526, 0.525)] [G loss: 0.548] [G acc: 0.939]\n",
      "1153 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.548] [G acc: 0.939]\n",
      "1154 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.548] [G acc: 0.939]\n",
      "1155 [D loss: (0.701)(R 0.701, F 0.701)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.548] [G acc: 0.939]\n",
      "1156 [D loss: (0.701)(R 0.701, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.548] [G acc: 0.939]\n",
      "1157 [D loss: (0.701)(R 0.701, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.548] [G acc: 0.939]\n",
      "1158 [D loss: (0.701)(R 0.701, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.548] [G acc: 0.939]\n",
      "1159 [D loss: (0.701)(R 0.701, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.548] [G acc: 0.939]\n",
      "1160 [D loss: (0.701)(R 0.701, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.548] [G acc: 0.939]\n",
      "1161 [D loss: (0.702)(R 0.701, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.548] [G acc: 0.939]\n",
      "1162 [D loss: (0.702)(R 0.701, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.548] [G acc: 0.939]\n",
      "1163 [D loss: (0.702)(R 0.701, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.548] [G acc: 0.939]\n",
      "1164 [D loss: (0.702)(R 0.701, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.548] [G acc: 0.939]\n",
      "1165 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.547] [G acc: 0.939]\n",
      "1166 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.547] [G acc: 0.939]\n",
      "1167 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.547] [G acc: 0.939]\n",
      "1168 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.547] [G acc: 0.939]\n",
      "1169 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.547] [G acc: 0.939]\n",
      "1170 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.547] [G acc: 0.939]\n",
      "1171 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.547] [G acc: 0.940]\n",
      "1172 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.547] [G acc: 0.940]\n",
      "1173 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.547] [G acc: 0.940]\n",
      "1174 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.547] [G acc: 0.940]\n",
      "1175 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.547] [G acc: 0.940]\n",
      "1176 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.547] [G acc: 0.940]\n",
      "1177 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.547] [G acc: 0.940]\n",
      "1178 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.547] [G acc: 0.940]\n",
      "1179 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.547] [G acc: 0.940]\n",
      "1180 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.547] [G acc: 0.940]\n",
      "1181 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.547] [G acc: 0.940]\n",
      "1182 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.547] [G acc: 0.940]\n",
      "1183 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.546] [G acc: 0.940]\n",
      "1184 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.546] [G acc: 0.940]\n",
      "1185 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.546] [G acc: 0.940]\n",
      "1186 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.546] [G acc: 0.940]\n",
      "1187 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.546] [G acc: 0.940]\n",
      "1188 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.546] [G acc: 0.940]\n",
      "1189 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.525)] [G loss: 0.546] [G acc: 0.940]\n",
      "1190 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.524)] [G loss: 0.546] [G acc: 0.941]\n",
      "1191 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.524)] [G loss: 0.546] [G acc: 0.941]\n",
      "1192 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.524)] [G loss: 0.546] [G acc: 0.941]\n",
      "1193 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.524)] [G loss: 0.546] [G acc: 0.941]\n",
      "1194 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.525)(0.525, 0.524)] [G loss: 0.546] [G acc: 0.941]\n",
      "1195 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.525, 0.524)] [G loss: 0.546] [G acc: 0.941]\n",
      "1196 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.525, 0.524)] [G loss: 0.546] [G acc: 0.941]\n",
      "1197 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.525, 0.524)] [G loss: 0.546] [G acc: 0.941]\n",
      "1198 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.525, 0.524)] [G loss: 0.546] [G acc: 0.941]\n",
      "1199 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.525, 0.524)] [G loss: 0.546] [G acc: 0.941]\n",
      "1200 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.545] [G acc: 0.941]\n",
      "1201 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.545] [G acc: 0.941]\n",
      "1202 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.545] [G acc: 0.941]\n",
      "1203 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.545] [G acc: 0.941]\n",
      "1204 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.545] [G acc: 0.941]\n",
      "1205 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.545] [G acc: 0.941]\n",
      "1206 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.545] [G acc: 0.941]\n",
      "1207 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.545] [G acc: 0.941]\n",
      "1208 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.545] [G acc: 0.941]\n",
      "1209 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.545] [G acc: 0.941]\n",
      "1210 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.545] [G acc: 0.941]\n",
      "1211 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.545] [G acc: 0.942]\n",
      "1212 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.545] [G acc: 0.942]\n",
      "1213 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.545] [G acc: 0.942]\n",
      "1214 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.545] [G acc: 0.942]\n",
      "1215 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.545] [G acc: 0.942]\n",
      "1216 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.545] [G acc: 0.942]\n",
      "1217 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.545] [G acc: 0.942]\n",
      "1218 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.544] [G acc: 0.942]\n",
      "1219 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.544] [G acc: 0.942]\n",
      "1220 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.544] [G acc: 0.942]\n",
      "1221 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.544] [G acc: 0.942]\n",
      "1222 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.544] [G acc: 0.942]\n",
      "1223 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.544] [G acc: 0.942]\n",
      "1224 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.544] [G acc: 0.942]\n",
      "1225 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.544] [G acc: 0.942]\n",
      "1226 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.544] [G acc: 0.942]\n",
      "1227 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.544] [G acc: 0.942]\n",
      "1228 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.544] [G acc: 0.942]\n",
      "1229 [D loss: (0.702)(R 0.702, F 0.702)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.544] [G acc: 0.942]\n",
      "1230 [D loss: (0.702)(R 0.702, F 0.703)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.544] [G acc: 0.942]\n",
      "1231 [D loss: (0.702)(R 0.702, F 0.703)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.544] [G acc: 0.942]\n",
      "1232 [D loss: (0.702)(R 0.702, F 0.703)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.544] [G acc: 0.943]\n",
      "1233 [D loss: (0.702)(R 0.702, F 0.703)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.544] [G acc: 0.943]\n",
      "1234 [D loss: (0.702)(R 0.702, F 0.703)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.544] [G acc: 0.943]\n",
      "1235 [D loss: (0.703)(R 0.702, F 0.703)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.544] [G acc: 0.943]\n",
      "1236 [D loss: (0.703)(R 0.702, F 0.703)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.544] [G acc: 0.943]\n",
      "1237 [D loss: (0.703)(R 0.702, F 0.703)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.543] [G acc: 0.943]\n",
      "1238 [D loss: (0.703)(R 0.702, F 0.703)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.543] [G acc: 0.943]\n",
      "1239 [D loss: (0.703)(R 0.702, F 0.703)] [D acc: (0.524)(0.524, 0.524)] [G loss: 0.543] [G acc: 0.943]\n",
      "1240 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.524)(0.524, 0.523)] [G loss: 0.543] [G acc: 0.943]\n",
      "1241 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.524)(0.524, 0.523)] [G loss: 0.543] [G acc: 0.943]\n",
      "1242 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.524)(0.524, 0.523)] [G loss: 0.543] [G acc: 0.943]\n",
      "1243 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.524)(0.524, 0.523)] [G loss: 0.543] [G acc: 0.943]\n",
      "1244 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.524)(0.524, 0.523)] [G loss: 0.543] [G acc: 0.943]\n",
      "1245 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.524)(0.524, 0.523)] [G loss: 0.543] [G acc: 0.943]\n",
      "1246 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.524, 0.523)] [G loss: 0.543] [G acc: 0.943]\n",
      "1247 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.524, 0.523)] [G loss: 0.543] [G acc: 0.943]\n",
      "1248 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.524, 0.523)] [G loss: 0.543] [G acc: 0.943]\n",
      "1249 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.524, 0.523)] [G loss: 0.543] [G acc: 0.943]\n",
      "1250 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.524, 0.523)] [G loss: 0.543] [G acc: 0.943]\n",
      "1251 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.524, 0.523)] [G loss: 0.543] [G acc: 0.943]\n",
      "1252 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.543] [G acc: 0.943]\n",
      "1253 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.543] [G acc: 0.943]\n",
      "1254 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.543] [G acc: 0.944]\n",
      "1255 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.543] [G acc: 0.944]\n",
      "1256 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.542] [G acc: 0.944]\n",
      "1257 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.542] [G acc: 0.944]\n",
      "1258 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.542] [G acc: 0.944]\n",
      "1259 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.542] [G acc: 0.944]\n",
      "1260 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.542] [G acc: 0.944]\n",
      "1261 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.542] [G acc: 0.944]\n",
      "1262 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.542] [G acc: 0.944]\n",
      "1263 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.542] [G acc: 0.944]\n",
      "1264 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.542] [G acc: 0.944]\n",
      "1265 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.542] [G acc: 0.944]\n",
      "1266 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.542] [G acc: 0.944]\n",
      "1267 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.542] [G acc: 0.944]\n",
      "1268 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.542] [G acc: 0.944]\n",
      "1269 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.542] [G acc: 0.944]\n",
      "1270 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.542] [G acc: 0.944]\n",
      "1271 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.542] [G acc: 0.944]\n",
      "1272 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.542] [G acc: 0.944]\n",
      "1273 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.542] [G acc: 0.944]\n",
      "1274 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.542] [G acc: 0.944]\n",
      "1275 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.541] [G acc: 0.944]\n",
      "1276 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.541] [G acc: 0.945]\n",
      "1277 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.541] [G acc: 0.945]\n",
      "1278 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.541] [G acc: 0.945]\n",
      "1279 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.541] [G acc: 0.945]\n",
      "1280 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.541] [G acc: 0.945]\n",
      "1281 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.541] [G acc: 0.945]\n",
      "1282 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.541] [G acc: 0.945]\n",
      "1283 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.541] [G acc: 0.945]\n",
      "1284 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.541] [G acc: 0.945]\n",
      "1285 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.541] [G acc: 0.945]\n",
      "1286 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.541] [G acc: 0.945]\n",
      "1287 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.541] [G acc: 0.945]\n",
      "1288 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.541] [G acc: 0.945]\n",
      "1289 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.541] [G acc: 0.945]\n",
      "1290 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.541] [G acc: 0.945]\n",
      "1291 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.541] [G acc: 0.945]\n",
      "1292 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.541] [G acc: 0.945]\n",
      "1293 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.541] [G acc: 0.945]\n",
      "1294 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.541] [G acc: 0.945]\n",
      "1295 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.523)] [G loss: 0.540] [G acc: 0.945]\n",
      "1296 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.522)] [G loss: 0.540] [G acc: 0.945]\n",
      "1297 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.522)] [G loss: 0.540] [G acc: 0.945]\n",
      "1298 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.522)] [G loss: 0.540] [G acc: 0.945]\n",
      "1299 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.522)] [G loss: 0.540] [G acc: 0.945]\n",
      "1300 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.523)(0.523, 0.522)] [G loss: 0.540] [G acc: 0.946]\n",
      "1301 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.522)(0.523, 0.522)] [G loss: 0.540] [G acc: 0.946]\n",
      "1302 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.522)(0.523, 0.522)] [G loss: 0.540] [G acc: 0.946]\n",
      "1303 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.522)(0.523, 0.522)] [G loss: 0.540] [G acc: 0.946]\n",
      "1304 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.522)(0.523, 0.522)] [G loss: 0.540] [G acc: 0.946]\n",
      "1305 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.522)(0.523, 0.522)] [G loss: 0.540] [G acc: 0.946]\n",
      "1306 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.522)(0.523, 0.522)] [G loss: 0.540] [G acc: 0.946]\n",
      "1307 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.540] [G acc: 0.946]\n",
      "1308 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.540] [G acc: 0.946]\n",
      "1309 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.540] [G acc: 0.946]\n",
      "1310 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.540] [G acc: 0.946]\n",
      "1311 [D loss: (0.703)(R 0.703, F 0.703)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.540] [G acc: 0.946]\n",
      "1312 [D loss: (0.703)(R 0.703, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.540] [G acc: 0.946]\n",
      "1313 [D loss: (0.703)(R 0.703, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.540] [G acc: 0.946]\n",
      "1314 [D loss: (0.703)(R 0.703, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.540] [G acc: 0.946]\n",
      "1315 [D loss: (0.703)(R 0.703, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.540] [G acc: 0.946]\n",
      "1316 [D loss: (0.703)(R 0.703, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.540] [G acc: 0.946]\n",
      "1317 [D loss: (0.704)(R 0.703, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.539] [G acc: 0.946]\n",
      "1318 [D loss: (0.704)(R 0.703, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.539] [G acc: 0.946]\n",
      "1319 [D loss: (0.704)(R 0.703, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.539] [G acc: 0.946]\n",
      "1320 [D loss: (0.704)(R 0.703, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.539] [G acc: 0.946]\n",
      "1321 [D loss: (0.704)(R 0.703, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.539] [G acc: 0.946]\n",
      "1322 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.539] [G acc: 0.946]\n",
      "1323 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.539] [G acc: 0.946]\n",
      "1324 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.539] [G acc: 0.947]\n",
      "1325 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.539] [G acc: 0.947]\n",
      "1326 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.539] [G acc: 0.947]\n",
      "1327 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.539] [G acc: 0.947]\n",
      "1328 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.539] [G acc: 0.947]\n",
      "1329 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.539] [G acc: 0.947]\n",
      "1330 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.539] [G acc: 0.947]\n",
      "1331 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.539] [G acc: 0.947]\n",
      "1332 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.539] [G acc: 0.947]\n",
      "1333 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.539] [G acc: 0.947]\n",
      "1334 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.539] [G acc: 0.947]\n",
      "1335 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.539] [G acc: 0.947]\n",
      "1336 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.539] [G acc: 0.947]\n",
      "1337 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.539] [G acc: 0.947]\n",
      "1338 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.539] [G acc: 0.947]\n",
      "1339 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.538] [G acc: 0.947]\n",
      "1340 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.538] [G acc: 0.947]\n",
      "1341 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.538] [G acc: 0.947]\n",
      "1342 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.538] [G acc: 0.947]\n",
      "1343 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.538] [G acc: 0.947]\n",
      "1344 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.538] [G acc: 0.947]\n",
      "1345 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.538] [G acc: 0.947]\n",
      "1346 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.538] [G acc: 0.947]\n",
      "1347 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.538] [G acc: 0.947]\n",
      "1348 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.538] [G acc: 0.947]\n",
      "1349 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.538] [G acc: 0.948]\n",
      "1350 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.538] [G acc: 0.948]\n",
      "1351 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.538] [G acc: 0.948]\n",
      "1352 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.538] [G acc: 0.948]\n",
      "1353 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.538] [G acc: 0.948]\n",
      "1354 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.538] [G acc: 0.948]\n",
      "1355 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.522)] [G loss: 0.538] [G acc: 0.948]\n",
      "1356 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.521)] [G loss: 0.538] [G acc: 0.948]\n",
      "1357 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.521)] [G loss: 0.538] [G acc: 0.948]\n",
      "1358 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.521)] [G loss: 0.538] [G acc: 0.948]\n",
      "1359 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.521)] [G loss: 0.538] [G acc: 0.948]\n",
      "1360 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.521)] [G loss: 0.538] [G acc: 0.948]\n",
      "1361 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.522)(0.522, 0.521)] [G loss: 0.537] [G acc: 0.948]\n",
      "1362 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.522, 0.521)] [G loss: 0.537] [G acc: 0.948]\n",
      "1363 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.522, 0.521)] [G loss: 0.537] [G acc: 0.948]\n",
      "1364 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.522, 0.521)] [G loss: 0.537] [G acc: 0.948]\n",
      "1365 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.522, 0.521)] [G loss: 0.537] [G acc: 0.948]\n",
      "1366 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.522, 0.521)] [G loss: 0.537] [G acc: 0.948]\n",
      "1367 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.522, 0.521)] [G loss: 0.537] [G acc: 0.948]\n",
      "1368 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.537] [G acc: 0.948]\n",
      "1369 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.537] [G acc: 0.948]\n",
      "1370 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.537] [G acc: 0.948]\n",
      "1371 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.537] [G acc: 0.948]\n",
      "1372 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.537] [G acc: 0.948]\n",
      "1373 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.537] [G acc: 0.948]\n",
      "1374 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.537] [G acc: 0.948]\n",
      "1375 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.537] [G acc: 0.948]\n",
      "1376 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.537] [G acc: 0.949]\n",
      "1377 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.537] [G acc: 0.949]\n",
      "1378 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.537] [G acc: 0.949]\n",
      "1379 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.537] [G acc: 0.949]\n",
      "1380 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.537] [G acc: 0.949]\n",
      "1381 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.537] [G acc: 0.949]\n",
      "1382 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.537] [G acc: 0.949]\n",
      "1383 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.537] [G acc: 0.949]\n",
      "1384 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.537] [G acc: 0.949]\n",
      "1385 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.536] [G acc: 0.949]\n",
      "1386 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.536] [G acc: 0.949]\n",
      "1387 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.536] [G acc: 0.949]\n",
      "1388 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.536] [G acc: 0.949]\n",
      "1389 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.536] [G acc: 0.949]\n",
      "1390 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.536] [G acc: 0.949]\n",
      "1391 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.536] [G acc: 0.949]\n",
      "1392 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.536] [G acc: 0.949]\n",
      "1393 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.536] [G acc: 0.949]\n",
      "1394 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.536] [G acc: 0.949]\n",
      "1395 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.536] [G acc: 0.949]\n",
      "1396 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.536] [G acc: 0.949]\n",
      "1397 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.536] [G acc: 0.949]\n",
      "1398 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.536] [G acc: 0.949]\n",
      "1399 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.536] [G acc: 0.949]\n",
      "1400 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.536] [G acc: 0.949]\n",
      "1401 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.536] [G acc: 0.949]\n",
      "1402 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.536] [G acc: 0.949]\n",
      "1403 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.536] [G acc: 0.950]\n",
      "1404 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.536] [G acc: 0.950]\n",
      "1405 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.536] [G acc: 0.950]\n",
      "1406 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.536] [G acc: 0.950]\n",
      "1407 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.536] [G acc: 0.950]\n",
      "1408 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.536] [G acc: 0.950]\n",
      "1409 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.536] [G acc: 0.950]\n",
      "1410 [D loss: (0.704)(R 0.704, F 0.704)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.535] [G acc: 0.950]\n",
      "1411 [D loss: (0.704)(R 0.704, F 0.705)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.535] [G acc: 0.950]\n",
      "1412 [D loss: (0.704)(R 0.704, F 0.705)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.535] [G acc: 0.950]\n",
      "1413 [D loss: (0.704)(R 0.704, F 0.705)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.535] [G acc: 0.950]\n",
      "1414 [D loss: (0.704)(R 0.704, F 0.705)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.535] [G acc: 0.950]\n",
      "1415 [D loss: (0.704)(R 0.704, F 0.705)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.535] [G acc: 0.950]\n",
      "1416 [D loss: (0.704)(R 0.704, F 0.705)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.535] [G acc: 0.950]\n",
      "1417 [D loss: (0.705)(R 0.704, F 0.705)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.535] [G acc: 0.950]\n",
      "1418 [D loss: (0.705)(R 0.704, F 0.705)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.535] [G acc: 0.950]\n",
      "1419 [D loss: (0.705)(R 0.704, F 0.705)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.535] [G acc: 0.950]\n",
      "1420 [D loss: (0.705)(R 0.704, F 0.705)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.535] [G acc: 0.950]\n",
      "1421 [D loss: (0.705)(R 0.704, F 0.705)] [D acc: (0.521)(0.521, 0.521)] [G loss: 0.535] [G acc: 0.950]\n",
      "1422 [D loss: (0.705)(R 0.704, F 0.705)] [D acc: (0.521)(0.521, 0.520)] [G loss: 0.535] [G acc: 0.950]\n",
      "1423 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.521)(0.521, 0.520)] [G loss: 0.535] [G acc: 0.950]\n",
      "1424 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.521)(0.521, 0.520)] [G loss: 0.535] [G acc: 0.950]\n",
      "1425 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.521)(0.521, 0.520)] [G loss: 0.535] [G acc: 0.950]\n",
      "1426 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.521)(0.521, 0.520)] [G loss: 0.535] [G acc: 0.950]\n",
      "1427 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.521)(0.521, 0.520)] [G loss: 0.535] [G acc: 0.950]\n",
      "1428 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.521, 0.520)] [G loss: 0.535] [G acc: 0.950]\n",
      "1429 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.521, 0.520)] [G loss: 0.535] [G acc: 0.950]\n",
      "1430 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.521, 0.520)] [G loss: 0.535] [G acc: 0.950]\n",
      "1431 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.521, 0.520)] [G loss: 0.535] [G acc: 0.951]\n",
      "1432 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.521, 0.520)] [G loss: 0.535] [G acc: 0.951]\n",
      "1433 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.521, 0.520)] [G loss: 0.535] [G acc: 0.951]\n",
      "1434 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.521, 0.520)] [G loss: 0.535] [G acc: 0.951]\n",
      "1435 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.534] [G acc: 0.951]\n",
      "1436 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.534] [G acc: 0.951]\n",
      "1437 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.534] [G acc: 0.951]\n",
      "1438 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.534] [G acc: 0.951]\n",
      "1439 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.534] [G acc: 0.951]\n",
      "1440 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.534] [G acc: 0.951]\n",
      "1441 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.534] [G acc: 0.951]\n",
      "1442 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.534] [G acc: 0.951]\n",
      "1443 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.534] [G acc: 0.951]\n",
      "1444 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.534] [G acc: 0.951]\n",
      "1445 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.534] [G acc: 0.951]\n",
      "1446 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.534] [G acc: 0.951]\n",
      "1447 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.534] [G acc: 0.951]\n",
      "1448 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.534] [G acc: 0.951]\n",
      "1449 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.534] [G acc: 0.951]\n",
      "1450 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.534] [G acc: 0.951]\n",
      "1451 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.534] [G acc: 0.951]\n",
      "1452 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.534] [G acc: 0.951]\n",
      "1453 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.534] [G acc: 0.951]\n",
      "1454 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.534] [G acc: 0.951]\n",
      "1455 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.534] [G acc: 0.951]\n",
      "1456 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.534] [G acc: 0.951]\n",
      "1457 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.534] [G acc: 0.951]\n",
      "1458 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.534] [G acc: 0.951]\n",
      "1459 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.534] [G acc: 0.951]\n",
      "1460 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.534] [G acc: 0.951]\n",
      "1461 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.534] [G acc: 0.952]\n",
      "1462 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.533] [G acc: 0.952]\n",
      "1463 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.533] [G acc: 0.952]\n",
      "1464 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.533] [G acc: 0.952]\n",
      "1465 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.533] [G acc: 0.952]\n",
      "1466 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.533] [G acc: 0.952]\n",
      "1467 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.533] [G acc: 0.952]\n",
      "1468 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.533] [G acc: 0.952]\n",
      "1469 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.533] [G acc: 0.952]\n",
      "1470 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.533] [G acc: 0.952]\n",
      "1471 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.533] [G acc: 0.952]\n",
      "1472 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.533] [G acc: 0.952]\n",
      "1473 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.533] [G acc: 0.952]\n",
      "1474 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.533] [G acc: 0.952]\n",
      "1475 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.533] [G acc: 0.952]\n",
      "1476 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.533] [G acc: 0.952]\n",
      "1477 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.533] [G acc: 0.952]\n",
      "1478 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.533] [G acc: 0.952]\n",
      "1479 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.533] [G acc: 0.952]\n",
      "1480 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.533] [G acc: 0.952]\n",
      "1481 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.533] [G acc: 0.952]\n",
      "1482 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.533] [G acc: 0.952]\n",
      "1483 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.533] [G acc: 0.952]\n",
      "1484 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.533] [G acc: 0.952]\n",
      "1485 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.533] [G acc: 0.952]\n",
      "1486 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.533] [G acc: 0.952]\n",
      "1487 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.533] [G acc: 0.952]\n",
      "1488 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.533] [G acc: 0.952]\n",
      "1489 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.533] [G acc: 0.952]\n",
      "1490 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.532] [G acc: 0.952]\n",
      "1491 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.532] [G acc: 0.952]\n",
      "1492 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.532] [G acc: 0.953]\n",
      "1493 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.532] [G acc: 0.953]\n",
      "1494 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.520)] [G loss: 0.532] [G acc: 0.953]\n",
      "1495 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.519)] [G loss: 0.532] [G acc: 0.953]\n",
      "1496 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.519)] [G loss: 0.532] [G acc: 0.953]\n",
      "1497 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.519)] [G loss: 0.532] [G acc: 0.953]\n",
      "1498 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.519)] [G loss: 0.532] [G acc: 0.953]\n",
      "1499 [D loss: (0.705)(R 0.705, F 0.705)] [D acc: (0.520)(0.520, 0.519)] [G loss: 0.532] [G acc: 0.953]\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TRAINING\n",
    "# =============================================================================\n",
    "# Train the GAN with:\n",
    "# - W&B logging for all metrics\n",
    "# - Step decay LR scheduler\n",
    "# - Periodic weight saving and sample generation\n",
    "\n",
    "gan.train(\n",
    "    x_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    run_folder=RUN_FOLDER,\n",
    "    print_every_n_batches=PRINT_EVERY_N_BATCHES,\n",
    "    use_wandb=True,           # Enable W&B logging\n",
    "    lr_decay_factor=LR_DECAY_FACTOR,\n",
    "    lr_decay_epochs=LR_DECAY_EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Visualization\n",
    "\n",
    "Generate comprehensive training plots showing loss, accuracy, and LR history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training summary saved to ../run/gan/0001_camel/training_summary.png\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TRAINING VISUALIZATION\n",
    "# =============================================================================\n",
    "# Creates a 3-panel figure showing:\n",
    "# 1. Discriminator/Generator Loss vs Epoch\n",
    "# 2. Discriminator/Generator Accuracy vs Epoch\n",
    "# 3. Learning Rate Schedule (log scale)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Plot 1: D/G Loss vs Epoch\n",
    "# -----------------------------------------------------------------------------\n",
    "ax1 = axes[0]\n",
    "ax1.plot(\n",
    "    [x[0] for x in gan.d_losses],\n",
    "    color='blue', linewidth=0.5, label='D Total'\n",
    ")\n",
    "ax1.plot(\n",
    "    [x[1] for x in gan.d_losses],\n",
    "    color='green', linewidth=0.25, alpha=0.6, label='D Real'\n",
    ")\n",
    "ax1.plot(\n",
    "    [x[2] for x in gan.d_losses],\n",
    "    color='red', linewidth=0.25, alpha=0.6, label='D Fake'\n",
    ")\n",
    "ax1.plot(\n",
    "    [x[0] for x in gan.g_losses],\n",
    "    color='orange', linewidth=0.5, label='G'\n",
    ")\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Loss', fontsize=12)\n",
    "ax1.set_title('Discriminator / Generator Loss', fontsize=14)\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.set_ylim(0, 2)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Plot 2: D/G Accuracy vs Epoch\n",
    "# -----------------------------------------------------------------------------\n",
    "ax2 = axes[1]\n",
    "ax2.plot(\n",
    "    [x[3] for x in gan.d_losses],\n",
    "    color='blue', linewidth=0.5, label='D Total'\n",
    ")\n",
    "ax2.plot(\n",
    "    [x[4] for x in gan.d_losses],\n",
    "    color='green', linewidth=0.25, alpha=0.6, label='D Real'\n",
    ")\n",
    "ax2.plot(\n",
    "    [x[5] for x in gan.d_losses],\n",
    "    color='red', linewidth=0.25, alpha=0.6, label='D Fake'\n",
    ")\n",
    "ax2.plot(\n",
    "    [x[1] for x in gan.g_losses],\n",
    "    color='orange', linewidth=0.5, label='G'\n",
    ")\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('Accuracy', fontsize=12)\n",
    "ax2.set_title('Discriminator / Generator Accuracy', fontsize=14)\n",
    "ax2.legend(loc='lower right')\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Plot 3: Learning Rate vs Epoch (Log Scale)\n",
    "# -----------------------------------------------------------------------------\n",
    "ax3 = axes[2]\n",
    "ax3.semilogy(\n",
    "    gan.d_lr_history,\n",
    "    color='blue', linewidth=1.5, label='Discriminator LR'\n",
    ")\n",
    "ax3.semilogy(\n",
    "    gan.g_lr_history,\n",
    "    color='orange', linewidth=1.5, label='Generator LR'\n",
    ")\n",
    "ax3.set_xlabel('Epoch', fontsize=12)\n",
    "ax3.set_ylabel('Learning Rate (log scale)', fontsize=12)\n",
    "ax3.set_title('Learning Rate Schedule', fontsize=14)\n",
    "ax3.legend(loc='upper right')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Finalize and Save\n",
    "# -----------------------------------------------------------------------------\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    os.path.join(RUN_FOLDER, 'training_summary.png'),\n",
    "    dpi=200,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(f\"✓ Training summary saved to {RUN_FOLDER}/training_summary.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "════════════════════════════════════════════════════════════\n",
      "TRAINING COMPLETE\n",
      "════════════════════════════════════════════════════════════\n",
      "  Epochs trained  : 1500\n",
      "  Final D loss    : 0.7052\n",
      "  Final G loss    : 0.5321\n",
      "  Final D accuracy: 0.5195\n",
      "  Final G accuracy: 0.9527\n",
      "  Final D LR      : 1.00e-04\n",
      "  Final G LR      : 5.00e-05\n",
      "  Weights saved   : ../run/gan/0001_camel/weights/\n",
      "════════════════════════════════════════════════════════════\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TRAINING SUMMARY\n",
    "# =============================================================================\n",
    "# Print final training metrics\n",
    "\n",
    "print(f\"\\n{'═' * 60}\")\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(f\"{'═' * 60}\")\n",
    "print(f\"  Epochs trained  : {gan.epoch}\")\n",
    "print(f\"  Final D loss    : {gan.d_losses[-1][0]:.4f}\")\n",
    "print(f\"  Final G loss    : {gan.g_losses[-1][0]:.4f}\")\n",
    "print(f\"  Final D accuracy: {gan.d_losses[-1][3]:.4f}\")\n",
    "print(f\"  Final G accuracy: {gan.g_losses[-1][1]:.4f}\")\n",
    "print(f\"  Final D LR      : {gan.d_lr_history[-1]:.2e}\")\n",
    "print(f\"  Final G LR      : {gan.g_lr_history[-1]:.2e}\")\n",
    "print(f\"  Weights saved   : {RUN_FOLDER}/weights/\")\n",
    "print(f\"{'═' * 60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Finish W&B run and optionally restart kernel to release GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>d_acc</td><td>▆██▅▅▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>d_acc_fake</td><td>██▆▄▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>d_acc_real</td><td>█▆▅▅▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>d_loss</td><td>▃▁▁▂▄▆▆▆▆▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>d_loss_fake</td><td>█▄▂▁▁▁▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>d_loss_real</td><td>▆▃▂▂▁▃▄▆▆▆▆▇▇▇▇▇████████████████████████</td></tr><tr><td>d_lr</td><td>███████▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>g_acc</td><td>▃▁▁▂▄▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>g_loss</td><td>▃██▇▇▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>d_acc</td><td>0.51953</td></tr><tr><td>d_acc_fake</td><td>0.51944</td></tr><tr><td>d_acc_real</td><td>0.51962</td></tr><tr><td>d_loss</td><td>0.7052</td></tr><tr><td>d_loss_fake</td><td>0.70525</td></tr><tr><td>d_loss_real</td><td>0.70516</td></tr><tr><td>d_lr</td><td>0.0001</td></tr><tr><td>epoch</td><td>1499</td></tr><tr><td>g_acc</td><td>0.95275</td></tr><tr><td>g_loss</td><td>0.53215</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">gan-camel-bs1024</strong> at: <a href='https://wandb.ai/cataluna84/generative-deep-learning/runs/uexhdo3y' target=\"_blank\">https://wandb.ai/cataluna84/generative-deep-learning/runs/uexhdo3y</a><br> View project at: <a href='https://wandb.ai/cataluna84/generative-deep-learning' target=\"_blank\">https://wandb.ai/cataluna84/generative-deep-learning</a><br>Synced 4 W&B file(s), 125 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260102_153319-uexhdo3y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ W&B run finished and synced\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# W&B CLEANUP\n",
    "# =============================================================================\n",
    "# Finish the W&B run to ensure all data is synced\n",
    "\n",
    "wandb.finish()\n",
    "print(\"✓ W&B run finished and synced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restarting kernel to release GPU memory...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CLEANUP: Restart Kernel to Release GPU Memory\n",
    "# =============================================================================\n",
    "# TensorFlow/CUDA does not release GPU memory within a running Python process.\n",
    "# Restarting the kernel is the only guaranteed way to free all GPU resources.\n",
    "#\n",
    "# ⚠️ WARNING: This will clear all variables and outputs!\n",
    "# Only run after all work is complete and saved.\n",
    "\n",
    "import IPython\n",
    "print(\"Restarting kernel to release GPU memory...\")\n",
    "IPython.Application.instance().kernel.do_shutdown(restart=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
